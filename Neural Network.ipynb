{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea4fe41",
   "metadata": {},
   "source": [
    "# Loan Prediction Project: Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338fa9e1",
   "metadata": {},
   "source": [
    "Some basic notes about the NN we are creating here\n",
    " - We are splitting the train and test set 80:20\n",
    " - This is a with a 22x3 NN with a learning rate of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78734f",
   "metadata": {},
   "source": [
    "## Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71522e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "dataset = pd.read_csv(\"train_u6lujuX_CVtuZ9i.csv\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201bbe28",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64819e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataset :  (480, 13)\n",
      "  Gender Married Dependents     Education Self_Employed Property_Area\n",
      "1   Male     Yes          1      Graduate            No         Rural\n",
      "2   Male     Yes          0      Graduate           Yes         Urban\n",
      "3   Male     Yes          0  Not Graduate            No         Urban\n",
      "4   Male      No          0      Graduate            No         Urban\n",
      "5   Male     Yes          2      Graduate           Yes         Urban\n",
      "Gender\n",
      "       0    1\n",
      "0    0.0  1.0\n",
      "1    0.0  1.0\n",
      "2    0.0  1.0\n",
      "3    0.0  1.0\n",
      "4    0.0  1.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  0.0  1.0\n",
      "477  0.0  1.0\n",
      "478  0.0  1.0\n",
      "479  1.0  0.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Married\n",
      "       0    1\n",
      "0    0.0  1.0\n",
      "1    0.0  1.0\n",
      "2    0.0  1.0\n",
      "3    1.0  0.0\n",
      "4    0.0  1.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  0.0  1.0\n",
      "477  0.0  1.0\n",
      "478  0.0  1.0\n",
      "479  1.0  0.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Dependents\n",
      "       0    1    2    3\n",
      "0    0.0  1.0  0.0  0.0\n",
      "1    1.0  0.0  0.0  0.0\n",
      "2    1.0  0.0  0.0  0.0\n",
      "3    1.0  0.0  0.0  0.0\n",
      "4    0.0  0.0  1.0  0.0\n",
      "..   ...  ...  ...  ...\n",
      "475  1.0  0.0  0.0  0.0\n",
      "476  0.0  0.0  0.0  1.0\n",
      "477  0.0  1.0  0.0  0.0\n",
      "478  0.0  0.0  1.0  0.0\n",
      "479  1.0  0.0  0.0  0.0\n",
      "\n",
      "[480 rows x 4 columns]\n",
      "Education\n",
      "       0    1\n",
      "0    1.0  0.0\n",
      "1    1.0  0.0\n",
      "2    0.0  1.0\n",
      "3    1.0  0.0\n",
      "4    1.0  0.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  1.0  0.0\n",
      "477  1.0  0.0\n",
      "478  1.0  0.0\n",
      "479  1.0  0.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Self_Employed\n",
      "       0    1\n",
      "0    1.0  0.0\n",
      "1    0.0  1.0\n",
      "2    1.0  0.0\n",
      "3    1.0  0.0\n",
      "4    0.0  1.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  1.0  0.0\n",
      "477  1.0  0.0\n",
      "478  1.0  0.0\n",
      "479  0.0  1.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Property_Area\n",
      "       0    1    2\n",
      "0    1.0  0.0  0.0\n",
      "1    0.0  0.0  1.0\n",
      "2    0.0  0.0  1.0\n",
      "3    0.0  0.0  1.0\n",
      "4    0.0  0.0  1.0\n",
      "..   ...  ...  ...\n",
      "475  1.0  0.0  0.0\n",
      "476  1.0  0.0  0.0\n",
      "477  0.0  0.0  1.0\n",
      "478  0.0  0.0  1.0\n",
      "479  0.0  1.0  0.0\n",
      "\n",
      "[480 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataset :  (480, 13)\n",
      "  Gender Married Dependents     Education Self_Employed Property_Area\n",
      "1   Male     Yes          1      Graduate            No         Rural\n",
      "2   Male     Yes          0      Graduate           Yes         Urban\n",
      "3   Male     Yes          0  Not Graduate            No         Urban\n",
      "4   Male      No          0      Graduate            No         Urban\n",
      "5   Male     Yes          2      Graduate           Yes         Urban\n",
      "Gender\n",
      "       0    1\n",
      "0    0.0  1.0\n",
      "1    0.0  1.0\n",
      "2    0.0  1.0\n",
      "3    0.0  1.0\n",
      "4    0.0  1.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  0.0  1.0\n",
      "477  0.0  1.0\n",
      "478  0.0  1.0\n",
      "479  1.0  0.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Married\n",
      "       0    1\n",
      "0    0.0  1.0\n",
      "1    0.0  1.0\n",
      "2    0.0  1.0\n",
      "3    1.0  0.0\n",
      "4    0.0  1.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  0.0  1.0\n",
      "477  0.0  1.0\n",
      "478  0.0  1.0\n",
      "479  1.0  0.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Dependents\n",
      "       0    1    2    3\n",
      "0    0.0  1.0  0.0  0.0\n",
      "1    1.0  0.0  0.0  0.0\n",
      "2    1.0  0.0  0.0  0.0\n",
      "3    1.0  0.0  0.0  0.0\n",
      "4    0.0  0.0  1.0  0.0\n",
      "..   ...  ...  ...  ...\n",
      "475  1.0  0.0  0.0  0.0\n",
      "476  0.0  0.0  0.0  1.0\n",
      "477  0.0  1.0  0.0  0.0\n",
      "478  0.0  0.0  1.0  0.0\n",
      "479  1.0  0.0  0.0  0.0\n",
      "\n",
      "[480 rows x 4 columns]\n",
      "Education\n",
      "       0    1\n",
      "0    1.0  0.0\n",
      "1    1.0  0.0\n",
      "2    0.0  1.0\n",
      "3    1.0  0.0\n",
      "4    1.0  0.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  1.0  0.0\n",
      "477  1.0  0.0\n",
      "478  1.0  0.0\n",
      "479  1.0  0.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Self_Employed\n",
      "       0    1\n",
      "0    1.0  0.0\n",
      "1    0.0  1.0\n",
      "2    1.0  0.0\n",
      "3    1.0  0.0\n",
      "4    0.0  1.0\n",
      "..   ...  ...\n",
      "475  1.0  0.0\n",
      "476  1.0  0.0\n",
      "477  1.0  0.0\n",
      "478  1.0  0.0\n",
      "479  0.0  1.0\n",
      "\n",
      "[480 rows x 2 columns]\n",
      "Property_Area\n",
      "       0    1    2\n",
      "0    1.0  0.0  0.0\n",
      "1    0.0  0.0  1.0\n",
      "2    0.0  0.0  1.0\n",
      "3    0.0  0.0  1.0\n",
      "4    0.0  0.0  1.0\n",
      "..   ...  ...  ...\n",
      "475  1.0  0.0  0.0\n",
      "476  1.0  0.0  0.0\n",
      "477  0.0  0.0  1.0\n",
      "478  0.0  0.0  1.0\n",
      "479  0.0  1.0  0.0\n",
      "\n",
      "[480 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14\n",
       "0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "2  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0\n",
       "3  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "4  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14\n",
       "0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       "2  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0\n",
       "3  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "4  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all the datapoints that have null values\n",
    "nan_value = float(\"NaN\")\n",
    "dataset.replace('', nan_value, inplace=True)\n",
    "dataset.dropna(inplace=True)\n",
    "print(\"Dimensions of the dataset : \", dataset.shape)\n",
    "\n",
    "# one-hot encoding all the categorical values\n",
    "g = dataset.select_dtypes(include=['object'])\n",
    "g.drop(['Loan_ID', 'Loan_Status'], axis=1, inplace=True)\n",
    "print(g.head())\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame()\n",
    "\n",
    "for feature in g.columns.values:\n",
    "    print(feature)\n",
    "    temp_df = pd.DataFrame(onehot_encoder.fit_transform(g[[feature]]).toarray())\n",
    "    print(temp_df)\n",
    "    left = pd.DataFrame(enc_df)\n",
    "    right = pd.DataFrame(temp_df)\n",
    "\n",
    "    # Join one-hot encoded DataFrame with total DataFrame of encoded values\n",
    "    enc_df = pd.concat([left, right], axis=1, ignore_index=True)\n",
    "      \n",
    "enc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b970c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Gender\n",
      "Married\n",
      "Dependents\n",
      "Education\n",
      "Self_Employed\n",
      "Property_Area\n",
      "Married\n",
      "Dependents\n",
      "Education\n",
      "Self_Employed\n",
      "Property_Area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-078f36f6f402>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_encoded[column] = label_encoder.fit_transform(g[column])\n",
      "<ipython-input-3-078f36f6f402>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_encoded[column] = label_encoder.fit_transform(g[column])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test label encoding of feature variables\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoded = g\n",
    "\n",
    "for column in g:\n",
    "    print(column)\n",
    "    label_encoded[column] = label_encoder.fit_transform(g[column])\n",
    "\n",
    "label_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ba210",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270dd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['Loan_Status'])\n",
    "Y = pd.get_dummies(dataset['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0989357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 5)\n",
      "(480, 5)\n",
      "[0.05482993 0.0445666  0.20135364 0.72972973 1.        ]\n",
      "(480, 5)\n",
      "(480, 5)\n",
      "[0.05482993 0.0445666  0.20135364 0.72972973 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#get numerical features and scale them\n",
    "X_nums = dataset.select_dtypes(exclude=['object'])\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "X_nums_scaled = minmax_scaler.fit_transform(X_nums)\n",
    "\n",
    "print(X_nums.shape)\n",
    "print(X_nums_scaled.shape)\n",
    "print(X_nums_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969b18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 20)\n",
      "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
      "\n",
      "        15        16        17       18   19  \n",
      "0  0.05483  0.044567  0.201354  0.72973  1.0  \n",
      "(384, 20)\n",
      "(96, 2)\n",
      "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
      "96   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "16   0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
      "52   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
      "91   1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n",
      "215  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "23   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "198  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0   \n",
      "149  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
      "119  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "69   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "\n",
      "      14        15        16        17        18   19  \n",
      "96   1.0  0.023055  0.057009  0.109983  0.729730  1.0  \n",
      "16   1.0  0.092888  0.000000  0.160745  0.729730  0.0  \n",
      "52   1.0  0.037724  0.066613  0.197970  0.324324  0.0  \n",
      "91   0.0  0.049672  0.000000  0.059222  0.729730  1.0  \n",
      "215  0.0  0.030550  0.065697  0.238579  0.729730  1.0  \n",
      "..   ...       ...       ...       ...       ...  ...  \n",
      "23   1.0  0.037316  0.000000  0.109983  0.729730  1.0  \n",
      "198  0.0  0.031058  0.209859  0.456853  0.324324  1.0  \n",
      "149  1.0  0.072764  0.000000  0.255499  0.729730  1.0  \n",
      "119  1.0  0.038392  0.000000  0.069374  0.729730  1.0  \n",
      "69   1.0  0.104094  0.000000  0.340102  0.729730  1.0  \n",
      "\n",
      "[96 rows x 20 columns]\n",
      "     N  Y\n",
      "131  0  1\n",
      "20   1  0\n",
      "66   1  0\n",
      "121  0  1\n",
      "273  0  1\n",
      "..  .. ..\n",
      "31   1  0\n",
      "253  0  1\n",
      "192  1  0\n",
      "154  0  1\n",
      "88   0  1\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "(480, 20)\n",
      "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
      "\n",
      "        15        16        17       18   19  \n",
      "0  0.05483  0.044567  0.201354  0.72973  1.0  \n",
      "(384, 20)\n",
      "(96, 2)\n",
      "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
      "96   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "16   0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
      "52   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
      "91   1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n",
      "215  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "23   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "198  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0   \n",
      "149  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
      "119  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "69   0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "\n",
      "      14        15        16        17        18   19  \n",
      "96   1.0  0.023055  0.057009  0.109983  0.729730  1.0  \n",
      "16   1.0  0.092888  0.000000  0.160745  0.729730  0.0  \n",
      "52   1.0  0.037724  0.066613  0.197970  0.324324  0.0  \n",
      "91   0.0  0.049672  0.000000  0.059222  0.729730  1.0  \n",
      "215  0.0  0.030550  0.065697  0.238579  0.729730  1.0  \n",
      "..   ...       ...       ...       ...       ...  ...  \n",
      "23   1.0  0.037316  0.000000  0.109983  0.729730  1.0  \n",
      "198  0.0  0.031058  0.209859  0.456853  0.324324  1.0  \n",
      "149  1.0  0.072764  0.000000  0.255499  0.729730  1.0  \n",
      "119  1.0  0.038392  0.000000  0.069374  0.729730  1.0  \n",
      "69   1.0  0.104094  0.000000  0.340102  0.729730  1.0  \n",
      "\n",
      "[96 rows x 20 columns]\n",
      "     N  Y\n",
      "131  0  1\n",
      "20   1  0\n",
      "66   1  0\n",
      "121  0  1\n",
      "273  0  1\n",
      "..  .. ..\n",
      "31   1  0\n",
      "253  0  1\n",
      "192  1  0\n",
      "154  0  1\n",
      "88   0  1\n",
      "\n",
      "[96 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame(enc_df)\n",
    "right = pd.DataFrame(X_nums_scaled)\n",
    "\n",
    "# Join categorical and numerical Data Frames\n",
    "X_scaled = pd.concat([left, right], axis=1, ignore_index=True)\n",
    "\n",
    "print(X_scaled.shape)\n",
    "print(X_scaled.iloc[[0]])\n",
    "\n",
    "# Split and shuffle data 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, \n",
    "                                                    test_size=0.2, random_state=21)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e9b8ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.17424886\n",
      "Iteration 2, loss = 1.07781402\n",
      "Iteration 3, loss = 1.10174717\n",
      "Iteration 4, loss = 1.01907244\n",
      "Iteration 5, loss = 1.00164091\n",
      "Iteration 6, loss = 0.97198560\n",
      "Iteration 7, loss = 0.96263884\n",
      "Iteration 8, loss = 0.97221763\n",
      "Iteration 9, loss = 0.96848949\n",
      "Iteration 10, loss = 0.97881406\n",
      "Iteration 11, loss = 0.96311410\n",
      "Iteration 12, loss = 0.95861804\n",
      "Iteration 13, loss = 0.94502759\n",
      "Iteration 14, loss = 0.95816767\n",
      "Iteration 1, loss = 1.17424886\n",
      "Iteration 2, loss = 1.07781402\n",
      "Iteration 3, loss = 1.10174717\n",
      "Iteration 4, loss = 1.01907244\n",
      "Iteration 5, loss = 1.00164091\n",
      "Iteration 6, loss = 0.97198560\n",
      "Iteration 7, loss = 0.96263884\n",
      "Iteration 8, loss = 0.97221763\n",
      "Iteration 9, loss = 0.96848949\n",
      "Iteration 10, loss = 0.97881406\n",
      "Iteration 11, loss = 0.96311410\n",
      "Iteration 12, loss = 0.95861804\n",
      "Iteration 13, loss = 0.94502759\n",
      "Iteration 14, loss = 0.95816767\n",
      "Iteration 15, loss = 0.94206556\n",
      "Iteration 16, loss = 1.01332500\n",
      "Iteration 17, loss = 1.10572286\n",
      "Iteration 18, loss = 1.03189420\n",
      "Iteration 19, loss = 0.96713464\n",
      "Iteration 20, loss = 0.98021599\n",
      "Iteration 21, loss = 0.93451101\n",
      "Iteration 22, loss = 0.93410068\n",
      "Iteration 23, loss = 0.92049490\n",
      "Iteration 24, loss = 0.93356765\n",
      "Iteration 25, loss = 0.93772829\n",
      "Iteration 26, loss = 0.93407512\n",
      "Iteration 27, loss = 0.93158180\n",
      "Iteration 15, loss = 0.94206556\n",
      "Iteration 16, loss = 1.01332500\n",
      "Iteration 17, loss = 1.10572286\n",
      "Iteration 18, loss = 1.03189420\n",
      "Iteration 19, loss = 0.96713464\n",
      "Iteration 20, loss = 0.98021599\n",
      "Iteration 21, loss = 0.93451101\n",
      "Iteration 22, loss = 0.93410068\n",
      "Iteration 23, loss = 0.92049490\n",
      "Iteration 24, loss = 0.93356765\n",
      "Iteration 25, loss = 0.93772829\n",
      "Iteration 26, loss = 0.93407512\n",
      "Iteration 27, loss = 0.93158180\n",
      "Iteration 28, loss = 0.94252283\n",
      "Iteration 29, loss = 0.96100491\n",
      "Iteration 30, loss = 0.93619245\n",
      "Iteration 31, loss = 0.93849685\n",
      "Iteration 32, loss = 0.93316960\n",
      "Iteration 33, loss = 0.95212045\n",
      "Iteration 34, loss = 0.94575619\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.817708\n",
      "Test set score: 0.770833\n",
      "Iteration 28, loss = 0.94252283\n",
      "Iteration 29, loss = 0.96100491\n",
      "Iteration 30, loss = 0.93619245\n",
      "Iteration 31, loss = 0.93849685\n",
      "Iteration 32, loss = 0.93316960\n",
      "Iteration 33, loss = 0.95212045\n",
      "Iteration 34, loss = 0.94575619\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.817708\n",
      "Test set score: 0.770833\n"
     ]
    }
   ],
   "source": [
    "# fit to MLP classifier\n",
    "mlp = MLPClassifier(solver='sgd', random_state=1, activation='relu', alpha=1e-3,verbose=5,\n",
    "                   learning_rate_init=0.1, batch_size = 10, hidden_layer_sizes=(50, 10))\n",
    "mlp.fit(X_train, y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e550b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7708333333333334\n",
      "Mean Square Error :  0.22916666666666666\n",
      "Confusion Matrix for each label : \n",
      "[[[61  0]\n",
      "  [22 13]]\n",
      "\n",
      " [[13 22]\n",
      "  [ 0 61]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54        35\n",
      "           1       0.73      1.00      0.85        61\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        96\n",
      "   macro avg       0.87      0.69      0.69        96\n",
      "weighted avg       0.83      0.77      0.74        96\n",
      " samples avg       0.77      0.77      0.77        96\n",
      "\n",
      "Accuracy :  0.7708333333333334\n",
      "Mean Square Error :  0.22916666666666666\n",
      "Confusion Matrix for each label : \n",
      "[[[61  0]\n",
      "  [22 13]]\n",
      "\n",
      " [[13 22]\n",
      "  [ 0 61]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54        35\n",
      "           1       0.73      1.00      0.85        61\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        96\n",
      "   macro avg       0.87      0.69      0.69        96\n",
      "weighted avg       0.83      0.77      0.74        96\n",
      " samples avg       0.77      0.77      0.77        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \", accuracy_score(y_test, predictions))\n",
    "print(\"Mean Square Error : \", mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a54050b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.18969139\n",
      "Iteration 2, loss = 1.07212750\n",
      "Iteration 3, loss = 1.05769057\n",
      "Iteration 4, loss = 1.04210089\n",
      "Iteration 5, loss = 1.02931833\n",
      "Iteration 6, loss = 1.01038750\n",
      "Iteration 7, loss = 1.03398649\n",
      "Iteration 8, loss = 0.97176107\n",
      "Iteration 9, loss = 0.97758954\n",
      "Iteration 10, loss = 0.98898277\n",
      "Iteration 1, loss = 1.17885659\n",
      "Iteration 2, loss = 1.03488548\n",
      "Iteration 3, loss = 0.99351976\n",
      "Iteration 1, loss = 1.18969139\n",
      "Iteration 2, loss = 1.07212750\n",
      "Iteration 3, loss = 1.05769057\n",
      "Iteration 4, loss = 1.04210089\n",
      "Iteration 5, loss = 1.02931833\n",
      "Iteration 6, loss = 1.01038750\n",
      "Iteration 7, loss = 1.03398649\n",
      "Iteration 8, loss = 0.97176107\n",
      "Iteration 9, loss = 0.97758954\n",
      "Iteration 10, loss = 0.98898277\n",
      "Iteration 1, loss = 1.17885659\n",
      "Iteration 2, loss = 1.03488548\n",
      "Iteration 3, loss = 0.99351976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.95255299\n",
      "Iteration 5, loss = 0.98231760\n",
      "Iteration 6, loss = 0.96283292\n",
      "Iteration 7, loss = 0.94911123\n",
      "Iteration 8, loss = 0.94131168\n",
      "Iteration 9, loss = 0.90670871\n",
      "Iteration 10, loss = 0.98228073\n",
      "Iteration 1, loss = 1.21795017\n",
      "Iteration 2, loss = 1.11559580\n",
      "Iteration 3, loss = 1.11065634\n",
      "Iteration 4, loss = 1.02435534\n",
      "Iteration 4, loss = 0.95255299\n",
      "Iteration 5, loss = 0.98231760\n",
      "Iteration 6, loss = 0.96283292\n",
      "Iteration 7, loss = 0.94911123\n",
      "Iteration 8, loss = 0.94131168\n",
      "Iteration 9, loss = 0.90670871\n",
      "Iteration 10, loss = 0.98228073\n",
      "Iteration 1, loss = 1.21795017\n",
      "Iteration 2, loss = 1.11559580\n",
      "Iteration 3, loss = 1.11065634\n",
      "Iteration 4, loss = 1.02435534\n",
      "Iteration 5, loss = 1.05157405\n",
      "Iteration 6, loss = 0.98610799\n",
      "Iteration 7, loss = 1.02163180\n",
      "Iteration 8, loss = 0.98010924\n",
      "Iteration 9, loss = 0.99318885\n",
      "Iteration 10, loss = 1.02518563\n",
      "Iteration 1, loss = 1.23187307\n",
      "Iteration 2, loss = 1.16604844\n",
      "Iteration 3, loss = 1.13494182\n",
      "Iteration 4, loss = 1.03866448\n",
      "Iteration 5, loss = 1.09649206\n",
      "Iteration 5, loss = 1.05157405\n",
      "Iteration 6, loss = 0.98610799\n",
      "Iteration 7, loss = 1.02163180\n",
      "Iteration 8, loss = 0.98010924\n",
      "Iteration 9, loss = 0.99318885\n",
      "Iteration 10, loss = 1.02518563\n",
      "Iteration 1, loss = 1.23187307\n",
      "Iteration 2, loss = 1.16604844\n",
      "Iteration 3, loss = 1.13494182\n",
      "Iteration 4, loss = 1.03866448\n",
      "Iteration 5, loss = 1.09649206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.03832327\n",
      "Iteration 7, loss = 1.07301649\n",
      "Iteration 8, loss = 1.00711858\n",
      "Iteration 9, loss = 1.00311675\n",
      "Iteration 10, loss = 1.02428221\n",
      "Iteration 1, loss = 1.20688296\n",
      "Iteration 2, loss = 1.13611776\n",
      "Iteration 3, loss = 1.15501889\n",
      "Iteration 4, loss = 1.05697831\n",
      "Iteration 5, loss = 1.06387011\n",
      "Iteration 6, loss = 1.02253760\n",
      "Iteration 7, loss = 1.01685988\n",
      "Iteration 6, loss = 1.03832327\n",
      "Iteration 7, loss = 1.07301649\n",
      "Iteration 8, loss = 1.00711858\n",
      "Iteration 9, loss = 1.00311675\n",
      "Iteration 10, loss = 1.02428221\n",
      "Iteration 1, loss = 1.20688296\n",
      "Iteration 2, loss = 1.13611776\n",
      "Iteration 3, loss = 1.15501889\n",
      "Iteration 4, loss = 1.05697831\n",
      "Iteration 5, loss = 1.06387011\n",
      "Iteration 6, loss = 1.02253760\n",
      "Iteration 7, loss = 1.01685988\n",
      "Iteration 8, loss = 0.97831766\n",
      "Iteration 9, loss = 0.99406575\n",
      "Iteration 10, loss = 0.98539974\n",
      "Iteration 1, loss = 1.18969139\n",
      "Iteration 2, loss = 1.07212750\n",
      "Iteration 3, loss = 1.05769057\n",
      "Iteration 4, loss = 1.04210089\n",
      "Iteration 5, loss = 1.02931833\n",
      "Iteration 6, loss = 1.01038750\n",
      "Iteration 7, loss = 1.03398649\n",
      "Iteration 8, loss = 0.97176107\n",
      "Iteration 9, loss = 0.97758954\n",
      "Iteration 10, loss = 0.98898277\n",
      "Iteration 8, loss = 0.97831766\n",
      "Iteration 9, loss = 0.99406575\n",
      "Iteration 10, loss = 0.98539974\n",
      "Iteration 1, loss = 1.18969139\n",
      "Iteration 2, loss = 1.07212750\n",
      "Iteration 3, loss = 1.05769057\n",
      "Iteration 4, loss = 1.04210089\n",
      "Iteration 5, loss = 1.02931833\n",
      "Iteration 6, loss = 1.01038750\n",
      "Iteration 7, loss = 1.03398649\n",
      "Iteration 8, loss = 0.97176107\n",
      "Iteration 9, loss = 0.97758954\n",
      "Iteration 10, loss = 0.98898277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.97763190\n",
      "Iteration 12, loss = 0.96207933\n",
      "Iteration 13, loss = 0.95919741\n",
      "Iteration 14, loss = 1.01109674\n",
      "Iteration 15, loss = 0.97519015\n",
      "Iteration 16, loss = 0.98395474\n",
      "Iteration 17, loss = 0.95245167\n",
      "Iteration 18, loss = 0.96534872\n",
      "Iteration 19, loss = 0.97385024\n",
      "Iteration 20, loss = 0.98965584\n",
      "Iteration 21, loss = 0.95341673\n",
      "Iteration 22, loss = 0.97658778\n",
      "Iteration 23, loss = 0.92462647\n",
      "Iteration 24, loss = 0.96167435\n",
      "Iteration 25, loss = 0.91048531\n",
      "Iteration 11, loss = 0.97763190\n",
      "Iteration 12, loss = 0.96207933\n",
      "Iteration 13, loss = 0.95919741\n",
      "Iteration 14, loss = 1.01109674\n",
      "Iteration 15, loss = 0.97519015\n",
      "Iteration 16, loss = 0.98395474\n",
      "Iteration 17, loss = 0.95245167\n",
      "Iteration 18, loss = 0.96534872\n",
      "Iteration 19, loss = 0.97385024\n",
      "Iteration 20, loss = 0.98965584\n",
      "Iteration 21, loss = 0.95341673\n",
      "Iteration 22, loss = 0.97658778\n",
      "Iteration 23, loss = 0.92462647\n",
      "Iteration 24, loss = 0.96167435\n",
      "Iteration 25, loss = 0.91048531\n",
      "Iteration 26, loss = 0.90337187\n",
      "Iteration 27, loss = 0.91659151\n",
      "Iteration 28, loss = 0.92496114\n",
      "Iteration 29, loss = 0.93610281\n",
      "Iteration 30, loss = 0.90496540\n",
      "Iteration 31, loss = 0.90953984\n",
      "Iteration 32, loss = 0.91681757\n",
      "Iteration 33, loss = 0.87367824\n",
      "Iteration 34, loss = 0.91690031\n",
      "Iteration 35, loss = 0.92332717\n",
      "Iteration 36, loss = 0.95124000\n",
      "Iteration 37, loss = 0.98835264\n",
      "Iteration 38, loss = 0.96119374\n",
      "Iteration 39, loss = 0.90238574\n",
      "Iteration 40, loss = 0.90207554\n",
      "Iteration 41, loss = 0.88680930\n",
      "Iteration 26, loss = 0.90337187\n",
      "Iteration 27, loss = 0.91659151\n",
      "Iteration 28, loss = 0.92496114\n",
      "Iteration 29, loss = 0.93610281\n",
      "Iteration 30, loss = 0.90496540\n",
      "Iteration 31, loss = 0.90953984\n",
      "Iteration 32, loss = 0.91681757\n",
      "Iteration 33, loss = 0.87367824\n",
      "Iteration 34, loss = 0.91690031\n",
      "Iteration 35, loss = 0.92332717\n",
      "Iteration 36, loss = 0.95124000\n",
      "Iteration 37, loss = 0.98835264\n",
      "Iteration 38, loss = 0.96119374\n",
      "Iteration 39, loss = 0.90238574\n",
      "Iteration 40, loss = 0.90207554\n",
      "Iteration 41, loss = 0.88680930\n",
      "Iteration 42, loss = 0.92032319\n",
      "Iteration 43, loss = 0.92936824\n",
      "Iteration 44, loss = 0.98895293\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17885659\n",
      "Iteration 2, loss = 1.03488548\n",
      "Iteration 3, loss = 0.99351976\n",
      "Iteration 4, loss = 0.95255299\n",
      "Iteration 5, loss = 0.98231760\n",
      "Iteration 6, loss = 0.96283292\n",
      "Iteration 7, loss = 0.94911123\n",
      "Iteration 8, loss = 0.94131168\n",
      "Iteration 42, loss = 0.92032319\n",
      "Iteration 43, loss = 0.92936824\n",
      "Iteration 44, loss = 0.98895293\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17885659\n",
      "Iteration 2, loss = 1.03488548\n",
      "Iteration 3, loss = 0.99351976\n",
      "Iteration 4, loss = 0.95255299\n",
      "Iteration 5, loss = 0.98231760\n",
      "Iteration 6, loss = 0.96283292\n",
      "Iteration 7, loss = 0.94911123\n",
      "Iteration 8, loss = 0.94131168\n",
      "Iteration 9, loss = 0.90670871\n",
      "Iteration 10, loss = 0.98228073\n",
      "Iteration 11, loss = 0.92402312\n",
      "Iteration 12, loss = 0.90080288\n",
      "Iteration 13, loss = 0.96289787\n",
      "Iteration 14, loss = 0.94503673\n",
      "Iteration 15, loss = 0.92629591\n",
      "Iteration 16, loss = 0.93035168\n",
      "Iteration 17, loss = 0.93097642\n",
      "Iteration 18, loss = 0.91028452\n",
      "Iteration 19, loss = 0.95329567\n",
      "Iteration 20, loss = 0.89460427\n",
      "Iteration 21, loss = 0.87756083\n",
      "Iteration 22, loss = 0.90623086\n",
      "Iteration 23, loss = 0.87526646\n",
      "Iteration 24, loss = 0.88897108\n",
      "Iteration 9, loss = 0.90670871\n",
      "Iteration 10, loss = 0.98228073\n",
      "Iteration 11, loss = 0.92402312\n",
      "Iteration 12, loss = 0.90080288\n",
      "Iteration 13, loss = 0.96289787\n",
      "Iteration 14, loss = 0.94503673\n",
      "Iteration 15, loss = 0.92629591\n",
      "Iteration 16, loss = 0.93035168\n",
      "Iteration 17, loss = 0.93097642\n",
      "Iteration 18, loss = 0.91028452\n",
      "Iteration 19, loss = 0.95329567\n",
      "Iteration 20, loss = 0.89460427\n",
      "Iteration 21, loss = 0.87756083\n",
      "Iteration 22, loss = 0.90623086\n",
      "Iteration 23, loss = 0.87526646\n",
      "Iteration 24, loss = 0.88897108\n",
      "Iteration 25, loss = 0.92296164\n",
      "Iteration 26, loss = 0.88171893\n",
      "Iteration 27, loss = 0.86982923\n",
      "Iteration 28, loss = 0.85361215\n",
      "Iteration 29, loss = 0.88665631\n",
      "Iteration 30, loss = 0.87222403\n",
      "Iteration 31, loss = 0.85510876\n",
      "Iteration 32, loss = 0.86514298\n",
      "Iteration 33, loss = 0.86222795\n",
      "Iteration 34, loss = 0.86764189\n",
      "Iteration 35, loss = 0.86463009\n",
      "Iteration 36, loss = 0.92228863\n",
      "Iteration 37, loss = 0.82235238\n",
      "Iteration 38, loss = 0.85383272\n",
      "Iteration 39, loss = 0.84713068\n",
      "Iteration 40, loss = 0.85301731\n",
      "Iteration 25, loss = 0.92296164\n",
      "Iteration 26, loss = 0.88171893\n",
      "Iteration 27, loss = 0.86982923\n",
      "Iteration 28, loss = 0.85361215\n",
      "Iteration 29, loss = 0.88665631\n",
      "Iteration 30, loss = 0.87222403\n",
      "Iteration 31, loss = 0.85510876\n",
      "Iteration 32, loss = 0.86514298\n",
      "Iteration 33, loss = 0.86222795\n",
      "Iteration 34, loss = 0.86764189\n",
      "Iteration 35, loss = 0.86463009\n",
      "Iteration 36, loss = 0.92228863\n",
      "Iteration 37, loss = 0.82235238\n",
      "Iteration 38, loss = 0.85383272\n",
      "Iteration 39, loss = 0.84713068\n",
      "Iteration 40, loss = 0.85301731\n",
      "Iteration 41, loss = 0.85568252\n",
      "Iteration 42, loss = 0.85161545\n",
      "Iteration 43, loss = 0.82401619\n",
      "Iteration 44, loss = 0.78938977\n",
      "Iteration 45, loss = 0.82386636\n",
      "Iteration 46, loss = 0.83644975\n",
      "Iteration 47, loss = 0.86557679\n",
      "Iteration 48, loss = 0.81855408\n",
      "Iteration 49, loss = 0.83359031\n",
      "Iteration 50, loss = 0.82064371\n",
      "Iteration 1, loss = 1.21795017\n",
      "Iteration 2, loss = 1.11559580\n",
      "Iteration 3, loss = 1.11065634\n",
      "Iteration 4, loss = 1.02435534\n",
      "Iteration 5, loss = 1.05157405\n",
      "Iteration 6, loss = 0.98610799\n",
      "Iteration 41, loss = 0.85568252\n",
      "Iteration 42, loss = 0.85161545\n",
      "Iteration 43, loss = 0.82401619\n",
      "Iteration 44, loss = 0.78938977\n",
      "Iteration 45, loss = 0.82386636\n",
      "Iteration 46, loss = 0.83644975\n",
      "Iteration 47, loss = 0.86557679\n",
      "Iteration 48, loss = 0.81855408\n",
      "Iteration 49, loss = 0.83359031\n",
      "Iteration 50, loss = 0.82064371\n",
      "Iteration 1, loss = 1.21795017\n",
      "Iteration 2, loss = 1.11559580\n",
      "Iteration 3, loss = 1.11065634\n",
      "Iteration 4, loss = 1.02435534\n",
      "Iteration 5, loss = 1.05157405\n",
      "Iteration 6, loss = 0.98610799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.02163180\n",
      "Iteration 8, loss = 0.98010924\n",
      "Iteration 9, loss = 0.99318885\n",
      "Iteration 10, loss = 1.02518563\n",
      "Iteration 11, loss = 0.96303141\n",
      "Iteration 12, loss = 0.95891034\n",
      "Iteration 13, loss = 0.98637946\n",
      "Iteration 14, loss = 0.99648736\n",
      "Iteration 15, loss = 0.96081094\n",
      "Iteration 16, loss = 0.93748214\n",
      "Iteration 17, loss = 0.97261733\n",
      "Iteration 18, loss = 0.99148448\n",
      "Iteration 19, loss = 0.97550506\n",
      "Iteration 20, loss = 0.97088276\n",
      "Iteration 21, loss = 0.95767443\n",
      "Iteration 7, loss = 1.02163180\n",
      "Iteration 8, loss = 0.98010924\n",
      "Iteration 9, loss = 0.99318885\n",
      "Iteration 10, loss = 1.02518563\n",
      "Iteration 11, loss = 0.96303141\n",
      "Iteration 12, loss = 0.95891034\n",
      "Iteration 13, loss = 0.98637946\n",
      "Iteration 14, loss = 0.99648736\n",
      "Iteration 15, loss = 0.96081094\n",
      "Iteration 16, loss = 0.93748214\n",
      "Iteration 17, loss = 0.97261733\n",
      "Iteration 18, loss = 0.99148448\n",
      "Iteration 19, loss = 0.97550506\n",
      "Iteration 20, loss = 0.97088276\n",
      "Iteration 21, loss = 0.95767443\n",
      "Iteration 22, loss = 0.96001670\n",
      "Iteration 23, loss = 0.93186723\n",
      "Iteration 24, loss = 0.95262893\n",
      "Iteration 25, loss = 0.95542075\n",
      "Iteration 26, loss = 0.95170901\n",
      "Iteration 27, loss = 0.93552267\n",
      "Iteration 28, loss = 0.93316707\n",
      "Iteration 29, loss = 0.97353503\n",
      "Iteration 30, loss = 0.91855310\n",
      "Iteration 31, loss = 0.94171268\n",
      "Iteration 32, loss = 0.92711360\n",
      "Iteration 33, loss = 0.93376653\n",
      "Iteration 34, loss = 0.92000843\n",
      "Iteration 35, loss = 0.92375184\n",
      "Iteration 36, loss = 0.94274325\n",
      "Iteration 37, loss = 0.92193286\n",
      "Iteration 38, loss = 0.91936023\n",
      "Iteration 22, loss = 0.96001670\n",
      "Iteration 23, loss = 0.93186723\n",
      "Iteration 24, loss = 0.95262893\n",
      "Iteration 25, loss = 0.95542075\n",
      "Iteration 26, loss = 0.95170901\n",
      "Iteration 27, loss = 0.93552267\n",
      "Iteration 28, loss = 0.93316707\n",
      "Iteration 29, loss = 0.97353503\n",
      "Iteration 30, loss = 0.91855310\n",
      "Iteration 31, loss = 0.94171268\n",
      "Iteration 32, loss = 0.92711360\n",
      "Iteration 33, loss = 0.93376653\n",
      "Iteration 34, loss = 0.92000843\n",
      "Iteration 35, loss = 0.92375184\n",
      "Iteration 36, loss = 0.94274325\n",
      "Iteration 37, loss = 0.92193286\n",
      "Iteration 38, loss = 0.91936023\n",
      "Iteration 39, loss = 0.88138128\n",
      "Iteration 40, loss = 0.89441960\n",
      "Iteration 41, loss = 0.91151654\n",
      "Iteration 42, loss = 0.88310881\n",
      "Iteration 43, loss = 0.86528183\n",
      "Iteration 44, loss = 0.87331767\n",
      "Iteration 45, loss = 0.85677283\n",
      "Iteration 46, loss = 0.86515757\n",
      "Iteration 47, loss = 0.85343325\n",
      "Iteration 48, loss = 0.88876832\n",
      "Iteration 49, loss = 0.87701741\n",
      "Iteration 50, loss = 0.87979161\n",
      "Iteration 1, loss = 1.23187307\n",
      "Iteration 2, loss = 1.16604844\n",
      "Iteration 3, loss = 1.13494182\n",
      "Iteration 4, loss = 1.03866448\n",
      "Iteration 39, loss = 0.88138128\n",
      "Iteration 40, loss = 0.89441960\n",
      "Iteration 41, loss = 0.91151654\n",
      "Iteration 42, loss = 0.88310881\n",
      "Iteration 43, loss = 0.86528183\n",
      "Iteration 44, loss = 0.87331767\n",
      "Iteration 45, loss = 0.85677283\n",
      "Iteration 46, loss = 0.86515757\n",
      "Iteration 47, loss = 0.85343325\n",
      "Iteration 48, loss = 0.88876832\n",
      "Iteration 49, loss = 0.87701741\n",
      "Iteration 50, loss = 0.87979161\n",
      "Iteration 1, loss = 1.23187307\n",
      "Iteration 2, loss = 1.16604844\n",
      "Iteration 3, loss = 1.13494182\n",
      "Iteration 4, loss = 1.03866448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.09649206\n",
      "Iteration 6, loss = 1.03832327\n",
      "Iteration 7, loss = 1.07301649\n",
      "Iteration 8, loss = 1.00711858\n",
      "Iteration 9, loss = 1.00311675\n",
      "Iteration 10, loss = 1.02428221\n",
      "Iteration 11, loss = 0.98915607\n",
      "Iteration 12, loss = 0.96871300\n",
      "Iteration 13, loss = 0.97125375\n",
      "Iteration 14, loss = 0.94786369\n",
      "Iteration 15, loss = 0.95994073\n",
      "Iteration 16, loss = 0.96801121\n",
      "Iteration 17, loss = 1.02122519\n",
      "Iteration 18, loss = 0.98346313\n",
      "Iteration 19, loss = 1.00521384\n",
      "Iteration 5, loss = 1.09649206\n",
      "Iteration 6, loss = 1.03832327\n",
      "Iteration 7, loss = 1.07301649\n",
      "Iteration 8, loss = 1.00711858\n",
      "Iteration 9, loss = 1.00311675\n",
      "Iteration 10, loss = 1.02428221\n",
      "Iteration 11, loss = 0.98915607\n",
      "Iteration 12, loss = 0.96871300\n",
      "Iteration 13, loss = 0.97125375\n",
      "Iteration 14, loss = 0.94786369\n",
      "Iteration 15, loss = 0.95994073\n",
      "Iteration 16, loss = 0.96801121\n",
      "Iteration 17, loss = 1.02122519\n",
      "Iteration 18, loss = 0.98346313\n",
      "Iteration 19, loss = 1.00521384\n",
      "Iteration 20, loss = 1.01708449\n",
      "Iteration 21, loss = 0.94939653\n",
      "Iteration 22, loss = 0.98108349\n",
      "Iteration 23, loss = 0.94525647\n",
      "Iteration 24, loss = 0.93868542\n",
      "Iteration 25, loss = 0.94047062\n",
      "Iteration 26, loss = 0.94724569\n",
      "Iteration 27, loss = 0.93681483\n",
      "Iteration 28, loss = 0.95597403\n",
      "Iteration 29, loss = 0.90832790\n",
      "Iteration 30, loss = 0.89065937\n",
      "Iteration 31, loss = 0.92385472\n",
      "Iteration 32, loss = 0.89266970\n",
      "Iteration 33, loss = 0.86241468\n",
      "Iteration 34, loss = 0.92639481\n",
      "Iteration 35, loss = 0.92928050\n",
      "Iteration 20, loss = 1.01708449\n",
      "Iteration 21, loss = 0.94939653\n",
      "Iteration 22, loss = 0.98108349\n",
      "Iteration 23, loss = 0.94525647\n",
      "Iteration 24, loss = 0.93868542\n",
      "Iteration 25, loss = 0.94047062\n",
      "Iteration 26, loss = 0.94724569\n",
      "Iteration 27, loss = 0.93681483\n",
      "Iteration 28, loss = 0.95597403\n",
      "Iteration 29, loss = 0.90832790\n",
      "Iteration 30, loss = 0.89065937\n",
      "Iteration 31, loss = 0.92385472\n",
      "Iteration 32, loss = 0.89266970\n",
      "Iteration 33, loss = 0.86241468\n",
      "Iteration 34, loss = 0.92639481\n",
      "Iteration 35, loss = 0.92928050\n",
      "Iteration 36, loss = 0.93167690\n",
      "Iteration 37, loss = 0.88459107\n",
      "Iteration 38, loss = 0.86477705\n",
      "Iteration 39, loss = 0.84825955\n",
      "Iteration 40, loss = 0.82456217\n",
      "Iteration 41, loss = 0.89738012\n",
      "Iteration 42, loss = 0.88875345\n",
      "Iteration 43, loss = 0.84023012\n",
      "Iteration 44, loss = 0.85231573\n",
      "Iteration 45, loss = 0.84777178\n",
      "Iteration 46, loss = 0.80716054\n",
      "Iteration 47, loss = 0.85356834\n",
      "Iteration 48, loss = 0.85732974\n",
      "Iteration 49, loss = 0.83764981\n",
      "Iteration 50, loss = 0.85878876\n",
      "Iteration 1, loss = 1.20688296\n",
      "Iteration 36, loss = 0.93167690\n",
      "Iteration 37, loss = 0.88459107\n",
      "Iteration 38, loss = 0.86477705\n",
      "Iteration 39, loss = 0.84825955\n",
      "Iteration 40, loss = 0.82456217\n",
      "Iteration 41, loss = 0.89738012\n",
      "Iteration 42, loss = 0.88875345\n",
      "Iteration 43, loss = 0.84023012\n",
      "Iteration 44, loss = 0.85231573\n",
      "Iteration 45, loss = 0.84777178\n",
      "Iteration 46, loss = 0.80716054\n",
      "Iteration 47, loss = 0.85356834\n",
      "Iteration 48, loss = 0.85732974\n",
      "Iteration 49, loss = 0.83764981\n",
      "Iteration 50, loss = 0.85878876\n",
      "Iteration 1, loss = 1.20688296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.13611776\n",
      "Iteration 3, loss = 1.15501889\n",
      "Iteration 4, loss = 1.05697831\n",
      "Iteration 5, loss = 1.06387011\n",
      "Iteration 6, loss = 1.02253760\n",
      "Iteration 7, loss = 1.01685988\n",
      "Iteration 8, loss = 0.97831766\n",
      "Iteration 9, loss = 0.99406575\n",
      "Iteration 10, loss = 0.98539974\n",
      "Iteration 11, loss = 0.96641205\n",
      "Iteration 12, loss = 0.97557678\n",
      "Iteration 13, loss = 0.93559950\n",
      "Iteration 14, loss = 0.95354545\n",
      "Iteration 2, loss = 1.13611776\n",
      "Iteration 3, loss = 1.15501889\n",
      "Iteration 4, loss = 1.05697831\n",
      "Iteration 5, loss = 1.06387011\n",
      "Iteration 6, loss = 1.02253760\n",
      "Iteration 7, loss = 1.01685988\n",
      "Iteration 8, loss = 0.97831766\n",
      "Iteration 9, loss = 0.99406575\n",
      "Iteration 10, loss = 0.98539974\n",
      "Iteration 11, loss = 0.96641205\n",
      "Iteration 12, loss = 0.97557678\n",
      "Iteration 13, loss = 0.93559950\n",
      "Iteration 14, loss = 0.95354545\n",
      "Iteration 15, loss = 0.95296629\n",
      "Iteration 16, loss = 0.92416207\n",
      "Iteration 17, loss = 0.93096660\n",
      "Iteration 18, loss = 0.94372418\n",
      "Iteration 19, loss = 0.92949323\n",
      "Iteration 20, loss = 0.91760284\n",
      "Iteration 21, loss = 0.91623237\n",
      "Iteration 22, loss = 0.89781269\n",
      "Iteration 23, loss = 0.95690446\n",
      "Iteration 24, loss = 0.88611792\n",
      "Iteration 25, loss = 0.89470619\n",
      "Iteration 26, loss = 0.92033324\n",
      "Iteration 27, loss = 0.88252506\n",
      "Iteration 28, loss = 0.92109642\n",
      "Iteration 29, loss = 0.85497241\n",
      "Iteration 30, loss = 0.93439345\n",
      "Iteration 31, loss = 0.90856122\n",
      "Iteration 15, loss = 0.95296629\n",
      "Iteration 16, loss = 0.92416207\n",
      "Iteration 17, loss = 0.93096660\n",
      "Iteration 18, loss = 0.94372418\n",
      "Iteration 19, loss = 0.92949323\n",
      "Iteration 20, loss = 0.91760284\n",
      "Iteration 21, loss = 0.91623237\n",
      "Iteration 22, loss = 0.89781269\n",
      "Iteration 23, loss = 0.95690446\n",
      "Iteration 24, loss = 0.88611792\n",
      "Iteration 25, loss = 0.89470619\n",
      "Iteration 26, loss = 0.92033324\n",
      "Iteration 27, loss = 0.88252506\n",
      "Iteration 28, loss = 0.92109642\n",
      "Iteration 29, loss = 0.85497241\n",
      "Iteration 30, loss = 0.93439345\n",
      "Iteration 31, loss = 0.90856122\n",
      "Iteration 32, loss = 0.87890807\n",
      "Iteration 33, loss = 0.87964366\n",
      "Iteration 34, loss = 0.85729462\n",
      "Iteration 35, loss = 0.86523215\n",
      "Iteration 36, loss = 0.81341455\n",
      "Iteration 37, loss = 0.82975722\n",
      "Iteration 38, loss = 0.84498700\n",
      "Iteration 39, loss = 0.87805661\n",
      "Iteration 40, loss = 0.86217708\n",
      "Iteration 41, loss = 0.84921857\n",
      "Iteration 42, loss = 0.83728183\n",
      "Iteration 43, loss = 0.82708506\n",
      "Iteration 44, loss = 0.83092160\n",
      "Iteration 45, loss = 0.82905629\n",
      "Iteration 46, loss = 0.82599022\n",
      "Iteration 47, loss = 0.86902187\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.87890807\n",
      "Iteration 33, loss = 0.87964366\n",
      "Iteration 34, loss = 0.85729462\n",
      "Iteration 35, loss = 0.86523215\n",
      "Iteration 36, loss = 0.81341455\n",
      "Iteration 37, loss = 0.82975722\n",
      "Iteration 38, loss = 0.84498700\n",
      "Iteration 39, loss = 0.87805661\n",
      "Iteration 40, loss = 0.86217708\n",
      "Iteration 41, loss = 0.84921857\n",
      "Iteration 42, loss = 0.83728183\n",
      "Iteration 43, loss = 0.82708506\n",
      "Iteration 44, loss = 0.83092160\n",
      "Iteration 45, loss = 0.82905629\n",
      "Iteration 46, loss = 0.82599022\n",
      "Iteration 47, loss = 0.86902187\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18969139\n",
      "Iteration 2, loss = 1.07212750\n",
      "Iteration 3, loss = 1.05769057\n",
      "Iteration 4, loss = 1.04210089\n",
      "Iteration 5, loss = 1.02931833\n",
      "Iteration 6, loss = 1.01038750\n",
      "Iteration 7, loss = 1.03398649\n",
      "Iteration 8, loss = 0.97176107\n",
      "Iteration 9, loss = 0.97758954\n",
      "Iteration 10, loss = 0.98898277\n",
      "Iteration 11, loss = 0.97763190\n",
      "Iteration 12, loss = 0.96207933\n",
      "Iteration 13, loss = 0.95919741\n",
      "Iteration 14, loss = 1.01109674\n",
      "Iteration 15, loss = 0.97519015\n",
      "Iteration 1, loss = 1.18969139\n",
      "Iteration 2, loss = 1.07212750\n",
      "Iteration 3, loss = 1.05769057\n",
      "Iteration 4, loss = 1.04210089\n",
      "Iteration 5, loss = 1.02931833\n",
      "Iteration 6, loss = 1.01038750\n",
      "Iteration 7, loss = 1.03398649\n",
      "Iteration 8, loss = 0.97176107\n",
      "Iteration 9, loss = 0.97758954\n",
      "Iteration 10, loss = 0.98898277\n",
      "Iteration 11, loss = 0.97763190\n",
      "Iteration 12, loss = 0.96207933\n",
      "Iteration 13, loss = 0.95919741\n",
      "Iteration 14, loss = 1.01109674\n",
      "Iteration 15, loss = 0.97519015\n",
      "Iteration 16, loss = 0.98395474\n",
      "Iteration 17, loss = 0.95245167\n",
      "Iteration 18, loss = 0.96534872\n",
      "Iteration 19, loss = 0.97385024\n",
      "Iteration 20, loss = 0.98965584\n",
      "Iteration 21, loss = 0.95341673\n",
      "Iteration 22, loss = 0.97658778\n",
      "Iteration 23, loss = 0.92462647\n",
      "Iteration 24, loss = 0.96167435\n",
      "Iteration 25, loss = 0.91048531\n",
      "Iteration 26, loss = 0.90337187\n",
      "Iteration 27, loss = 0.91659151\n",
      "Iteration 28, loss = 0.92496114\n",
      "Iteration 29, loss = 0.93610281\n",
      "Iteration 30, loss = 0.90496540\n",
      "Iteration 31, loss = 0.90953984\n",
      "Iteration 16, loss = 0.98395474\n",
      "Iteration 17, loss = 0.95245167\n",
      "Iteration 18, loss = 0.96534872\n",
      "Iteration 19, loss = 0.97385024\n",
      "Iteration 20, loss = 0.98965584\n",
      "Iteration 21, loss = 0.95341673\n",
      "Iteration 22, loss = 0.97658778\n",
      "Iteration 23, loss = 0.92462647\n",
      "Iteration 24, loss = 0.96167435\n",
      "Iteration 25, loss = 0.91048531\n",
      "Iteration 26, loss = 0.90337187\n",
      "Iteration 27, loss = 0.91659151\n",
      "Iteration 28, loss = 0.92496114\n",
      "Iteration 29, loss = 0.93610281\n",
      "Iteration 30, loss = 0.90496540\n",
      "Iteration 31, loss = 0.90953984\n",
      "Iteration 32, loss = 0.91681757\n",
      "Iteration 33, loss = 0.87367824\n",
      "Iteration 34, loss = 0.91690031\n",
      "Iteration 35, loss = 0.92332717\n",
      "Iteration 36, loss = 0.95124000\n",
      "Iteration 37, loss = 0.98835264\n",
      "Iteration 38, loss = 0.96119374\n",
      "Iteration 39, loss = 0.90238574\n",
      "Iteration 40, loss = 0.90207554\n",
      "Iteration 41, loss = 0.88680930\n",
      "Iteration 42, loss = 0.92032319\n",
      "Iteration 43, loss = 0.92936824\n",
      "Iteration 44, loss = 0.98895293\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17885659\n",
      "Iteration 32, loss = 0.91681757\n",
      "Iteration 33, loss = 0.87367824\n",
      "Iteration 34, loss = 0.91690031\n",
      "Iteration 35, loss = 0.92332717\n",
      "Iteration 36, loss = 0.95124000\n",
      "Iteration 37, loss = 0.98835264\n",
      "Iteration 38, loss = 0.96119374\n",
      "Iteration 39, loss = 0.90238574\n",
      "Iteration 40, loss = 0.90207554\n",
      "Iteration 41, loss = 0.88680930\n",
      "Iteration 42, loss = 0.92032319\n",
      "Iteration 43, loss = 0.92936824\n",
      "Iteration 44, loss = 0.98895293\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17885659\n",
      "Iteration 2, loss = 1.03488548\n",
      "Iteration 3, loss = 0.99351976\n",
      "Iteration 4, loss = 0.95255299\n",
      "Iteration 5, loss = 0.98231760\n",
      "Iteration 6, loss = 0.96283292\n",
      "Iteration 7, loss = 0.94911123\n",
      "Iteration 8, loss = 0.94131168\n",
      "Iteration 9, loss = 0.90670871\n",
      "Iteration 10, loss = 0.98228073\n",
      "Iteration 11, loss = 0.92402312\n",
      "Iteration 12, loss = 0.90080288\n",
      "Iteration 13, loss = 0.96289787\n",
      "Iteration 14, loss = 0.94503673\n",
      "Iteration 15, loss = 0.92629591\n",
      "Iteration 2, loss = 1.03488548\n",
      "Iteration 3, loss = 0.99351976\n",
      "Iteration 4, loss = 0.95255299\n",
      "Iteration 5, loss = 0.98231760\n",
      "Iteration 6, loss = 0.96283292\n",
      "Iteration 7, loss = 0.94911123\n",
      "Iteration 8, loss = 0.94131168\n",
      "Iteration 9, loss = 0.90670871\n",
      "Iteration 10, loss = 0.98228073\n",
      "Iteration 11, loss = 0.92402312\n",
      "Iteration 12, loss = 0.90080288\n",
      "Iteration 13, loss = 0.96289787\n",
      "Iteration 14, loss = 0.94503673\n",
      "Iteration 15, loss = 0.92629591\n",
      "Iteration 16, loss = 0.93035168\n",
      "Iteration 17, loss = 0.93097642\n",
      "Iteration 18, loss = 0.91028452\n",
      "Iteration 19, loss = 0.95329567\n",
      "Iteration 20, loss = 0.89460427\n",
      "Iteration 21, loss = 0.87756083\n",
      "Iteration 22, loss = 0.90623086\n",
      "Iteration 23, loss = 0.87526646\n",
      "Iteration 24, loss = 0.88897108\n",
      "Iteration 25, loss = 0.92296164\n",
      "Iteration 26, loss = 0.88171893\n",
      "Iteration 27, loss = 0.86982923\n",
      "Iteration 28, loss = 0.85361215\n",
      "Iteration 29, loss = 0.88665631\n",
      "Iteration 30, loss = 0.87222403\n",
      "Iteration 31, loss = 0.85510876\n",
      "Iteration 16, loss = 0.93035168\n",
      "Iteration 17, loss = 0.93097642\n",
      "Iteration 18, loss = 0.91028452\n",
      "Iteration 19, loss = 0.95329567\n",
      "Iteration 20, loss = 0.89460427\n",
      "Iteration 21, loss = 0.87756083\n",
      "Iteration 22, loss = 0.90623086\n",
      "Iteration 23, loss = 0.87526646\n",
      "Iteration 24, loss = 0.88897108\n",
      "Iteration 25, loss = 0.92296164\n",
      "Iteration 26, loss = 0.88171893\n",
      "Iteration 27, loss = 0.86982923\n",
      "Iteration 28, loss = 0.85361215\n",
      "Iteration 29, loss = 0.88665631\n",
      "Iteration 30, loss = 0.87222403\n",
      "Iteration 31, loss = 0.85510876\n",
      "Iteration 32, loss = 0.86514298\n",
      "Iteration 33, loss = 0.86222795\n",
      "Iteration 34, loss = 0.86764189\n",
      "Iteration 35, loss = 0.86463009\n",
      "Iteration 36, loss = 0.92228863\n",
      "Iteration 37, loss = 0.82235238\n",
      "Iteration 38, loss = 0.85383272\n",
      "Iteration 39, loss = 0.84713068\n",
      "Iteration 40, loss = 0.85301731\n",
      "Iteration 41, loss = 0.85568252\n",
      "Iteration 42, loss = 0.85161545\n",
      "Iteration 43, loss = 0.82401619\n",
      "Iteration 44, loss = 0.78938977\n",
      "Iteration 45, loss = 0.82386636\n",
      "Iteration 46, loss = 0.83644975\n",
      "Iteration 47, loss = 0.86557679\n",
      "Iteration 32, loss = 0.86514298\n",
      "Iteration 33, loss = 0.86222795\n",
      "Iteration 34, loss = 0.86764189\n",
      "Iteration 35, loss = 0.86463009\n",
      "Iteration 36, loss = 0.92228863\n",
      "Iteration 37, loss = 0.82235238\n",
      "Iteration 38, loss = 0.85383272\n",
      "Iteration 39, loss = 0.84713068\n",
      "Iteration 40, loss = 0.85301731\n",
      "Iteration 41, loss = 0.85568252\n",
      "Iteration 42, loss = 0.85161545\n",
      "Iteration 43, loss = 0.82401619\n",
      "Iteration 44, loss = 0.78938977\n",
      "Iteration 45, loss = 0.82386636\n",
      "Iteration 46, loss = 0.83644975\n",
      "Iteration 47, loss = 0.86557679\n",
      "Iteration 48, loss = 0.81855408\n",
      "Iteration 49, loss = 0.83359031\n",
      "Iteration 50, loss = 0.82064371\n",
      "Iteration 51, loss = 0.80802234\n",
      "Iteration 52, loss = 0.78738650\n",
      "Iteration 53, loss = 0.84027293\n",
      "Iteration 54, loss = 0.79572109\n",
      "Iteration 55, loss = 0.88670862\n",
      "Iteration 56, loss = 0.86784282\n",
      "Iteration 57, loss = 0.81004723\n",
      "Iteration 58, loss = 0.79347920\n",
      "Iteration 59, loss = 0.81381257\n",
      "Iteration 60, loss = 0.79904774\n",
      "Iteration 61, loss = 0.80695839\n",
      "Iteration 62, loss = 0.76672605\n",
      "Iteration 63, loss = 0.85567729\n",
      "Iteration 48, loss = 0.81855408\n",
      "Iteration 49, loss = 0.83359031\n",
      "Iteration 50, loss = 0.82064371\n",
      "Iteration 51, loss = 0.80802234\n",
      "Iteration 52, loss = 0.78738650\n",
      "Iteration 53, loss = 0.84027293\n",
      "Iteration 54, loss = 0.79572109\n",
      "Iteration 55, loss = 0.88670862\n",
      "Iteration 56, loss = 0.86784282\n",
      "Iteration 57, loss = 0.81004723\n",
      "Iteration 58, loss = 0.79347920\n",
      "Iteration 59, loss = 0.81381257\n",
      "Iteration 60, loss = 0.79904774\n",
      "Iteration 61, loss = 0.80695839\n",
      "Iteration 62, loss = 0.76672605\n",
      "Iteration 63, loss = 0.85567729\n",
      "Iteration 64, loss = 0.82053110\n",
      "Iteration 65, loss = 0.78432694\n",
      "Iteration 66, loss = 0.79162734\n",
      "Iteration 67, loss = 0.76241075\n",
      "Iteration 68, loss = 0.77144078\n",
      "Iteration 69, loss = 0.77192750\n",
      "Iteration 70, loss = 0.76222541\n",
      "Iteration 71, loss = 0.77040052\n",
      "Iteration 72, loss = 0.74522485\n",
      "Iteration 73, loss = 0.71197290\n",
      "Iteration 74, loss = 0.73599792\n",
      "Iteration 75, loss = 0.77868810\n",
      "Iteration 76, loss = 0.86074684\n",
      "Iteration 77, loss = 1.00737516\n",
      "Iteration 78, loss = 0.83514711\n",
      "Iteration 79, loss = 0.77868556\n",
      "Iteration 80, loss = 0.77050453\n",
      "Iteration 64, loss = 0.82053110\n",
      "Iteration 65, loss = 0.78432694\n",
      "Iteration 66, loss = 0.79162734\n",
      "Iteration 67, loss = 0.76241075\n",
      "Iteration 68, loss = 0.77144078\n",
      "Iteration 69, loss = 0.77192750\n",
      "Iteration 70, loss = 0.76222541\n",
      "Iteration 71, loss = 0.77040052\n",
      "Iteration 72, loss = 0.74522485\n",
      "Iteration 73, loss = 0.71197290\n",
      "Iteration 74, loss = 0.73599792\n",
      "Iteration 75, loss = 0.77868810\n",
      "Iteration 76, loss = 0.86074684\n",
      "Iteration 77, loss = 1.00737516\n",
      "Iteration 78, loss = 0.83514711\n",
      "Iteration 79, loss = 0.77868556\n",
      "Iteration 80, loss = 0.77050453\n",
      "Iteration 81, loss = 0.75635418\n",
      "Iteration 82, loss = 0.78817409\n",
      "Iteration 83, loss = 0.79380662\n",
      "Iteration 84, loss = 0.75084663\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21795017\n",
      "Iteration 2, loss = 1.11559580\n",
      "Iteration 3, loss = 1.11065634\n",
      "Iteration 4, loss = 1.02435534\n",
      "Iteration 5, loss = 1.05157405\n",
      "Iteration 6, loss = 0.98610799\n",
      "Iteration 7, loss = 1.02163180\n",
      "Iteration 8, loss = 0.98010924\n",
      "Iteration 9, loss = 0.99318885\n",
      "Iteration 10, loss = 1.02518563\n",
      "Iteration 81, loss = 0.75635418\n",
      "Iteration 82, loss = 0.78817409\n",
      "Iteration 83, loss = 0.79380662\n",
      "Iteration 84, loss = 0.75084663\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21795017\n",
      "Iteration 2, loss = 1.11559580\n",
      "Iteration 3, loss = 1.11065634\n",
      "Iteration 4, loss = 1.02435534\n",
      "Iteration 5, loss = 1.05157405\n",
      "Iteration 6, loss = 0.98610799\n",
      "Iteration 7, loss = 1.02163180\n",
      "Iteration 8, loss = 0.98010924\n",
      "Iteration 9, loss = 0.99318885\n",
      "Iteration 10, loss = 1.02518563\n",
      "Iteration 11, loss = 0.96303141\n",
      "Iteration 12, loss = 0.95891034\n",
      "Iteration 13, loss = 0.98637946\n",
      "Iteration 14, loss = 0.99648736\n",
      "Iteration 15, loss = 0.96081094\n",
      "Iteration 16, loss = 0.93748214\n",
      "Iteration 17, loss = 0.97261733\n",
      "Iteration 18, loss = 0.99148448\n",
      "Iteration 19, loss = 0.97550506\n",
      "Iteration 20, loss = 0.97088276\n",
      "Iteration 21, loss = 0.95767443\n",
      "Iteration 22, loss = 0.96001670\n",
      "Iteration 23, loss = 0.93186723\n",
      "Iteration 24, loss = 0.95262893\n",
      "Iteration 25, loss = 0.95542075\n",
      "Iteration 11, loss = 0.96303141\n",
      "Iteration 12, loss = 0.95891034\n",
      "Iteration 13, loss = 0.98637946\n",
      "Iteration 14, loss = 0.99648736\n",
      "Iteration 15, loss = 0.96081094\n",
      "Iteration 16, loss = 0.93748214\n",
      "Iteration 17, loss = 0.97261733\n",
      "Iteration 18, loss = 0.99148448\n",
      "Iteration 19, loss = 0.97550506\n",
      "Iteration 20, loss = 0.97088276\n",
      "Iteration 21, loss = 0.95767443\n",
      "Iteration 22, loss = 0.96001670\n",
      "Iteration 23, loss = 0.93186723\n",
      "Iteration 24, loss = 0.95262893\n",
      "Iteration 25, loss = 0.95542075\n",
      "Iteration 26, loss = 0.95170901\n",
      "Iteration 27, loss = 0.93552267\n",
      "Iteration 28, loss = 0.93316707\n",
      "Iteration 29, loss = 0.97353503\n",
      "Iteration 30, loss = 0.91855310\n",
      "Iteration 31, loss = 0.94171268\n",
      "Iteration 32, loss = 0.92711360\n",
      "Iteration 33, loss = 0.93376653\n",
      "Iteration 34, loss = 0.92000843\n",
      "Iteration 35, loss = 0.92375184\n",
      "Iteration 36, loss = 0.94274325\n",
      "Iteration 37, loss = 0.92193286\n",
      "Iteration 38, loss = 0.91936023\n",
      "Iteration 39, loss = 0.88138128\n",
      "Iteration 40, loss = 0.89441960\n",
      "Iteration 41, loss = 0.91151654\n",
      "Iteration 26, loss = 0.95170901\n",
      "Iteration 27, loss = 0.93552267\n",
      "Iteration 28, loss = 0.93316707\n",
      "Iteration 29, loss = 0.97353503\n",
      "Iteration 30, loss = 0.91855310\n",
      "Iteration 31, loss = 0.94171268\n",
      "Iteration 32, loss = 0.92711360\n",
      "Iteration 33, loss = 0.93376653\n",
      "Iteration 34, loss = 0.92000843\n",
      "Iteration 35, loss = 0.92375184\n",
      "Iteration 36, loss = 0.94274325\n",
      "Iteration 37, loss = 0.92193286\n",
      "Iteration 38, loss = 0.91936023\n",
      "Iteration 39, loss = 0.88138128\n",
      "Iteration 40, loss = 0.89441960\n",
      "Iteration 41, loss = 0.91151654\n",
      "Iteration 42, loss = 0.88310881\n",
      "Iteration 43, loss = 0.86528183\n",
      "Iteration 44, loss = 0.87331767\n",
      "Iteration 45, loss = 0.85677283\n",
      "Iteration 46, loss = 0.86515757\n",
      "Iteration 47, loss = 0.85343325\n",
      "Iteration 48, loss = 0.88876832\n",
      "Iteration 49, loss = 0.87701741\n",
      "Iteration 50, loss = 0.87979161\n",
      "Iteration 51, loss = 0.85875234\n",
      "Iteration 52, loss = 0.92940432\n",
      "Iteration 53, loss = 0.92581637\n",
      "Iteration 54, loss = 0.89244023\n",
      "Iteration 55, loss = 0.86292431\n",
      "Iteration 56, loss = 0.87777591\n",
      "Iteration 57, loss = 0.87761148\n",
      "Iteration 42, loss = 0.88310881\n",
      "Iteration 43, loss = 0.86528183\n",
      "Iteration 44, loss = 0.87331767\n",
      "Iteration 45, loss = 0.85677283\n",
      "Iteration 46, loss = 0.86515757\n",
      "Iteration 47, loss = 0.85343325\n",
      "Iteration 48, loss = 0.88876832\n",
      "Iteration 49, loss = 0.87701741\n",
      "Iteration 50, loss = 0.87979161\n",
      "Iteration 51, loss = 0.85875234\n",
      "Iteration 52, loss = 0.92940432\n",
      "Iteration 53, loss = 0.92581637\n",
      "Iteration 54, loss = 0.89244023\n",
      "Iteration 55, loss = 0.86292431\n",
      "Iteration 56, loss = 0.87777591\n",
      "Iteration 57, loss = 0.87761148\n",
      "Iteration 58, loss = 0.85637020\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23187307\n",
      "Iteration 2, loss = 1.16604844\n",
      "Iteration 3, loss = 1.13494182\n",
      "Iteration 4, loss = 1.03866448\n",
      "Iteration 5, loss = 1.09649206\n",
      "Iteration 6, loss = 1.03832327\n",
      "Iteration 7, loss = 1.07301649\n",
      "Iteration 8, loss = 1.00711858\n",
      "Iteration 9, loss = 1.00311675\n",
      "Iteration 10, loss = 1.02428221\n",
      "Iteration 11, loss = 0.98915607\n",
      "Iteration 12, loss = 0.96871300\n",
      "Iteration 13, loss = 0.97125375\n",
      "Iteration 14, loss = 0.94786369Iteration 58, loss = 0.85637020\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23187307\n",
      "Iteration 2, loss = 1.16604844\n",
      "Iteration 3, loss = 1.13494182\n",
      "Iteration 4, loss = 1.03866448\n",
      "Iteration 5, loss = 1.09649206\n",
      "Iteration 6, loss = 1.03832327\n",
      "Iteration 7, loss = 1.07301649\n",
      "Iteration 8, loss = 1.00711858\n",
      "Iteration 9, loss = 1.00311675\n",
      "Iteration 10, loss = 1.02428221\n",
      "Iteration 11, loss = 0.98915607\n",
      "Iteration 12, loss = 0.96871300\n",
      "Iteration 13, loss = 0.97125375\n",
      "Iteration 14, loss = 0.94786369\n",
      "Iteration 15, loss = 0.95994073\n",
      "Iteration 16, loss = 0.96801121\n",
      "Iteration 17, loss = 1.02122519\n",
      "Iteration 18, loss = 0.98346313\n",
      "Iteration 19, loss = 1.00521384\n",
      "Iteration 20, loss = 1.01708449\n",
      "Iteration 21, loss = 0.94939653\n",
      "Iteration 22, loss = 0.98108349\n",
      "Iteration 23, loss = 0.94525647\n",
      "Iteration 24, loss = 0.93868542\n",
      "Iteration 25, loss = 0.94047062\n",
      "Iteration 26, loss = 0.94724569\n",
      "Iteration 27, loss = 0.93681483\n",
      "Iteration 28, loss = 0.95597403\n",
      "Iteration 29, loss = 0.90832790\n",
      "\n",
      "Iteration 15, loss = 0.95994073\n",
      "Iteration 16, loss = 0.96801121\n",
      "Iteration 17, loss = 1.02122519\n",
      "Iteration 18, loss = 0.98346313\n",
      "Iteration 19, loss = 1.00521384\n",
      "Iteration 20, loss = 1.01708449\n",
      "Iteration 21, loss = 0.94939653\n",
      "Iteration 22, loss = 0.98108349\n",
      "Iteration 23, loss = 0.94525647\n",
      "Iteration 24, loss = 0.93868542\n",
      "Iteration 25, loss = 0.94047062\n",
      "Iteration 26, loss = 0.94724569\n",
      "Iteration 27, loss = 0.93681483\n",
      "Iteration 28, loss = 0.95597403\n",
      "Iteration 29, loss = 0.90832790\n",
      "Iteration 30, loss = 0.89065937\n",
      "Iteration 31, loss = 0.92385472\n",
      "Iteration 32, loss = 0.89266970\n",
      "Iteration 33, loss = 0.86241468\n",
      "Iteration 34, loss = 0.92639481\n",
      "Iteration 35, loss = 0.92928050\n",
      "Iteration 36, loss = 0.93167690\n",
      "Iteration 37, loss = 0.88459107\n",
      "Iteration 38, loss = 0.86477705\n",
      "Iteration 39, loss = 0.84825955\n",
      "Iteration 40, loss = 0.82456217\n",
      "Iteration 41, loss = 0.89738012\n",
      "Iteration 42, loss = 0.88875345\n",
      "Iteration 43, loss = 0.84023012\n",
      "Iteration 44, loss = 0.85231573\n",
      "Iteration 30, loss = 0.89065937\n",
      "Iteration 31, loss = 0.92385472\n",
      "Iteration 32, loss = 0.89266970\n",
      "Iteration 33, loss = 0.86241468\n",
      "Iteration 34, loss = 0.92639481\n",
      "Iteration 35, loss = 0.92928050\n",
      "Iteration 36, loss = 0.93167690\n",
      "Iteration 37, loss = 0.88459107\n",
      "Iteration 38, loss = 0.86477705\n",
      "Iteration 39, loss = 0.84825955\n",
      "Iteration 40, loss = 0.82456217\n",
      "Iteration 41, loss = 0.89738012\n",
      "Iteration 42, loss = 0.88875345\n",
      "Iteration 43, loss = 0.84023012\n",
      "Iteration 44, loss = 0.85231573\n",
      "Iteration 45, loss = 0.84777178\n",
      "Iteration 46, loss = 0.80716054\n",
      "Iteration 47, loss = 0.85356834\n",
      "Iteration 48, loss = 0.85732974\n",
      "Iteration 49, loss = 0.83764981\n",
      "Iteration 50, loss = 0.85878876\n",
      "Iteration 51, loss = 0.81606455\n",
      "Iteration 52, loss = 0.83426585\n",
      "Iteration 53, loss = 0.87053097\n",
      "Iteration 54, loss = 0.81099189\n",
      "Iteration 55, loss = 0.80646209\n",
      "Iteration 56, loss = 0.79617932\n",
      "Iteration 57, loss = 0.86716275\n",
      "Iteration 58, loss = 0.80379704\n",
      "Iteration 59, loss = 0.85108725\n",
      "Iteration 60, loss = 0.82746558\n",
      "Iteration 61, loss = 0.81084165\n",
      "Iteration 45, loss = 0.84777178\n",
      "Iteration 46, loss = 0.80716054\n",
      "Iteration 47, loss = 0.85356834\n",
      "Iteration 48, loss = 0.85732974\n",
      "Iteration 49, loss = 0.83764981\n",
      "Iteration 50, loss = 0.85878876\n",
      "Iteration 51, loss = 0.81606455\n",
      "Iteration 52, loss = 0.83426585\n",
      "Iteration 53, loss = 0.87053097\n",
      "Iteration 54, loss = 0.81099189\n",
      "Iteration 55, loss = 0.80646209\n",
      "Iteration 56, loss = 0.79617932\n",
      "Iteration 57, loss = 0.86716275\n",
      "Iteration 58, loss = 0.80379704\n",
      "Iteration 59, loss = 0.85108725\n",
      "Iteration 60, loss = 0.82746558\n",
      "Iteration 61, loss = 0.81084165\n",
      "Iteration 62, loss = 0.83222042\n",
      "Iteration 63, loss = 0.81218833\n",
      "Iteration 64, loss = 0.85644525\n",
      "Iteration 65, loss = 0.82904097\n",
      "Iteration 66, loss = 0.83928140\n",
      "Iteration 67, loss = 0.81123441\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20688296\n",
      "Iteration 2, loss = 1.13611776\n",
      "Iteration 3, loss = 1.15501889\n",
      "Iteration 4, loss = 1.05697831\n",
      "Iteration 5, loss = 1.06387011\n",
      "Iteration 6, loss = 1.02253760\n",
      "Iteration 7, loss = 1.01685988\n",
      "Iteration 8, loss = 0.97831766\n",
      "Iteration 62, loss = 0.83222042\n",
      "Iteration 63, loss = 0.81218833\n",
      "Iteration 64, loss = 0.85644525\n",
      "Iteration 65, loss = 0.82904097\n",
      "Iteration 66, loss = 0.83928140\n",
      "Iteration 67, loss = 0.81123441\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20688296\n",
      "Iteration 2, loss = 1.13611776\n",
      "Iteration 3, loss = 1.15501889\n",
      "Iteration 4, loss = 1.05697831\n",
      "Iteration 5, loss = 1.06387011\n",
      "Iteration 6, loss = 1.02253760\n",
      "Iteration 7, loss = 1.01685988\n",
      "Iteration 8, loss = 0.97831766\n",
      "Iteration 9, loss = 0.99406575\n",
      "Iteration 10, loss = 0.98539974\n",
      "Iteration 11, loss = 0.96641205\n",
      "Iteration 12, loss = 0.97557678\n",
      "Iteration 13, loss = 0.93559950\n",
      "Iteration 14, loss = 0.95354545\n",
      "Iteration 15, loss = 0.95296629\n",
      "Iteration 16, loss = 0.92416207\n",
      "Iteration 17, loss = 0.93096660\n",
      "Iteration 18, loss = 0.94372418\n",
      "Iteration 19, loss = 0.92949323\n",
      "Iteration 20, loss = 0.91760284\n",
      "Iteration 21, loss = 0.91623237\n",
      "Iteration 22, loss = 0.89781269\n",
      "Iteration 23, loss = 0.95690446\n",
      "Iteration 24, loss = 0.88611792\n",
      "Iteration 9, loss = 0.99406575\n",
      "Iteration 10, loss = 0.98539974\n",
      "Iteration 11, loss = 0.96641205\n",
      "Iteration 12, loss = 0.97557678\n",
      "Iteration 13, loss = 0.93559950\n",
      "Iteration 14, loss = 0.95354545\n",
      "Iteration 15, loss = 0.95296629\n",
      "Iteration 16, loss = 0.92416207\n",
      "Iteration 17, loss = 0.93096660\n",
      "Iteration 18, loss = 0.94372418\n",
      "Iteration 19, loss = 0.92949323\n",
      "Iteration 20, loss = 0.91760284\n",
      "Iteration 21, loss = 0.91623237\n",
      "Iteration 22, loss = 0.89781269\n",
      "Iteration 23, loss = 0.95690446\n",
      "Iteration 24, loss = 0.88611792\n",
      "Iteration 25, loss = 0.89470619\n",
      "Iteration 26, loss = 0.92033324\n",
      "Iteration 27, loss = 0.88252506\n",
      "Iteration 28, loss = 0.92109642\n",
      "Iteration 29, loss = 0.85497241\n",
      "Iteration 30, loss = 0.93439345\n",
      "Iteration 31, loss = 0.90856122\n",
      "Iteration 32, loss = 0.87890807\n",
      "Iteration 33, loss = 0.87964366\n",
      "Iteration 34, loss = 0.85729462\n",
      "Iteration 35, loss = 0.86523215\n",
      "Iteration 36, loss = 0.81341455\n",
      "Iteration 37, loss = 0.82975722\n",
      "Iteration 38, loss = 0.84498700\n",
      "Iteration 39, loss = 0.87805661\n",
      "Iteration 40, loss = 0.86217708\n",
      "Iteration 25, loss = 0.89470619\n",
      "Iteration 26, loss = 0.92033324\n",
      "Iteration 27, loss = 0.88252506\n",
      "Iteration 28, loss = 0.92109642\n",
      "Iteration 29, loss = 0.85497241\n",
      "Iteration 30, loss = 0.93439345\n",
      "Iteration 31, loss = 0.90856122\n",
      "Iteration 32, loss = 0.87890807\n",
      "Iteration 33, loss = 0.87964366\n",
      "Iteration 34, loss = 0.85729462\n",
      "Iteration 35, loss = 0.86523215\n",
      "Iteration 36, loss = 0.81341455\n",
      "Iteration 37, loss = 0.82975722\n",
      "Iteration 38, loss = 0.84498700\n",
      "Iteration 39, loss = 0.87805661\n",
      "Iteration 40, loss = 0.86217708\n",
      "Iteration 41, loss = 0.84921857\n",
      "Iteration 42, loss = 0.83728183\n",
      "Iteration 43, loss = 0.82708506\n",
      "Iteration 44, loss = 0.83092160\n",
      "Iteration 45, loss = 0.82905629\n",
      "Iteration 46, loss = 0.82599022\n",
      "Iteration 47, loss = 0.86902187\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21978505\n",
      "Iteration 2, loss = 1.10419276\n",
      "Iteration 3, loss = 1.10235203\n",
      "Iteration 4, loss = 1.08792625\n",
      "Iteration 5, loss = 1.03773933\n",
      "Iteration 6, loss = 1.01009515\n",
      "Iteration 7, loss = 1.03539933\n",
      "Iteration 8, loss = 0.99301246Iteration 41, loss = 0.84921857\n",
      "Iteration 42, loss = 0.83728183\n",
      "Iteration 43, loss = 0.82708506\n",
      "Iteration 44, loss = 0.83092160\n",
      "Iteration 45, loss = 0.82905629\n",
      "Iteration 46, loss = 0.82599022\n",
      "Iteration 47, loss = 0.86902187\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21978505\n",
      "Iteration 2, loss = 1.10419276\n",
      "Iteration 3, loss = 1.10235203\n",
      "Iteration 4, loss = 1.08792625\n",
      "Iteration 5, loss = 1.03773933\n",
      "Iteration 6, loss = 1.01009515\n",
      "Iteration 7, loss = 1.03539933\n",
      "Iteration 8, loss = 0.99301246\n",
      "Iteration 9, loss = 0.99513243\n",
      "Iteration 10, loss = 0.99853532\n",
      "Iteration 1, loss = 1.22516612\n",
      "Iteration 2, loss = 1.16252225\n",
      "Iteration 3, loss = 1.04863635\n",
      "Iteration 4, loss = 1.05589090\n",
      "Iteration 5, loss = 1.07535699\n",
      "Iteration 6, loss = 1.00889072\n",
      "Iteration 7, loss = 0.99373462\n",
      "Iteration 8, loss = 0.97559254\n",
      "Iteration 9, loss = 0.95364697\n",
      "Iteration 10, loss = 0.97536416\n",
      "Iteration 1, loss = 1.24202549\n",
      "\n",
      "Iteration 9, loss = 0.99513243\n",
      "Iteration 10, loss = 0.99853532\n",
      "Iteration 1, loss = 1.22516612\n",
      "Iteration 2, loss = 1.16252225\n",
      "Iteration 3, loss = 1.04863635\n",
      "Iteration 4, loss = 1.05589090\n",
      "Iteration 5, loss = 1.07535699\n",
      "Iteration 6, loss = 1.00889072\n",
      "Iteration 7, loss = 0.99373462\n",
      "Iteration 8, loss = 0.97559254\n",
      "Iteration 9, loss = 0.95364697\n",
      "Iteration 10, loss = 0.97536416\n",
      "Iteration 1, loss = 1.24202549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.19487124\n",
      "Iteration 3, loss = 1.11570997\n",
      "Iteration 4, loss = 1.01299150\n",
      "Iteration 5, loss = 1.03529283\n",
      "Iteration 6, loss = 0.98040279\n",
      "Iteration 7, loss = 1.01410537\n",
      "Iteration 8, loss = 1.00385454\n",
      "Iteration 9, loss = 1.00312902\n",
      "Iteration 10, loss = 1.00025671\n",
      "Iteration 1, loss = 1.24415771\n",
      "Iteration 2, loss = 1.20808554\n",
      "Iteration 3, loss = 1.20892165\n",
      "Iteration 4, loss = 1.09040465\n",
      "Iteration 5, loss = 1.10326341\n",
      "Iteration 2, loss = 1.19487124\n",
      "Iteration 3, loss = 1.11570997\n",
      "Iteration 4, loss = 1.01299150\n",
      "Iteration 5, loss = 1.03529283\n",
      "Iteration 6, loss = 0.98040279\n",
      "Iteration 7, loss = 1.01410537\n",
      "Iteration 8, loss = 1.00385454\n",
      "Iteration 9, loss = 1.00312902\n",
      "Iteration 10, loss = 1.00025671\n",
      "Iteration 1, loss = 1.24415771\n",
      "Iteration 2, loss = 1.20808554\n",
      "Iteration 3, loss = 1.20892165\n",
      "Iteration 4, loss = 1.09040465\n",
      "Iteration 5, loss = 1.10326341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.16693117\n",
      "Iteration 7, loss = 1.08704637\n",
      "Iteration 8, loss = 1.04933486\n",
      "Iteration 9, loss = 1.08595650\n",
      "Iteration 10, loss = 1.03373412\n",
      "Iteration 1, loss = 1.25045268\n",
      "Iteration 2, loss = 1.16552189\n",
      "Iteration 3, loss = 1.22833781\n",
      "Iteration 4, loss = 1.09674254\n",
      "Iteration 5, loss = 1.16024526\n",
      "Iteration 6, loss = 1.05841825\n",
      "Iteration 7, loss = 1.08543485\n",
      "Iteration 8, loss = 1.04659840\n",
      "Iteration 6, loss = 1.16693117\n",
      "Iteration 7, loss = 1.08704637\n",
      "Iteration 8, loss = 1.04933486\n",
      "Iteration 9, loss = 1.08595650\n",
      "Iteration 10, loss = 1.03373412\n",
      "Iteration 1, loss = 1.25045268\n",
      "Iteration 2, loss = 1.16552189\n",
      "Iteration 3, loss = 1.22833781\n",
      "Iteration 4, loss = 1.09674254\n",
      "Iteration 5, loss = 1.16024526\n",
      "Iteration 6, loss = 1.05841825\n",
      "Iteration 7, loss = 1.08543485\n",
      "Iteration 8, loss = 1.04659840\n",
      "Iteration 9, loss = 1.02597117\n",
      "Iteration 10, loss = 0.99909994\n",
      "Iteration 1, loss = 1.21978505\n",
      "Iteration 2, loss = 1.10419276\n",
      "Iteration 3, loss = 1.10235203\n",
      "Iteration 4, loss = 1.08792625\n",
      "Iteration 5, loss = 1.03773933\n",
      "Iteration 6, loss = 1.01009515\n",
      "Iteration 7, loss = 1.03539933\n",
      "Iteration 8, loss = 0.99301246\n",
      "Iteration 9, loss = 0.99513243\n",
      "Iteration 10, loss = 0.99853532\n",
      "Iteration 11, loss = 1.02491282\n",
      "Iteration 9, loss = 1.02597117\n",
      "Iteration 10, loss = 0.99909994\n",
      "Iteration 1, loss = 1.21978505\n",
      "Iteration 2, loss = 1.10419276\n",
      "Iteration 3, loss = 1.10235203\n",
      "Iteration 4, loss = 1.08792625\n",
      "Iteration 5, loss = 1.03773933\n",
      "Iteration 6, loss = 1.01009515\n",
      "Iteration 7, loss = 1.03539933\n",
      "Iteration 8, loss = 0.99301246\n",
      "Iteration 9, loss = 0.99513243\n",
      "Iteration 10, loss = 0.99853532\n",
      "Iteration 11, loss = 1.02491282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 1.00640833\n",
      "Iteration 13, loss = 0.99732368\n",
      "Iteration 14, loss = 1.04196421\n",
      "Iteration 15, loss = 1.03952734\n",
      "Iteration 16, loss = 1.02876634\n",
      "Iteration 17, loss = 1.00476543\n",
      "Iteration 18, loss = 1.02251016\n",
      "Iteration 19, loss = 1.04472198\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22516612\n",
      "Iteration 2, loss = 1.16252225\n",
      "Iteration 3, loss = 1.04863635\n",
      "Iteration 4, loss = 1.05589090\n",
      "Iteration 5, loss = 1.07535699\n",
      "Iteration 6, loss = 1.00889072\n",
      "Iteration 12, loss = 1.00640833\n",
      "Iteration 13, loss = 0.99732368\n",
      "Iteration 14, loss = 1.04196421\n",
      "Iteration 15, loss = 1.03952734\n",
      "Iteration 16, loss = 1.02876634\n",
      "Iteration 17, loss = 1.00476543\n",
      "Iteration 18, loss = 1.02251016\n",
      "Iteration 19, loss = 1.04472198\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22516612\n",
      "Iteration 2, loss = 1.16252225\n",
      "Iteration 3, loss = 1.04863635\n",
      "Iteration 4, loss = 1.05589090\n",
      "Iteration 5, loss = 1.07535699\n",
      "Iteration 6, loss = 1.00889072\n",
      "Iteration 7, loss = 0.99373462\n",
      "Iteration 8, loss = 0.97559254\n",
      "Iteration 9, loss = 0.95364697\n",
      "Iteration 10, loss = 0.97536416\n",
      "Iteration 11, loss = 0.95213781\n",
      "Iteration 12, loss = 0.92603642\n",
      "Iteration 13, loss = 0.98873079\n",
      "Iteration 14, loss = 1.00006945\n",
      "Iteration 15, loss = 0.96244625\n",
      "Iteration 16, loss = 1.00490508\n",
      "Iteration 17, loss = 0.97187707\n",
      "Iteration 18, loss = 0.93468915\n",
      "Iteration 19, loss = 0.98392794\n",
      "Iteration 20, loss = 0.93892887\n",
      "Iteration 7, loss = 0.99373462\n",
      "Iteration 8, loss = 0.97559254\n",
      "Iteration 9, loss = 0.95364697\n",
      "Iteration 10, loss = 0.97536416\n",
      "Iteration 11, loss = 0.95213781\n",
      "Iteration 12, loss = 0.92603642\n",
      "Iteration 13, loss = 0.98873079\n",
      "Iteration 14, loss = 1.00006945\n",
      "Iteration 15, loss = 0.96244625\n",
      "Iteration 16, loss = 1.00490508\n",
      "Iteration 17, loss = 0.97187707\n",
      "Iteration 18, loss = 0.93468915\n",
      "Iteration 19, loss = 0.98392794\n",
      "Iteration 20, loss = 0.93892887\n",
      "Iteration 21, loss = 0.95248585\n",
      "Iteration 22, loss = 0.94343869\n",
      "Iteration 23, loss = 0.88496205\n",
      "Iteration 24, loss = 0.97410818\n",
      "Iteration 25, loss = 0.96513682\n",
      "Iteration 26, loss = 0.91429662\n",
      "Iteration 27, loss = 0.91598290\n",
      "Iteration 28, loss = 0.93075736\n",
      "Iteration 29, loss = 0.90775555\n",
      "Iteration 30, loss = 0.90307040\n",
      "Iteration 31, loss = 0.91362084\n",
      "Iteration 32, loss = 0.94968253\n",
      "Iteration 33, loss = 0.97082177\n",
      "Iteration 34, loss = 1.03609423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24202549\n",
      "Iteration 21, loss = 0.95248585\n",
      "Iteration 22, loss = 0.94343869\n",
      "Iteration 23, loss = 0.88496205\n",
      "Iteration 24, loss = 0.97410818\n",
      "Iteration 25, loss = 0.96513682\n",
      "Iteration 26, loss = 0.91429662\n",
      "Iteration 27, loss = 0.91598290\n",
      "Iteration 28, loss = 0.93075736\n",
      "Iteration 29, loss = 0.90775555\n",
      "Iteration 30, loss = 0.90307040\n",
      "Iteration 31, loss = 0.91362084\n",
      "Iteration 32, loss = 0.94968253\n",
      "Iteration 33, loss = 0.97082177\n",
      "Iteration 34, loss = 1.03609423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24202549\n",
      "Iteration 2, loss = 1.19487124\n",
      "Iteration 3, loss = 1.11570997\n",
      "Iteration 4, loss = 1.01299150\n",
      "Iteration 5, loss = 1.03529283\n",
      "Iteration 6, loss = 0.98040279\n",
      "Iteration 7, loss = 1.01410537\n",
      "Iteration 8, loss = 1.00385454\n",
      "Iteration 9, loss = 1.00312902\n",
      "Iteration 10, loss = 1.00025671\n",
      "Iteration 11, loss = 1.02046772\n",
      "Iteration 12, loss = 0.99175837\n",
      "Iteration 13, loss = 0.99708116\n",
      "Iteration 14, loss = 1.04391129\n",
      "Iteration 2, loss = 1.19487124\n",
      "Iteration 3, loss = 1.11570997\n",
      "Iteration 4, loss = 1.01299150\n",
      "Iteration 5, loss = 1.03529283\n",
      "Iteration 6, loss = 0.98040279\n",
      "Iteration 7, loss = 1.01410537\n",
      "Iteration 8, loss = 1.00385454\n",
      "Iteration 9, loss = 1.00312902\n",
      "Iteration 10, loss = 1.00025671\n",
      "Iteration 11, loss = 1.02046772\n",
      "Iteration 12, loss = 0.99175837\n",
      "Iteration 13, loss = 0.99708116\n",
      "Iteration 14, loss = 1.04391129\n",
      "Iteration 15, loss = 0.99966261\n",
      "Iteration 16, loss = 0.98558036\n",
      "Iteration 17, loss = 1.01210573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24415771\n",
      "Iteration 2, loss = 1.20808554\n",
      "Iteration 3, loss = 1.20892165\n",
      "Iteration 4, loss = 1.09040465\n",
      "Iteration 5, loss = 1.10326341\n",
      "Iteration 6, loss = 1.16693117\n",
      "Iteration 7, loss = 1.08704637\n",
      "Iteration 8, loss = 1.04933486\n",
      "Iteration 9, loss = 1.08595650\n",
      "Iteration 10, loss = 1.03373412\n",
      "Iteration 11, loss = 1.06067506\n",
      "Iteration 15, loss = 0.99966261\n",
      "Iteration 16, loss = 0.98558036\n",
      "Iteration 17, loss = 1.01210573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24415771\n",
      "Iteration 2, loss = 1.20808554\n",
      "Iteration 3, loss = 1.20892165\n",
      "Iteration 4, loss = 1.09040465\n",
      "Iteration 5, loss = 1.10326341\n",
      "Iteration 6, loss = 1.16693117\n",
      "Iteration 7, loss = 1.08704637\n",
      "Iteration 8, loss = 1.04933486\n",
      "Iteration 9, loss = 1.08595650\n",
      "Iteration 10, loss = 1.03373412\n",
      "Iteration 11, loss = 1.06067506\n",
      "Iteration 12, loss = 1.05692821\n",
      "Iteration 13, loss = 1.03887581\n",
      "Iteration 14, loss = 1.03852301\n",
      "Iteration 15, loss = 1.03743821\n",
      "Iteration 16, loss = 1.04869444\n",
      "Iteration 17, loss = 1.09595568\n",
      "Iteration 18, loss = 1.05713876\n",
      "Iteration 19, loss = 1.05196338\n",
      "Iteration 20, loss = 1.05935968\n",
      "Iteration 21, loss = 1.06716426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25045268\n",
      "Iteration 2, loss = 1.16552189\n",
      "Iteration 3, loss = 1.22833781\n",
      "Iteration 4, loss = 1.09674254\n",
      "Iteration 5, loss = 1.16024526\n",
      "Iteration 12, loss = 1.05692821\n",
      "Iteration 13, loss = 1.03887581\n",
      "Iteration 14, loss = 1.03852301\n",
      "Iteration 15, loss = 1.03743821\n",
      "Iteration 16, loss = 1.04869444\n",
      "Iteration 17, loss = 1.09595568\n",
      "Iteration 18, loss = 1.05713876\n",
      "Iteration 19, loss = 1.05196338\n",
      "Iteration 20, loss = 1.05935968\n",
      "Iteration 21, loss = 1.06716426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25045268\n",
      "Iteration 2, loss = 1.16552189\n",
      "Iteration 3, loss = 1.22833781\n",
      "Iteration 4, loss = 1.09674254\n",
      "Iteration 5, loss = 1.16024526\n",
      "Iteration 6, loss = 1.05841825\n",
      "Iteration 7, loss = 1.08543485\n",
      "Iteration 8, loss = 1.04659840\n",
      "Iteration 9, loss = 1.02597117\n",
      "Iteration 10, loss = 0.99909994\n",
      "Iteration 11, loss = 0.98867384\n",
      "Iteration 12, loss = 1.02016102\n",
      "Iteration 13, loss = 0.95782234\n",
      "Iteration 14, loss = 0.97722154\n",
      "Iteration 15, loss = 1.01131905\n",
      "Iteration 16, loss = 0.98493966\n",
      "Iteration 17, loss = 0.99608388\n",
      "Iteration 18, loss = 1.01681805\n",
      "Iteration 6, loss = 1.05841825\n",
      "Iteration 7, loss = 1.08543485\n",
      "Iteration 8, loss = 1.04659840\n",
      "Iteration 9, loss = 1.02597117\n",
      "Iteration 10, loss = 0.99909994\n",
      "Iteration 11, loss = 0.98867384\n",
      "Iteration 12, loss = 1.02016102\n",
      "Iteration 13, loss = 0.95782234\n",
      "Iteration 14, loss = 0.97722154\n",
      "Iteration 15, loss = 1.01131905\n",
      "Iteration 16, loss = 0.98493966\n",
      "Iteration 17, loss = 0.99608388\n",
      "Iteration 18, loss = 1.01681805\n",
      "Iteration 19, loss = 0.98055819\n",
      "Iteration 20, loss = 1.00416832\n",
      "Iteration 21, loss = 0.98311082\n",
      "Iteration 22, loss = 0.96516836\n",
      "Iteration 23, loss = 0.98239161\n",
      "Iteration 24, loss = 1.02616884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21978505\n",
      "Iteration 2, loss = 1.10419276\n",
      "Iteration 3, loss = 1.10235203\n",
      "Iteration 4, loss = 1.08792625\n",
      "Iteration 5, loss = 1.03773933\n",
      "Iteration 6, loss = 1.01009515\n",
      "Iteration 7, loss = 1.03539933\n",
      "Iteration 19, loss = 0.98055819\n",
      "Iteration 20, loss = 1.00416832\n",
      "Iteration 21, loss = 0.98311082\n",
      "Iteration 22, loss = 0.96516836\n",
      "Iteration 23, loss = 0.98239161\n",
      "Iteration 24, loss = 1.02616884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21978505\n",
      "Iteration 2, loss = 1.10419276\n",
      "Iteration 3, loss = 1.10235203\n",
      "Iteration 4, loss = 1.08792625\n",
      "Iteration 5, loss = 1.03773933\n",
      "Iteration 6, loss = 1.01009515\n",
      "Iteration 7, loss = 1.03539933\n",
      "Iteration 8, loss = 0.99301246\n",
      "Iteration 9, loss = 0.99513243\n",
      "Iteration 10, loss = 0.99853532\n",
      "Iteration 11, loss = 1.02491282\n",
      "Iteration 12, loss = 1.00640833\n",
      "Iteration 13, loss = 0.99732368\n",
      "Iteration 14, loss = 1.04196421\n",
      "Iteration 15, loss = 1.03952734\n",
      "Iteration 16, loss = 1.02876634\n",
      "Iteration 17, loss = 1.00476543\n",
      "Iteration 18, loss = 1.02251016\n",
      "Iteration 19, loss = 1.04472198\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22516612\n",
      "Iteration 8, loss = 0.99301246\n",
      "Iteration 9, loss = 0.99513243\n",
      "Iteration 10, loss = 0.99853532\n",
      "Iteration 11, loss = 1.02491282\n",
      "Iteration 12, loss = 1.00640833\n",
      "Iteration 13, loss = 0.99732368\n",
      "Iteration 14, loss = 1.04196421\n",
      "Iteration 15, loss = 1.03952734\n",
      "Iteration 16, loss = 1.02876634\n",
      "Iteration 17, loss = 1.00476543\n",
      "Iteration 18, loss = 1.02251016\n",
      "Iteration 19, loss = 1.04472198\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22516612\n",
      "Iteration 2, loss = 1.16252225\n",
      "Iteration 3, loss = 1.04863635\n",
      "Iteration 4, loss = 1.05589090\n",
      "Iteration 5, loss = 1.07535699\n",
      "Iteration 6, loss = 1.00889072\n",
      "Iteration 7, loss = 0.99373462\n",
      "Iteration 8, loss = 0.97559254\n",
      "Iteration 9, loss = 0.95364697\n",
      "Iteration 10, loss = 0.97536416\n",
      "Iteration 11, loss = 0.95213781\n",
      "Iteration 12, loss = 0.92603642\n",
      "Iteration 13, loss = 0.98873079\n",
      "Iteration 14, loss = 1.00006945\n",
      "Iteration 15, loss = 0.96244625\n",
      "Iteration 2, loss = 1.16252225\n",
      "Iteration 3, loss = 1.04863635\n",
      "Iteration 4, loss = 1.05589090\n",
      "Iteration 5, loss = 1.07535699\n",
      "Iteration 6, loss = 1.00889072\n",
      "Iteration 7, loss = 0.99373462\n",
      "Iteration 8, loss = 0.97559254\n",
      "Iteration 9, loss = 0.95364697\n",
      "Iteration 10, loss = 0.97536416\n",
      "Iteration 11, loss = 0.95213781\n",
      "Iteration 12, loss = 0.92603642\n",
      "Iteration 13, loss = 0.98873079\n",
      "Iteration 14, loss = 1.00006945\n",
      "Iteration 15, loss = 0.96244625\n",
      "Iteration 16, loss = 1.00490508\n",
      "Iteration 17, loss = 0.97187707\n",
      "Iteration 18, loss = 0.93468915\n",
      "Iteration 19, loss = 0.98392794\n",
      "Iteration 20, loss = 0.93892887\n",
      "Iteration 21, loss = 0.95248585\n",
      "Iteration 22, loss = 0.94343869\n",
      "Iteration 23, loss = 0.88496205\n",
      "Iteration 24, loss = 0.97410818\n",
      "Iteration 25, loss = 0.96513682\n",
      "Iteration 26, loss = 0.91429662\n",
      "Iteration 27, loss = 0.91598290\n",
      "Iteration 28, loss = 0.93075736\n",
      "Iteration 29, loss = 0.90775555\n",
      "Iteration 30, loss = 0.90307040\n",
      "Iteration 31, loss = 0.91362084\n",
      "Iteration 16, loss = 1.00490508\n",
      "Iteration 17, loss = 0.97187707\n",
      "Iteration 18, loss = 0.93468915\n",
      "Iteration 19, loss = 0.98392794\n",
      "Iteration 20, loss = 0.93892887\n",
      "Iteration 21, loss = 0.95248585\n",
      "Iteration 22, loss = 0.94343869\n",
      "Iteration 23, loss = 0.88496205\n",
      "Iteration 24, loss = 0.97410818\n",
      "Iteration 25, loss = 0.96513682\n",
      "Iteration 26, loss = 0.91429662\n",
      "Iteration 27, loss = 0.91598290\n",
      "Iteration 28, loss = 0.93075736\n",
      "Iteration 29, loss = 0.90775555\n",
      "Iteration 30, loss = 0.90307040\n",
      "Iteration 31, loss = 0.91362084\n",
      "Iteration 32, loss = 0.94968253\n",
      "Iteration 33, loss = 0.97082177\n",
      "Iteration 34, loss = 1.03609423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24202549\n",
      "Iteration 2, loss = 1.19487124\n",
      "Iteration 3, loss = 1.11570997\n",
      "Iteration 4, loss = 1.01299150\n",
      "Iteration 5, loss = 1.03529283\n",
      "Iteration 6, loss = 0.98040279\n",
      "Iteration 7, loss = 1.01410537\n",
      "Iteration 8, loss = 1.00385454\n",
      "Iteration 9, loss = 1.00312902\n",
      "Iteration 10, loss = 1.00025671\n",
      "Iteration 11, loss = 1.02046772Iteration 32, loss = 0.94968253\n",
      "Iteration 33, loss = 0.97082177\n",
      "Iteration 34, loss = 1.03609423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24202549\n",
      "Iteration 2, loss = 1.19487124\n",
      "Iteration 3, loss = 1.11570997\n",
      "Iteration 4, loss = 1.01299150\n",
      "Iteration 5, loss = 1.03529283\n",
      "Iteration 6, loss = 0.98040279\n",
      "Iteration 7, loss = 1.01410537\n",
      "Iteration 8, loss = 1.00385454\n",
      "Iteration 9, loss = 1.00312902\n",
      "Iteration 10, loss = 1.00025671\n",
      "Iteration 11, loss = 1.02046772\n",
      "Iteration 12, loss = 0.99175837\n",
      "Iteration 13, loss = 0.99708116\n",
      "Iteration 14, loss = 1.04391129\n",
      "Iteration 15, loss = 0.99966261\n",
      "Iteration 16, loss = 0.98558036\n",
      "Iteration 17, loss = 1.01210573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24415771\n",
      "Iteration 2, loss = 1.20808554\n",
      "Iteration 3, loss = 1.20892165\n",
      "Iteration 4, loss = 1.09040465\n",
      "Iteration 5, loss = 1.10326341\n",
      "Iteration 6, loss = 1.16693117\n",
      "Iteration 7, loss = 1.08704637\n",
      "\n",
      "Iteration 12, loss = 0.99175837\n",
      "Iteration 13, loss = 0.99708116\n",
      "Iteration 14, loss = 1.04391129\n",
      "Iteration 15, loss = 0.99966261\n",
      "Iteration 16, loss = 0.98558036\n",
      "Iteration 17, loss = 1.01210573\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24415771\n",
      "Iteration 2, loss = 1.20808554\n",
      "Iteration 3, loss = 1.20892165\n",
      "Iteration 4, loss = 1.09040465\n",
      "Iteration 5, loss = 1.10326341\n",
      "Iteration 6, loss = 1.16693117\n",
      "Iteration 7, loss = 1.08704637\n",
      "Iteration 8, loss = 1.04933486\n",
      "Iteration 9, loss = 1.08595650\n",
      "Iteration 10, loss = 1.03373412\n",
      "Iteration 11, loss = 1.06067506\n",
      "Iteration 12, loss = 1.05692821\n",
      "Iteration 13, loss = 1.03887581\n",
      "Iteration 14, loss = 1.03852301\n",
      "Iteration 15, loss = 1.03743821\n",
      "Iteration 16, loss = 1.04869444\n",
      "Iteration 17, loss = 1.09595568\n",
      "Iteration 18, loss = 1.05713876\n",
      "Iteration 19, loss = 1.05196338\n",
      "Iteration 20, loss = 1.05935968\n",
      "Iteration 21, loss = 1.06716426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25045268\n",
      "Iteration 8, loss = 1.04933486\n",
      "Iteration 9, loss = 1.08595650\n",
      "Iteration 10, loss = 1.03373412\n",
      "Iteration 11, loss = 1.06067506\n",
      "Iteration 12, loss = 1.05692821\n",
      "Iteration 13, loss = 1.03887581\n",
      "Iteration 14, loss = 1.03852301\n",
      "Iteration 15, loss = 1.03743821\n",
      "Iteration 16, loss = 1.04869444\n",
      "Iteration 17, loss = 1.09595568\n",
      "Iteration 18, loss = 1.05713876\n",
      "Iteration 19, loss = 1.05196338\n",
      "Iteration 20, loss = 1.05935968\n",
      "Iteration 21, loss = 1.06716426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25045268\n",
      "Iteration 2, loss = 1.16552189\n",
      "Iteration 3, loss = 1.22833781\n",
      "Iteration 4, loss = 1.09674254\n",
      "Iteration 5, loss = 1.16024526\n",
      "Iteration 6, loss = 1.05841825\n",
      "Iteration 7, loss = 1.08543485\n",
      "Iteration 8, loss = 1.04659840\n",
      "Iteration 9, loss = 1.02597117\n",
      "Iteration 10, loss = 0.99909994\n",
      "Iteration 11, loss = 0.98867384\n",
      "Iteration 12, loss = 1.02016102\n",
      "Iteration 13, loss = 0.95782234\n",
      "Iteration 14, loss = 0.97722154\n",
      "Iteration 2, loss = 1.16552189\n",
      "Iteration 3, loss = 1.22833781\n",
      "Iteration 4, loss = 1.09674254\n",
      "Iteration 5, loss = 1.16024526\n",
      "Iteration 6, loss = 1.05841825\n",
      "Iteration 7, loss = 1.08543485\n",
      "Iteration 8, loss = 1.04659840\n",
      "Iteration 9, loss = 1.02597117\n",
      "Iteration 10, loss = 0.99909994\n",
      "Iteration 11, loss = 0.98867384\n",
      "Iteration 12, loss = 1.02016102\n",
      "Iteration 13, loss = 0.95782234\n",
      "Iteration 14, loss = 0.97722154\n",
      "Iteration 15, loss = 1.01131905\n",
      "Iteration 16, loss = 0.98493966\n",
      "Iteration 17, loss = 0.99608388\n",
      "Iteration 18, loss = 1.01681805\n",
      "Iteration 19, loss = 0.98055819\n",
      "Iteration 20, loss = 1.00416832\n",
      "Iteration 21, loss = 0.98311082\n",
      "Iteration 22, loss = 0.96516836\n",
      "Iteration 23, loss = 0.98239161\n",
      "Iteration 24, loss = 1.02616884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25747610\n",
      "Iteration 2, loss = 1.22186118\n",
      "Iteration 3, loss = 1.19239922\n",
      "Iteration 4, loss = 1.16804616\n",
      "Iteration 5, loss = 1.12359069\n",
      "Iteration 6, loss = 1.14435036\n",
      "Iteration 15, loss = 1.01131905\n",
      "Iteration 16, loss = 0.98493966\n",
      "Iteration 17, loss = 0.99608388\n",
      "Iteration 18, loss = 1.01681805\n",
      "Iteration 19, loss = 0.98055819\n",
      "Iteration 20, loss = 1.00416832\n",
      "Iteration 21, loss = 0.98311082\n",
      "Iteration 22, loss = 0.96516836\n",
      "Iteration 23, loss = 0.98239161\n",
      "Iteration 24, loss = 1.02616884\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25747610\n",
      "Iteration 2, loss = 1.22186118\n",
      "Iteration 3, loss = 1.19239922\n",
      "Iteration 4, loss = 1.16804616\n",
      "Iteration 5, loss = 1.12359069\n",
      "Iteration 6, loss = 1.14435036\n",
      "Iteration 7, loss = 1.10274618\n",
      "Iteration 8, loss = 1.03698042\n",
      "Iteration 9, loss = 1.01044872\n",
      "Iteration 10, loss = 1.00870756\n",
      "Iteration 1, loss = 1.25373257\n",
      "Iteration 2, loss = 1.23899797\n",
      "Iteration 3, loss = 1.24616267\n",
      "Iteration 4, loss = 1.25455178\n",
      "Iteration 5, loss = 1.23896407\n",
      "Iteration 6, loss = 1.26789933\n",
      "Iteration 7, loss = 1.25038300\n",
      "Iteration 8, loss = 1.22869474\n",
      "Iteration 7, loss = 1.10274618\n",
      "Iteration 8, loss = 1.03698042\n",
      "Iteration 9, loss = 1.01044872\n",
      "Iteration 10, loss = 1.00870756\n",
      "Iteration 1, loss = 1.25373257\n",
      "Iteration 2, loss = 1.23899797\n",
      "Iteration 3, loss = 1.24616267\n",
      "Iteration 4, loss = 1.25455178\n",
      "Iteration 5, loss = 1.23896407\n",
      "Iteration 6, loss = 1.26789933\n",
      "Iteration 7, loss = 1.25038300\n",
      "Iteration 8, loss = 1.22869474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.24517927\n",
      "Iteration 10, loss = 1.24297750\n",
      "Iteration 1, loss = 1.27173893\n",
      "Iteration 2, loss = 1.21518119\n",
      "Iteration 3, loss = 1.18315849\n",
      "Iteration 4, loss = 1.09524768\n",
      "Iteration 5, loss = 1.03696173\n",
      "Iteration 6, loss = 1.01142011\n",
      "Iteration 7, loss = 1.04291486\n",
      "Iteration 8, loss = 1.00963013\n",
      "Iteration 9, loss = 1.00946157\n",
      "Iteration 10, loss = 1.03594396\n",
      "Iteration 1, loss = 1.27094317\n",
      "Iteration 9, loss = 1.24517927\n",
      "Iteration 10, loss = 1.24297750\n",
      "Iteration 1, loss = 1.27173893\n",
      "Iteration 2, loss = 1.21518119\n",
      "Iteration 3, loss = 1.18315849\n",
      "Iteration 4, loss = 1.09524768\n",
      "Iteration 5, loss = 1.03696173\n",
      "Iteration 6, loss = 1.01142011\n",
      "Iteration 7, loss = 1.04291486\n",
      "Iteration 8, loss = 1.00963013\n",
      "Iteration 9, loss = 1.00946157\n",
      "Iteration 10, loss = 1.03594396\n",
      "Iteration 1, loss = 1.27094317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.24299417\n",
      "Iteration 3, loss = 1.25256959\n",
      "Iteration 4, loss = 1.24914811\n",
      "Iteration 5, loss = 1.25193762\n",
      "Iteration 6, loss = 1.27716512\n",
      "Iteration 7, loss = 1.25329232\n",
      "Iteration 8, loss = 1.24757446\n",
      "Iteration 9, loss = 1.26775892\n",
      "Iteration 10, loss = 1.25449877\n",
      "Iteration 1, loss = 1.27151723\n",
      "Iteration 2, loss = 1.26356918\n",
      "Iteration 3, loss = 1.27860057\n",
      "Iteration 4, loss = 1.27684847\n",
      "Iteration 2, loss = 1.24299417\n",
      "Iteration 3, loss = 1.25256959\n",
      "Iteration 4, loss = 1.24914811\n",
      "Iteration 5, loss = 1.25193762\n",
      "Iteration 6, loss = 1.27716512\n",
      "Iteration 7, loss = 1.25329232\n",
      "Iteration 8, loss = 1.24757446\n",
      "Iteration 9, loss = 1.26775892\n",
      "Iteration 10, loss = 1.25449877\n",
      "Iteration 1, loss = 1.27151723\n",
      "Iteration 2, loss = 1.26356918\n",
      "Iteration 3, loss = 1.27860057\n",
      "Iteration 4, loss = 1.27684847\n",
      "Iteration 5, loss = 1.26766968\n",
      "Iteration 6, loss = 1.26986357\n",
      "Iteration 7, loss = 1.26979080\n",
      "Iteration 8, loss = 1.26681091\n",
      "Iteration 9, loss = 1.27466580\n",
      "Iteration 10, loss = 1.26535155\n",
      "Iteration 1, loss = 1.25747610\n",
      "Iteration 2, loss = 1.22186118\n",
      "Iteration 3, loss = 1.19239922\n",
      "Iteration 4, loss = 1.16804616\n",
      "Iteration 5, loss = 1.12359069\n",
      "Iteration 6, loss = 1.14435036\n",
      "Iteration 7, loss = 1.10274618\n",
      "Iteration 8, loss = 1.03698042\n",
      "Iteration 9, loss = 1.01044872\n",
      "Iteration 5, loss = 1.26766968\n",
      "Iteration 6, loss = 1.26986357\n",
      "Iteration 7, loss = 1.26979080\n",
      "Iteration 8, loss = 1.26681091\n",
      "Iteration 9, loss = 1.27466580\n",
      "Iteration 10, loss = 1.26535155\n",
      "Iteration 1, loss = 1.25747610\n",
      "Iteration 2, loss = 1.22186118\n",
      "Iteration 3, loss = 1.19239922\n",
      "Iteration 4, loss = 1.16804616\n",
      "Iteration 5, loss = 1.12359069\n",
      "Iteration 6, loss = 1.14435036\n",
      "Iteration 7, loss = 1.10274618\n",
      "Iteration 8, loss = 1.03698042\n",
      "Iteration 9, loss = 1.01044872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.00870756\n",
      "Iteration 11, loss = 1.03797181\n",
      "Iteration 12, loss = 1.03219291\n",
      "Iteration 13, loss = 1.00895584\n",
      "Iteration 14, loss = 1.07627268\n",
      "Iteration 15, loss = 1.04949969\n",
      "Iteration 16, loss = 1.05301989\n",
      "Iteration 17, loss = 1.02311778\n",
      "Iteration 18, loss = 1.04319235\n",
      "Iteration 19, loss = 1.05209355\n",
      "Iteration 20, loss = 1.04840765\n",
      "Iteration 21, loss = 1.05810701\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25373257\n",
      "Iteration 10, loss = 1.00870756\n",
      "Iteration 11, loss = 1.03797181\n",
      "Iteration 12, loss = 1.03219291\n",
      "Iteration 13, loss = 1.00895584\n",
      "Iteration 14, loss = 1.07627268\n",
      "Iteration 15, loss = 1.04949969\n",
      "Iteration 16, loss = 1.05301989\n",
      "Iteration 17, loss = 1.02311778\n",
      "Iteration 18, loss = 1.04319235\n",
      "Iteration 19, loss = 1.05209355\n",
      "Iteration 20, loss = 1.04840765\n",
      "Iteration 21, loss = 1.05810701\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25373257\n",
      "Iteration 2, loss = 1.23899797\n",
      "Iteration 3, loss = 1.24616267\n",
      "Iteration 4, loss = 1.25455178\n",
      "Iteration 5, loss = 1.23896407\n",
      "Iteration 6, loss = 1.26789933\n",
      "Iteration 7, loss = 1.25038300\n",
      "Iteration 8, loss = 1.22869474\n",
      "Iteration 9, loss = 1.24517927\n",
      "Iteration 10, loss = 1.24297750\n",
      "Iteration 11, loss = 1.23270881\n",
      "Iteration 12, loss = 1.24896090\n",
      "Iteration 13, loss = 1.24894434\n",
      "Iteration 14, loss = 1.24966668\n",
      "Iteration 15, loss = 1.24511432\n",
      "Iteration 16, loss = 1.24853779\n",
      "Iteration 2, loss = 1.23899797\n",
      "Iteration 3, loss = 1.24616267\n",
      "Iteration 4, loss = 1.25455178\n",
      "Iteration 5, loss = 1.23896407\n",
      "Iteration 6, loss = 1.26789933\n",
      "Iteration 7, loss = 1.25038300\n",
      "Iteration 8, loss = 1.22869474\n",
      "Iteration 9, loss = 1.24517927\n",
      "Iteration 10, loss = 1.24297750\n",
      "Iteration 11, loss = 1.23270881\n",
      "Iteration 12, loss = 1.24896090\n",
      "Iteration 13, loss = 1.24894434\n",
      "Iteration 14, loss = 1.24966668\n",
      "Iteration 15, loss = 1.24511432\n",
      "Iteration 16, loss = 1.24853779\n",
      "Iteration 17, loss = 1.23708484\n",
      "Iteration 18, loss = 1.23554015\n",
      "Iteration 19, loss = 1.24708043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27173893\n",
      "Iteration 2, loss = 1.21518119\n",
      "Iteration 3, loss = 1.18315849\n",
      "Iteration 4, loss = 1.09524768\n",
      "Iteration 5, loss = 1.03696173\n",
      "Iteration 6, loss = 1.01142011\n",
      "Iteration 7, loss = 1.04291486\n",
      "Iteration 8, loss = 1.00963013\n",
      "Iteration 9, loss = 1.00946157\n",
      "Iteration 10, loss = 1.03594396\n",
      "Iteration 17, loss = 1.23708484\n",
      "Iteration 18, loss = 1.23554015\n",
      "Iteration 19, loss = 1.24708043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27173893\n",
      "Iteration 2, loss = 1.21518119\n",
      "Iteration 3, loss = 1.18315849\n",
      "Iteration 4, loss = 1.09524768\n",
      "Iteration 5, loss = 1.03696173\n",
      "Iteration 6, loss = 1.01142011\n",
      "Iteration 7, loss = 1.04291486\n",
      "Iteration 8, loss = 1.00963013\n",
      "Iteration 9, loss = 1.00946157\n",
      "Iteration 10, loss = 1.03594396\n",
      "Iteration 11, loss = 1.03303724\n",
      "Iteration 12, loss = 1.05764465\n",
      "Iteration 13, loss = 1.08912071\n",
      "Iteration 14, loss = 1.09056625\n",
      "Iteration 15, loss = 1.03017534\n",
      "Iteration 16, loss = 1.01259817\n",
      "Iteration 17, loss = 1.04875357\n",
      "Iteration 18, loss = 1.06815147\n",
      "Iteration 19, loss = 1.06915184\n",
      "Iteration 20, loss = 1.06938652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27094317\n",
      "Iteration 2, loss = 1.24299417\n",
      "Iteration 3, loss = 1.25256959\n",
      "Iteration 4, loss = 1.24914811\n",
      "Iteration 5, loss = 1.25193762\n",
      "Iteration 6, loss = 1.27716512\n",
      "Iteration 11, loss = 1.03303724\n",
      "Iteration 12, loss = 1.05764465\n",
      "Iteration 13, loss = 1.08912071\n",
      "Iteration 14, loss = 1.09056625\n",
      "Iteration 15, loss = 1.03017534\n",
      "Iteration 16, loss = 1.01259817\n",
      "Iteration 17, loss = 1.04875357\n",
      "Iteration 18, loss = 1.06815147\n",
      "Iteration 19, loss = 1.06915184\n",
      "Iteration 20, loss = 1.06938652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27094317\n",
      "Iteration 2, loss = 1.24299417\n",
      "Iteration 3, loss = 1.25256959\n",
      "Iteration 4, loss = 1.24914811\n",
      "Iteration 5, loss = 1.25193762\n",
      "Iteration 6, loss = 1.27716512\n",
      "Iteration 7, loss = 1.25329232\n",
      "Iteration 8, loss = 1.24757446\n",
      "Iteration 9, loss = 1.26775892\n",
      "Iteration 10, loss = 1.25449877\n",
      "Iteration 11, loss = 1.28198646\n",
      "Iteration 12, loss = 1.25482794\n",
      "Iteration 13, loss = 1.25388569\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27151723\n",
      "Iteration 2, loss = 1.26356918\n",
      "Iteration 3, loss = 1.27860057\n",
      "Iteration 4, loss = 1.27684847\n",
      "Iteration 5, loss = 1.26766968\n",
      "Iteration 6, loss = 1.26986357\n",
      "Iteration 7, loss = 1.26979080\n",
      "Iteration 7, loss = 1.25329232\n",
      "Iteration 8, loss = 1.24757446\n",
      "Iteration 9, loss = 1.26775892\n",
      "Iteration 10, loss = 1.25449877\n",
      "Iteration 11, loss = 1.28198646\n",
      "Iteration 12, loss = 1.25482794\n",
      "Iteration 13, loss = 1.25388569\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27151723\n",
      "Iteration 2, loss = 1.26356918\n",
      "Iteration 3, loss = 1.27860057\n",
      "Iteration 4, loss = 1.27684847\n",
      "Iteration 5, loss = 1.26766968\n",
      "Iteration 6, loss = 1.26986357\n",
      "Iteration 7, loss = 1.26979080\n",
      "Iteration 8, loss = 1.26681091\n",
      "Iteration 9, loss = 1.27466580\n",
      "Iteration 10, loss = 1.26535155\n",
      "Iteration 11, loss = 1.28295657\n",
      "Iteration 12, loss = 1.25654456\n",
      "Iteration 13, loss = 1.26460303\n",
      "Iteration 14, loss = 1.25398889\n",
      "Iteration 15, loss = 1.26808636\n",
      "Iteration 16, loss = 1.26616957\n",
      "Iteration 17, loss = 1.26945926\n",
      "Iteration 18, loss = 1.25527185\n",
      "Iteration 19, loss = 1.25255319\n",
      "Iteration 20, loss = 1.26703625\n",
      "Iteration 21, loss = 1.27253418\n",
      "Iteration 22, loss = 1.25352217\n",
      "Iteration 23, loss = 1.26264881\n",
      "Iteration 8, loss = 1.26681091\n",
      "Iteration 9, loss = 1.27466580\n",
      "Iteration 10, loss = 1.26535155\n",
      "Iteration 11, loss = 1.28295657\n",
      "Iteration 12, loss = 1.25654456\n",
      "Iteration 13, loss = 1.26460303\n",
      "Iteration 14, loss = 1.25398889\n",
      "Iteration 15, loss = 1.26808636\n",
      "Iteration 16, loss = 1.26616957\n",
      "Iteration 17, loss = 1.26945926\n",
      "Iteration 18, loss = 1.25527185\n",
      "Iteration 19, loss = 1.25255319\n",
      "Iteration 20, loss = 1.26703625\n",
      "Iteration 21, loss = 1.27253418\n",
      "Iteration 22, loss = 1.25352217\n",
      "Iteration 23, loss = 1.26264881\n",
      "Iteration 24, loss = 1.26544420\n",
      "Iteration 25, loss = 1.25993110\n",
      "Iteration 26, loss = 1.26215679\n",
      "Iteration 27, loss = 1.25908939\n",
      "Iteration 28, loss = 1.26763561\n",
      "Iteration 29, loss = 1.25410386\n",
      "Iteration 30, loss = 1.28102183\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25747610\n",
      "Iteration 2, loss = 1.22186118\n",
      "Iteration 3, loss = 1.19239922\n",
      "Iteration 4, loss = 1.16804616\n",
      "Iteration 5, loss = 1.12359069\n",
      "Iteration 6, loss = 1.14435036\n",
      "Iteration 24, loss = 1.26544420\n",
      "Iteration 25, loss = 1.25993110\n",
      "Iteration 26, loss = 1.26215679\n",
      "Iteration 27, loss = 1.25908939\n",
      "Iteration 28, loss = 1.26763561\n",
      "Iteration 29, loss = 1.25410386\n",
      "Iteration 30, loss = 1.28102183\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25747610\n",
      "Iteration 2, loss = 1.22186118\n",
      "Iteration 3, loss = 1.19239922\n",
      "Iteration 4, loss = 1.16804616\n",
      "Iteration 5, loss = 1.12359069\n",
      "Iteration 6, loss = 1.14435036\n",
      "Iteration 7, loss = 1.10274618\n",
      "Iteration 8, loss = 1.03698042\n",
      "Iteration 9, loss = 1.01044872\n",
      "Iteration 10, loss = 1.00870756\n",
      "Iteration 11, loss = 1.03797181\n",
      "Iteration 12, loss = 1.03219291\n",
      "Iteration 13, loss = 1.00895584\n",
      "Iteration 14, loss = 1.07627268\n",
      "Iteration 15, loss = 1.04949969\n",
      "Iteration 16, loss = 1.05301989\n",
      "Iteration 17, loss = 1.02311778\n",
      "Iteration 18, loss = 1.04319235\n",
      "Iteration 19, loss = 1.05209355\n",
      "Iteration 20, loss = 1.04840765\n",
      "Iteration 21, loss = 1.05810701\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25373257\n",
      "Iteration 7, loss = 1.10274618\n",
      "Iteration 8, loss = 1.03698042\n",
      "Iteration 9, loss = 1.01044872\n",
      "Iteration 10, loss = 1.00870756\n",
      "Iteration 11, loss = 1.03797181\n",
      "Iteration 12, loss = 1.03219291\n",
      "Iteration 13, loss = 1.00895584\n",
      "Iteration 14, loss = 1.07627268\n",
      "Iteration 15, loss = 1.04949969\n",
      "Iteration 16, loss = 1.05301989\n",
      "Iteration 17, loss = 1.02311778\n",
      "Iteration 18, loss = 1.04319235\n",
      "Iteration 19, loss = 1.05209355\n",
      "Iteration 20, loss = 1.04840765\n",
      "Iteration 21, loss = 1.05810701\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25373257\n",
      "Iteration 2, loss = 1.23899797\n",
      "Iteration 3, loss = 1.24616267\n",
      "Iteration 4, loss = 1.25455178\n",
      "Iteration 5, loss = 1.23896407\n",
      "Iteration 6, loss = 1.26789933\n",
      "Iteration 7, loss = 1.25038300\n",
      "Iteration 8, loss = 1.22869474\n",
      "Iteration 9, loss = 1.24517927\n",
      "Iteration 10, loss = 1.24297750\n",
      "Iteration 11, loss = 1.23270881\n",
      "Iteration 12, loss = 1.24896090\n",
      "Iteration 13, loss = 1.24894434\n",
      "Iteration 14, loss = 1.24966668\n",
      "Iteration 15, loss = 1.24511432\n",
      "Iteration 16, loss = 1.24853779\n",
      "Iteration 2, loss = 1.23899797\n",
      "Iteration 3, loss = 1.24616267\n",
      "Iteration 4, loss = 1.25455178\n",
      "Iteration 5, loss = 1.23896407\n",
      "Iteration 6, loss = 1.26789933\n",
      "Iteration 7, loss = 1.25038300\n",
      "Iteration 8, loss = 1.22869474\n",
      "Iteration 9, loss = 1.24517927\n",
      "Iteration 10, loss = 1.24297750\n",
      "Iteration 11, loss = 1.23270881\n",
      "Iteration 12, loss = 1.24896090\n",
      "Iteration 13, loss = 1.24894434\n",
      "Iteration 14, loss = 1.24966668\n",
      "Iteration 15, loss = 1.24511432\n",
      "Iteration 16, loss = 1.24853779\n",
      "Iteration 17, loss = 1.23708484\n",
      "Iteration 18, loss = 1.23554015\n",
      "Iteration 19, loss = 1.24708043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27173893\n",
      "Iteration 2, loss = 1.21518119\n",
      "Iteration 3, loss = 1.18315849\n",
      "Iteration 4, loss = 1.09524768\n",
      "Iteration 5, loss = 1.03696173\n",
      "Iteration 6, loss = 1.01142011\n",
      "Iteration 7, loss = 1.04291486\n",
      "Iteration 8, loss = 1.00963013\n",
      "Iteration 9, loss = 1.00946157\n",
      "Iteration 10, loss = 1.03594396\n",
      "Iteration 17, loss = 1.23708484\n",
      "Iteration 18, loss = 1.23554015\n",
      "Iteration 19, loss = 1.24708043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27173893\n",
      "Iteration 2, loss = 1.21518119\n",
      "Iteration 3, loss = 1.18315849\n",
      "Iteration 4, loss = 1.09524768\n",
      "Iteration 5, loss = 1.03696173\n",
      "Iteration 6, loss = 1.01142011\n",
      "Iteration 7, loss = 1.04291486\n",
      "Iteration 8, loss = 1.00963013\n",
      "Iteration 9, loss = 1.00946157\n",
      "Iteration 10, loss = 1.03594396\n",
      "Iteration 11, loss = 1.03303724\n",
      "Iteration 12, loss = 1.05764465\n",
      "Iteration 13, loss = 1.08912071\n",
      "Iteration 14, loss = 1.09056625\n",
      "Iteration 15, loss = 1.03017534\n",
      "Iteration 16, loss = 1.01259817\n",
      "Iteration 17, loss = 1.04875357\n",
      "Iteration 18, loss = 1.06815147\n",
      "Iteration 19, loss = 1.06915184\n",
      "Iteration 20, loss = 1.06938652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27094317\n",
      "Iteration 2, loss = 1.24299417\n",
      "Iteration 3, loss = 1.25256959\n",
      "Iteration 4, loss = 1.24914811\n",
      "Iteration 5, loss = 1.25193762\n",
      "Iteration 11, loss = 1.03303724\n",
      "Iteration 12, loss = 1.05764465\n",
      "Iteration 13, loss = 1.08912071\n",
      "Iteration 14, loss = 1.09056625\n",
      "Iteration 15, loss = 1.03017534\n",
      "Iteration 16, loss = 1.01259817\n",
      "Iteration 17, loss = 1.04875357\n",
      "Iteration 18, loss = 1.06815147\n",
      "Iteration 19, loss = 1.06915184\n",
      "Iteration 20, loss = 1.06938652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27094317\n",
      "Iteration 2, loss = 1.24299417\n",
      "Iteration 3, loss = 1.25256959\n",
      "Iteration 4, loss = 1.24914811\n",
      "Iteration 5, loss = 1.25193762\n",
      "Iteration 6, loss = 1.27716512\n",
      "Iteration 7, loss = 1.25329232\n",
      "Iteration 8, loss = 1.24757446\n",
      "Iteration 9, loss = 1.26775892\n",
      "Iteration 10, loss = 1.25449877\n",
      "Iteration 11, loss = 1.28198646\n",
      "Iteration 12, loss = 1.25482794\n",
      "Iteration 13, loss = 1.25388569\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27151723\n",
      "Iteration 2, loss = 1.26356918\n",
      "Iteration 3, loss = 1.27860057\n",
      "Iteration 4, loss = 1.27684847\n",
      "Iteration 5, loss = 1.26766968\n",
      "Iteration 6, loss = 1.26986357\n",
      "Iteration 6, loss = 1.27716512\n",
      "Iteration 7, loss = 1.25329232\n",
      "Iteration 8, loss = 1.24757446\n",
      "Iteration 9, loss = 1.26775892\n",
      "Iteration 10, loss = 1.25449877\n",
      "Iteration 11, loss = 1.28198646\n",
      "Iteration 12, loss = 1.25482794\n",
      "Iteration 13, loss = 1.25388569\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27151723\n",
      "Iteration 2, loss = 1.26356918\n",
      "Iteration 3, loss = 1.27860057\n",
      "Iteration 4, loss = 1.27684847\n",
      "Iteration 5, loss = 1.26766968\n",
      "Iteration 6, loss = 1.26986357\n",
      "Iteration 7, loss = 1.26979080\n",
      "Iteration 8, loss = 1.26681091\n",
      "Iteration 9, loss = 1.27466580\n",
      "Iteration 10, loss = 1.26535155\n",
      "Iteration 11, loss = 1.28295657\n",
      "Iteration 12, loss = 1.25654456\n",
      "Iteration 13, loss = 1.26460303\n",
      "Iteration 14, loss = 1.25398889\n",
      "Iteration 15, loss = 1.26808636\n",
      "Iteration 16, loss = 1.26616957\n",
      "Iteration 17, loss = 1.26945926\n",
      "Iteration 18, loss = 1.25527185\n",
      "Iteration 19, loss = 1.25255319\n",
      "Iteration 20, loss = 1.26703625\n",
      "Iteration 21, loss = 1.27253418\n",
      "Iteration 22, loss = 1.25352217\n",
      "Iteration 7, loss = 1.26979080\n",
      "Iteration 8, loss = 1.26681091\n",
      "Iteration 9, loss = 1.27466580\n",
      "Iteration 10, loss = 1.26535155\n",
      "Iteration 11, loss = 1.28295657\n",
      "Iteration 12, loss = 1.25654456\n",
      "Iteration 13, loss = 1.26460303\n",
      "Iteration 14, loss = 1.25398889\n",
      "Iteration 15, loss = 1.26808636\n",
      "Iteration 16, loss = 1.26616957\n",
      "Iteration 17, loss = 1.26945926\n",
      "Iteration 18, loss = 1.25527185\n",
      "Iteration 19, loss = 1.25255319\n",
      "Iteration 20, loss = 1.26703625\n",
      "Iteration 21, loss = 1.27253418\n",
      "Iteration 22, loss = 1.25352217\n",
      "Iteration 23, loss = 1.26264881\n",
      "Iteration 24, loss = 1.26544420\n",
      "Iteration 25, loss = 1.25993110\n",
      "Iteration 26, loss = 1.26215679\n",
      "Iteration 27, loss = 1.25908939\n",
      "Iteration 28, loss = 1.26763561\n",
      "Iteration 29, loss = 1.25410386\n",
      "Iteration 30, loss = 1.28102183\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26306628\n",
      "Iteration 2, loss = 1.25328841\n",
      "Iteration 3, loss = 1.24175924\n",
      "Iteration 4, loss = 1.25306881\n",
      "Iteration 5, loss = 1.23308769\n",
      "Iteration 6, loss = 1.26015216\n",
      "Iteration 7, loss = 1.24542113\n",
      "Iteration 23, loss = 1.26264881\n",
      "Iteration 24, loss = 1.26544420\n",
      "Iteration 25, loss = 1.25993110\n",
      "Iteration 26, loss = 1.26215679\n",
      "Iteration 27, loss = 1.25908939\n",
      "Iteration 28, loss = 1.26763561\n",
      "Iteration 29, loss = 1.25410386\n",
      "Iteration 30, loss = 1.28102183\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26306628\n",
      "Iteration 2, loss = 1.25328841\n",
      "Iteration 3, loss = 1.24175924\n",
      "Iteration 4, loss = 1.25306881\n",
      "Iteration 5, loss = 1.23308769\n",
      "Iteration 6, loss = 1.26015216\n",
      "Iteration 7, loss = 1.24542113\n",
      "Iteration 8, loss = 1.22830496\n",
      "Iteration 9, loss = 1.23459325\n",
      "Iteration 10, loss = 1.24288882\n",
      "Iteration 1, loss = 1.27770982\n",
      "Iteration 2, loss = 1.24116271\n",
      "Iteration 3, loss = 1.25206802\n",
      "Iteration 4, loss = 1.25951392\n",
      "Iteration 5, loss = 1.24364129\n",
      "Iteration 6, loss = 1.26855508\n",
      "Iteration 7, loss = 1.25992714\n",
      "Iteration 8, loss = 1.23134544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.22830496\n",
      "Iteration 9, loss = 1.23459325\n",
      "Iteration 10, loss = 1.24288882\n",
      "Iteration 1, loss = 1.27770982\n",
      "Iteration 2, loss = 1.24116271\n",
      "Iteration 3, loss = 1.25206802\n",
      "Iteration 4, loss = 1.25951392\n",
      "Iteration 5, loss = 1.24364129\n",
      "Iteration 6, loss = 1.26855508\n",
      "Iteration 7, loss = 1.25992714\n",
      "Iteration 8, loss = 1.23134544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.24953526\n",
      "Iteration 10, loss = 1.24689610\n",
      "Iteration 1, loss = 1.29313158\n",
      "Iteration 2, loss = 1.24896927\n",
      "Iteration 3, loss = 1.27636094\n",
      "Iteration 4, loss = 1.27349082\n",
      "Iteration 5, loss = 1.25732684\n",
      "Iteration 6, loss = 1.27855384\n",
      "Iteration 7, loss = 1.26763575\n",
      "Iteration 8, loss = 1.24712346\n",
      "Iteration 9, loss = 1.26515287\n",
      "Iteration 10, loss = 1.25768965\n",
      "Iteration 9, loss = 1.24953526\n",
      "Iteration 10, loss = 1.24689610\n",
      "Iteration 1, loss = 1.29313158\n",
      "Iteration 2, loss = 1.24896927\n",
      "Iteration 3, loss = 1.27636094\n",
      "Iteration 4, loss = 1.27349082\n",
      "Iteration 5, loss = 1.25732684\n",
      "Iteration 6, loss = 1.27855384\n",
      "Iteration 7, loss = 1.26763575\n",
      "Iteration 8, loss = 1.24712346\n",
      "Iteration 9, loss = 1.26515287\n",
      "Iteration 10, loss = 1.25768965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.30483258\n",
      "Iteration 2, loss = 1.23879073\n",
      "Iteration 3, loss = 1.26307825\n",
      "Iteration 4, loss = 1.25124883\n",
      "Iteration 5, loss = 1.25814534\n",
      "Iteration 6, loss = 1.27508589\n",
      "Iteration 7, loss = 1.26364094\n",
      "Iteration 8, loss = 1.24915483\n",
      "Iteration 9, loss = 1.27691451\n",
      "Iteration 10, loss = 1.25439344\n",
      "Iteration 1, loss = 1.27319392\n",
      "Iteration 2, loss = 1.26309810\n",
      "Iteration 3, loss = 1.28785576\n",
      "Iteration 1, loss = 1.30483258\n",
      "Iteration 2, loss = 1.23879073\n",
      "Iteration 3, loss = 1.26307825\n",
      "Iteration 4, loss = 1.25124883\n",
      "Iteration 5, loss = 1.25814534\n",
      "Iteration 6, loss = 1.27508589\n",
      "Iteration 7, loss = 1.26364094\n",
      "Iteration 8, loss = 1.24915483\n",
      "Iteration 9, loss = 1.27691451\n",
      "Iteration 10, loss = 1.25439344\n",
      "Iteration 1, loss = 1.27319392\n",
      "Iteration 2, loss = 1.26309810\n",
      "Iteration 3, loss = 1.28785576\n",
      "Iteration 4, loss = 1.28750364\n",
      "Iteration 5, loss = 1.27646302\n",
      "Iteration 6, loss = 1.27111448\n",
      "Iteration 7, loss = 1.27642326\n",
      "Iteration 8, loss = 1.26648103\n",
      "Iteration 9, loss = 1.27954929\n",
      "Iteration 10, loss = 1.26734711\n",
      "Iteration 1, loss = 1.26306628\n",
      "Iteration 2, loss = 1.25328841\n",
      "Iteration 3, loss = 1.24175924\n",
      "Iteration 4, loss = 1.25306881\n",
      "Iteration 5, loss = 1.23308769\n",
      "Iteration 4, loss = 1.28750364\n",
      "Iteration 5, loss = 1.27646302\n",
      "Iteration 6, loss = 1.27111448\n",
      "Iteration 7, loss = 1.27642326\n",
      "Iteration 8, loss = 1.26648103\n",
      "Iteration 9, loss = 1.27954929\n",
      "Iteration 10, loss = 1.26734711\n",
      "Iteration 1, loss = 1.26306628\n",
      "Iteration 2, loss = 1.25328841\n",
      "Iteration 3, loss = 1.24175924\n",
      "Iteration 4, loss = 1.25306881\n",
      "Iteration 5, loss = 1.23308769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.26015216\n",
      "Iteration 7, loss = 1.24542113\n",
      "Iteration 8, loss = 1.22830496\n",
      "Iteration 9, loss = 1.23459325\n",
      "Iteration 10, loss = 1.24288882\n",
      "Iteration 11, loss = 1.24377614\n",
      "Iteration 12, loss = 1.24141354\n",
      "Iteration 13, loss = 1.26960869\n",
      "Iteration 14, loss = 1.26857281\n",
      "Iteration 15, loss = 1.24436406\n",
      "Iteration 16, loss = 1.24851913\n",
      "Iteration 17, loss = 1.24320466\n",
      "Iteration 18, loss = 1.24694306\n",
      "Iteration 19, loss = 1.23623725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 1.26015216\n",
      "Iteration 7, loss = 1.24542113\n",
      "Iteration 8, loss = 1.22830496\n",
      "Iteration 9, loss = 1.23459325\n",
      "Iteration 10, loss = 1.24288882\n",
      "Iteration 11, loss = 1.24377614\n",
      "Iteration 12, loss = 1.24141354\n",
      "Iteration 13, loss = 1.26960869\n",
      "Iteration 14, loss = 1.26857281\n",
      "Iteration 15, loss = 1.24436406\n",
      "Iteration 16, loss = 1.24851913\n",
      "Iteration 17, loss = 1.24320466\n",
      "Iteration 18, loss = 1.24694306\n",
      "Iteration 19, loss = 1.23623725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27770982\n",
      "Iteration 2, loss = 1.24116271\n",
      "Iteration 3, loss = 1.25206802\n",
      "Iteration 4, loss = 1.25951392\n",
      "Iteration 5, loss = 1.24364129\n",
      "Iteration 6, loss = 1.26855508\n",
      "Iteration 7, loss = 1.25992714\n",
      "Iteration 8, loss = 1.23134544\n",
      "Iteration 9, loss = 1.24953526\n",
      "Iteration 10, loss = 1.24689610\n",
      "Iteration 11, loss = 1.23552840\n",
      "Iteration 12, loss = 1.24772432\n",
      "Iteration 13, loss = 1.26140502\n",
      "Iteration 14, loss = 1.25685720\n",
      "Iteration 15, loss = 1.25004152\n",
      "Iteration 1, loss = 1.27770982\n",
      "Iteration 2, loss = 1.24116271\n",
      "Iteration 3, loss = 1.25206802\n",
      "Iteration 4, loss = 1.25951392\n",
      "Iteration 5, loss = 1.24364129\n",
      "Iteration 6, loss = 1.26855508\n",
      "Iteration 7, loss = 1.25992714\n",
      "Iteration 8, loss = 1.23134544\n",
      "Iteration 9, loss = 1.24953526\n",
      "Iteration 10, loss = 1.24689610\n",
      "Iteration 11, loss = 1.23552840\n",
      "Iteration 12, loss = 1.24772432\n",
      "Iteration 13, loss = 1.26140502\n",
      "Iteration 14, loss = 1.25685720\n",
      "Iteration 15, loss = 1.25004152\n",
      "Iteration 16, loss = 1.25644698\n",
      "Iteration 17, loss = 1.23947378\n",
      "Iteration 18, loss = 1.23886377\n",
      "Iteration 19, loss = 1.25151488\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29313158\n",
      "Iteration 2, loss = 1.24896927\n",
      "Iteration 3, loss = 1.27636094\n",
      "Iteration 4, loss = 1.27349082\n",
      "Iteration 5, loss = 1.25732684\n",
      "Iteration 6, loss = 1.27855384\n",
      "Iteration 7, loss = 1.26763575\n",
      "Iteration 8, loss = 1.24712346\n",
      "Iteration 9, loss = 1.26515287\n",
      "Iteration 10, loss = 1.25768965\n",
      "Iteration 11, loss = 1.27143531\n",
      "Iteration 16, loss = 1.25644698\n",
      "Iteration 17, loss = 1.23947378\n",
      "Iteration 18, loss = 1.23886377\n",
      "Iteration 19, loss = 1.25151488\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29313158\n",
      "Iteration 2, loss = 1.24896927\n",
      "Iteration 3, loss = 1.27636094\n",
      "Iteration 4, loss = 1.27349082\n",
      "Iteration 5, loss = 1.25732684\n",
      "Iteration 6, loss = 1.27855384\n",
      "Iteration 7, loss = 1.26763575\n",
      "Iteration 8, loss = 1.24712346\n",
      "Iteration 9, loss = 1.26515287\n",
      "Iteration 10, loss = 1.25768965\n",
      "Iteration 11, loss = 1.27143531\n",
      "Iteration 12, loss = 1.26644855\n",
      "Iteration 13, loss = 1.28450468\n",
      "Iteration 14, loss = 1.26983380\n",
      "Iteration 15, loss = 1.26371583\n",
      "Iteration 16, loss = 1.27717440\n",
      "Iteration 17, loss = 1.26116193\n",
      "Iteration 18, loss = 1.26852660\n",
      "Iteration 19, loss = 1.27703553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30483258\n",
      "Iteration 2, loss = 1.23879073\n",
      "Iteration 3, loss = 1.26307825\n",
      "Iteration 4, loss = 1.25124883\n",
      "Iteration 12, loss = 1.26644855\n",
      "Iteration 13, loss = 1.28450468\n",
      "Iteration 14, loss = 1.26983380\n",
      "Iteration 15, loss = 1.26371583\n",
      "Iteration 16, loss = 1.27717440\n",
      "Iteration 17, loss = 1.26116193\n",
      "Iteration 18, loss = 1.26852660\n",
      "Iteration 19, loss = 1.27703553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30483258\n",
      "Iteration 2, loss = 1.23879073\n",
      "Iteration 3, loss = 1.26307825\n",
      "Iteration 4, loss = 1.25124883\n",
      "Iteration 5, loss = 1.25814534\n",
      "Iteration 6, loss = 1.27508589\n",
      "Iteration 7, loss = 1.26364094\n",
      "Iteration 8, loss = 1.24915483\n",
      "Iteration 9, loss = 1.27691451\n",
      "Iteration 10, loss = 1.25439344\n",
      "Iteration 11, loss = 1.29096740\n",
      "Iteration 12, loss = 1.26075836\n",
      "Iteration 13, loss = 1.25990480\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27319392\n",
      "Iteration 2, loss = 1.26309810\n",
      "Iteration 3, loss = 1.28785576\n",
      "Iteration 4, loss = 1.28750364\n",
      "Iteration 5, loss = 1.25814534\n",
      "Iteration 6, loss = 1.27508589\n",
      "Iteration 7, loss = 1.26364094\n",
      "Iteration 8, loss = 1.24915483\n",
      "Iteration 9, loss = 1.27691451\n",
      "Iteration 10, loss = 1.25439344\n",
      "Iteration 11, loss = 1.29096740\n",
      "Iteration 12, loss = 1.26075836\n",
      "Iteration 13, loss = 1.25990480\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27319392\n",
      "Iteration 2, loss = 1.26309810\n",
      "Iteration 3, loss = 1.28785576\n",
      "Iteration 4, loss = 1.28750364\n",
      "Iteration 5, loss = 1.27646302\n",
      "Iteration 6, loss = 1.27111448\n",
      "Iteration 7, loss = 1.27642326\n",
      "Iteration 8, loss = 1.26648103\n",
      "Iteration 9, loss = 1.27954929\n",
      "Iteration 10, loss = 1.26734711\n",
      "Iteration 11, loss = 1.28940803\n",
      "Iteration 12, loss = 1.25960802\n",
      "Iteration 13, loss = 1.26932251\n",
      "Iteration 14, loss = 1.25515730\n",
      "Iteration 15, loss = 1.26986635\n",
      "Iteration 16, loss = 1.27305746\n",
      "Iteration 17, loss = 1.27571701\n",
      "Iteration 18, loss = 1.25392636\n",
      "Iteration 5, loss = 1.27646302\n",
      "Iteration 6, loss = 1.27111448\n",
      "Iteration 7, loss = 1.27642326\n",
      "Iteration 8, loss = 1.26648103\n",
      "Iteration 9, loss = 1.27954929\n",
      "Iteration 10, loss = 1.26734711\n",
      "Iteration 11, loss = 1.28940803\n",
      "Iteration 12, loss = 1.25960802\n",
      "Iteration 13, loss = 1.26932251\n",
      "Iteration 14, loss = 1.25515730\n",
      "Iteration 15, loss = 1.26986635\n",
      "Iteration 16, loss = 1.27305746\n",
      "Iteration 17, loss = 1.27571701\n",
      "Iteration 18, loss = 1.25392636\n",
      "Iteration 19, loss = 1.25347631\n",
      "Iteration 20, loss = 1.27287088\n",
      "Iteration 21, loss = 1.28060510\n",
      "Iteration 22, loss = 1.25731449\n",
      "Iteration 23, loss = 1.26673087\n",
      "Iteration 24, loss = 1.26999048\n",
      "Iteration 25, loss = 1.26308748\n",
      "Iteration 26, loss = 1.26297239\n",
      "Iteration 27, loss = 1.26233300\n",
      "Iteration 28, loss = 1.27178720\n",
      "Iteration 29, loss = 1.25447781\n",
      "Iteration 30, loss = 1.28616015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26306628\n",
      "Iteration 2, loss = 1.25328841\n",
      "Iteration 3, loss = 1.24175924\n",
      "Iteration 4, loss = 1.25306881\n",
      "Iteration 19, loss = 1.25347631\n",
      "Iteration 20, loss = 1.27287088\n",
      "Iteration 21, loss = 1.28060510\n",
      "Iteration 22, loss = 1.25731449\n",
      "Iteration 23, loss = 1.26673087\n",
      "Iteration 24, loss = 1.26999048\n",
      "Iteration 25, loss = 1.26308748\n",
      "Iteration 26, loss = 1.26297239\n",
      "Iteration 27, loss = 1.26233300\n",
      "Iteration 28, loss = 1.27178720\n",
      "Iteration 29, loss = 1.25447781\n",
      "Iteration 30, loss = 1.28616015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26306628\n",
      "Iteration 2, loss = 1.25328841\n",
      "Iteration 3, loss = 1.24175924\n",
      "Iteration 4, loss = 1.25306881\n",
      "Iteration 5, loss = 1.23308769\n",
      "Iteration 6, loss = 1.26015216\n",
      "Iteration 7, loss = 1.24542113\n",
      "Iteration 8, loss = 1.22830496\n",
      "Iteration 9, loss = 1.23459325\n",
      "Iteration 10, loss = 1.24288882\n",
      "Iteration 11, loss = 1.24377614\n",
      "Iteration 12, loss = 1.24141354\n",
      "Iteration 13, loss = 1.26960869\n",
      "Iteration 14, loss = 1.26857281\n",
      "Iteration 15, loss = 1.24436406\n",
      "Iteration 16, loss = 1.24851913\n",
      "Iteration 17, loss = 1.24320466\n",
      "Iteration 18, loss = 1.24694306\n",
      "Iteration 19, loss = 1.23623725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27770982\n",
      "Iteration 5, loss = 1.23308769\n",
      "Iteration 6, loss = 1.26015216\n",
      "Iteration 7, loss = 1.24542113\n",
      "Iteration 8, loss = 1.22830496\n",
      "Iteration 9, loss = 1.23459325\n",
      "Iteration 10, loss = 1.24288882\n",
      "Iteration 11, loss = 1.24377614\n",
      "Iteration 12, loss = 1.24141354\n",
      "Iteration 13, loss = 1.26960869\n",
      "Iteration 14, loss = 1.26857281\n",
      "Iteration 15, loss = 1.24436406\n",
      "Iteration 16, loss = 1.24851913\n",
      "Iteration 17, loss = 1.24320466\n",
      "Iteration 18, loss = 1.24694306\n",
      "Iteration 19, loss = 1.23623725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27770982\n",
      "Iteration 2, loss = 1.24116271\n",
      "Iteration 3, loss = 1.25206802\n",
      "Iteration 4, loss = 1.25951392\n",
      "Iteration 5, loss = 1.24364129\n",
      "Iteration 6, loss = 1.26855508\n",
      "Iteration 7, loss = 1.25992714\n",
      "Iteration 8, loss = 1.23134544\n",
      "Iteration 9, loss = 1.24953526\n",
      "Iteration 10, loss = 1.24689610\n",
      "Iteration 11, loss = 1.23552840\n",
      "Iteration 12, loss = 1.24772432\n",
      "Iteration 13, loss = 1.26140502\n",
      "Iteration 14, loss = 1.25685720\n",
      "Iteration 15, loss = 1.25004152\n",
      "Iteration 16, loss = 1.25644698\n",
      "Iteration 17, loss = 1.23947378\n",
      "Iteration 2, loss = 1.24116271\n",
      "Iteration 3, loss = 1.25206802\n",
      "Iteration 4, loss = 1.25951392\n",
      "Iteration 5, loss = 1.24364129\n",
      "Iteration 6, loss = 1.26855508\n",
      "Iteration 7, loss = 1.25992714\n",
      "Iteration 8, loss = 1.23134544\n",
      "Iteration 9, loss = 1.24953526\n",
      "Iteration 10, loss = 1.24689610\n",
      "Iteration 11, loss = 1.23552840\n",
      "Iteration 12, loss = 1.24772432\n",
      "Iteration 13, loss = 1.26140502\n",
      "Iteration 14, loss = 1.25685720\n",
      "Iteration 15, loss = 1.25004152\n",
      "Iteration 16, loss = 1.25644698\n",
      "Iteration 17, loss = 1.23947378\n",
      "Iteration 18, loss = 1.23886377\n",
      "Iteration 19, loss = 1.25151488\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29313158\n",
      "Iteration 2, loss = 1.24896927\n",
      "Iteration 3, loss = 1.27636094\n",
      "Iteration 4, loss = 1.27349082\n",
      "Iteration 5, loss = 1.25732684\n",
      "Iteration 6, loss = 1.27855384\n",
      "Iteration 7, loss = 1.26763575\n",
      "Iteration 8, loss = 1.24712346\n",
      "Iteration 9, loss = 1.26515287\n",
      "Iteration 10, loss = 1.25768965\n",
      "Iteration 11, loss = 1.27143531\n",
      "Iteration 12, loss = 1.26644855\n",
      "Iteration 13, loss = 1.28450468\n",
      "Iteration 18, loss = 1.23886377\n",
      "Iteration 19, loss = 1.25151488\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29313158\n",
      "Iteration 2, loss = 1.24896927\n",
      "Iteration 3, loss = 1.27636094\n",
      "Iteration 4, loss = 1.27349082\n",
      "Iteration 5, loss = 1.25732684\n",
      "Iteration 6, loss = 1.27855384\n",
      "Iteration 7, loss = 1.26763575\n",
      "Iteration 8, loss = 1.24712346\n",
      "Iteration 9, loss = 1.26515287\n",
      "Iteration 10, loss = 1.25768965\n",
      "Iteration 11, loss = 1.27143531\n",
      "Iteration 12, loss = 1.26644855\n",
      "Iteration 13, loss = 1.28450468\n",
      "Iteration 14, loss = 1.26983380\n",
      "Iteration 15, loss = 1.26371583\n",
      "Iteration 16, loss = 1.27717440\n",
      "Iteration 17, loss = 1.26116193\n",
      "Iteration 18, loss = 1.26852660\n",
      "Iteration 19, loss = 1.27703553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30483258\n",
      "Iteration 2, loss = 1.23879073\n",
      "Iteration 3, loss = 1.26307825\n",
      "Iteration 4, loss = 1.25124883\n",
      "Iteration 5, loss = 1.25814534\n",
      "Iteration 6, loss = 1.27508589\n",
      "Iteration 7, loss = 1.26364094\n",
      "Iteration 8, loss = 1.24915483\n",
      "Iteration 14, loss = 1.26983380\n",
      "Iteration 15, loss = 1.26371583\n",
      "Iteration 16, loss = 1.27717440\n",
      "Iteration 17, loss = 1.26116193\n",
      "Iteration 18, loss = 1.26852660\n",
      "Iteration 19, loss = 1.27703553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30483258\n",
      "Iteration 2, loss = 1.23879073\n",
      "Iteration 3, loss = 1.26307825\n",
      "Iteration 4, loss = 1.25124883\n",
      "Iteration 5, loss = 1.25814534\n",
      "Iteration 6, loss = 1.27508589\n",
      "Iteration 7, loss = 1.26364094\n",
      "Iteration 8, loss = 1.24915483\n",
      "Iteration 9, loss = 1.27691451\n",
      "Iteration 10, loss = 1.25439344\n",
      "Iteration 11, loss = 1.29096740\n",
      "Iteration 12, loss = 1.26075836\n",
      "Iteration 13, loss = 1.25990480\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27319392\n",
      "Iteration 2, loss = 1.26309810\n",
      "Iteration 3, loss = 1.28785576\n",
      "Iteration 4, loss = 1.28750364\n",
      "Iteration 5, loss = 1.27646302\n",
      "Iteration 6, loss = 1.27111448\n",
      "Iteration 7, loss = 1.27642326\n",
      "Iteration 8, loss = 1.26648103\n",
      "Iteration 9, loss = 1.27954929\n",
      "Iteration 9, loss = 1.27691451\n",
      "Iteration 10, loss = 1.25439344\n",
      "Iteration 11, loss = 1.29096740\n",
      "Iteration 12, loss = 1.26075836\n",
      "Iteration 13, loss = 1.25990480\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27319392\n",
      "Iteration 2, loss = 1.26309810\n",
      "Iteration 3, loss = 1.28785576\n",
      "Iteration 4, loss = 1.28750364\n",
      "Iteration 5, loss = 1.27646302\n",
      "Iteration 6, loss = 1.27111448\n",
      "Iteration 7, loss = 1.27642326\n",
      "Iteration 8, loss = 1.26648103\n",
      "Iteration 9, loss = 1.27954929\n",
      "Iteration 10, loss = 1.26734711\n",
      "Iteration 11, loss = 1.28940803\n",
      "Iteration 12, loss = 1.25960802\n",
      "Iteration 13, loss = 1.26932251\n",
      "Iteration 14, loss = 1.25515730\n",
      "Iteration 15, loss = 1.26986635\n",
      "Iteration 16, loss = 1.27305746\n",
      "Iteration 17, loss = 1.27571701\n",
      "Iteration 18, loss = 1.25392636\n",
      "Iteration 19, loss = 1.25347631\n",
      "Iteration 20, loss = 1.27287088\n",
      "Iteration 21, loss = 1.28060510\n",
      "Iteration 22, loss = 1.25731449\n",
      "Iteration 23, loss = 1.26673087\n",
      "Iteration 10, loss = 1.26734711\n",
      "Iteration 11, loss = 1.28940803\n",
      "Iteration 12, loss = 1.25960802\n",
      "Iteration 13, loss = 1.26932251\n",
      "Iteration 14, loss = 1.25515730\n",
      "Iteration 15, loss = 1.26986635\n",
      "Iteration 16, loss = 1.27305746\n",
      "Iteration 17, loss = 1.27571701\n",
      "Iteration 18, loss = 1.25392636\n",
      "Iteration 19, loss = 1.25347631\n",
      "Iteration 20, loss = 1.27287088\n",
      "Iteration 21, loss = 1.28060510\n",
      "Iteration 22, loss = 1.25731449\n",
      "Iteration 23, loss = 1.26673087\n",
      "Iteration 24, loss = 1.26999048\n",
      "Iteration 25, loss = 1.26308748\n",
      "Iteration 26, loss = 1.26297239\n",
      "Iteration 27, loss = 1.26233300\n",
      "Iteration 28, loss = 1.27178720\n",
      "Iteration 29, loss = 1.25447781\n",
      "Iteration 30, loss = 1.28616015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528900\n",
      "Iteration 2, loss = 1.12292931\n",
      "Iteration 3, loss = 1.05766595\n",
      "Iteration 4, loss = 1.00302982\n",
      "Iteration 5, loss = 0.97094682\n",
      "Iteration 6, loss = 0.97845709\n",
      "Iteration 24, loss = 1.26999048\n",
      "Iteration 25, loss = 1.26308748\n",
      "Iteration 26, loss = 1.26297239\n",
      "Iteration 27, loss = 1.26233300\n",
      "Iteration 28, loss = 1.27178720\n",
      "Iteration 29, loss = 1.25447781\n",
      "Iteration 30, loss = 1.28616015\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528900\n",
      "Iteration 2, loss = 1.12292931\n",
      "Iteration 3, loss = 1.05766595\n",
      "Iteration 4, loss = 1.00302982\n",
      "Iteration 5, loss = 0.97094682\n",
      "Iteration 6, loss = 0.97845709\n",
      "Iteration 7, loss = 0.95636455\n",
      "Iteration 8, loss = 0.95850113\n",
      "Iteration 9, loss = 0.96653526\n",
      "Iteration 10, loss = 0.95394163\n",
      "Iteration 1, loss = 1.19654808\n",
      "Iteration 2, loss = 1.02749937\n",
      "Iteration 3, loss = 0.96128687\n",
      "Iteration 4, loss = 0.92397459\n",
      "Iteration 5, loss = 0.89491921\n",
      "Iteration 6, loss = 0.92586457\n",
      "Iteration 7, loss = 0.92674403\n",
      "Iteration 7, loss = 0.95636455\n",
      "Iteration 8, loss = 0.95850113\n",
      "Iteration 9, loss = 0.96653526\n",
      "Iteration 10, loss = 0.95394163\n",
      "Iteration 1, loss = 1.19654808\n",
      "Iteration 2, loss = 1.02749937\n",
      "Iteration 3, loss = 0.96128687\n",
      "Iteration 4, loss = 0.92397459\n",
      "Iteration 5, loss = 0.89491921\n",
      "Iteration 6, loss = 0.92586457\n",
      "Iteration 7, loss = 0.92674403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.94633127\n",
      "Iteration 9, loss = 0.90883866\n",
      "Iteration 10, loss = 0.90231670\n",
      "Iteration 1, loss = 1.25164822\n",
      "Iteration 2, loss = 1.14407153\n",
      "Iteration 3, loss = 1.00412991\n",
      "Iteration 4, loss = 1.01647821\n",
      "Iteration 5, loss = 0.96525501\n",
      "Iteration 6, loss = 0.97649921\n",
      "Iteration 7, loss = 0.96649180\n",
      "Iteration 8, loss = 0.96753363\n",
      "Iteration 8, loss = 0.94633127\n",
      "Iteration 9, loss = 0.90883866\n",
      "Iteration 10, loss = 0.90231670\n",
      "Iteration 1, loss = 1.25164822\n",
      "Iteration 2, loss = 1.14407153\n",
      "Iteration 3, loss = 1.00412991\n",
      "Iteration 4, loss = 1.01647821\n",
      "Iteration 5, loss = 0.96525501\n",
      "Iteration 6, loss = 0.97649921\n",
      "Iteration 7, loss = 0.96649180\n",
      "Iteration 8, loss = 0.96753363\n",
      "Iteration 9, loss = 0.93665294\n",
      "Iteration 10, loss = 0.95619578\n",
      "Iteration 1, loss = 1.23187850\n",
      "Iteration 2, loss = 1.10763697\n",
      "Iteration 3, loss = 1.02388778\n",
      "Iteration 4, loss = 1.02027055\n",
      "Iteration 5, loss = 0.99174807\n",
      "Iteration 6, loss = 0.98962553\n",
      "Iteration 7, loss = 1.00265971\n",
      "Iteration 8, loss = 0.99627557\n",
      "Iteration 9, loss = 0.97292738\n",
      "Iteration 10, loss = 0.96792068\n",
      "Iteration 1, loss = 1.24073950\n",
      "Iteration 9, loss = 0.93665294\n",
      "Iteration 10, loss = 0.95619578\n",
      "Iteration 1, loss = 1.23187850\n",
      "Iteration 2, loss = 1.10763697\n",
      "Iteration 3, loss = 1.02388778\n",
      "Iteration 4, loss = 1.02027055\n",
      "Iteration 5, loss = 0.99174807\n",
      "Iteration 6, loss = 0.98962553\n",
      "Iteration 7, loss = 1.00265971\n",
      "Iteration 8, loss = 0.99627557\n",
      "Iteration 9, loss = 0.97292738\n",
      "Iteration 10, loss = 0.96792068\n",
      "Iteration 1, loss = 1.24073950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.11105198\n",
      "Iteration 3, loss = 1.02496262\n",
      "Iteration 4, loss = 1.00946051\n",
      "Iteration 5, loss = 0.95778084\n",
      "Iteration 6, loss = 0.98335081\n",
      "Iteration 7, loss = 0.95674478\n",
      "Iteration 8, loss = 0.98147800\n",
      "Iteration 9, loss = 0.93205207\n",
      "Iteration 10, loss = 0.91906307\n",
      "Iteration 1, loss = 1.26528900\n",
      "Iteration 2, loss = 1.12292931\n",
      "Iteration 3, loss = 1.05766595\n",
      "Iteration 2, loss = 1.11105198\n",
      "Iteration 3, loss = 1.02496262\n",
      "Iteration 4, loss = 1.00946051\n",
      "Iteration 5, loss = 0.95778084\n",
      "Iteration 6, loss = 0.98335081\n",
      "Iteration 7, loss = 0.95674478\n",
      "Iteration 8, loss = 0.98147800\n",
      "Iteration 9, loss = 0.93205207\n",
      "Iteration 10, loss = 0.91906307\n",
      "Iteration 1, loss = 1.26528900\n",
      "Iteration 2, loss = 1.12292931\n",
      "Iteration 3, loss = 1.05766595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.00302982\n",
      "Iteration 5, loss = 0.97094682\n",
      "Iteration 6, loss = 0.97845709\n",
      "Iteration 7, loss = 0.95636455\n",
      "Iteration 8, loss = 0.95850113\n",
      "Iteration 9, loss = 0.96653526\n",
      "Iteration 10, loss = 0.95394163\n",
      "Iteration 11, loss = 0.93599420\n",
      "Iteration 12, loss = 0.96679951\n",
      "Iteration 13, loss = 0.93781697\n",
      "Iteration 14, loss = 0.94513135\n",
      "Iteration 15, loss = 0.94226803\n",
      "Iteration 16, loss = 0.97475196\n",
      "Iteration 4, loss = 1.00302982\n",
      "Iteration 5, loss = 0.97094682\n",
      "Iteration 6, loss = 0.97845709\n",
      "Iteration 7, loss = 0.95636455\n",
      "Iteration 8, loss = 0.95850113\n",
      "Iteration 9, loss = 0.96653526\n",
      "Iteration 10, loss = 0.95394163\n",
      "Iteration 11, loss = 0.93599420\n",
      "Iteration 12, loss = 0.96679951\n",
      "Iteration 13, loss = 0.93781697\n",
      "Iteration 14, loss = 0.94513135\n",
      "Iteration 15, loss = 0.94226803\n",
      "Iteration 16, loss = 0.97475196\n",
      "Iteration 17, loss = 0.94941344\n",
      "Iteration 18, loss = 0.96609903\n",
      "Iteration 19, loss = 0.93578567\n",
      "Iteration 20, loss = 0.94075286\n",
      "Iteration 21, loss = 0.92627643\n",
      "Iteration 22, loss = 0.93577823\n",
      "Iteration 23, loss = 0.90833175\n",
      "Iteration 24, loss = 0.91000372\n",
      "Iteration 25, loss = 0.90933301\n",
      "Iteration 26, loss = 0.91105209\n",
      "Iteration 27, loss = 0.92021066\n",
      "Iteration 28, loss = 0.89931066\n",
      "Iteration 29, loss = 0.95672340\n",
      "Iteration 30, loss = 0.92894017\n",
      "Iteration 31, loss = 0.89367086\n",
      "Iteration 32, loss = 0.96094732\n",
      "Iteration 17, loss = 0.94941344\n",
      "Iteration 18, loss = 0.96609903\n",
      "Iteration 19, loss = 0.93578567\n",
      "Iteration 20, loss = 0.94075286\n",
      "Iteration 21, loss = 0.92627643\n",
      "Iteration 22, loss = 0.93577823\n",
      "Iteration 23, loss = 0.90833175\n",
      "Iteration 24, loss = 0.91000372\n",
      "Iteration 25, loss = 0.90933301\n",
      "Iteration 26, loss = 0.91105209\n",
      "Iteration 27, loss = 0.92021066\n",
      "Iteration 28, loss = 0.89931066\n",
      "Iteration 29, loss = 0.95672340\n",
      "Iteration 30, loss = 0.92894017\n",
      "Iteration 31, loss = 0.89367086\n",
      "Iteration 32, loss = 0.96094732\n",
      "Iteration 33, loss = 0.94357624\n",
      "Iteration 34, loss = 0.91110634\n",
      "Iteration 35, loss = 0.89867851\n",
      "Iteration 36, loss = 0.90123921\n",
      "Iteration 37, loss = 0.85911132\n",
      "Iteration 38, loss = 0.91059293\n",
      "Iteration 39, loss = 0.90920203\n",
      "Iteration 40, loss = 0.87269246\n",
      "Iteration 41, loss = 0.87404597\n",
      "Iteration 42, loss = 0.85959969\n",
      "Iteration 43, loss = 0.85888235\n",
      "Iteration 44, loss = 0.83043717\n",
      "Iteration 45, loss = 0.87799815\n",
      "Iteration 46, loss = 0.86209454\n",
      "Iteration 47, loss = 0.86772097\n",
      "Iteration 48, loss = 0.85846941\n",
      "Iteration 33, loss = 0.94357624\n",
      "Iteration 34, loss = 0.91110634\n",
      "Iteration 35, loss = 0.89867851\n",
      "Iteration 36, loss = 0.90123921\n",
      "Iteration 37, loss = 0.85911132\n",
      "Iteration 38, loss = 0.91059293\n",
      "Iteration 39, loss = 0.90920203\n",
      "Iteration 40, loss = 0.87269246\n",
      "Iteration 41, loss = 0.87404597\n",
      "Iteration 42, loss = 0.85959969\n",
      "Iteration 43, loss = 0.85888235\n",
      "Iteration 44, loss = 0.83043717\n",
      "Iteration 45, loss = 0.87799815\n",
      "Iteration 46, loss = 0.86209454\n",
      "Iteration 47, loss = 0.86772097\n",
      "Iteration 48, loss = 0.85846941\n",
      "Iteration 49, loss = 0.86282671\n",
      "Iteration 50, loss = 0.84846196\n",
      "Iteration 1, loss = 1.19654808\n",
      "Iteration 2, loss = 1.02749937\n",
      "Iteration 3, loss = 0.96128687\n",
      "Iteration 4, loss = 0.92397459\n",
      "Iteration 5, loss = 0.89491921\n",
      "Iteration 6, loss = 0.92586457\n",
      "Iteration 7, loss = 0.92674403\n",
      "Iteration 8, loss = 0.94633127\n",
      "Iteration 9, loss = 0.90883866\n",
      "Iteration 10, loss = 0.90231670\n",
      "Iteration 11, loss = 0.89187237\n",
      "Iteration 12, loss = 0.92590695\n",
      "Iteration 13, loss = 0.89975364\n",
      "Iteration 14, loss = 0.88766639\n",
      "Iteration 15, loss = 0.88344580\n",
      "Iteration 49, loss = 0.86282671\n",
      "Iteration 50, loss = 0.84846196\n",
      "Iteration 1, loss = 1.19654808\n",
      "Iteration 2, loss = 1.02749937\n",
      "Iteration 3, loss = 0.96128687\n",
      "Iteration 4, loss = 0.92397459\n",
      "Iteration 5, loss = 0.89491921\n",
      "Iteration 6, loss = 0.92586457\n",
      "Iteration 7, loss = 0.92674403\n",
      "Iteration 8, loss = 0.94633127\n",
      "Iteration 9, loss = 0.90883866\n",
      "Iteration 10, loss = 0.90231670\n",
      "Iteration 11, loss = 0.89187237\n",
      "Iteration 12, loss = 0.92590695\n",
      "Iteration 13, loss = 0.89975364\n",
      "Iteration 14, loss = 0.88766639\n",
      "Iteration 15, loss = 0.88344580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, loss = 0.91475697\n",
      "Iteration 17, loss = 0.88042401\n",
      "Iteration 18, loss = 0.94658612\n",
      "Iteration 19, loss = 0.96057267\n",
      "Iteration 20, loss = 0.90755426\n",
      "Iteration 21, loss = 0.87686499\n",
      "Iteration 22, loss = 0.87029456\n",
      "Iteration 23, loss = 0.91480000\n",
      "Iteration 24, loss = 0.92746873\n",
      "Iteration 25, loss = 0.88621250\n",
      "Iteration 26, loss = 0.86765460\n",
      "Iteration 27, loss = 0.87154759\n",
      "Iteration 28, loss = 0.88284695\n",
      "Iteration 29, loss = 0.91203471\n",
      "Iteration 30, loss = 0.86389369\n",
      "Iteration 31, loss = 0.79943453\n",
      "Iteration 16, loss = 0.91475697\n",
      "Iteration 17, loss = 0.88042401\n",
      "Iteration 18, loss = 0.94658612\n",
      "Iteration 19, loss = 0.96057267\n",
      "Iteration 20, loss = 0.90755426\n",
      "Iteration 21, loss = 0.87686499\n",
      "Iteration 22, loss = 0.87029456\n",
      "Iteration 23, loss = 0.91480000\n",
      "Iteration 24, loss = 0.92746873\n",
      "Iteration 25, loss = 0.88621250\n",
      "Iteration 26, loss = 0.86765460\n",
      "Iteration 27, loss = 0.87154759\n",
      "Iteration 28, loss = 0.88284695\n",
      "Iteration 29, loss = 0.91203471\n",
      "Iteration 30, loss = 0.86389369\n",
      "Iteration 31, loss = 0.79943453\n",
      "Iteration 32, loss = 0.96819443\n",
      "Iteration 33, loss = 0.85408304\n",
      "Iteration 34, loss = 0.83376433\n",
      "Iteration 35, loss = 0.82520118\n",
      "Iteration 36, loss = 0.85317791\n",
      "Iteration 37, loss = 0.85206952\n",
      "Iteration 38, loss = 0.81078560\n",
      "Iteration 39, loss = 0.81501532\n",
      "Iteration 40, loss = 0.80958746\n",
      "Iteration 41, loss = 0.78867499\n",
      "Iteration 42, loss = 0.75237997\n",
      "Iteration 43, loss = 0.82249603\n",
      "Iteration 44, loss = 0.77492483\n",
      "Iteration 45, loss = 0.76123619\n",
      "Iteration 46, loss = 0.82299127\n",
      "Iteration 47, loss = 0.81165445\n",
      "Iteration 48, loss = 0.78988485\n",
      "Iteration 49, loss = 0.75087167\n",
      "Iteration 32, loss = 0.96819443\n",
      "Iteration 33, loss = 0.85408304\n",
      "Iteration 34, loss = 0.83376433\n",
      "Iteration 35, loss = 0.82520118\n",
      "Iteration 36, loss = 0.85317791\n",
      "Iteration 37, loss = 0.85206952\n",
      "Iteration 38, loss = 0.81078560\n",
      "Iteration 39, loss = 0.81501532\n",
      "Iteration 40, loss = 0.80958746\n",
      "Iteration 41, loss = 0.78867499\n",
      "Iteration 42, loss = 0.75237997\n",
      "Iteration 43, loss = 0.82249603\n",
      "Iteration 44, loss = 0.77492483\n",
      "Iteration 45, loss = 0.76123619\n",
      "Iteration 46, loss = 0.82299127\n",
      "Iteration 47, loss = 0.81165445\n",
      "Iteration 48, loss = 0.78988485\n",
      "Iteration 49, loss = 0.75087167\n",
      "Iteration 50, loss = 0.79132480\n",
      "Iteration 1, loss = 1.25164822\n",
      "Iteration 2, loss = 1.14407153\n",
      "Iteration 3, loss = 1.00412991\n",
      "Iteration 4, loss = 1.01647821\n",
      "Iteration 5, loss = 0.96525501\n",
      "Iteration 6, loss = 0.97649921\n",
      "Iteration 7, loss = 0.96649180\n",
      "Iteration 8, loss = 0.96753363\n",
      "Iteration 9, loss = 0.93665294\n",
      "Iteration 10, loss = 0.95619578\n",
      "Iteration 11, loss = 0.93439592\n",
      "Iteration 50, loss = 0.79132480\n",
      "Iteration 1, loss = 1.25164822\n",
      "Iteration 2, loss = 1.14407153\n",
      "Iteration 3, loss = 1.00412991\n",
      "Iteration 4, loss = 1.01647821\n",
      "Iteration 5, loss = 0.96525501\n",
      "Iteration 6, loss = 0.97649921\n",
      "Iteration 7, loss = 0.96649180\n",
      "Iteration 8, loss = 0.96753363\n",
      "Iteration 9, loss = 0.93665294\n",
      "Iteration 10, loss = 0.95619578\n",
      "Iteration 11, loss = 0.93439592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.91381787\n",
      "Iteration 13, loss = 0.93595529\n",
      "Iteration 14, loss = 0.92803849\n",
      "Iteration 15, loss = 0.90359084\n",
      "Iteration 16, loss = 0.92027329\n",
      "Iteration 17, loss = 0.94359087\n",
      "Iteration 18, loss = 0.91014875\n",
      "Iteration 19, loss = 0.93472433\n",
      "Iteration 20, loss = 0.95206173\n",
      "Iteration 21, loss = 0.93976889\n",
      "Iteration 22, loss = 0.91955430\n",
      "Iteration 23, loss = 0.91009584\n",
      "Iteration 24, loss = 0.94261250\n",
      "Iteration 25, loss = 0.91502118\n",
      "Iteration 26, loss = 0.89793766\n",
      "Iteration 27, loss = 0.92010079\n",
      "Iteration 28, loss = 0.93195498\n",
      "Iteration 12, loss = 0.91381787\n",
      "Iteration 13, loss = 0.93595529\n",
      "Iteration 14, loss = 0.92803849\n",
      "Iteration 15, loss = 0.90359084\n",
      "Iteration 16, loss = 0.92027329\n",
      "Iteration 17, loss = 0.94359087\n",
      "Iteration 18, loss = 0.91014875\n",
      "Iteration 19, loss = 0.93472433\n",
      "Iteration 20, loss = 0.95206173\n",
      "Iteration 21, loss = 0.93976889\n",
      "Iteration 22, loss = 0.91955430\n",
      "Iteration 23, loss = 0.91009584\n",
      "Iteration 24, loss = 0.94261250\n",
      "Iteration 25, loss = 0.91502118\n",
      "Iteration 26, loss = 0.89793766\n",
      "Iteration 27, loss = 0.92010079\n",
      "Iteration 28, loss = 0.93195498\n",
      "Iteration 29, loss = 0.92860700\n",
      "Iteration 30, loss = 0.89682697\n",
      "Iteration 31, loss = 0.88203122\n",
      "Iteration 32, loss = 0.90553438\n",
      "Iteration 33, loss = 0.90988853\n",
      "Iteration 34, loss = 0.92514058\n",
      "Iteration 35, loss = 0.92179744\n",
      "Iteration 36, loss = 0.91540314\n",
      "Iteration 37, loss = 0.87287280\n",
      "Iteration 38, loss = 0.85549657\n",
      "Iteration 39, loss = 0.85143952\n",
      "Iteration 40, loss = 0.85946932\n",
      "Iteration 41, loss = 0.92407302\n",
      "Iteration 42, loss = 0.85043069\n",
      "Iteration 43, loss = 0.90679360\n",
      "Iteration 44, loss = 0.90558334\n",
      "Iteration 29, loss = 0.92860700\n",
      "Iteration 30, loss = 0.89682697\n",
      "Iteration 31, loss = 0.88203122\n",
      "Iteration 32, loss = 0.90553438\n",
      "Iteration 33, loss = 0.90988853\n",
      "Iteration 34, loss = 0.92514058\n",
      "Iteration 35, loss = 0.92179744\n",
      "Iteration 36, loss = 0.91540314\n",
      "Iteration 37, loss = 0.87287280\n",
      "Iteration 38, loss = 0.85549657\n",
      "Iteration 39, loss = 0.85143952\n",
      "Iteration 40, loss = 0.85946932\n",
      "Iteration 41, loss = 0.92407302\n",
      "Iteration 42, loss = 0.85043069\n",
      "Iteration 43, loss = 0.90679360\n",
      "Iteration 44, loss = 0.90558334\n",
      "Iteration 45, loss = 0.93328893\n",
      "Iteration 46, loss = 0.89131829\n",
      "Iteration 47, loss = 0.87565385\n",
      "Iteration 48, loss = 0.87486417\n",
      "Iteration 49, loss = 0.85990000\n",
      "Iteration 50, loss = 0.83812957\n",
      "Iteration 1, loss = 1.23187850\n",
      "Iteration 2, loss = 1.10763697\n",
      "Iteration 3, loss = 1.02388778\n",
      "Iteration 4, loss = 1.02027055\n",
      "Iteration 5, loss = 0.99174807\n",
      "Iteration 6, loss = 0.98962553\n",
      "Iteration 7, loss = 1.00265971\n",
      "Iteration 45, loss = 0.93328893\n",
      "Iteration 46, loss = 0.89131829\n",
      "Iteration 47, loss = 0.87565385\n",
      "Iteration 48, loss = 0.87486417\n",
      "Iteration 49, loss = 0.85990000\n",
      "Iteration 50, loss = 0.83812957\n",
      "Iteration 1, loss = 1.23187850\n",
      "Iteration 2, loss = 1.10763697\n",
      "Iteration 3, loss = 1.02388778\n",
      "Iteration 4, loss = 1.02027055\n",
      "Iteration 5, loss = 0.99174807\n",
      "Iteration 6, loss = 0.98962553\n",
      "Iteration 7, loss = 1.00265971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.99627557\n",
      "Iteration 9, loss = 0.97292738\n",
      "Iteration 10, loss = 0.96792068\n",
      "Iteration 11, loss = 0.94928238\n",
      "Iteration 12, loss = 0.92652208\n",
      "Iteration 13, loss = 0.95268971\n",
      "Iteration 14, loss = 0.94240347\n",
      "Iteration 15, loss = 0.95077629\n",
      "Iteration 16, loss = 0.91899162\n",
      "Iteration 17, loss = 0.93569054\n",
      "Iteration 18, loss = 0.91052030\n",
      "Iteration 19, loss = 0.93451853\n",
      "Iteration 20, loss = 0.92794006\n",
      "Iteration 21, loss = 0.93300867\n",
      "Iteration 22, loss = 0.88288403\n",
      "Iteration 8, loss = 0.99627557\n",
      "Iteration 9, loss = 0.97292738\n",
      "Iteration 10, loss = 0.96792068\n",
      "Iteration 11, loss = 0.94928238\n",
      "Iteration 12, loss = 0.92652208\n",
      "Iteration 13, loss = 0.95268971\n",
      "Iteration 14, loss = 0.94240347\n",
      "Iteration 15, loss = 0.95077629\n",
      "Iteration 16, loss = 0.91899162\n",
      "Iteration 17, loss = 0.93569054\n",
      "Iteration 18, loss = 0.91052030\n",
      "Iteration 19, loss = 0.93451853\n",
      "Iteration 20, loss = 0.92794006\n",
      "Iteration 21, loss = 0.93300867\n",
      "Iteration 22, loss = 0.88288403\n",
      "Iteration 23, loss = 0.89218192\n",
      "Iteration 24, loss = 0.88835074\n",
      "Iteration 25, loss = 0.90758353\n",
      "Iteration 26, loss = 0.88823502\n",
      "Iteration 27, loss = 0.89678708\n",
      "Iteration 28, loss = 0.99457392\n",
      "Iteration 29, loss = 0.91863311\n",
      "Iteration 30, loss = 0.87260710\n",
      "Iteration 31, loss = 0.89737961\n",
      "Iteration 32, loss = 0.84808945\n",
      "Iteration 33, loss = 0.85870093\n",
      "Iteration 34, loss = 0.88251749\n",
      "Iteration 35, loss = 0.84469555\n",
      "Iteration 36, loss = 0.85234489\n",
      "Iteration 37, loss = 0.89142420\n",
      "Iteration 38, loss = 0.84536389\n",
      "Iteration 39, loss = 0.84052033\n",
      "Iteration 40, loss = 0.80755177\n",
      "Iteration 23, loss = 0.89218192\n",
      "Iteration 24, loss = 0.88835074\n",
      "Iteration 25, loss = 0.90758353\n",
      "Iteration 26, loss = 0.88823502\n",
      "Iteration 27, loss = 0.89678708\n",
      "Iteration 28, loss = 0.99457392\n",
      "Iteration 29, loss = 0.91863311\n",
      "Iteration 30, loss = 0.87260710\n",
      "Iteration 31, loss = 0.89737961\n",
      "Iteration 32, loss = 0.84808945\n",
      "Iteration 33, loss = 0.85870093\n",
      "Iteration 34, loss = 0.88251749\n",
      "Iteration 35, loss = 0.84469555\n",
      "Iteration 36, loss = 0.85234489\n",
      "Iteration 37, loss = 0.89142420\n",
      "Iteration 38, loss = 0.84536389\n",
      "Iteration 39, loss = 0.84052033\n",
      "Iteration 40, loss = 0.80755177\n",
      "Iteration 41, loss = 0.79677806\n",
      "Iteration 42, loss = 0.81947352\n",
      "Iteration 43, loss = 0.81363874\n",
      "Iteration 44, loss = 0.80387691\n",
      "Iteration 45, loss = 0.86841097\n",
      "Iteration 46, loss = 0.86496436\n",
      "Iteration 47, loss = 0.81803490\n",
      "Iteration 48, loss = 0.87558868\n",
      "Iteration 49, loss = 0.82541836\n",
      "Iteration 50, loss = 0.80787498\n",
      "Iteration 1, loss = 1.24073950\n",
      "Iteration 2, loss = 1.11105198\n",
      "Iteration 3, loss = 1.02496262\n",
      "Iteration 4, loss = 1.00946051\n",
      "Iteration 5, loss = 0.95778084\n",
      "Iteration 41, loss = 0.79677806\n",
      "Iteration 42, loss = 0.81947352\n",
      "Iteration 43, loss = 0.81363874\n",
      "Iteration 44, loss = 0.80387691\n",
      "Iteration 45, loss = 0.86841097\n",
      "Iteration 46, loss = 0.86496436\n",
      "Iteration 47, loss = 0.81803490\n",
      "Iteration 48, loss = 0.87558868\n",
      "Iteration 49, loss = 0.82541836\n",
      "Iteration 50, loss = 0.80787498\n",
      "Iteration 1, loss = 1.24073950\n",
      "Iteration 2, loss = 1.11105198\n",
      "Iteration 3, loss = 1.02496262\n",
      "Iteration 4, loss = 1.00946051\n",
      "Iteration 5, loss = 0.95778084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.98335081\n",
      "Iteration 7, loss = 0.95674478\n",
      "Iteration 8, loss = 0.98147800\n",
      "Iteration 9, loss = 0.93205207\n",
      "Iteration 10, loss = 0.91906307\n",
      "Iteration 11, loss = 0.93853374\n",
      "Iteration 12, loss = 0.93158359\n",
      "Iteration 13, loss = 0.92853181\n",
      "Iteration 14, loss = 0.91910564\n",
      "Iteration 15, loss = 0.89350867\n",
      "Iteration 16, loss = 0.88897792\n",
      "Iteration 17, loss = 0.91813376\n",
      "Iteration 18, loss = 0.91960600\n",
      "Iteration 19, loss = 0.89820069\n",
      "Iteration 6, loss = 0.98335081\n",
      "Iteration 7, loss = 0.95674478\n",
      "Iteration 8, loss = 0.98147800\n",
      "Iteration 9, loss = 0.93205207\n",
      "Iteration 10, loss = 0.91906307\n",
      "Iteration 11, loss = 0.93853374\n",
      "Iteration 12, loss = 0.93158359\n",
      "Iteration 13, loss = 0.92853181\n",
      "Iteration 14, loss = 0.91910564\n",
      "Iteration 15, loss = 0.89350867\n",
      "Iteration 16, loss = 0.88897792\n",
      "Iteration 17, loss = 0.91813376\n",
      "Iteration 18, loss = 0.91960600\n",
      "Iteration 19, loss = 0.89820069\n",
      "Iteration 20, loss = 0.89712083\n",
      "Iteration 21, loss = 0.91277487\n",
      "Iteration 22, loss = 0.93900199\n",
      "Iteration 23, loss = 0.92153985\n",
      "Iteration 24, loss = 0.92543136\n",
      "Iteration 25, loss = 0.91150891\n",
      "Iteration 26, loss = 0.91261412\n",
      "Iteration 27, loss = 0.89965547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528900\n",
      "Iteration 2, loss = 1.12292931\n",
      "Iteration 3, loss = 1.05766595\n",
      "Iteration 4, loss = 1.00302982\n",
      "Iteration 5, loss = 0.97094682\n",
      "Iteration 6, loss = 0.97845709\n",
      "Iteration 20, loss = 0.89712083\n",
      "Iteration 21, loss = 0.91277487\n",
      "Iteration 22, loss = 0.93900199\n",
      "Iteration 23, loss = 0.92153985\n",
      "Iteration 24, loss = 0.92543136\n",
      "Iteration 25, loss = 0.91150891\n",
      "Iteration 26, loss = 0.91261412\n",
      "Iteration 27, loss = 0.89965547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528900\n",
      "Iteration 2, loss = 1.12292931\n",
      "Iteration 3, loss = 1.05766595\n",
      "Iteration 4, loss = 1.00302982\n",
      "Iteration 5, loss = 0.97094682\n",
      "Iteration 6, loss = 0.97845709\n",
      "Iteration 7, loss = 0.95636455\n",
      "Iteration 8, loss = 0.95850113\n",
      "Iteration 9, loss = 0.96653526\n",
      "Iteration 10, loss = 0.95394163\n",
      "Iteration 11, loss = 0.93599420\n",
      "Iteration 12, loss = 0.96679951\n",
      "Iteration 13, loss = 0.93781697\n",
      "Iteration 14, loss = 0.94513135\n",
      "Iteration 15, loss = 0.94226803\n",
      "Iteration 16, loss = 0.97475196\n",
      "Iteration 17, loss = 0.94941344\n",
      "Iteration 18, loss = 0.96609903\n",
      "Iteration 19, loss = 0.93578567\n",
      "Iteration 20, loss = 0.94075286\n",
      "Iteration 7, loss = 0.95636455\n",
      "Iteration 8, loss = 0.95850113\n",
      "Iteration 9, loss = 0.96653526\n",
      "Iteration 10, loss = 0.95394163\n",
      "Iteration 11, loss = 0.93599420\n",
      "Iteration 12, loss = 0.96679951\n",
      "Iteration 13, loss = 0.93781697\n",
      "Iteration 14, loss = 0.94513135\n",
      "Iteration 15, loss = 0.94226803\n",
      "Iteration 16, loss = 0.97475196\n",
      "Iteration 17, loss = 0.94941344\n",
      "Iteration 18, loss = 0.96609903\n",
      "Iteration 19, loss = 0.93578567\n",
      "Iteration 20, loss = 0.94075286\n",
      "Iteration 21, loss = 0.92627643\n",
      "Iteration 22, loss = 0.93577823\n",
      "Iteration 23, loss = 0.90833175\n",
      "Iteration 24, loss = 0.91000372\n",
      "Iteration 25, loss = 0.90933301\n",
      "Iteration 26, loss = 0.91105209\n",
      "Iteration 27, loss = 0.92021066\n",
      "Iteration 28, loss = 0.89931066\n",
      "Iteration 29, loss = 0.95672340\n",
      "Iteration 30, loss = 0.92894017\n",
      "Iteration 31, loss = 0.89367086\n",
      "Iteration 32, loss = 0.96094732\n",
      "Iteration 33, loss = 0.94357624\n",
      "Iteration 34, loss = 0.91110634\n",
      "Iteration 35, loss = 0.89867851\n",
      "Iteration 36, loss = 0.90123921\n",
      "Iteration 37, loss = 0.85911132\n",
      "Iteration 21, loss = 0.92627643\n",
      "Iteration 22, loss = 0.93577823\n",
      "Iteration 23, loss = 0.90833175\n",
      "Iteration 24, loss = 0.91000372\n",
      "Iteration 25, loss = 0.90933301\n",
      "Iteration 26, loss = 0.91105209\n",
      "Iteration 27, loss = 0.92021066\n",
      "Iteration 28, loss = 0.89931066\n",
      "Iteration 29, loss = 0.95672340\n",
      "Iteration 30, loss = 0.92894017\n",
      "Iteration 31, loss = 0.89367086\n",
      "Iteration 32, loss = 0.96094732\n",
      "Iteration 33, loss = 0.94357624\n",
      "Iteration 34, loss = 0.91110634\n",
      "Iteration 35, loss = 0.89867851\n",
      "Iteration 36, loss = 0.90123921\n",
      "Iteration 37, loss = 0.85911132\n",
      "Iteration 38, loss = 0.91059293\n",
      "Iteration 39, loss = 0.90920203\n",
      "Iteration 40, loss = 0.87269246\n",
      "Iteration 41, loss = 0.87404597\n",
      "Iteration 42, loss = 0.85959969\n",
      "Iteration 43, loss = 0.85888235\n",
      "Iteration 44, loss = 0.83043717\n",
      "Iteration 45, loss = 0.87799815\n",
      "Iteration 46, loss = 0.86209454\n",
      "Iteration 47, loss = 0.86772097\n",
      "Iteration 48, loss = 0.85846941\n",
      "Iteration 49, loss = 0.86282671\n",
      "Iteration 50, loss = 0.84846196\n",
      "Iteration 51, loss = 0.83240698\n",
      "Iteration 52, loss = 0.81485205\n",
      "Iteration 53, loss = 0.84929219\n",
      "Iteration 54, loss = 0.78554390\n",
      "Iteration 38, loss = 0.91059293\n",
      "Iteration 39, loss = 0.90920203\n",
      "Iteration 40, loss = 0.87269246\n",
      "Iteration 41, loss = 0.87404597\n",
      "Iteration 42, loss = 0.85959969\n",
      "Iteration 43, loss = 0.85888235\n",
      "Iteration 44, loss = 0.83043717\n",
      "Iteration 45, loss = 0.87799815\n",
      "Iteration 46, loss = 0.86209454\n",
      "Iteration 47, loss = 0.86772097\n",
      "Iteration 48, loss = 0.85846941\n",
      "Iteration 49, loss = 0.86282671\n",
      "Iteration 50, loss = 0.84846196\n",
      "Iteration 51, loss = 0.83240698\n",
      "Iteration 52, loss = 0.81485205\n",
      "Iteration 53, loss = 0.84929219\n",
      "Iteration 54, loss = 0.78554390\n",
      "Iteration 55, loss = 0.78807178\n",
      "Iteration 56, loss = 0.85036846\n",
      "Iteration 57, loss = 0.86766317\n",
      "Iteration 58, loss = 0.80718326\n",
      "Iteration 59, loss = 0.78677976\n",
      "Iteration 60, loss = 0.83770041\n",
      "Iteration 61, loss = 0.83695613\n",
      "Iteration 62, loss = 0.79387457\n",
      "Iteration 63, loss = 0.79541772\n",
      "Iteration 64, loss = 0.77561296\n",
      "Iteration 65, loss = 0.78966221\n",
      "Iteration 66, loss = 0.82475553\n",
      "Iteration 67, loss = 0.80059991\n",
      "Iteration 68, loss = 0.78237459\n",
      "Iteration 69, loss = 0.76575693\n",
      "Iteration 70, loss = 0.77235882\n",
      "Iteration 55, loss = 0.78807178\n",
      "Iteration 56, loss = 0.85036846\n",
      "Iteration 57, loss = 0.86766317\n",
      "Iteration 58, loss = 0.80718326\n",
      "Iteration 59, loss = 0.78677976\n",
      "Iteration 60, loss = 0.83770041\n",
      "Iteration 61, loss = 0.83695613\n",
      "Iteration 62, loss = 0.79387457\n",
      "Iteration 63, loss = 0.79541772\n",
      "Iteration 64, loss = 0.77561296\n",
      "Iteration 65, loss = 0.78966221\n",
      "Iteration 66, loss = 0.82475553\n",
      "Iteration 67, loss = 0.80059991\n",
      "Iteration 68, loss = 0.78237459\n",
      "Iteration 69, loss = 0.76575693\n",
      "Iteration 70, loss = 0.77235882\n",
      "Iteration 71, loss = 0.79427125\n",
      "Iteration 72, loss = 0.77737091\n",
      "Iteration 73, loss = 0.79220080\n",
      "Iteration 74, loss = 0.79755705\n",
      "Iteration 75, loss = 0.75230077\n",
      "Iteration 76, loss = 0.76857555\n",
      "Iteration 77, loss = 0.76474494\n",
      "Iteration 78, loss = 0.75538808\n",
      "Iteration 79, loss = 0.77049476\n",
      "Iteration 80, loss = 0.79112739\n",
      "Iteration 81, loss = 0.74790834\n",
      "Iteration 82, loss = 0.73608923\n",
      "Iteration 83, loss = 0.78247039\n",
      "Iteration 84, loss = 0.73019514\n",
      "Iteration 85, loss = 0.75348545\n",
      "Iteration 86, loss = 0.72699450\n",
      "Iteration 87, loss = 0.75667829\n",
      "Iteration 88, loss = 0.77562004\n",
      "Iteration 71, loss = 0.79427125\n",
      "Iteration 72, loss = 0.77737091\n",
      "Iteration 73, loss = 0.79220080\n",
      "Iteration 74, loss = 0.79755705\n",
      "Iteration 75, loss = 0.75230077\n",
      "Iteration 76, loss = 0.76857555\n",
      "Iteration 77, loss = 0.76474494\n",
      "Iteration 78, loss = 0.75538808\n",
      "Iteration 79, loss = 0.77049476\n",
      "Iteration 80, loss = 0.79112739\n",
      "Iteration 81, loss = 0.74790834\n",
      "Iteration 82, loss = 0.73608923\n",
      "Iteration 83, loss = 0.78247039\n",
      "Iteration 84, loss = 0.73019514\n",
      "Iteration 85, loss = 0.75348545\n",
      "Iteration 86, loss = 0.72699450\n",
      "Iteration 87, loss = 0.75667829\n",
      "Iteration 88, loss = 0.77562004\n",
      "Iteration 89, loss = 0.73537721\n",
      "Iteration 90, loss = 0.74681600\n",
      "Iteration 91, loss = 0.71222380\n",
      "Iteration 92, loss = 0.74557425\n",
      "Iteration 93, loss = 0.77221546\n",
      "Iteration 94, loss = 0.80289411\n",
      "Iteration 95, loss = 0.76732668\n",
      "Iteration 96, loss = 0.80896562\n",
      "Iteration 97, loss = 0.72995135\n",
      "Iteration 98, loss = 0.77035285\n",
      "Iteration 99, loss = 0.74884206\n",
      "Iteration 100, loss = 0.74700761\n",
      "Iteration 1, loss = 1.19654808\n",
      "Iteration 2, loss = 1.02749937\n",
      "Iteration 3, loss = 0.96128687\n",
      "Iteration 4, loss = 0.92397459\n",
      "Iteration 5, loss = 0.89491921\n",
      "Iteration 89, loss = 0.73537721\n",
      "Iteration 90, loss = 0.74681600\n",
      "Iteration 91, loss = 0.71222380\n",
      "Iteration 92, loss = 0.74557425\n",
      "Iteration 93, loss = 0.77221546\n",
      "Iteration 94, loss = 0.80289411\n",
      "Iteration 95, loss = 0.76732668\n",
      "Iteration 96, loss = 0.80896562\n",
      "Iteration 97, loss = 0.72995135\n",
      "Iteration 98, loss = 0.77035285\n",
      "Iteration 99, loss = 0.74884206\n",
      "Iteration 100, loss = 0.74700761\n",
      "Iteration 1, loss = 1.19654808\n",
      "Iteration 2, loss = 1.02749937\n",
      "Iteration 3, loss = 0.96128687\n",
      "Iteration 4, loss = 0.92397459\n",
      "Iteration 5, loss = 0.89491921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.92586457\n",
      "Iteration 7, loss = 0.92674403\n",
      "Iteration 8, loss = 0.94633127\n",
      "Iteration 9, loss = 0.90883866\n",
      "Iteration 10, loss = 0.90231670\n",
      "Iteration 11, loss = 0.89187237\n",
      "Iteration 12, loss = 0.92590695\n",
      "Iteration 13, loss = 0.89975364\n",
      "Iteration 14, loss = 0.88766639\n",
      "Iteration 15, loss = 0.88344580\n",
      "Iteration 16, loss = 0.91475697\n",
      "Iteration 17, loss = 0.88042401\n",
      "Iteration 18, loss = 0.94658612\n",
      "Iteration 19, loss = 0.96057267\n",
      "Iteration 6, loss = 0.92586457\n",
      "Iteration 7, loss = 0.92674403\n",
      "Iteration 8, loss = 0.94633127\n",
      "Iteration 9, loss = 0.90883866\n",
      "Iteration 10, loss = 0.90231670\n",
      "Iteration 11, loss = 0.89187237\n",
      "Iteration 12, loss = 0.92590695\n",
      "Iteration 13, loss = 0.89975364\n",
      "Iteration 14, loss = 0.88766639\n",
      "Iteration 15, loss = 0.88344580\n",
      "Iteration 16, loss = 0.91475697\n",
      "Iteration 17, loss = 0.88042401\n",
      "Iteration 18, loss = 0.94658612\n",
      "Iteration 19, loss = 0.96057267\n",
      "Iteration 20, loss = 0.90755426\n",
      "Iteration 21, loss = 0.87686499\n",
      "Iteration 22, loss = 0.87029456\n",
      "Iteration 23, loss = 0.91480000\n",
      "Iteration 24, loss = 0.92746873\n",
      "Iteration 25, loss = 0.88621250\n",
      "Iteration 26, loss = 0.86765460\n",
      "Iteration 27, loss = 0.87154759\n",
      "Iteration 28, loss = 0.88284695\n",
      "Iteration 29, loss = 0.91203471\n",
      "Iteration 30, loss = 0.86389369\n",
      "Iteration 31, loss = 0.79943453\n",
      "Iteration 32, loss = 0.96819443\n",
      "Iteration 33, loss = 0.85408304\n",
      "Iteration 34, loss = 0.83376433\n",
      "Iteration 35, loss = 0.82520118\n",
      "Iteration 36, loss = 0.85317791\n",
      "Iteration 20, loss = 0.90755426\n",
      "Iteration 21, loss = 0.87686499\n",
      "Iteration 22, loss = 0.87029456\n",
      "Iteration 23, loss = 0.91480000\n",
      "Iteration 24, loss = 0.92746873\n",
      "Iteration 25, loss = 0.88621250\n",
      "Iteration 26, loss = 0.86765460\n",
      "Iteration 27, loss = 0.87154759\n",
      "Iteration 28, loss = 0.88284695\n",
      "Iteration 29, loss = 0.91203471\n",
      "Iteration 30, loss = 0.86389369\n",
      "Iteration 31, loss = 0.79943453\n",
      "Iteration 32, loss = 0.96819443\n",
      "Iteration 33, loss = 0.85408304\n",
      "Iteration 34, loss = 0.83376433\n",
      "Iteration 35, loss = 0.82520118\n",
      "Iteration 36, loss = 0.85317791\n",
      "Iteration 37, loss = 0.85206952\n",
      "Iteration 38, loss = 0.81078560\n",
      "Iteration 39, loss = 0.81501532\n",
      "Iteration 40, loss = 0.80958746\n",
      "Iteration 41, loss = 0.78867499\n",
      "Iteration 42, loss = 0.75237997\n",
      "Iteration 43, loss = 0.82249603\n",
      "Iteration 44, loss = 0.77492483\n",
      "Iteration 45, loss = 0.76123619\n",
      "Iteration 46, loss = 0.82299127\n",
      "Iteration 47, loss = 0.81165445\n",
      "Iteration 48, loss = 0.78988485\n",
      "Iteration 49, loss = 0.75087167\n",
      "Iteration 50, loss = 0.79132480\n",
      "Iteration 51, loss = 0.78737535\n",
      "Iteration 52, loss = 0.77694095\n",
      "Iteration 53, loss = 0.77421249\n",
      "Iteration 37, loss = 0.85206952\n",
      "Iteration 38, loss = 0.81078560\n",
      "Iteration 39, loss = 0.81501532\n",
      "Iteration 40, loss = 0.80958746\n",
      "Iteration 41, loss = 0.78867499\n",
      "Iteration 42, loss = 0.75237997\n",
      "Iteration 43, loss = 0.82249603\n",
      "Iteration 44, loss = 0.77492483\n",
      "Iteration 45, loss = 0.76123619\n",
      "Iteration 46, loss = 0.82299127\n",
      "Iteration 47, loss = 0.81165445\n",
      "Iteration 48, loss = 0.78988485\n",
      "Iteration 49, loss = 0.75087167\n",
      "Iteration 50, loss = 0.79132480\n",
      "Iteration 51, loss = 0.78737535\n",
      "Iteration 52, loss = 0.77694095\n",
      "Iteration 53, loss = 0.77421249\n",
      "Iteration 54, loss = 0.75325763\n",
      "Iteration 55, loss = 0.72329745\n",
      "Iteration 56, loss = 0.79936445\n",
      "Iteration 57, loss = 0.81553694\n",
      "Iteration 58, loss = 0.73866526\n",
      "Iteration 59, loss = 0.75768609\n",
      "Iteration 60, loss = 0.71865815\n",
      "Iteration 61, loss = 0.74412540\n",
      "Iteration 62, loss = 0.72186963\n",
      "Iteration 63, loss = 0.72362307\n",
      "Iteration 64, loss = 0.76960546\n",
      "Iteration 65, loss = 0.73548003\n",
      "Iteration 66, loss = 0.75315465\n",
      "Iteration 67, loss = 0.81492530\n",
      "Iteration 68, loss = 0.78988829\n",
      "Iteration 69, loss = 0.70346614\n",
      "Iteration 54, loss = 0.75325763\n",
      "Iteration 55, loss = 0.72329745\n",
      "Iteration 56, loss = 0.79936445\n",
      "Iteration 57, loss = 0.81553694\n",
      "Iteration 58, loss = 0.73866526\n",
      "Iteration 59, loss = 0.75768609\n",
      "Iteration 60, loss = 0.71865815\n",
      "Iteration 61, loss = 0.74412540\n",
      "Iteration 62, loss = 0.72186963\n",
      "Iteration 63, loss = 0.72362307\n",
      "Iteration 64, loss = 0.76960546\n",
      "Iteration 65, loss = 0.73548003\n",
      "Iteration 66, loss = 0.75315465\n",
      "Iteration 67, loss = 0.81492530\n",
      "Iteration 68, loss = 0.78988829\n",
      "Iteration 69, loss = 0.70346614\n",
      "Iteration 70, loss = 0.71234459\n",
      "Iteration 71, loss = 0.75524057\n",
      "Iteration 72, loss = 0.69775266\n",
      "Iteration 73, loss = 0.70778058\n",
      "Iteration 74, loss = 0.68822263\n",
      "Iteration 75, loss = 0.72433559\n",
      "Iteration 76, loss = 0.70046550\n",
      "Iteration 77, loss = 0.68338417\n",
      "Iteration 78, loss = 0.75657371\n",
      "Iteration 79, loss = 0.70201150\n",
      "Iteration 80, loss = 0.67603937\n",
      "Iteration 81, loss = 0.67615184\n",
      "Iteration 82, loss = 0.65889612\n",
      "Iteration 83, loss = 0.76956085\n",
      "Iteration 84, loss = 0.80365554\n",
      "Iteration 85, loss = 0.73016931\n",
      "Iteration 70, loss = 0.71234459\n",
      "Iteration 71, loss = 0.75524057\n",
      "Iteration 72, loss = 0.69775266\n",
      "Iteration 73, loss = 0.70778058\n",
      "Iteration 74, loss = 0.68822263\n",
      "Iteration 75, loss = 0.72433559\n",
      "Iteration 76, loss = 0.70046550\n",
      "Iteration 77, loss = 0.68338417\n",
      "Iteration 78, loss = 0.75657371\n",
      "Iteration 79, loss = 0.70201150\n",
      "Iteration 80, loss = 0.67603937\n",
      "Iteration 81, loss = 0.67615184\n",
      "Iteration 82, loss = 0.65889612\n",
      "Iteration 83, loss = 0.76956085\n",
      "Iteration 84, loss = 0.80365554\n",
      "Iteration 85, loss = 0.73016931\n",
      "Iteration 86, loss = 0.70378746\n",
      "Iteration 87, loss = 0.82477781\n",
      "Iteration 88, loss = 0.78153518\n",
      "Iteration 89, loss = 0.76179421\n",
      "Iteration 90, loss = 0.78328635\n",
      "Iteration 91, loss = 0.72246835\n",
      "Iteration 92, loss = 0.72780450\n",
      "Iteration 93, loss = 0.68877145\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25164822\n",
      "Iteration 2, loss = 1.14407153\n",
      "Iteration 3, loss = 1.00412991\n",
      "Iteration 4, loss = 1.01647821\n",
      "Iteration 5, loss = 0.96525501\n",
      "Iteration 6, loss = 0.97649921\n",
      "Iteration 7, loss = 0.96649180\n",
      "Iteration 86, loss = 0.70378746\n",
      "Iteration 87, loss = 0.82477781\n",
      "Iteration 88, loss = 0.78153518\n",
      "Iteration 89, loss = 0.76179421\n",
      "Iteration 90, loss = 0.78328635\n",
      "Iteration 91, loss = 0.72246835\n",
      "Iteration 92, loss = 0.72780450\n",
      "Iteration 93, loss = 0.68877145\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25164822\n",
      "Iteration 2, loss = 1.14407153\n",
      "Iteration 3, loss = 1.00412991\n",
      "Iteration 4, loss = 1.01647821\n",
      "Iteration 5, loss = 0.96525501\n",
      "Iteration 6, loss = 0.97649921\n",
      "Iteration 7, loss = 0.96649180\n",
      "Iteration 8, loss = 0.96753363\n",
      "Iteration 9, loss = 0.93665294\n",
      "Iteration 10, loss = 0.95619578\n",
      "Iteration 11, loss = 0.93439592\n",
      "Iteration 12, loss = 0.91381787\n",
      "Iteration 13, loss = 0.93595529\n",
      "Iteration 14, loss = 0.92803849\n",
      "Iteration 15, loss = 0.90359084\n",
      "Iteration 16, loss = 0.92027329\n",
      "Iteration 17, loss = 0.94359087\n",
      "Iteration 18, loss = 0.91014875\n",
      "Iteration 19, loss = 0.93472433\n",
      "Iteration 20, loss = 0.95206173\n",
      "Iteration 21, loss = 0.93976889\n",
      "Iteration 22, loss = 0.91955430\n",
      "Iteration 8, loss = 0.96753363\n",
      "Iteration 9, loss = 0.93665294\n",
      "Iteration 10, loss = 0.95619578\n",
      "Iteration 11, loss = 0.93439592\n",
      "Iteration 12, loss = 0.91381787\n",
      "Iteration 13, loss = 0.93595529\n",
      "Iteration 14, loss = 0.92803849\n",
      "Iteration 15, loss = 0.90359084\n",
      "Iteration 16, loss = 0.92027329\n",
      "Iteration 17, loss = 0.94359087\n",
      "Iteration 18, loss = 0.91014875\n",
      "Iteration 19, loss = 0.93472433\n",
      "Iteration 20, loss = 0.95206173\n",
      "Iteration 21, loss = 0.93976889\n",
      "Iteration 22, loss = 0.91955430\n",
      "Iteration 23, loss = 0.91009584\n",
      "Iteration 24, loss = 0.94261250\n",
      "Iteration 25, loss = 0.91502118\n",
      "Iteration 26, loss = 0.89793766\n",
      "Iteration 27, loss = 0.92010079\n",
      "Iteration 28, loss = 0.93195498\n",
      "Iteration 29, loss = 0.92860700\n",
      "Iteration 30, loss = 0.89682697\n",
      "Iteration 31, loss = 0.88203122\n",
      "Iteration 32, loss = 0.90553438\n",
      "Iteration 33, loss = 0.90988853\n",
      "Iteration 34, loss = 0.92514058\n",
      "Iteration 35, loss = 0.92179744\n",
      "Iteration 36, loss = 0.91540314\n",
      "Iteration 37, loss = 0.87287280\n",
      "Iteration 38, loss = 0.85549657\n",
      "Iteration 23, loss = 0.91009584\n",
      "Iteration 24, loss = 0.94261250\n",
      "Iteration 25, loss = 0.91502118\n",
      "Iteration 26, loss = 0.89793766\n",
      "Iteration 27, loss = 0.92010079\n",
      "Iteration 28, loss = 0.93195498\n",
      "Iteration 29, loss = 0.92860700\n",
      "Iteration 30, loss = 0.89682697\n",
      "Iteration 31, loss = 0.88203122\n",
      "Iteration 32, loss = 0.90553438\n",
      "Iteration 33, loss = 0.90988853\n",
      "Iteration 34, loss = 0.92514058\n",
      "Iteration 35, loss = 0.92179744\n",
      "Iteration 36, loss = 0.91540314\n",
      "Iteration 37, loss = 0.87287280\n",
      "Iteration 38, loss = 0.85549657\n",
      "Iteration 39, loss = 0.85143952\n",
      "Iteration 40, loss = 0.85946932\n",
      "Iteration 41, loss = 0.92407302\n",
      "Iteration 42, loss = 0.85043069\n",
      "Iteration 43, loss = 0.90679360\n",
      "Iteration 44, loss = 0.90558334\n",
      "Iteration 45, loss = 0.93328893\n",
      "Iteration 46, loss = 0.89131829\n",
      "Iteration 47, loss = 0.87565385\n",
      "Iteration 48, loss = 0.87486417\n",
      "Iteration 49, loss = 0.85990000\n",
      "Iteration 50, loss = 0.83812957\n",
      "Iteration 51, loss = 0.86249463\n",
      "Iteration 52, loss = 0.85694873\n",
      "Iteration 53, loss = 0.85982328\n",
      "Iteration 54, loss = 0.83458350\n",
      "Iteration 55, loss = 0.80071981\n",
      "Iteration 39, loss = 0.85143952\n",
      "Iteration 40, loss = 0.85946932\n",
      "Iteration 41, loss = 0.92407302\n",
      "Iteration 42, loss = 0.85043069\n",
      "Iteration 43, loss = 0.90679360\n",
      "Iteration 44, loss = 0.90558334\n",
      "Iteration 45, loss = 0.93328893\n",
      "Iteration 46, loss = 0.89131829\n",
      "Iteration 47, loss = 0.87565385\n",
      "Iteration 48, loss = 0.87486417\n",
      "Iteration 49, loss = 0.85990000\n",
      "Iteration 50, loss = 0.83812957\n",
      "Iteration 51, loss = 0.86249463\n",
      "Iteration 52, loss = 0.85694873\n",
      "Iteration 53, loss = 0.85982328\n",
      "Iteration 54, loss = 0.83458350\n",
      "Iteration 55, loss = 0.80071981\n",
      "Iteration 56, loss = 0.81099830\n",
      "Iteration 57, loss = 0.87093407\n",
      "Iteration 58, loss = 0.89440907\n",
      "Iteration 59, loss = 0.89713336\n",
      "Iteration 60, loss = 0.85687862\n",
      "Iteration 61, loss = 0.90692661\n",
      "Iteration 62, loss = 0.80854842\n",
      "Iteration 63, loss = 0.79781255\n",
      "Iteration 64, loss = 0.84578090\n",
      "Iteration 65, loss = 0.80977640\n",
      "Iteration 66, loss = 0.83239335\n",
      "Iteration 67, loss = 0.83420942\n",
      "Iteration 68, loss = 0.82807849\n",
      "Iteration 69, loss = 0.76797021\n",
      "Iteration 70, loss = 0.79707382\n",
      "Iteration 71, loss = 0.76432225\n",
      "Iteration 56, loss = 0.81099830\n",
      "Iteration 57, loss = 0.87093407\n",
      "Iteration 58, loss = 0.89440907\n",
      "Iteration 59, loss = 0.89713336\n",
      "Iteration 60, loss = 0.85687862\n",
      "Iteration 61, loss = 0.90692661\n",
      "Iteration 62, loss = 0.80854842\n",
      "Iteration 63, loss = 0.79781255\n",
      "Iteration 64, loss = 0.84578090\n",
      "Iteration 65, loss = 0.80977640\n",
      "Iteration 66, loss = 0.83239335\n",
      "Iteration 67, loss = 0.83420942\n",
      "Iteration 68, loss = 0.82807849\n",
      "Iteration 69, loss = 0.76797021\n",
      "Iteration 70, loss = 0.79707382\n",
      "Iteration 71, loss = 0.76432225\n",
      "Iteration 72, loss = 0.80380916\n",
      "Iteration 73, loss = 0.84382856\n",
      "Iteration 74, loss = 0.84960197\n",
      "Iteration 75, loss = 0.79484600\n",
      "Iteration 76, loss = 0.80299381\n",
      "Iteration 77, loss = 0.76007273\n",
      "Iteration 78, loss = 0.76619349\n",
      "Iteration 79, loss = 0.76259720\n",
      "Iteration 80, loss = 0.75564180\n",
      "Iteration 81, loss = 0.79431331\n",
      "Iteration 82, loss = 0.79678291\n",
      "Iteration 83, loss = 0.74949687\n",
      "Iteration 84, loss = 0.79438437\n",
      "Iteration 85, loss = 0.75221483\n",
      "Iteration 86, loss = 0.78587903\n",
      "Iteration 87, loss = 0.79416383\n",
      "Iteration 88, loss = 0.82157485\n",
      "Iteration 72, loss = 0.80380916\n",
      "Iteration 73, loss = 0.84382856\n",
      "Iteration 74, loss = 0.84960197\n",
      "Iteration 75, loss = 0.79484600\n",
      "Iteration 76, loss = 0.80299381\n",
      "Iteration 77, loss = 0.76007273\n",
      "Iteration 78, loss = 0.76619349\n",
      "Iteration 79, loss = 0.76259720\n",
      "Iteration 80, loss = 0.75564180\n",
      "Iteration 81, loss = 0.79431331\n",
      "Iteration 82, loss = 0.79678291\n",
      "Iteration 83, loss = 0.74949687\n",
      "Iteration 84, loss = 0.79438437\n",
      "Iteration 85, loss = 0.75221483\n",
      "Iteration 86, loss = 0.78587903\n",
      "Iteration 87, loss = 0.79416383\n",
      "Iteration 88, loss = 0.82157485\n",
      "Iteration 89, loss = 0.75663133\n",
      "Iteration 90, loss = 0.83545156\n",
      "Iteration 91, loss = 0.79446570\n",
      "Iteration 92, loss = 0.75190516\n",
      "Iteration 93, loss = 0.81428067\n",
      "Iteration 94, loss = 0.76707578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23187850\n",
      "Iteration 2, loss = 1.10763697\n",
      "Iteration 3, loss = 1.02388778\n",
      "Iteration 4, loss = 1.02027055\n",
      "Iteration 5, loss = 0.99174807\n",
      "Iteration 6, loss = 0.98962553\n",
      "Iteration 7, loss = 1.00265971\n",
      "Iteration 8, loss = 0.99627557\n",
      "Iteration 9, loss = 0.97292738\n",
      "Iteration 10, loss = 0.96792068\n",
      "Iteration 89, loss = 0.75663133\n",
      "Iteration 90, loss = 0.83545156\n",
      "Iteration 91, loss = 0.79446570\n",
      "Iteration 92, loss = 0.75190516\n",
      "Iteration 93, loss = 0.81428067\n",
      "Iteration 94, loss = 0.76707578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23187850\n",
      "Iteration 2, loss = 1.10763697\n",
      "Iteration 3, loss = 1.02388778\n",
      "Iteration 4, loss = 1.02027055\n",
      "Iteration 5, loss = 0.99174807\n",
      "Iteration 6, loss = 0.98962553\n",
      "Iteration 7, loss = 1.00265971\n",
      "Iteration 8, loss = 0.99627557\n",
      "Iteration 9, loss = 0.97292738\n",
      "Iteration 10, loss = 0.96792068\n",
      "Iteration 11, loss = 0.94928238\n",
      "Iteration 12, loss = 0.92652208\n",
      "Iteration 13, loss = 0.95268971\n",
      "Iteration 14, loss = 0.94240347\n",
      "Iteration 15, loss = 0.95077629\n",
      "Iteration 16, loss = 0.91899162\n",
      "Iteration 17, loss = 0.93569054\n",
      "Iteration 18, loss = 0.91052030\n",
      "Iteration 19, loss = 0.93451853\n",
      "Iteration 20, loss = 0.92794006\n",
      "Iteration 21, loss = 0.93300867\n",
      "Iteration 22, loss = 0.88288403\n",
      "Iteration 23, loss = 0.89218192\n",
      "Iteration 24, loss = 0.88835074\n",
      "Iteration 25, loss = 0.90758353\n",
      "Iteration 11, loss = 0.94928238\n",
      "Iteration 12, loss = 0.92652208\n",
      "Iteration 13, loss = 0.95268971\n",
      "Iteration 14, loss = 0.94240347\n",
      "Iteration 15, loss = 0.95077629\n",
      "Iteration 16, loss = 0.91899162\n",
      "Iteration 17, loss = 0.93569054\n",
      "Iteration 18, loss = 0.91052030\n",
      "Iteration 19, loss = 0.93451853\n",
      "Iteration 20, loss = 0.92794006\n",
      "Iteration 21, loss = 0.93300867\n",
      "Iteration 22, loss = 0.88288403\n",
      "Iteration 23, loss = 0.89218192\n",
      "Iteration 24, loss = 0.88835074\n",
      "Iteration 25, loss = 0.90758353\n",
      "Iteration 26, loss = 0.88823502\n",
      "Iteration 27, loss = 0.89678708\n",
      "Iteration 28, loss = 0.99457392\n",
      "Iteration 29, loss = 0.91863311\n",
      "Iteration 30, loss = 0.87260710\n",
      "Iteration 31, loss = 0.89737961\n",
      "Iteration 32, loss = 0.84808945\n",
      "Iteration 33, loss = 0.85870093\n",
      "Iteration 34, loss = 0.88251749\n",
      "Iteration 35, loss = 0.84469555\n",
      "Iteration 36, loss = 0.85234489\n",
      "Iteration 37, loss = 0.89142420\n",
      "Iteration 38, loss = 0.84536389\n",
      "Iteration 39, loss = 0.84052033\n",
      "Iteration 40, loss = 0.80755177\n",
      "Iteration 41, loss = 0.79677806\n",
      "Iteration 26, loss = 0.88823502\n",
      "Iteration 27, loss = 0.89678708\n",
      "Iteration 28, loss = 0.99457392\n",
      "Iteration 29, loss = 0.91863311\n",
      "Iteration 30, loss = 0.87260710\n",
      "Iteration 31, loss = 0.89737961\n",
      "Iteration 32, loss = 0.84808945\n",
      "Iteration 33, loss = 0.85870093\n",
      "Iteration 34, loss = 0.88251749\n",
      "Iteration 35, loss = 0.84469555\n",
      "Iteration 36, loss = 0.85234489\n",
      "Iteration 37, loss = 0.89142420\n",
      "Iteration 38, loss = 0.84536389\n",
      "Iteration 39, loss = 0.84052033\n",
      "Iteration 40, loss = 0.80755177\n",
      "Iteration 41, loss = 0.79677806\n",
      "Iteration 42, loss = 0.81947352\n",
      "Iteration 43, loss = 0.81363874\n",
      "Iteration 44, loss = 0.80387691\n",
      "Iteration 45, loss = 0.86841097\n",
      "Iteration 46, loss = 0.86496436\n",
      "Iteration 47, loss = 0.81803490\n",
      "Iteration 48, loss = 0.87558868\n",
      "Iteration 49, loss = 0.82541836\n",
      "Iteration 50, loss = 0.80787498\n",
      "Iteration 51, loss = 0.84418170\n",
      "Iteration 52, loss = 0.77809719\n",
      "Iteration 53, loss = 0.78901507\n",
      "Iteration 54, loss = 0.78102638\n",
      "Iteration 55, loss = 0.78668511\n",
      "Iteration 56, loss = 0.77600299\n",
      "Iteration 57, loss = 0.81678028\n",
      "Iteration 42, loss = 0.81947352\n",
      "Iteration 43, loss = 0.81363874\n",
      "Iteration 44, loss = 0.80387691\n",
      "Iteration 45, loss = 0.86841097\n",
      "Iteration 46, loss = 0.86496436\n",
      "Iteration 47, loss = 0.81803490\n",
      "Iteration 48, loss = 0.87558868\n",
      "Iteration 49, loss = 0.82541836\n",
      "Iteration 50, loss = 0.80787498\n",
      "Iteration 51, loss = 0.84418170\n",
      "Iteration 52, loss = 0.77809719\n",
      "Iteration 53, loss = 0.78901507\n",
      "Iteration 54, loss = 0.78102638\n",
      "Iteration 55, loss = 0.78668511\n",
      "Iteration 56, loss = 0.77600299\n",
      "Iteration 57, loss = 0.81678028\n",
      "Iteration 58, loss = 0.86301632\n",
      "Iteration 59, loss = 0.82464477\n",
      "Iteration 60, loss = 0.82994338\n",
      "Iteration 61, loss = 0.82317162\n",
      "Iteration 62, loss = 0.80257409\n",
      "Iteration 63, loss = 0.83202491\n",
      "Iteration 64, loss = 0.77120833\n",
      "Iteration 65, loss = 0.83955629\n",
      "Iteration 66, loss = 0.78935896\n",
      "Iteration 67, loss = 0.82307509\n",
      "Iteration 68, loss = 0.81328276\n",
      "Iteration 69, loss = 0.72823143\n",
      "Iteration 70, loss = 0.74111980\n",
      "Iteration 71, loss = 0.73365460\n",
      "Iteration 72, loss = 0.76346581\n",
      "Iteration 73, loss = 0.87394327\n",
      "Iteration 58, loss = 0.86301632\n",
      "Iteration 59, loss = 0.82464477\n",
      "Iteration 60, loss = 0.82994338\n",
      "Iteration 61, loss = 0.82317162\n",
      "Iteration 62, loss = 0.80257409\n",
      "Iteration 63, loss = 0.83202491\n",
      "Iteration 64, loss = 0.77120833\n",
      "Iteration 65, loss = 0.83955629\n",
      "Iteration 66, loss = 0.78935896\n",
      "Iteration 67, loss = 0.82307509\n",
      "Iteration 68, loss = 0.81328276\n",
      "Iteration 69, loss = 0.72823143\n",
      "Iteration 70, loss = 0.74111980\n",
      "Iteration 71, loss = 0.73365460\n",
      "Iteration 72, loss = 0.76346581\n",
      "Iteration 73, loss = 0.87394327\n",
      "Iteration 74, loss = 0.77278582\n",
      "Iteration 75, loss = 0.74124057\n",
      "Iteration 76, loss = 0.73440612\n",
      "Iteration 77, loss = 0.75150461\n",
      "Iteration 78, loss = 0.80345196\n",
      "Iteration 79, loss = 0.78925556\n",
      "Iteration 80, loss = 0.77735042\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24073950\n",
      "Iteration 2, loss = 1.11105198\n",
      "Iteration 3, loss = 1.02496262\n",
      "Iteration 4, loss = 1.00946051\n",
      "Iteration 5, loss = 0.95778084\n",
      "Iteration 6, loss = 0.98335081\n",
      "Iteration 7, loss = 0.95674478\n",
      "Iteration 74, loss = 0.77278582\n",
      "Iteration 75, loss = 0.74124057\n",
      "Iteration 76, loss = 0.73440612\n",
      "Iteration 77, loss = 0.75150461\n",
      "Iteration 78, loss = 0.80345196\n",
      "Iteration 79, loss = 0.78925556\n",
      "Iteration 80, loss = 0.77735042\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24073950\n",
      "Iteration 2, loss = 1.11105198\n",
      "Iteration 3, loss = 1.02496262\n",
      "Iteration 4, loss = 1.00946051\n",
      "Iteration 5, loss = 0.95778084\n",
      "Iteration 6, loss = 0.98335081\n",
      "Iteration 7, loss = 0.95674478\n",
      "Iteration 8, loss = 0.98147800\n",
      "Iteration 9, loss = 0.93205207\n",
      "Iteration 10, loss = 0.91906307\n",
      "Iteration 11, loss = 0.93853374\n",
      "Iteration 12, loss = 0.93158359\n",
      "Iteration 13, loss = 0.92853181\n",
      "Iteration 14, loss = 0.91910564\n",
      "Iteration 15, loss = 0.89350867\n",
      "Iteration 16, loss = 0.88897792\n",
      "Iteration 17, loss = 0.91813376\n",
      "Iteration 18, loss = 0.91960600\n",
      "Iteration 19, loss = 0.89820069\n",
      "Iteration 20, loss = 0.89712083\n",
      "Iteration 21, loss = 0.91277487\n",
      "Iteration 22, loss = 0.93900199\n",
      "Iteration 23, loss = 0.92153985\n",
      "Iteration 8, loss = 0.98147800\n",
      "Iteration 9, loss = 0.93205207\n",
      "Iteration 10, loss = 0.91906307\n",
      "Iteration 11, loss = 0.93853374\n",
      "Iteration 12, loss = 0.93158359\n",
      "Iteration 13, loss = 0.92853181\n",
      "Iteration 14, loss = 0.91910564\n",
      "Iteration 15, loss = 0.89350867\n",
      "Iteration 16, loss = 0.88897792\n",
      "Iteration 17, loss = 0.91813376\n",
      "Iteration 18, loss = 0.91960600\n",
      "Iteration 19, loss = 0.89820069\n",
      "Iteration 20, loss = 0.89712083\n",
      "Iteration 21, loss = 0.91277487\n",
      "Iteration 22, loss = 0.93900199\n",
      "Iteration 23, loss = 0.92153985\n",
      "Iteration 24, loss = 0.92543136\n",
      "Iteration 25, loss = 0.91150891\n",
      "Iteration 26, loss = 0.91261412\n",
      "Iteration 27, loss = 0.89965547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23475623\n",
      "Iteration 2, loss = 1.06412249\n",
      "Iteration 3, loss = 1.00264851\n",
      "Iteration 4, loss = 0.99986094\n",
      "Iteration 5, loss = 0.96554806\n",
      "Iteration 6, loss = 1.00326284\n",
      "Iteration 7, loss = 1.05870700\n",
      "Iteration 8, loss = 1.00848045\n",
      "Iteration 9, loss = 0.99257462\n",
      "Iteration 10, loss = 1.05184178\n",
      "Iteration 24, loss = 0.92543136\n",
      "Iteration 25, loss = 0.91150891\n",
      "Iteration 26, loss = 0.91261412\n",
      "Iteration 27, loss = 0.89965547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23475623\n",
      "Iteration 2, loss = 1.06412249\n",
      "Iteration 3, loss = 1.00264851\n",
      "Iteration 4, loss = 0.99986094\n",
      "Iteration 5, loss = 0.96554806\n",
      "Iteration 6, loss = 1.00326284\n",
      "Iteration 7, loss = 1.05870700\n",
      "Iteration 8, loss = 1.00848045\n",
      "Iteration 9, loss = 0.99257462\n",
      "Iteration 10, loss = 1.05184178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.17750789\n",
      "Iteration 2, loss = 1.03535453\n",
      "Iteration 3, loss = 1.00423249\n",
      "Iteration 4, loss = 0.92866159\n",
      "Iteration 5, loss = 0.99063485\n",
      "Iteration 6, loss = 1.00652087\n",
      "Iteration 7, loss = 0.96423738\n",
      "Iteration 8, loss = 0.98348698\n",
      "Iteration 9, loss = 0.93288054\n",
      "Iteration 10, loss = 0.92177909\n",
      "Iteration 1, loss = 1.23970122\n",
      "Iteration 2, loss = 1.06760809\n",
      "Iteration 3, loss = 0.97852333\n",
      "Iteration 1, loss = 1.17750789\n",
      "Iteration 2, loss = 1.03535453\n",
      "Iteration 3, loss = 1.00423249\n",
      "Iteration 4, loss = 0.92866159\n",
      "Iteration 5, loss = 0.99063485\n",
      "Iteration 6, loss = 1.00652087\n",
      "Iteration 7, loss = 0.96423738\n",
      "Iteration 8, loss = 0.98348698\n",
      "Iteration 9, loss = 0.93288054\n",
      "Iteration 10, loss = 0.92177909\n",
      "Iteration 1, loss = 1.23970122\n",
      "Iteration 2, loss = 1.06760809\n",
      "Iteration 3, loss = 0.97852333\n",
      "Iteration 4, loss = 1.01522146\n",
      "Iteration 5, loss = 0.95438119\n",
      "Iteration 6, loss = 0.97541894\n",
      "Iteration 7, loss = 0.96542054\n",
      "Iteration 8, loss = 0.99957621\n",
      "Iteration 9, loss = 0.97850858\n",
      "Iteration 10, loss = 0.97199747\n",
      "Iteration 1, loss = 1.23993547\n",
      "Iteration 2, loss = 1.11397393\n",
      "Iteration 3, loss = 1.02614584\n",
      "Iteration 4, loss = 1.05131889\n",
      "Iteration 5, loss = 0.99542317\n",
      "Iteration 6, loss = 1.00375564\n",
      "Iteration 7, loss = 0.99929775\n",
      "Iteration 4, loss = 1.01522146\n",
      "Iteration 5, loss = 0.95438119\n",
      "Iteration 6, loss = 0.97541894\n",
      "Iteration 7, loss = 0.96542054\n",
      "Iteration 8, loss = 0.99957621\n",
      "Iteration 9, loss = 0.97850858\n",
      "Iteration 10, loss = 0.97199747\n",
      "Iteration 1, loss = 1.23993547\n",
      "Iteration 2, loss = 1.11397393\n",
      "Iteration 3, loss = 1.02614584\n",
      "Iteration 4, loss = 1.05131889\n",
      "Iteration 5, loss = 0.99542317\n",
      "Iteration 6, loss = 1.00375564\n",
      "Iteration 7, loss = 0.99929775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.98874101\n",
      "Iteration 9, loss = 0.98400614\n",
      "Iteration 10, loss = 1.01140161\n",
      "Iteration 1, loss = 1.21282645\n",
      "Iteration 2, loss = 1.06709726\n",
      "Iteration 3, loss = 1.01379038\n",
      "Iteration 4, loss = 1.04338419\n",
      "Iteration 5, loss = 0.99608461\n",
      "Iteration 6, loss = 0.97950851\n",
      "Iteration 7, loss = 0.97153412\n",
      "Iteration 8, loss = 0.99865786\n",
      "Iteration 8, loss = 0.98874101\n",
      "Iteration 9, loss = 0.98400614\n",
      "Iteration 10, loss = 1.01140161\n",
      "Iteration 1, loss = 1.21282645\n",
      "Iteration 2, loss = 1.06709726\n",
      "Iteration 3, loss = 1.01379038\n",
      "Iteration 4, loss = 1.04338419\n",
      "Iteration 5, loss = 0.99608461\n",
      "Iteration 6, loss = 0.97950851\n",
      "Iteration 7, loss = 0.97153412\n",
      "Iteration 8, loss = 0.99865786\n",
      "Iteration 9, loss = 0.97145979\n",
      "Iteration 10, loss = 0.95780845\n",
      "Iteration 1, loss = 1.23475623\n",
      "Iteration 2, loss = 1.06412249\n",
      "Iteration 3, loss = 1.00264851\n",
      "Iteration 4, loss = 0.99986094\n",
      "Iteration 5, loss = 0.96554806\n",
      "Iteration 6, loss = 1.00326284\n",
      "Iteration 7, loss = 1.05870700\n",
      "Iteration 8, loss = 1.00848045\n",
      "Iteration 9, loss = 0.99257462\n",
      "Iteration 10, loss = 1.05184178\n",
      "Iteration 11, loss = 0.97452847\n",
      "Iteration 12, loss = 0.96840042\n",
      "Iteration 9, loss = 0.97145979\n",
      "Iteration 10, loss = 0.95780845\n",
      "Iteration 1, loss = 1.23475623\n",
      "Iteration 2, loss = 1.06412249\n",
      "Iteration 3, loss = 1.00264851\n",
      "Iteration 4, loss = 0.99986094\n",
      "Iteration 5, loss = 0.96554806\n",
      "Iteration 6, loss = 1.00326284\n",
      "Iteration 7, loss = 1.05870700\n",
      "Iteration 8, loss = 1.00848045\n",
      "Iteration 9, loss = 0.99257462\n",
      "Iteration 10, loss = 1.05184178\n",
      "Iteration 11, loss = 0.97452847\n",
      "Iteration 12, loss = 0.96840042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.97653989\n",
      "Iteration 14, loss = 0.98047122\n",
      "Iteration 15, loss = 0.96657164\n",
      "Iteration 16, loss = 0.96262117\n",
      "Iteration 17, loss = 0.96779572\n",
      "Iteration 18, loss = 0.97513773\n",
      "Iteration 19, loss = 0.96850958\n",
      "Iteration 20, loss = 0.95705550\n",
      "Iteration 21, loss = 0.95894308\n",
      "Iteration 22, loss = 0.96459256\n",
      "Iteration 23, loss = 0.96159009\n",
      "Iteration 24, loss = 0.95320391\n",
      "Iteration 25, loss = 0.95148491\n",
      "Iteration 26, loss = 0.96204121\n",
      "Iteration 27, loss = 0.95713869\n",
      "Iteration 28, loss = 0.95888910\n",
      "Iteration 29, loss = 0.95692793\n",
      "Iteration 13, loss = 0.97653989\n",
      "Iteration 14, loss = 0.98047122\n",
      "Iteration 15, loss = 0.96657164\n",
      "Iteration 16, loss = 0.96262117\n",
      "Iteration 17, loss = 0.96779572\n",
      "Iteration 18, loss = 0.97513773\n",
      "Iteration 19, loss = 0.96850958\n",
      "Iteration 20, loss = 0.95705550\n",
      "Iteration 21, loss = 0.95894308\n",
      "Iteration 22, loss = 0.96459256\n",
      "Iteration 23, loss = 0.96159009\n",
      "Iteration 24, loss = 0.95320391\n",
      "Iteration 25, loss = 0.95148491\n",
      "Iteration 26, loss = 0.96204121\n",
      "Iteration 27, loss = 0.95713869\n",
      "Iteration 28, loss = 0.95888910\n",
      "Iteration 29, loss = 0.95692793\n",
      "Iteration 30, loss = 0.96176339\n",
      "Iteration 31, loss = 0.95350490\n",
      "Iteration 32, loss = 1.01244815\n",
      "Iteration 33, loss = 0.98100907\n",
      "Iteration 34, loss = 0.96220710\n",
      "Iteration 35, loss = 0.96302934\n",
      "Iteration 36, loss = 0.96898955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17750789\n",
      "Iteration 2, loss = 1.03535453\n",
      "Iteration 3, loss = 1.00423249\n",
      "Iteration 4, loss = 0.92866159\n",
      "Iteration 5, loss = 0.99063485\n",
      "Iteration 6, loss = 1.00652087\n",
      "Iteration 7, loss = 0.96423738\n",
      "Iteration 8, loss = 0.98348698\n",
      "Iteration 9, loss = 0.93288054\n",
      "Iteration 30, loss = 0.96176339\n",
      "Iteration 31, loss = 0.95350490\n",
      "Iteration 32, loss = 1.01244815\n",
      "Iteration 33, loss = 0.98100907\n",
      "Iteration 34, loss = 0.96220710\n",
      "Iteration 35, loss = 0.96302934\n",
      "Iteration 36, loss = 0.96898955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17750789\n",
      "Iteration 2, loss = 1.03535453\n",
      "Iteration 3, loss = 1.00423249\n",
      "Iteration 4, loss = 0.92866159\n",
      "Iteration 5, loss = 0.99063485\n",
      "Iteration 6, loss = 1.00652087\n",
      "Iteration 7, loss = 0.96423738\n",
      "Iteration 8, loss = 0.98348698\n",
      "Iteration 9, loss = 0.93288054\n",
      "Iteration 10, loss = 0.92177909\n",
      "Iteration 11, loss = 0.92813328\n",
      "Iteration 12, loss = 0.92010731\n",
      "Iteration 13, loss = 0.91993333\n",
      "Iteration 14, loss = 0.94332012\n",
      "Iteration 15, loss = 0.92019757\n",
      "Iteration 16, loss = 0.92353017\n",
      "Iteration 17, loss = 0.91445357\n",
      "Iteration 18, loss = 0.92735094\n",
      "Iteration 19, loss = 0.92900069\n",
      "Iteration 20, loss = 0.90395137\n",
      "Iteration 21, loss = 0.92585386\n",
      "Iteration 22, loss = 0.92400848\n",
      "Iteration 23, loss = 0.92821813\n",
      "Iteration 24, loss = 0.92976043\n",
      "Iteration 25, loss = 0.91549160\n",
      "Iteration 26, loss = 0.92486929\n",
      "Iteration 10, loss = 0.92177909\n",
      "Iteration 11, loss = 0.92813328\n",
      "Iteration 12, loss = 0.92010731\n",
      "Iteration 13, loss = 0.91993333\n",
      "Iteration 14, loss = 0.94332012\n",
      "Iteration 15, loss = 0.92019757\n",
      "Iteration 16, loss = 0.92353017\n",
      "Iteration 17, loss = 0.91445357\n",
      "Iteration 18, loss = 0.92735094\n",
      "Iteration 19, loss = 0.92900069\n",
      "Iteration 20, loss = 0.90395137\n",
      "Iteration 21, loss = 0.92585386\n",
      "Iteration 22, loss = 0.92400848\n",
      "Iteration 23, loss = 0.92821813\n",
      "Iteration 24, loss = 0.92976043\n",
      "Iteration 25, loss = 0.91549160\n",
      "Iteration 26, loss = 0.92486929\n",
      "Iteration 27, loss = 0.93085935\n",
      "Iteration 28, loss = 0.93613897\n",
      "Iteration 29, loss = 0.92327079\n",
      "Iteration 30, loss = 0.90907913\n",
      "Iteration 31, loss = 0.92655542\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23970122\n",
      "Iteration 2, loss = 1.06760809\n",
      "Iteration 3, loss = 0.97852333\n",
      "Iteration 4, loss = 1.01522146\n",
      "Iteration 5, loss = 0.95438119\n",
      "Iteration 6, loss = 0.97541894\n",
      "Iteration 7, loss = 0.96542054\n",
      "Iteration 8, loss = 0.99957621\n",
      "Iteration 9, loss = 0.97850858\n",
      "Iteration 27, loss = 0.93085935\n",
      "Iteration 28, loss = 0.93613897\n",
      "Iteration 29, loss = 0.92327079\n",
      "Iteration 30, loss = 0.90907913\n",
      "Iteration 31, loss = 0.92655542\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23970122\n",
      "Iteration 2, loss = 1.06760809\n",
      "Iteration 3, loss = 0.97852333\n",
      "Iteration 4, loss = 1.01522146\n",
      "Iteration 5, loss = 0.95438119\n",
      "Iteration 6, loss = 0.97541894\n",
      "Iteration 7, loss = 0.96542054\n",
      "Iteration 8, loss = 0.99957621\n",
      "Iteration 9, loss = 0.97850858\n",
      "Iteration 10, loss = 0.97199747\n",
      "Iteration 11, loss = 0.95978042\n",
      "Iteration 12, loss = 0.94586601\n",
      "Iteration 13, loss = 0.97759207\n",
      "Iteration 14, loss = 0.97989470\n",
      "Iteration 15, loss = 0.93592836\n",
      "Iteration 16, loss = 0.95103132\n",
      "Iteration 17, loss = 0.98969008\n",
      "Iteration 18, loss = 0.99254435\n",
      "Iteration 19, loss = 0.97873167\n",
      "Iteration 20, loss = 0.95468392\n",
      "Iteration 21, loss = 0.97189126\n",
      "Iteration 22, loss = 0.97698417\n",
      "Iteration 23, loss = 0.95501032\n",
      "Iteration 24, loss = 0.99685677\n",
      "Iteration 10, loss = 0.97199747\n",
      "Iteration 11, loss = 0.95978042\n",
      "Iteration 12, loss = 0.94586601\n",
      "Iteration 13, loss = 0.97759207\n",
      "Iteration 14, loss = 0.97989470\n",
      "Iteration 15, loss = 0.93592836\n",
      "Iteration 16, loss = 0.95103132\n",
      "Iteration 17, loss = 0.98969008\n",
      "Iteration 18, loss = 0.99254435\n",
      "Iteration 19, loss = 0.97873167\n",
      "Iteration 20, loss = 0.95468392\n",
      "Iteration 21, loss = 0.97189126\n",
      "Iteration 22, loss = 0.97698417\n",
      "Iteration 23, loss = 0.95501032\n",
      "Iteration 24, loss = 0.99685677\n",
      "Iteration 25, loss = 0.97956700\n",
      "Iteration 26, loss = 0.94680979\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23993547\n",
      "Iteration 2, loss = 1.11397393\n",
      "Iteration 3, loss = 1.02614584\n",
      "Iteration 4, loss = 1.05131889\n",
      "Iteration 5, loss = 0.99542317\n",
      "Iteration 6, loss = 1.00375564\n",
      "Iteration 7, loss = 0.99929775\n",
      "Iteration 8, loss = 0.98874101\n",
      "Iteration 9, loss = 0.98400614\n",
      "Iteration 10, loss = 1.01140161\n",
      "Iteration 11, loss = 0.97710301Iteration 25, loss = 0.97956700\n",
      "Iteration 26, loss = 0.94680979\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23993547\n",
      "Iteration 2, loss = 1.11397393\n",
      "Iteration 3, loss = 1.02614584\n",
      "Iteration 4, loss = 1.05131889\n",
      "Iteration 5, loss = 0.99542317\n",
      "Iteration 6, loss = 1.00375564\n",
      "Iteration 7, loss = 0.99929775\n",
      "Iteration 8, loss = 0.98874101\n",
      "Iteration 9, loss = 0.98400614\n",
      "Iteration 10, loss = 1.01140161\n",
      "Iteration 11, loss = 0.97710301\n",
      "Iteration 12, loss = 0.92074458\n",
      "Iteration 13, loss = 1.07002520\n",
      "Iteration 14, loss = 1.03021911\n",
      "Iteration 15, loss = 1.00772697\n",
      "Iteration 16, loss = 0.96559599\n",
      "Iteration 17, loss = 0.95700267\n",
      "Iteration 18, loss = 0.95418177\n",
      "Iteration 19, loss = 1.02581388\n",
      "Iteration 20, loss = 1.01444959\n",
      "Iteration 21, loss = 1.03833330\n",
      "Iteration 22, loss = 1.00229199\n",
      "Iteration 23, loss = 0.94588659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21282645\n",
      "Iteration 2, loss = 1.06709726\n",
      "\n",
      "Iteration 12, loss = 0.92074458\n",
      "Iteration 13, loss = 1.07002520\n",
      "Iteration 14, loss = 1.03021911\n",
      "Iteration 15, loss = 1.00772697\n",
      "Iteration 16, loss = 0.96559599\n",
      "Iteration 17, loss = 0.95700267\n",
      "Iteration 18, loss = 0.95418177\n",
      "Iteration 19, loss = 1.02581388\n",
      "Iteration 20, loss = 1.01444959\n",
      "Iteration 21, loss = 1.03833330\n",
      "Iteration 22, loss = 1.00229199\n",
      "Iteration 23, loss = 0.94588659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21282645\n",
      "Iteration 2, loss = 1.06709726\n",
      "Iteration 3, loss = 1.01379038\n",
      "Iteration 4, loss = 1.04338419\n",
      "Iteration 5, loss = 0.99608461\n",
      "Iteration 6, loss = 0.97950851\n",
      "Iteration 7, loss = 0.97153412\n",
      "Iteration 8, loss = 0.99865786\n",
      "Iteration 9, loss = 0.97145979\n",
      "Iteration 10, loss = 0.95780845\n",
      "Iteration 11, loss = 0.96702213\n",
      "Iteration 12, loss = 1.02126796\n",
      "Iteration 13, loss = 1.00957956\n",
      "Iteration 14, loss = 0.97803467\n",
      "Iteration 15, loss = 0.97803717\n",
      "Iteration 3, loss = 1.01379038\n",
      "Iteration 4, loss = 1.04338419\n",
      "Iteration 5, loss = 0.99608461\n",
      "Iteration 6, loss = 0.97950851\n",
      "Iteration 7, loss = 0.97153412\n",
      "Iteration 8, loss = 0.99865786\n",
      "Iteration 9, loss = 0.97145979\n",
      "Iteration 10, loss = 0.95780845\n",
      "Iteration 11, loss = 0.96702213\n",
      "Iteration 12, loss = 1.02126796\n",
      "Iteration 13, loss = 1.00957956\n",
      "Iteration 14, loss = 0.97803467\n",
      "Iteration 15, loss = 0.97803717\n",
      "Iteration 16, loss = 0.91961108\n",
      "Iteration 17, loss = 0.98775726\n",
      "Iteration 18, loss = 0.99806332\n",
      "Iteration 19, loss = 0.92400369\n",
      "Iteration 20, loss = 1.01285311\n",
      "Iteration 21, loss = 1.01551531\n",
      "Iteration 22, loss = 0.98207969\n",
      "Iteration 23, loss = 0.98023225\n",
      "Iteration 24, loss = 1.01467174\n",
      "Iteration 25, loss = 0.97886881\n",
      "Iteration 26, loss = 0.98942425\n",
      "Iteration 27, loss = 0.98868958\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23475623\n",
      "Iteration 2, loss = 1.06412249\n",
      "Iteration 16, loss = 0.91961108\n",
      "Iteration 17, loss = 0.98775726\n",
      "Iteration 18, loss = 0.99806332\n",
      "Iteration 19, loss = 0.92400369\n",
      "Iteration 20, loss = 1.01285311\n",
      "Iteration 21, loss = 1.01551531\n",
      "Iteration 22, loss = 0.98207969\n",
      "Iteration 23, loss = 0.98023225\n",
      "Iteration 24, loss = 1.01467174\n",
      "Iteration 25, loss = 0.97886881\n",
      "Iteration 26, loss = 0.98942425\n",
      "Iteration 27, loss = 0.98868958\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23475623\n",
      "Iteration 2, loss = 1.06412249\n",
      "Iteration 3, loss = 1.00264851\n",
      "Iteration 4, loss = 0.99986094\n",
      "Iteration 5, loss = 0.96554806\n",
      "Iteration 6, loss = 1.00326284\n",
      "Iteration 7, loss = 1.05870700\n",
      "Iteration 8, loss = 1.00848045\n",
      "Iteration 9, loss = 0.99257462\n",
      "Iteration 10, loss = 1.05184178\n",
      "Iteration 11, loss = 0.97452847\n",
      "Iteration 12, loss = 0.96840042\n",
      "Iteration 13, loss = 0.97653989\n",
      "Iteration 14, loss = 0.98047122\n",
      "Iteration 15, loss = 0.96657164\n",
      "Iteration 3, loss = 1.00264851\n",
      "Iteration 4, loss = 0.99986094\n",
      "Iteration 5, loss = 0.96554806\n",
      "Iteration 6, loss = 1.00326284\n",
      "Iteration 7, loss = 1.05870700\n",
      "Iteration 8, loss = 1.00848045\n",
      "Iteration 9, loss = 0.99257462\n",
      "Iteration 10, loss = 1.05184178\n",
      "Iteration 11, loss = 0.97452847\n",
      "Iteration 12, loss = 0.96840042\n",
      "Iteration 13, loss = 0.97653989\n",
      "Iteration 14, loss = 0.98047122\n",
      "Iteration 15, loss = 0.96657164\n",
      "Iteration 16, loss = 0.96262117\n",
      "Iteration 17, loss = 0.96779572\n",
      "Iteration 18, loss = 0.97513773\n",
      "Iteration 19, loss = 0.96850958\n",
      "Iteration 20, loss = 0.95705550\n",
      "Iteration 21, loss = 0.95894308\n",
      "Iteration 22, loss = 0.96459256\n",
      "Iteration 23, loss = 0.96159009\n",
      "Iteration 24, loss = 0.95320391\n",
      "Iteration 25, loss = 0.95148491\n",
      "Iteration 26, loss = 0.96204121\n",
      "Iteration 27, loss = 0.95713869\n",
      "Iteration 28, loss = 0.95888910\n",
      "Iteration 29, loss = 0.95692793\n",
      "Iteration 30, loss = 0.96176339\n",
      "Iteration 31, loss = 0.95350490\n",
      "Iteration 32, loss = 1.01244815\n",
      "Iteration 16, loss = 0.96262117\n",
      "Iteration 17, loss = 0.96779572\n",
      "Iteration 18, loss = 0.97513773\n",
      "Iteration 19, loss = 0.96850958\n",
      "Iteration 20, loss = 0.95705550\n",
      "Iteration 21, loss = 0.95894308\n",
      "Iteration 22, loss = 0.96459256\n",
      "Iteration 23, loss = 0.96159009\n",
      "Iteration 24, loss = 0.95320391\n",
      "Iteration 25, loss = 0.95148491\n",
      "Iteration 26, loss = 0.96204121\n",
      "Iteration 27, loss = 0.95713869\n",
      "Iteration 28, loss = 0.95888910\n",
      "Iteration 29, loss = 0.95692793\n",
      "Iteration 30, loss = 0.96176339\n",
      "Iteration 31, loss = 0.95350490\n",
      "Iteration 32, loss = 1.01244815\n",
      "Iteration 33, loss = 0.98100907\n",
      "Iteration 34, loss = 0.96220710\n",
      "Iteration 35, loss = 0.96302934\n",
      "Iteration 36, loss = 0.96898955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17750789\n",
      "Iteration 2, loss = 1.03535453\n",
      "Iteration 3, loss = 1.00423249\n",
      "Iteration 4, loss = 0.92866159\n",
      "Iteration 5, loss = 0.99063485\n",
      "Iteration 6, loss = 1.00652087\n",
      "Iteration 7, loss = 0.96423738\n",
      "Iteration 8, loss = 0.98348698\n",
      "Iteration 9, loss = 0.93288054\n",
      "Iteration 33, loss = 0.98100907\n",
      "Iteration 34, loss = 0.96220710\n",
      "Iteration 35, loss = 0.96302934\n",
      "Iteration 36, loss = 0.96898955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17750789\n",
      "Iteration 2, loss = 1.03535453\n",
      "Iteration 3, loss = 1.00423249\n",
      "Iteration 4, loss = 0.92866159\n",
      "Iteration 5, loss = 0.99063485\n",
      "Iteration 6, loss = 1.00652087\n",
      "Iteration 7, loss = 0.96423738\n",
      "Iteration 8, loss = 0.98348698\n",
      "Iteration 9, loss = 0.93288054\n",
      "Iteration 10, loss = 0.92177909\n",
      "Iteration 11, loss = 0.92813328\n",
      "Iteration 12, loss = 0.92010731\n",
      "Iteration 13, loss = 0.91993333\n",
      "Iteration 14, loss = 0.94332012\n",
      "Iteration 15, loss = 0.92019757\n",
      "Iteration 16, loss = 0.92353017\n",
      "Iteration 17, loss = 0.91445357\n",
      "Iteration 18, loss = 0.92735094\n",
      "Iteration 19, loss = 0.92900069\n",
      "Iteration 20, loss = 0.90395137\n",
      "Iteration 21, loss = 0.92585386\n",
      "Iteration 22, loss = 0.92400848\n",
      "Iteration 23, loss = 0.92821813\n",
      "Iteration 24, loss = 0.92976043\n",
      "Iteration 10, loss = 0.92177909\n",
      "Iteration 11, loss = 0.92813328\n",
      "Iteration 12, loss = 0.92010731\n",
      "Iteration 13, loss = 0.91993333\n",
      "Iteration 14, loss = 0.94332012\n",
      "Iteration 15, loss = 0.92019757\n",
      "Iteration 16, loss = 0.92353017\n",
      "Iteration 17, loss = 0.91445357\n",
      "Iteration 18, loss = 0.92735094\n",
      "Iteration 19, loss = 0.92900069\n",
      "Iteration 20, loss = 0.90395137\n",
      "Iteration 21, loss = 0.92585386\n",
      "Iteration 22, loss = 0.92400848\n",
      "Iteration 23, loss = 0.92821813\n",
      "Iteration 24, loss = 0.92976043\n",
      "Iteration 25, loss = 0.91549160\n",
      "Iteration 26, loss = 0.92486929\n",
      "Iteration 27, loss = 0.93085935\n",
      "Iteration 28, loss = 0.93613897\n",
      "Iteration 29, loss = 0.92327079\n",
      "Iteration 30, loss = 0.90907913\n",
      "Iteration 31, loss = 0.92655542\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23970122\n",
      "Iteration 2, loss = 1.06760809\n",
      "Iteration 3, loss = 0.97852333\n",
      "Iteration 4, loss = 1.01522146\n",
      "Iteration 5, loss = 0.95438119\n",
      "Iteration 6, loss = 0.97541894\n",
      "Iteration 7, loss = 0.96542054\n",
      "Iteration 8, loss = 0.99957621\n",
      "Iteration 9, loss = 0.97850858\n",
      "Iteration 25, loss = 0.91549160\n",
      "Iteration 26, loss = 0.92486929\n",
      "Iteration 27, loss = 0.93085935\n",
      "Iteration 28, loss = 0.93613897\n",
      "Iteration 29, loss = 0.92327079\n",
      "Iteration 30, loss = 0.90907913\n",
      "Iteration 31, loss = 0.92655542\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23970122\n",
      "Iteration 2, loss = 1.06760809\n",
      "Iteration 3, loss = 0.97852333\n",
      "Iteration 4, loss = 1.01522146\n",
      "Iteration 5, loss = 0.95438119\n",
      "Iteration 6, loss = 0.97541894\n",
      "Iteration 7, loss = 0.96542054\n",
      "Iteration 8, loss = 0.99957621\n",
      "Iteration 9, loss = 0.97850858\n",
      "Iteration 10, loss = 0.97199747\n",
      "Iteration 11, loss = 0.95978042\n",
      "Iteration 12, loss = 0.94586601\n",
      "Iteration 13, loss = 0.97759207\n",
      "Iteration 14, loss = 0.97989470\n",
      "Iteration 15, loss = 0.93592836\n",
      "Iteration 16, loss = 0.95103132\n",
      "Iteration 17, loss = 0.98969008\n",
      "Iteration 18, loss = 0.99254435\n",
      "Iteration 19, loss = 0.97873167\n",
      "Iteration 20, loss = 0.95468392\n",
      "Iteration 21, loss = 0.97189126\n",
      "Iteration 22, loss = 0.97698417\n",
      "Iteration 23, loss = 0.95501032\n",
      "Iteration 24, loss = 0.99685677\n",
      "Iteration 10, loss = 0.97199747\n",
      "Iteration 11, loss = 0.95978042\n",
      "Iteration 12, loss = 0.94586601\n",
      "Iteration 13, loss = 0.97759207\n",
      "Iteration 14, loss = 0.97989470\n",
      "Iteration 15, loss = 0.93592836\n",
      "Iteration 16, loss = 0.95103132\n",
      "Iteration 17, loss = 0.98969008\n",
      "Iteration 18, loss = 0.99254435\n",
      "Iteration 19, loss = 0.97873167\n",
      "Iteration 20, loss = 0.95468392\n",
      "Iteration 21, loss = 0.97189126\n",
      "Iteration 22, loss = 0.97698417\n",
      "Iteration 23, loss = 0.95501032\n",
      "Iteration 24, loss = 0.99685677\n",
      "Iteration 25, loss = 0.97956700\n",
      "Iteration 26, loss = 0.94680979\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23993547\n",
      "Iteration 2, loss = 1.11397393\n",
      "Iteration 3, loss = 1.02614584\n",
      "Iteration 4, loss = 1.05131889\n",
      "Iteration 5, loss = 0.99542317\n",
      "Iteration 6, loss = 1.00375564\n",
      "Iteration 7, loss = 0.99929775\n",
      "Iteration 8, loss = 0.98874101\n",
      "Iteration 9, loss = 0.98400614\n",
      "Iteration 10, loss = 1.01140161\n",
      "Iteration 11, loss = 0.97710301\n",
      "Iteration 12, loss = 0.92074458\n",
      "Iteration 13, loss = 1.07002520\n",
      "Iteration 14, loss = 1.03021911\n",
      "Iteration 15, loss = 1.00772697\n",
      "Iteration 25, loss = 0.97956700\n",
      "Iteration 26, loss = 0.94680979\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23993547\n",
      "Iteration 2, loss = 1.11397393\n",
      "Iteration 3, loss = 1.02614584\n",
      "Iteration 4, loss = 1.05131889\n",
      "Iteration 5, loss = 0.99542317\n",
      "Iteration 6, loss = 1.00375564\n",
      "Iteration 7, loss = 0.99929775\n",
      "Iteration 8, loss = 0.98874101\n",
      "Iteration 9, loss = 0.98400614\n",
      "Iteration 10, loss = 1.01140161\n",
      "Iteration 11, loss = 0.97710301\n",
      "Iteration 12, loss = 0.92074458\n",
      "Iteration 13, loss = 1.07002520\n",
      "Iteration 14, loss = 1.03021911\n",
      "Iteration 15, loss = 1.00772697\n",
      "Iteration 16, loss = 0.96559599\n",
      "Iteration 17, loss = 0.95700267\n",
      "Iteration 18, loss = 0.95418177\n",
      "Iteration 19, loss = 1.02581388\n",
      "Iteration 20, loss = 1.01444959\n",
      "Iteration 21, loss = 1.03833330\n",
      "Iteration 22, loss = 1.00229199\n",
      "Iteration 23, loss = 0.94588659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21282645\n",
      "Iteration 2, loss = 1.06709726\n",
      "Iteration 3, loss = 1.01379038\n",
      "Iteration 4, loss = 1.04338419\n",
      "Iteration 5, loss = 0.99608461\n",
      "Iteration 6, loss = 0.97950851\n",
      "Iteration 7, loss = 0.97153412\n",
      "Iteration 16, loss = 0.96559599\n",
      "Iteration 17, loss = 0.95700267\n",
      "Iteration 18, loss = 0.95418177\n",
      "Iteration 19, loss = 1.02581388\n",
      "Iteration 20, loss = 1.01444959\n",
      "Iteration 21, loss = 1.03833330\n",
      "Iteration 22, loss = 1.00229199\n",
      "Iteration 23, loss = 0.94588659\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21282645\n",
      "Iteration 2, loss = 1.06709726\n",
      "Iteration 3, loss = 1.01379038\n",
      "Iteration 4, loss = 1.04338419\n",
      "Iteration 5, loss = 0.99608461\n",
      "Iteration 6, loss = 0.97950851\n",
      "Iteration 7, loss = 0.97153412\n",
      "Iteration 8, loss = 0.99865786\n",
      "Iteration 9, loss = 0.97145979\n",
      "Iteration 10, loss = 0.95780845\n",
      "Iteration 11, loss = 0.96702213\n",
      "Iteration 12, loss = 1.02126796\n",
      "Iteration 13, loss = 1.00957956\n",
      "Iteration 14, loss = 0.97803467\n",
      "Iteration 15, loss = 0.97803717\n",
      "Iteration 16, loss = 0.91961108\n",
      "Iteration 17, loss = 0.98775726\n",
      "Iteration 18, loss = 0.99806332\n",
      "Iteration 19, loss = 0.92400369\n",
      "Iteration 20, loss = 1.01285311\n",
      "Iteration 21, loss = 1.01551531\n",
      "Iteration 8, loss = 0.99865786\n",
      "Iteration 9, loss = 0.97145979\n",
      "Iteration 10, loss = 0.95780845\n",
      "Iteration 11, loss = 0.96702213\n",
      "Iteration 12, loss = 1.02126796\n",
      "Iteration 13, loss = 1.00957956\n",
      "Iteration 14, loss = 0.97803467\n",
      "Iteration 15, loss = 0.97803717\n",
      "Iteration 16, loss = 0.91961108\n",
      "Iteration 17, loss = 0.98775726\n",
      "Iteration 18, loss = 0.99806332\n",
      "Iteration 19, loss = 0.92400369\n",
      "Iteration 20, loss = 1.01285311\n",
      "Iteration 21, loss = 1.01551531\n",
      "Iteration 22, loss = 0.98207969\n",
      "Iteration 23, loss = 0.98023225\n",
      "Iteration 24, loss = 1.01467174\n",
      "Iteration 25, loss = 0.97886881\n",
      "Iteration 26, loss = 0.98942425\n",
      "Iteration 27, loss = 0.98868958\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25127041\n",
      "Iteration 2, loss = 1.28199786\n",
      "Iteration 3, loss = 1.24322130\n",
      "Iteration 4, loss = 1.08319720\n",
      "Iteration 5, loss = 0.99582953\n",
      "Iteration 6, loss = 1.04459993\n",
      "Iteration 7, loss = 1.05104546\n",
      "Iteration 8, loss = 0.99970459\n",
      "Iteration 22, loss = 0.98207969\n",
      "Iteration 23, loss = 0.98023225\n",
      "Iteration 24, loss = 1.01467174\n",
      "Iteration 25, loss = 0.97886881\n",
      "Iteration 26, loss = 0.98942425\n",
      "Iteration 27, loss = 0.98868958\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25127041\n",
      "Iteration 2, loss = 1.28199786\n",
      "Iteration 3, loss = 1.24322130\n",
      "Iteration 4, loss = 1.08319720\n",
      "Iteration 5, loss = 0.99582953\n",
      "Iteration 6, loss = 1.04459993\n",
      "Iteration 7, loss = 1.05104546\n",
      "Iteration 8, loss = 0.99970459\n",
      "Iteration 9, loss = 0.99798529\n",
      "Iteration 10, loss = 1.06566524\n",
      "Iteration 1, loss = 1.26786946\n",
      "Iteration 2, loss = 1.25701867\n",
      "Iteration 3, loss = 1.14901580\n",
      "Iteration 4, loss = 1.01998249\n",
      "Iteration 5, loss = 0.93524397\n",
      "Iteration 6, loss = 0.94906397\n",
      "Iteration 7, loss = 0.94659730\n",
      "Iteration 8, loss = 0.95043281\n",
      "Iteration 9, loss = 0.93190482\n",
      "Iteration 10, loss = 0.92704736\n",
      "Iteration 9, loss = 0.99798529\n",
      "Iteration 10, loss = 1.06566524\n",
      "Iteration 1, loss = 1.26786946\n",
      "Iteration 2, loss = 1.25701867\n",
      "Iteration 3, loss = 1.14901580\n",
      "Iteration 4, loss = 1.01998249\n",
      "Iteration 5, loss = 0.93524397\n",
      "Iteration 6, loss = 0.94906397\n",
      "Iteration 7, loss = 0.94659730\n",
      "Iteration 8, loss = 0.95043281\n",
      "Iteration 9, loss = 0.93190482\n",
      "Iteration 10, loss = 0.92704736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.26108349\n",
      "Iteration 2, loss = 1.13256920\n",
      "Iteration 3, loss = 1.01395387\n",
      "Iteration 4, loss = 0.98840191\n",
      "Iteration 5, loss = 0.98351661\n",
      "Iteration 6, loss = 1.04643515\n",
      "Iteration 7, loss = 1.01644695\n",
      "Iteration 8, loss = 1.03347151\n",
      "Iteration 9, loss = 1.17450323\n",
      "Iteration 10, loss = 1.03103557\n",
      "Iteration 1, loss = 1.22409108\n",
      "Iteration 2, loss = 1.10801217\n",
      "Iteration 3, loss = 1.09135902\n",
      "Iteration 1, loss = 1.26108349\n",
      "Iteration 2, loss = 1.13256920\n",
      "Iteration 3, loss = 1.01395387\n",
      "Iteration 4, loss = 0.98840191\n",
      "Iteration 5, loss = 0.98351661\n",
      "Iteration 6, loss = 1.04643515\n",
      "Iteration 7, loss = 1.01644695\n",
      "Iteration 8, loss = 1.03347151\n",
      "Iteration 9, loss = 1.17450323\n",
      "Iteration 10, loss = 1.03103557\n",
      "Iteration 1, loss = 1.22409108\n",
      "Iteration 2, loss = 1.10801217\n",
      "Iteration 3, loss = 1.09135902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.27879949\n",
      "Iteration 5, loss = 1.05080816\n",
      "Iteration 6, loss = 1.03850745\n",
      "Iteration 7, loss = 1.03229061\n",
      "Iteration 8, loss = 1.07942773\n",
      "Iteration 9, loss = 1.04237664\n",
      "Iteration 10, loss = 1.04748983\n",
      "Iteration 1, loss = 1.22033453\n",
      "Iteration 2, loss = 1.17224052\n",
      "Iteration 3, loss = 1.04500599\n",
      "Iteration 4, loss = 1.02435750\n",
      "Iteration 5, loss = 1.03816307\n",
      "Iteration 6, loss = 1.05540215\n",
      "Iteration 4, loss = 1.27879949\n",
      "Iteration 5, loss = 1.05080816\n",
      "Iteration 6, loss = 1.03850745\n",
      "Iteration 7, loss = 1.03229061\n",
      "Iteration 8, loss = 1.07942773\n",
      "Iteration 9, loss = 1.04237664\n",
      "Iteration 10, loss = 1.04748983\n",
      "Iteration 1, loss = 1.22033453\n",
      "Iteration 2, loss = 1.17224052\n",
      "Iteration 3, loss = 1.04500599\n",
      "Iteration 4, loss = 1.02435750\n",
      "Iteration 5, loss = 1.03816307\n",
      "Iteration 6, loss = 1.05540215\n",
      "Iteration 7, loss = 1.02364779\n",
      "Iteration 8, loss = 1.03892661\n",
      "Iteration 9, loss = 1.02174149\n",
      "Iteration 10, loss = 1.02241450\n",
      "Iteration 1, loss = 1.25127041\n",
      "Iteration 2, loss = 1.28199786\n",
      "Iteration 3, loss = 1.24322130\n",
      "Iteration 4, loss = 1.08319720\n",
      "Iteration 5, loss = 0.99582953\n",
      "Iteration 6, loss = 1.04459993\n",
      "Iteration 7, loss = 1.05104546\n",
      "Iteration 8, loss = 0.99970459\n",
      "Iteration 9, loss = 0.99798529\n",
      "Iteration 10, loss = 1.06566524\n",
      "Iteration 11, loss = 0.99135912\n",
      "Iteration 7, loss = 1.02364779\n",
      "Iteration 8, loss = 1.03892661\n",
      "Iteration 9, loss = 1.02174149\n",
      "Iteration 10, loss = 1.02241450\n",
      "Iteration 1, loss = 1.25127041\n",
      "Iteration 2, loss = 1.28199786\n",
      "Iteration 3, loss = 1.24322130\n",
      "Iteration 4, loss = 1.08319720\n",
      "Iteration 5, loss = 0.99582953\n",
      "Iteration 6, loss = 1.04459993\n",
      "Iteration 7, loss = 1.05104546\n",
      "Iteration 8, loss = 0.99970459\n",
      "Iteration 9, loss = 0.99798529\n",
      "Iteration 10, loss = 1.06566524\n",
      "Iteration 11, loss = 0.99135912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 1.00697075\n",
      "Iteration 13, loss = 0.99005828\n",
      "Iteration 14, loss = 0.99301868\n",
      "Iteration 15, loss = 0.99387306\n",
      "Iteration 16, loss = 0.99519922\n",
      "Iteration 17, loss = 0.98919860\n",
      "Iteration 18, loss = 1.00549725\n",
      "Iteration 19, loss = 0.98172512\n",
      "Iteration 20, loss = 0.99364701\n",
      "Iteration 21, loss = 0.99839445\n",
      "Iteration 22, loss = 0.99114650\n",
      "Iteration 23, loss = 0.98881571\n",
      "Iteration 24, loss = 0.99436618\n",
      "Iteration 25, loss = 0.99211901\n",
      "Iteration 26, loss = 0.98906515\n",
      "Iteration 12, loss = 1.00697075\n",
      "Iteration 13, loss = 0.99005828\n",
      "Iteration 14, loss = 0.99301868\n",
      "Iteration 15, loss = 0.99387306\n",
      "Iteration 16, loss = 0.99519922\n",
      "Iteration 17, loss = 0.98919860\n",
      "Iteration 18, loss = 1.00549725\n",
      "Iteration 19, loss = 0.98172512\n",
      "Iteration 20, loss = 0.99364701\n",
      "Iteration 21, loss = 0.99839445\n",
      "Iteration 22, loss = 0.99114650\n",
      "Iteration 23, loss = 0.98881571\n",
      "Iteration 24, loss = 0.99436618\n",
      "Iteration 25, loss = 0.99211901\n",
      "Iteration 26, loss = 0.98906515\n",
      "Iteration 27, loss = 0.99249307\n",
      "Iteration 28, loss = 0.99359372\n",
      "Iteration 29, loss = 0.99079889\n",
      "Iteration 30, loss = 0.97514267\n",
      "Iteration 31, loss = 0.99244999\n",
      "Iteration 32, loss = 1.03195713\n",
      "Iteration 33, loss = 0.99640818\n",
      "Iteration 34, loss = 0.98592064\n",
      "Iteration 35, loss = 0.98151891\n",
      "Iteration 36, loss = 0.97789202\n",
      "Iteration 37, loss = 0.97584458\n",
      "Iteration 38, loss = 0.99395330\n",
      "Iteration 39, loss = 0.98550709\n",
      "Iteration 40, loss = 0.97892827\n",
      "Iteration 41, loss = 0.97568045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.99249307\n",
      "Iteration 28, loss = 0.99359372\n",
      "Iteration 29, loss = 0.99079889\n",
      "Iteration 30, loss = 0.97514267\n",
      "Iteration 31, loss = 0.99244999\n",
      "Iteration 32, loss = 1.03195713\n",
      "Iteration 33, loss = 0.99640818\n",
      "Iteration 34, loss = 0.98592064\n",
      "Iteration 35, loss = 0.98151891\n",
      "Iteration 36, loss = 0.97789202\n",
      "Iteration 37, loss = 0.97584458\n",
      "Iteration 38, loss = 0.99395330\n",
      "Iteration 39, loss = 0.98550709\n",
      "Iteration 40, loss = 0.97892827\n",
      "Iteration 41, loss = 0.97568045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26786946\n",
      "Iteration 2, loss = 1.25701867\n",
      "Iteration 3, loss = 1.14901580\n",
      "Iteration 4, loss = 1.01998249\n",
      "Iteration 5, loss = 0.93524397\n",
      "Iteration 6, loss = 0.94906397\n",
      "Iteration 7, loss = 0.94659730\n",
      "Iteration 8, loss = 0.95043281\n",
      "Iteration 9, loss = 0.93190482\n",
      "Iteration 10, loss = 0.92704736\n",
      "Iteration 11, loss = 0.95430545\n",
      "Iteration 12, loss = 0.92922549\n",
      "Iteration 13, loss = 0.92859393\n",
      "Iteration 14, loss = 0.94731684\n",
      "Iteration 15, loss = 0.94701908\n",
      "Iteration 16, loss = 0.94543897\n",
      "Iteration 1, loss = 1.26786946\n",
      "Iteration 2, loss = 1.25701867\n",
      "Iteration 3, loss = 1.14901580\n",
      "Iteration 4, loss = 1.01998249\n",
      "Iteration 5, loss = 0.93524397\n",
      "Iteration 6, loss = 0.94906397\n",
      "Iteration 7, loss = 0.94659730\n",
      "Iteration 8, loss = 0.95043281\n",
      "Iteration 9, loss = 0.93190482\n",
      "Iteration 10, loss = 0.92704736\n",
      "Iteration 11, loss = 0.95430545\n",
      "Iteration 12, loss = 0.92922549\n",
      "Iteration 13, loss = 0.92859393\n",
      "Iteration 14, loss = 0.94731684\n",
      "Iteration 15, loss = 0.94701908\n",
      "Iteration 16, loss = 0.94543897\n",
      "Iteration 17, loss = 0.93653003\n",
      "Iteration 18, loss = 0.95239301\n",
      "Iteration 19, loss = 0.95563233\n",
      "Iteration 20, loss = 0.92443009\n",
      "Iteration 21, loss = 0.95042186\n",
      "Iteration 22, loss = 0.94250691\n",
      "Iteration 23, loss = 0.95179678\n",
      "Iteration 24, loss = 0.95194936\n",
      "Iteration 25, loss = 0.94855419\n",
      "Iteration 26, loss = 0.94232968\n",
      "Iteration 27, loss = 0.95549675\n",
      "Iteration 28, loss = 1.10163624\n",
      "Iteration 29, loss = 1.24411369\n",
      "Iteration 30, loss = 1.25346358\n",
      "Iteration 31, loss = 1.25011841\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.93653003\n",
      "Iteration 18, loss = 0.95239301\n",
      "Iteration 19, loss = 0.95563233\n",
      "Iteration 20, loss = 0.92443009\n",
      "Iteration 21, loss = 0.95042186\n",
      "Iteration 22, loss = 0.94250691\n",
      "Iteration 23, loss = 0.95179678\n",
      "Iteration 24, loss = 0.95194936\n",
      "Iteration 25, loss = 0.94855419\n",
      "Iteration 26, loss = 0.94232968\n",
      "Iteration 27, loss = 0.95549675\n",
      "Iteration 28, loss = 1.10163624\n",
      "Iteration 29, loss = 1.24411369\n",
      "Iteration 30, loss = 1.25346358\n",
      "Iteration 31, loss = 1.25011841\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26108349\n",
      "Iteration 2, loss = 1.13256920\n",
      "Iteration 3, loss = 1.01395387\n",
      "Iteration 4, loss = 0.98840191\n",
      "Iteration 5, loss = 0.98351661\n",
      "Iteration 6, loss = 1.04643515\n",
      "Iteration 7, loss = 1.01644695\n",
      "Iteration 8, loss = 1.03347151\n",
      "Iteration 9, loss = 1.17450323\n",
      "Iteration 10, loss = 1.03103557\n",
      "Iteration 11, loss = 0.99896601\n",
      "Iteration 12, loss = 1.02811641\n",
      "Iteration 13, loss = 1.00211447\n",
      "Iteration 14, loss = 1.01329001\n",
      "Iteration 1, loss = 1.26108349\n",
      "Iteration 2, loss = 1.13256920\n",
      "Iteration 3, loss = 1.01395387\n",
      "Iteration 4, loss = 0.98840191\n",
      "Iteration 5, loss = 0.98351661\n",
      "Iteration 6, loss = 1.04643515\n",
      "Iteration 7, loss = 1.01644695\n",
      "Iteration 8, loss = 1.03347151\n",
      "Iteration 9, loss = 1.17450323\n",
      "Iteration 10, loss = 1.03103557\n",
      "Iteration 11, loss = 0.99896601\n",
      "Iteration 12, loss = 1.02811641\n",
      "Iteration 13, loss = 1.00211447\n",
      "Iteration 14, loss = 1.01329001\n",
      "Iteration 15, loss = 1.02011281\n",
      "Iteration 16, loss = 0.97802221\n",
      "Iteration 17, loss = 0.96428447\n",
      "Iteration 18, loss = 0.95382481\n",
      "Iteration 19, loss = 1.05342228\n",
      "Iteration 20, loss = 1.06319614\n",
      "Iteration 21, loss = 0.96382123\n",
      "Iteration 22, loss = 0.98243163\n",
      "Iteration 23, loss = 0.97996370\n",
      "Iteration 24, loss = 0.97396415\n",
      "Iteration 25, loss = 1.08414495\n",
      "Iteration 26, loss = 0.96386029\n",
      "Iteration 27, loss = 1.03442881\n",
      "Iteration 28, loss = 1.02925839\n",
      "Iteration 29, loss = 0.97301455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22409108\n",
      "Iteration 15, loss = 1.02011281\n",
      "Iteration 16, loss = 0.97802221\n",
      "Iteration 17, loss = 0.96428447\n",
      "Iteration 18, loss = 0.95382481\n",
      "Iteration 19, loss = 1.05342228\n",
      "Iteration 20, loss = 1.06319614\n",
      "Iteration 21, loss = 0.96382123\n",
      "Iteration 22, loss = 0.98243163\n",
      "Iteration 23, loss = 0.97996370\n",
      "Iteration 24, loss = 0.97396415\n",
      "Iteration 25, loss = 1.08414495\n",
      "Iteration 26, loss = 0.96386029\n",
      "Iteration 27, loss = 1.03442881\n",
      "Iteration 28, loss = 1.02925839\n",
      "Iteration 29, loss = 0.97301455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22409108\n",
      "Iteration 2, loss = 1.10801217\n",
      "Iteration 3, loss = 1.09135902\n",
      "Iteration 4, loss = 1.27879949\n",
      "Iteration 5, loss = 1.05080816\n",
      "Iteration 6, loss = 1.03850745\n",
      "Iteration 7, loss = 1.03229061\n",
      "Iteration 8, loss = 1.07942773\n",
      "Iteration 9, loss = 1.04237664\n",
      "Iteration 10, loss = 1.04748983\n",
      "Iteration 11, loss = 1.03451677\n",
      "Iteration 12, loss = 0.98959633\n",
      "Iteration 13, loss = 1.09979177\n",
      "Iteration 14, loss = 1.00433366\n",
      "Iteration 15, loss = 1.03565791\n",
      "Iteration 2, loss = 1.10801217\n",
      "Iteration 3, loss = 1.09135902\n",
      "Iteration 4, loss = 1.27879949\n",
      "Iteration 5, loss = 1.05080816\n",
      "Iteration 6, loss = 1.03850745\n",
      "Iteration 7, loss = 1.03229061\n",
      "Iteration 8, loss = 1.07942773\n",
      "Iteration 9, loss = 1.04237664\n",
      "Iteration 10, loss = 1.04748983\n",
      "Iteration 11, loss = 1.03451677\n",
      "Iteration 12, loss = 0.98959633\n",
      "Iteration 13, loss = 1.09979177\n",
      "Iteration 14, loss = 1.00433366\n",
      "Iteration 15, loss = 1.03565791\n",
      "Iteration 16, loss = 1.07886055\n",
      "Iteration 17, loss = 1.05537504\n",
      "Iteration 18, loss = 1.01630167\n",
      "Iteration 19, loss = 1.02836021\n",
      "Iteration 20, loss = 1.04814706\n",
      "Iteration 21, loss = 1.02663590\n",
      "Iteration 22, loss = 1.06643960\n",
      "Iteration 23, loss = 1.03033303\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22033453\n",
      "Iteration 2, loss = 1.17224052\n",
      "Iteration 3, loss = 1.04500599\n",
      "Iteration 4, loss = 1.02435750\n",
      "Iteration 16, loss = 1.07886055\n",
      "Iteration 17, loss = 1.05537504\n",
      "Iteration 18, loss = 1.01630167\n",
      "Iteration 19, loss = 1.02836021\n",
      "Iteration 20, loss = 1.04814706\n",
      "Iteration 21, loss = 1.02663590\n",
      "Iteration 22, loss = 1.06643960\n",
      "Iteration 23, loss = 1.03033303\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22033453\n",
      "Iteration 2, loss = 1.17224052\n",
      "Iteration 3, loss = 1.04500599\n",
      "Iteration 4, loss = 1.02435750\n",
      "Iteration 5, loss = 1.03816307\n",
      "Iteration 6, loss = 1.05540215\n",
      "Iteration 7, loss = 1.02364779\n",
      "Iteration 8, loss = 1.03892661\n",
      "Iteration 9, loss = 1.02174149\n",
      "Iteration 10, loss = 1.02241450\n",
      "Iteration 11, loss = 1.00295724\n",
      "Iteration 12, loss = 1.01380055\n",
      "Iteration 13, loss = 1.00706749\n",
      "Iteration 14, loss = 0.98607037\n",
      "Iteration 15, loss = 1.07956472\n",
      "Iteration 16, loss = 0.99723231\n",
      "Iteration 17, loss = 1.01006476\n",
      "Iteration 18, loss = 1.05498700\n",
      "Iteration 19, loss = 1.01788197\n",
      "Iteration 20, loss = 1.01527505\n",
      "Iteration 5, loss = 1.03816307\n",
      "Iteration 6, loss = 1.05540215\n",
      "Iteration 7, loss = 1.02364779\n",
      "Iteration 8, loss = 1.03892661\n",
      "Iteration 9, loss = 1.02174149\n",
      "Iteration 10, loss = 1.02241450\n",
      "Iteration 11, loss = 1.00295724\n",
      "Iteration 12, loss = 1.01380055\n",
      "Iteration 13, loss = 1.00706749\n",
      "Iteration 14, loss = 0.98607037\n",
      "Iteration 15, loss = 1.07956472\n",
      "Iteration 16, loss = 0.99723231\n",
      "Iteration 17, loss = 1.01006476\n",
      "Iteration 18, loss = 1.05498700\n",
      "Iteration 19, loss = 1.01788197\n",
      "Iteration 20, loss = 1.01527505\n",
      "Iteration 21, loss = 1.02616158\n",
      "Iteration 22, loss = 1.02676536\n",
      "Iteration 23, loss = 1.00432810\n",
      "Iteration 24, loss = 1.03476840\n",
      "Iteration 25, loss = 1.06478915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25127041\n",
      "Iteration 2, loss = 1.28199786\n",
      "Iteration 3, loss = 1.24322130\n",
      "Iteration 4, loss = 1.08319720\n",
      "Iteration 5, loss = 0.99582953\n",
      "Iteration 6, loss = 1.04459993\n",
      "Iteration 7, loss = 1.05104546\n",
      "Iteration 8, loss = 0.99970459\n",
      "Iteration 9, loss = 0.99798529\n",
      "Iteration 10, loss = 1.06566524\n",
      "Iteration 21, loss = 1.02616158\n",
      "Iteration 22, loss = 1.02676536\n",
      "Iteration 23, loss = 1.00432810\n",
      "Iteration 24, loss = 1.03476840\n",
      "Iteration 25, loss = 1.06478915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25127041\n",
      "Iteration 2, loss = 1.28199786\n",
      "Iteration 3, loss = 1.24322130\n",
      "Iteration 4, loss = 1.08319720\n",
      "Iteration 5, loss = 0.99582953\n",
      "Iteration 6, loss = 1.04459993\n",
      "Iteration 7, loss = 1.05104546\n",
      "Iteration 8, loss = 0.99970459\n",
      "Iteration 9, loss = 0.99798529\n",
      "Iteration 10, loss = 1.06566524\n",
      "Iteration 11, loss = 0.99135912\n",
      "Iteration 12, loss = 1.00697075\n",
      "Iteration 13, loss = 0.99005828\n",
      "Iteration 14, loss = 0.99301868\n",
      "Iteration 15, loss = 0.99387306\n",
      "Iteration 16, loss = 0.99519922\n",
      "Iteration 17, loss = 0.98919860\n",
      "Iteration 18, loss = 1.00549725\n",
      "Iteration 19, loss = 0.98172512\n",
      "Iteration 20, loss = 0.99364701\n",
      "Iteration 21, loss = 0.99839445\n",
      "Iteration 22, loss = 0.99114650\n",
      "Iteration 23, loss = 0.98881571\n",
      "Iteration 24, loss = 0.99436618\n",
      "Iteration 25, loss = 0.99211901\n",
      "Iteration 11, loss = 0.99135912\n",
      "Iteration 12, loss = 1.00697075\n",
      "Iteration 13, loss = 0.99005828\n",
      "Iteration 14, loss = 0.99301868\n",
      "Iteration 15, loss = 0.99387306\n",
      "Iteration 16, loss = 0.99519922\n",
      "Iteration 17, loss = 0.98919860\n",
      "Iteration 18, loss = 1.00549725\n",
      "Iteration 19, loss = 0.98172512\n",
      "Iteration 20, loss = 0.99364701\n",
      "Iteration 21, loss = 0.99839445\n",
      "Iteration 22, loss = 0.99114650\n",
      "Iteration 23, loss = 0.98881571\n",
      "Iteration 24, loss = 0.99436618\n",
      "Iteration 25, loss = 0.99211901\n",
      "Iteration 26, loss = 0.98906515\n",
      "Iteration 27, loss = 0.99249307\n",
      "Iteration 28, loss = 0.99359372\n",
      "Iteration 29, loss = 0.99079889\n",
      "Iteration 30, loss = 0.97514267\n",
      "Iteration 31, loss = 0.99244999\n",
      "Iteration 32, loss = 1.03195713\n",
      "Iteration 33, loss = 0.99640818\n",
      "Iteration 34, loss = 0.98592064\n",
      "Iteration 35, loss = 0.98151891\n",
      "Iteration 36, loss = 0.97789202\n",
      "Iteration 37, loss = 0.97584458\n",
      "Iteration 38, loss = 0.99395330\n",
      "Iteration 39, loss = 0.98550709\n",
      "Iteration 40, loss = 0.97892827\n",
      "Iteration 41, loss = 0.97568045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26786946\n",
      "Iteration 26, loss = 0.98906515\n",
      "Iteration 27, loss = 0.99249307\n",
      "Iteration 28, loss = 0.99359372\n",
      "Iteration 29, loss = 0.99079889\n",
      "Iteration 30, loss = 0.97514267\n",
      "Iteration 31, loss = 0.99244999\n",
      "Iteration 32, loss = 1.03195713\n",
      "Iteration 33, loss = 0.99640818\n",
      "Iteration 34, loss = 0.98592064\n",
      "Iteration 35, loss = 0.98151891\n",
      "Iteration 36, loss = 0.97789202\n",
      "Iteration 37, loss = 0.97584458\n",
      "Iteration 38, loss = 0.99395330\n",
      "Iteration 39, loss = 0.98550709\n",
      "Iteration 40, loss = 0.97892827\n",
      "Iteration 41, loss = 0.97568045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26786946\n",
      "Iteration 2, loss = 1.25701867\n",
      "Iteration 3, loss = 1.14901580\n",
      "Iteration 4, loss = 1.01998249\n",
      "Iteration 5, loss = 0.93524397\n",
      "Iteration 6, loss = 0.94906397\n",
      "Iteration 7, loss = 0.94659730\n",
      "Iteration 8, loss = 0.95043281\n",
      "Iteration 9, loss = 0.93190482\n",
      "Iteration 10, loss = 0.92704736\n",
      "Iteration 11, loss = 0.95430545\n",
      "Iteration 12, loss = 0.92922549\n",
      "Iteration 13, loss = 0.92859393\n",
      "Iteration 14, loss = 0.94731684\n",
      "Iteration 15, loss = 0.94701908\n",
      "Iteration 16, loss = 0.94543897\n",
      "Iteration 17, loss = 0.93653003\n",
      "Iteration 2, loss = 1.25701867\n",
      "Iteration 3, loss = 1.14901580\n",
      "Iteration 4, loss = 1.01998249\n",
      "Iteration 5, loss = 0.93524397\n",
      "Iteration 6, loss = 0.94906397\n",
      "Iteration 7, loss = 0.94659730\n",
      "Iteration 8, loss = 0.95043281\n",
      "Iteration 9, loss = 0.93190482\n",
      "Iteration 10, loss = 0.92704736\n",
      "Iteration 11, loss = 0.95430545\n",
      "Iteration 12, loss = 0.92922549\n",
      "Iteration 13, loss = 0.92859393\n",
      "Iteration 14, loss = 0.94731684\n",
      "Iteration 15, loss = 0.94701908\n",
      "Iteration 16, loss = 0.94543897\n",
      "Iteration 17, loss = 0.93653003\n",
      "Iteration 18, loss = 0.95239301\n",
      "Iteration 19, loss = 0.95563233\n",
      "Iteration 20, loss = 0.92443009\n",
      "Iteration 21, loss = 0.95042186\n",
      "Iteration 22, loss = 0.94250691\n",
      "Iteration 23, loss = 0.95179678\n",
      "Iteration 24, loss = 0.95194936\n",
      "Iteration 25, loss = 0.94855419\n",
      "Iteration 26, loss = 0.94232968\n",
      "Iteration 27, loss = 0.95549675\n",
      "Iteration 28, loss = 1.10163624\n",
      "Iteration 29, loss = 1.24411369\n",
      "Iteration 30, loss = 1.25346358\n",
      "Iteration 31, loss = 1.25011841\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26108349\n",
      "Iteration 18, loss = 0.95239301\n",
      "Iteration 19, loss = 0.95563233\n",
      "Iteration 20, loss = 0.92443009\n",
      "Iteration 21, loss = 0.95042186\n",
      "Iteration 22, loss = 0.94250691\n",
      "Iteration 23, loss = 0.95179678\n",
      "Iteration 24, loss = 0.95194936\n",
      "Iteration 25, loss = 0.94855419\n",
      "Iteration 26, loss = 0.94232968\n",
      "Iteration 27, loss = 0.95549675\n",
      "Iteration 28, loss = 1.10163624\n",
      "Iteration 29, loss = 1.24411369\n",
      "Iteration 30, loss = 1.25346358\n",
      "Iteration 31, loss = 1.25011841\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26108349\n",
      "Iteration 2, loss = 1.13256920\n",
      "Iteration 3, loss = 1.01395387\n",
      "Iteration 4, loss = 0.98840191\n",
      "Iteration 5, loss = 0.98351661\n",
      "Iteration 6, loss = 1.04643515\n",
      "Iteration 7, loss = 1.01644695\n",
      "Iteration 8, loss = 1.03347151\n",
      "Iteration 9, loss = 1.17450323\n",
      "Iteration 10, loss = 1.03103557\n",
      "Iteration 11, loss = 0.99896601\n",
      "Iteration 12, loss = 1.02811641\n",
      "Iteration 13, loss = 1.00211447\n",
      "Iteration 14, loss = 1.01329001\n",
      "Iteration 15, loss = 1.02011281\n",
      "Iteration 2, loss = 1.13256920\n",
      "Iteration 3, loss = 1.01395387\n",
      "Iteration 4, loss = 0.98840191\n",
      "Iteration 5, loss = 0.98351661\n",
      "Iteration 6, loss = 1.04643515\n",
      "Iteration 7, loss = 1.01644695\n",
      "Iteration 8, loss = 1.03347151\n",
      "Iteration 9, loss = 1.17450323\n",
      "Iteration 10, loss = 1.03103557\n",
      "Iteration 11, loss = 0.99896601\n",
      "Iteration 12, loss = 1.02811641\n",
      "Iteration 13, loss = 1.00211447\n",
      "Iteration 14, loss = 1.01329001\n",
      "Iteration 15, loss = 1.02011281\n",
      "Iteration 16, loss = 0.97802221\n",
      "Iteration 17, loss = 0.96428447\n",
      "Iteration 18, loss = 0.95382481\n",
      "Iteration 19, loss = 1.05342228\n",
      "Iteration 20, loss = 1.06319614\n",
      "Iteration 21, loss = 0.96382123\n",
      "Iteration 22, loss = 0.98243163\n",
      "Iteration 23, loss = 0.97996370\n",
      "Iteration 24, loss = 0.97396415\n",
      "Iteration 25, loss = 1.08414495\n",
      "Iteration 26, loss = 0.96386029\n",
      "Iteration 27, loss = 1.03442881\n",
      "Iteration 28, loss = 1.02925839\n",
      "Iteration 29, loss = 0.97301455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22409108\n",
      "Iteration 16, loss = 0.97802221\n",
      "Iteration 17, loss = 0.96428447\n",
      "Iteration 18, loss = 0.95382481\n",
      "Iteration 19, loss = 1.05342228\n",
      "Iteration 20, loss = 1.06319614\n",
      "Iteration 21, loss = 0.96382123\n",
      "Iteration 22, loss = 0.98243163\n",
      "Iteration 23, loss = 0.97996370\n",
      "Iteration 24, loss = 0.97396415\n",
      "Iteration 25, loss = 1.08414495\n",
      "Iteration 26, loss = 0.96386029\n",
      "Iteration 27, loss = 1.03442881\n",
      "Iteration 28, loss = 1.02925839\n",
      "Iteration 29, loss = 0.97301455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22409108\n",
      "Iteration 2, loss = 1.10801217\n",
      "Iteration 3, loss = 1.09135902\n",
      "Iteration 4, loss = 1.27879949\n",
      "Iteration 5, loss = 1.05080816\n",
      "Iteration 6, loss = 1.03850745\n",
      "Iteration 7, loss = 1.03229061\n",
      "Iteration 8, loss = 1.07942773\n",
      "Iteration 9, loss = 1.04237664\n",
      "Iteration 10, loss = 1.04748983\n",
      "Iteration 11, loss = 1.03451677\n",
      "Iteration 12, loss = 0.98959633\n",
      "Iteration 13, loss = 1.09979177\n",
      "Iteration 14, loss = 1.00433366\n",
      "Iteration 15, loss = 1.03565791\n",
      "Iteration 16, loss = 1.07886055\n",
      "Iteration 17, loss = 1.05537504\n",
      "Iteration 2, loss = 1.10801217\n",
      "Iteration 3, loss = 1.09135902\n",
      "Iteration 4, loss = 1.27879949\n",
      "Iteration 5, loss = 1.05080816\n",
      "Iteration 6, loss = 1.03850745\n",
      "Iteration 7, loss = 1.03229061\n",
      "Iteration 8, loss = 1.07942773\n",
      "Iteration 9, loss = 1.04237664\n",
      "Iteration 10, loss = 1.04748983\n",
      "Iteration 11, loss = 1.03451677\n",
      "Iteration 12, loss = 0.98959633\n",
      "Iteration 13, loss = 1.09979177\n",
      "Iteration 14, loss = 1.00433366\n",
      "Iteration 15, loss = 1.03565791\n",
      "Iteration 16, loss = 1.07886055\n",
      "Iteration 17, loss = 1.05537504\n",
      "Iteration 18, loss = 1.01630167\n",
      "Iteration 19, loss = 1.02836021\n",
      "Iteration 20, loss = 1.04814706\n",
      "Iteration 21, loss = 1.02663590\n",
      "Iteration 22, loss = 1.06643960\n",
      "Iteration 23, loss = 1.03033303\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22033453\n",
      "Iteration 2, loss = 1.17224052\n",
      "Iteration 3, loss = 1.04500599\n",
      "Iteration 4, loss = 1.02435750\n",
      "Iteration 5, loss = 1.03816307\n",
      "Iteration 6, loss = 1.05540215\n",
      "Iteration 7, loss = 1.02364779\n",
      "Iteration 8, loss = 1.03892661\n",
      "Iteration 9, loss = 1.02174149\n",
      "Iteration 18, loss = 1.01630167\n",
      "Iteration 19, loss = 1.02836021\n",
      "Iteration 20, loss = 1.04814706\n",
      "Iteration 21, loss = 1.02663590\n",
      "Iteration 22, loss = 1.06643960\n",
      "Iteration 23, loss = 1.03033303\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22033453\n",
      "Iteration 2, loss = 1.17224052\n",
      "Iteration 3, loss = 1.04500599\n",
      "Iteration 4, loss = 1.02435750\n",
      "Iteration 5, loss = 1.03816307\n",
      "Iteration 6, loss = 1.05540215\n",
      "Iteration 7, loss = 1.02364779\n",
      "Iteration 8, loss = 1.03892661\n",
      "Iteration 9, loss = 1.02174149\n",
      "Iteration 10, loss = 1.02241450\n",
      "Iteration 11, loss = 1.00295724\n",
      "Iteration 12, loss = 1.01380055\n",
      "Iteration 13, loss = 1.00706749\n",
      "Iteration 14, loss = 0.98607037\n",
      "Iteration 15, loss = 1.07956472\n",
      "Iteration 16, loss = 0.99723231\n",
      "Iteration 17, loss = 1.01006476\n",
      "Iteration 18, loss = 1.05498700\n",
      "Iteration 19, loss = 1.01788197\n",
      "Iteration 20, loss = 1.01527505\n",
      "Iteration 21, loss = 1.02616158\n",
      "Iteration 22, loss = 1.02676536\n",
      "Iteration 23, loss = 1.00432810\n",
      "Iteration 24, loss = 1.03476840\n",
      "Iteration 25, loss = 1.06478915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28356506\n",
      "Iteration 10, loss = 1.02241450\n",
      "Iteration 11, loss = 1.00295724\n",
      "Iteration 12, loss = 1.01380055\n",
      "Iteration 13, loss = 1.00706749\n",
      "Iteration 14, loss = 0.98607037\n",
      "Iteration 15, loss = 1.07956472\n",
      "Iteration 16, loss = 0.99723231\n",
      "Iteration 17, loss = 1.01006476\n",
      "Iteration 18, loss = 1.05498700\n",
      "Iteration 19, loss = 1.01788197\n",
      "Iteration 20, loss = 1.01527505\n",
      "Iteration 21, loss = 1.02616158\n",
      "Iteration 22, loss = 1.02676536\n",
      "Iteration 23, loss = 1.00432810\n",
      "Iteration 24, loss = 1.03476840\n",
      "Iteration 25, loss = 1.06478915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28356506\n",
      "Iteration 2, loss = 1.28249555\n",
      "Iteration 3, loss = 1.24593457\n",
      "Iteration 4, loss = 1.24423285\n",
      "Iteration 5, loss = 1.24119903\n",
      "Iteration 6, loss = 1.25225299\n",
      "Iteration 7, loss = 1.25071888\n",
      "Iteration 8, loss = 1.23845844\n",
      "Iteration 9, loss = 1.25514627\n",
      "Iteration 10, loss = 1.24681596\n",
      "Iteration 1, loss = 1.33715288\n",
      "Iteration 2, loss = 1.25269177\n",
      "Iteration 3, loss = 1.23876768\n",
      "Iteration 4, loss = 1.24588416\n",
      "Iteration 5, loss = 1.23512031\n",
      "Iteration 2, loss = 1.28249555\n",
      "Iteration 3, loss = 1.24593457\n",
      "Iteration 4, loss = 1.24423285\n",
      "Iteration 5, loss = 1.24119903\n",
      "Iteration 6, loss = 1.25225299\n",
      "Iteration 7, loss = 1.25071888\n",
      "Iteration 8, loss = 1.23845844\n",
      "Iteration 9, loss = 1.25514627\n",
      "Iteration 10, loss = 1.24681596\n",
      "Iteration 1, loss = 1.33715288\n",
      "Iteration 2, loss = 1.25269177\n",
      "Iteration 3, loss = 1.23876768\n",
      "Iteration 4, loss = 1.24588416\n",
      "Iteration 5, loss = 1.23512031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.24120816\n",
      "Iteration 7, loss = 1.24566629\n",
      "Iteration 8, loss = 1.24355379\n",
      "Iteration 9, loss = 1.23882248\n",
      "Iteration 10, loss = 1.24298569\n",
      "Iteration 1, loss = 1.27238016\n",
      "Iteration 2, loss = 1.24385882\n",
      "Iteration 3, loss = 1.26131924\n",
      "Iteration 4, loss = 1.26827723\n",
      "Iteration 5, loss = 1.24549498\n",
      "Iteration 6, loss = 1.24120816\n",
      "Iteration 7, loss = 1.24566629\n",
      "Iteration 8, loss = 1.24355379\n",
      "Iteration 9, loss = 1.23882248\n",
      "Iteration 10, loss = 1.24298569\n",
      "Iteration 1, loss = 1.27238016\n",
      "Iteration 2, loss = 1.24385882\n",
      "Iteration 3, loss = 1.26131924\n",
      "Iteration 4, loss = 1.26827723\n",
      "Iteration 5, loss = 1.24549498\n",
      "Iteration 6, loss = 1.26623381\n",
      "Iteration 7, loss = 1.26506899\n",
      "Iteration 8, loss = 1.26230620\n",
      "Iteration 9, loss = 1.25961275\n",
      "Iteration 10, loss = 1.26106241\n",
      "Iteration 1, loss = 1.21056447\n",
      "Iteration 2, loss = 1.21734439\n",
      "Iteration 3, loss = 1.25757154\n",
      "Iteration 4, loss = 1.26011276\n",
      "Iteration 5, loss = 1.25002999\n",
      "Iteration 6, loss = 1.25060145\n",
      "Iteration 7, loss = 1.26709566\n",
      "Iteration 8, loss = 1.24956508\n",
      "Iteration 9, loss = 1.24903407\n",
      "Iteration 6, loss = 1.26623381\n",
      "Iteration 7, loss = 1.26506899\n",
      "Iteration 8, loss = 1.26230620\n",
      "Iteration 9, loss = 1.25961275\n",
      "Iteration 10, loss = 1.26106241\n",
      "Iteration 1, loss = 1.21056447\n",
      "Iteration 2, loss = 1.21734439\n",
      "Iteration 3, loss = 1.25757154\n",
      "Iteration 4, loss = 1.26011276\n",
      "Iteration 5, loss = 1.25002999\n",
      "Iteration 6, loss = 1.25060145\n",
      "Iteration 7, loss = 1.26709566\n",
      "Iteration 8, loss = 1.24956508\n",
      "Iteration 9, loss = 1.24903407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.26002036\n",
      "Iteration 1, loss = 1.20476783\n",
      "Iteration 2, loss = 1.13336020\n",
      "Iteration 3, loss = 1.09882260\n",
      "Iteration 4, loss = 1.03649559\n",
      "Iteration 5, loss = 1.02575322\n",
      "Iteration 6, loss = 1.02307714\n",
      "Iteration 7, loss = 1.00209337\n",
      "Iteration 8, loss = 1.01232870\n",
      "Iteration 9, loss = 0.99047543\n",
      "Iteration 10, loss = 1.03064883\n",
      "Iteration 1, loss = 1.28356506\n",
      "Iteration 10, loss = 1.26002036\n",
      "Iteration 1, loss = 1.20476783\n",
      "Iteration 2, loss = 1.13336020\n",
      "Iteration 3, loss = 1.09882260\n",
      "Iteration 4, loss = 1.03649559\n",
      "Iteration 5, loss = 1.02575322\n",
      "Iteration 6, loss = 1.02307714\n",
      "Iteration 7, loss = 1.00209337\n",
      "Iteration 8, loss = 1.01232870\n",
      "Iteration 9, loss = 0.99047543\n",
      "Iteration 10, loss = 1.03064883\n",
      "Iteration 1, loss = 1.28356506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.28249555\n",
      "Iteration 3, loss = 1.24593457\n",
      "Iteration 4, loss = 1.24423285\n",
      "Iteration 5, loss = 1.24119903\n",
      "Iteration 6, loss = 1.25225299\n",
      "Iteration 7, loss = 1.25071888\n",
      "Iteration 8, loss = 1.23845844\n",
      "Iteration 9, loss = 1.25514627\n",
      "Iteration 10, loss = 1.24681596\n",
      "Iteration 11, loss = 1.24943213\n",
      "Iteration 12, loss = 1.25981393\n",
      "Iteration 13, loss = 1.27021815\n",
      "Iteration 14, loss = 1.24251204\n",
      "Iteration 2, loss = 1.28249555\n",
      "Iteration 3, loss = 1.24593457\n",
      "Iteration 4, loss = 1.24423285\n",
      "Iteration 5, loss = 1.24119903\n",
      "Iteration 6, loss = 1.25225299\n",
      "Iteration 7, loss = 1.25071888\n",
      "Iteration 8, loss = 1.23845844\n",
      "Iteration 9, loss = 1.25514627\n",
      "Iteration 10, loss = 1.24681596\n",
      "Iteration 11, loss = 1.24943213\n",
      "Iteration 12, loss = 1.25981393\n",
      "Iteration 13, loss = 1.27021815\n",
      "Iteration 14, loss = 1.24251204\n",
      "Iteration 15, loss = 1.26458120\n",
      "Iteration 16, loss = 1.25760331\n",
      "Iteration 17, loss = 1.27089202\n",
      "Iteration 18, loss = 1.25116249\n",
      "Iteration 19, loss = 1.24569591\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33715288\n",
      "Iteration 2, loss = 1.25269177\n",
      "Iteration 3, loss = 1.23876768\n",
      "Iteration 4, loss = 1.24588416\n",
      "Iteration 5, loss = 1.23512031\n",
      "Iteration 6, loss = 1.24120816\n",
      "Iteration 7, loss = 1.24566629\n",
      "Iteration 8, loss = 1.24355379\n",
      "Iteration 9, loss = 1.23882248\n",
      "Iteration 10, loss = 1.24298569\n",
      "Iteration 15, loss = 1.26458120\n",
      "Iteration 16, loss = 1.25760331\n",
      "Iteration 17, loss = 1.27089202\n",
      "Iteration 18, loss = 1.25116249\n",
      "Iteration 19, loss = 1.24569591\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33715288\n",
      "Iteration 2, loss = 1.25269177\n",
      "Iteration 3, loss = 1.23876768\n",
      "Iteration 4, loss = 1.24588416\n",
      "Iteration 5, loss = 1.23512031\n",
      "Iteration 6, loss = 1.24120816\n",
      "Iteration 7, loss = 1.24566629\n",
      "Iteration 8, loss = 1.24355379\n",
      "Iteration 9, loss = 1.23882248\n",
      "Iteration 10, loss = 1.24298569\n",
      "Iteration 11, loss = 1.25517706\n",
      "Iteration 12, loss = 1.24952298\n",
      "Iteration 13, loss = 1.25487426\n",
      "Iteration 14, loss = 1.23987877\n",
      "Iteration 15, loss = 1.26296036\n",
      "Iteration 16, loss = 1.25043428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27238016\n",
      "Iteration 2, loss = 1.24385882\n",
      "Iteration 3, loss = 1.26131924\n",
      "Iteration 4, loss = 1.26827723\n",
      "Iteration 5, loss = 1.24549498\n",
      "Iteration 6, loss = 1.26623381\n",
      "Iteration 7, loss = 1.26506899\n",
      "Iteration 8, loss = 1.26230620\n",
      "Iteration 11, loss = 1.25517706\n",
      "Iteration 12, loss = 1.24952298\n",
      "Iteration 13, loss = 1.25487426\n",
      "Iteration 14, loss = 1.23987877\n",
      "Iteration 15, loss = 1.26296036\n",
      "Iteration 16, loss = 1.25043428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27238016\n",
      "Iteration 2, loss = 1.24385882\n",
      "Iteration 3, loss = 1.26131924\n",
      "Iteration 4, loss = 1.26827723\n",
      "Iteration 5, loss = 1.24549498\n",
      "Iteration 6, loss = 1.26623381\n",
      "Iteration 7, loss = 1.26506899\n",
      "Iteration 8, loss = 1.26230620\n",
      "Iteration 9, loss = 1.25961275\n",
      "Iteration 10, loss = 1.26106241\n",
      "Iteration 11, loss = 1.26144127\n",
      "Iteration 12, loss = 1.26578682\n",
      "Iteration 13, loss = 1.26597129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21056447\n",
      "Iteration 2, loss = 1.21734439\n",
      "Iteration 3, loss = 1.25757154\n",
      "Iteration 4, loss = 1.26011276\n",
      "Iteration 5, loss = 1.25002999\n",
      "Iteration 6, loss = 1.25060145\n",
      "Iteration 7, loss = 1.26709566\n",
      "Iteration 8, loss = 1.24956508\n",
      "Iteration 9, loss = 1.24903407\n",
      "Iteration 10, loss = 1.26002036\n",
      "Iteration 9, loss = 1.25961275\n",
      "Iteration 10, loss = 1.26106241\n",
      "Iteration 11, loss = 1.26144127\n",
      "Iteration 12, loss = 1.26578682\n",
      "Iteration 13, loss = 1.26597129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21056447\n",
      "Iteration 2, loss = 1.21734439\n",
      "Iteration 3, loss = 1.25757154\n",
      "Iteration 4, loss = 1.26011276\n",
      "Iteration 5, loss = 1.25002999\n",
      "Iteration 6, loss = 1.25060145\n",
      "Iteration 7, loss = 1.26709566\n",
      "Iteration 8, loss = 1.24956508\n",
      "Iteration 9, loss = 1.24903407\n",
      "Iteration 10, loss = 1.26002036\n",
      "Iteration 11, loss = 1.26057536\n",
      "Iteration 12, loss = 1.25557642\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20476783\n",
      "Iteration 2, loss = 1.13336020\n",
      "Iteration 3, loss = 1.09882260\n",
      "Iteration 4, loss = 1.03649559\n",
      "Iteration 5, loss = 1.02575322\n",
      "Iteration 6, loss = 1.02307714\n",
      "Iteration 7, loss = 1.00209337\n",
      "Iteration 8, loss = 1.01232870\n",
      "Iteration 9, loss = 0.99047543\n",
      "Iteration 10, loss = 1.03064883\n",
      "Iteration 11, loss = 1.02738584\n",
      "Iteration 12, loss = 1.11464934\n",
      "Iteration 11, loss = 1.26057536\n",
      "Iteration 12, loss = 1.25557642\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20476783\n",
      "Iteration 2, loss = 1.13336020\n",
      "Iteration 3, loss = 1.09882260\n",
      "Iteration 4, loss = 1.03649559\n",
      "Iteration 5, loss = 1.02575322\n",
      "Iteration 6, loss = 1.02307714\n",
      "Iteration 7, loss = 1.00209337\n",
      "Iteration 8, loss = 1.01232870\n",
      "Iteration 9, loss = 0.99047543\n",
      "Iteration 10, loss = 1.03064883\n",
      "Iteration 11, loss = 1.02738584\n",
      "Iteration 12, loss = 1.11464934\n",
      "Iteration 13, loss = 1.28518282\n",
      "Iteration 14, loss = 1.29285512\n",
      "Iteration 15, loss = 1.30999454\n",
      "Iteration 16, loss = 1.28165634\n",
      "Iteration 17, loss = 1.28360287\n",
      "Iteration 18, loss = 1.29328063\n",
      "Iteration 19, loss = 1.28546332\n",
      "Iteration 20, loss = 1.28540843\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28356506\n",
      "Iteration 2, loss = 1.28249555\n",
      "Iteration 3, loss = 1.24593457\n",
      "Iteration 4, loss = 1.24423285\n",
      "Iteration 5, loss = 1.24119903\n",
      "Iteration 6, loss = 1.25225299\n",
      "Iteration 7, loss = 1.25071888\n",
      "Iteration 13, loss = 1.28518282\n",
      "Iteration 14, loss = 1.29285512\n",
      "Iteration 15, loss = 1.30999454\n",
      "Iteration 16, loss = 1.28165634\n",
      "Iteration 17, loss = 1.28360287\n",
      "Iteration 18, loss = 1.29328063\n",
      "Iteration 19, loss = 1.28546332\n",
      "Iteration 20, loss = 1.28540843\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28356506\n",
      "Iteration 2, loss = 1.28249555\n",
      "Iteration 3, loss = 1.24593457\n",
      "Iteration 4, loss = 1.24423285\n",
      "Iteration 5, loss = 1.24119903\n",
      "Iteration 6, loss = 1.25225299\n",
      "Iteration 7, loss = 1.25071888\n",
      "Iteration 8, loss = 1.23845844\n",
      "Iteration 9, loss = 1.25514627\n",
      "Iteration 10, loss = 1.24681596\n",
      "Iteration 11, loss = 1.24943213\n",
      "Iteration 12, loss = 1.25981393\n",
      "Iteration 13, loss = 1.27021815\n",
      "Iteration 14, loss = 1.24251204\n",
      "Iteration 15, loss = 1.26458120\n",
      "Iteration 16, loss = 1.25760331\n",
      "Iteration 17, loss = 1.27089202\n",
      "Iteration 18, loss = 1.25116249\n",
      "Iteration 19, loss = 1.24569591\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33715288\n",
      "Iteration 2, loss = 1.25269177\n",
      "Iteration 8, loss = 1.23845844\n",
      "Iteration 9, loss = 1.25514627\n",
      "Iteration 10, loss = 1.24681596\n",
      "Iteration 11, loss = 1.24943213\n",
      "Iteration 12, loss = 1.25981393\n",
      "Iteration 13, loss = 1.27021815\n",
      "Iteration 14, loss = 1.24251204\n",
      "Iteration 15, loss = 1.26458120\n",
      "Iteration 16, loss = 1.25760331\n",
      "Iteration 17, loss = 1.27089202\n",
      "Iteration 18, loss = 1.25116249\n",
      "Iteration 19, loss = 1.24569591\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33715288\n",
      "Iteration 2, loss = 1.25269177\n",
      "Iteration 3, loss = 1.23876768\n",
      "Iteration 4, loss = 1.24588416\n",
      "Iteration 5, loss = 1.23512031\n",
      "Iteration 6, loss = 1.24120816\n",
      "Iteration 7, loss = 1.24566629\n",
      "Iteration 8, loss = 1.24355379\n",
      "Iteration 9, loss = 1.23882248\n",
      "Iteration 10, loss = 1.24298569\n",
      "Iteration 11, loss = 1.25517706\n",
      "Iteration 12, loss = 1.24952298\n",
      "Iteration 13, loss = 1.25487426\n",
      "Iteration 14, loss = 1.23987877\n",
      "Iteration 15, loss = 1.26296036\n",
      "Iteration 16, loss = 1.25043428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27238016\n",
      "Iteration 3, loss = 1.23876768\n",
      "Iteration 4, loss = 1.24588416\n",
      "Iteration 5, loss = 1.23512031\n",
      "Iteration 6, loss = 1.24120816\n",
      "Iteration 7, loss = 1.24566629\n",
      "Iteration 8, loss = 1.24355379\n",
      "Iteration 9, loss = 1.23882248\n",
      "Iteration 10, loss = 1.24298569\n",
      "Iteration 11, loss = 1.25517706\n",
      "Iteration 12, loss = 1.24952298\n",
      "Iteration 13, loss = 1.25487426\n",
      "Iteration 14, loss = 1.23987877\n",
      "Iteration 15, loss = 1.26296036\n",
      "Iteration 16, loss = 1.25043428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27238016\n",
      "Iteration 2, loss = 1.24385882\n",
      "Iteration 3, loss = 1.26131924\n",
      "Iteration 4, loss = 1.26827723\n",
      "Iteration 5, loss = 1.24549498\n",
      "Iteration 6, loss = 1.26623381\n",
      "Iteration 7, loss = 1.26506899\n",
      "Iteration 8, loss = 1.26230620\n",
      "Iteration 9, loss = 1.25961275\n",
      "Iteration 10, loss = 1.26106241\n",
      "Iteration 11, loss = 1.26144127\n",
      "Iteration 12, loss = 1.26578682\n",
      "Iteration 13, loss = 1.26597129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21056447\n",
      "Iteration 2, loss = 1.24385882\n",
      "Iteration 3, loss = 1.26131924\n",
      "Iteration 4, loss = 1.26827723\n",
      "Iteration 5, loss = 1.24549498\n",
      "Iteration 6, loss = 1.26623381\n",
      "Iteration 7, loss = 1.26506899\n",
      "Iteration 8, loss = 1.26230620\n",
      "Iteration 9, loss = 1.25961275\n",
      "Iteration 10, loss = 1.26106241\n",
      "Iteration 11, loss = 1.26144127\n",
      "Iteration 12, loss = 1.26578682\n",
      "Iteration 13, loss = 1.26597129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21056447\n",
      "Iteration 2, loss = 1.21734439\n",
      "Iteration 3, loss = 1.25757154\n",
      "Iteration 4, loss = 1.26011276\n",
      "Iteration 5, loss = 1.25002999\n",
      "Iteration 6, loss = 1.25060145\n",
      "Iteration 7, loss = 1.26709566\n",
      "Iteration 8, loss = 1.24956508\n",
      "Iteration 9, loss = 1.24903407\n",
      "Iteration 10, loss = 1.26002036\n",
      "Iteration 11, loss = 1.26057536\n",
      "Iteration 12, loss = 1.25557642\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20476783\n",
      "Iteration 2, loss = 1.13336020\n",
      "Iteration 3, loss = 1.09882260\n",
      "Iteration 4, loss = 1.03649559\n",
      "Iteration 2, loss = 1.21734439\n",
      "Iteration 3, loss = 1.25757154\n",
      "Iteration 4, loss = 1.26011276\n",
      "Iteration 5, loss = 1.25002999\n",
      "Iteration 6, loss = 1.25060145\n",
      "Iteration 7, loss = 1.26709566\n",
      "Iteration 8, loss = 1.24956508\n",
      "Iteration 9, loss = 1.24903407\n",
      "Iteration 10, loss = 1.26002036\n",
      "Iteration 11, loss = 1.26057536\n",
      "Iteration 12, loss = 1.25557642\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20476783\n",
      "Iteration 2, loss = 1.13336020\n",
      "Iteration 3, loss = 1.09882260\n",
      "Iteration 4, loss = 1.03649559\n",
      "Iteration 5, loss = 1.02575322\n",
      "Iteration 6, loss = 1.02307714\n",
      "Iteration 7, loss = 1.00209337\n",
      "Iteration 8, loss = 1.01232870\n",
      "Iteration 9, loss = 0.99047543\n",
      "Iteration 10, loss = 1.03064883\n",
      "Iteration 11, loss = 1.02738584\n",
      "Iteration 12, loss = 1.11464934\n",
      "Iteration 13, loss = 1.28518282\n",
      "Iteration 14, loss = 1.29285512\n",
      "Iteration 15, loss = 1.30999454\n",
      "Iteration 16, loss = 1.28165634\n",
      "Iteration 17, loss = 1.28360287\n",
      "Iteration 18, loss = 1.29328063\n",
      "Iteration 19, loss = 1.28546332\n",
      "Iteration 20, loss = 1.28540843\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 1.02575322\n",
      "Iteration 6, loss = 1.02307714\n",
      "Iteration 7, loss = 1.00209337\n",
      "Iteration 8, loss = 1.01232870\n",
      "Iteration 9, loss = 0.99047543\n",
      "Iteration 10, loss = 1.03064883\n",
      "Iteration 11, loss = 1.02738584\n",
      "Iteration 12, loss = 1.11464934\n",
      "Iteration 13, loss = 1.28518282\n",
      "Iteration 14, loss = 1.29285512\n",
      "Iteration 15, loss = 1.30999454\n",
      "Iteration 16, loss = 1.28165634\n",
      "Iteration 17, loss = 1.28360287\n",
      "Iteration 18, loss = 1.29328063\n",
      "Iteration 19, loss = 1.28546332\n",
      "Iteration 20, loss = 1.28540843\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24130168\n",
      "Iteration 2, loss = 1.09680862\n",
      "Iteration 3, loss = 1.00600462\n",
      "Iteration 4, loss = 0.99822181\n",
      "Iteration 5, loss = 0.96519139\n",
      "Iteration 6, loss = 0.98338087\n",
      "Iteration 7, loss = 0.96038599\n",
      "Iteration 8, loss = 0.93991611\n",
      "Iteration 9, loss = 0.96237577\n",
      "Iteration 10, loss = 0.95443451\n",
      "Iteration 1, loss = 1.21483003\n",
      "Iteration 1, loss = 1.24130168\n",
      "Iteration 2, loss = 1.09680862\n",
      "Iteration 3, loss = 1.00600462\n",
      "Iteration 4, loss = 0.99822181\n",
      "Iteration 5, loss = 0.96519139\n",
      "Iteration 6, loss = 0.98338087\n",
      "Iteration 7, loss = 0.96038599\n",
      "Iteration 8, loss = 0.93991611\n",
      "Iteration 9, loss = 0.96237577\n",
      "Iteration 10, loss = 0.95443451\n",
      "Iteration 1, loss = 1.21483003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.00280333\n",
      "Iteration 3, loss = 0.94633122\n",
      "Iteration 4, loss = 0.94369185\n",
      "Iteration 5, loss = 0.90911808\n",
      "Iteration 6, loss = 0.92656774\n",
      "Iteration 7, loss = 0.89248647\n",
      "Iteration 8, loss = 0.89487780\n",
      "Iteration 9, loss = 0.94626577\n",
      "Iteration 10, loss = 0.89771990\n",
      "Iteration 1, loss = 1.23162481\n",
      "Iteration 2, loss = 1.03658927\n",
      "Iteration 3, loss = 0.98613922\n",
      "Iteration 2, loss = 1.00280333\n",
      "Iteration 3, loss = 0.94633122\n",
      "Iteration 4, loss = 0.94369185\n",
      "Iteration 5, loss = 0.90911808\n",
      "Iteration 6, loss = 0.92656774\n",
      "Iteration 7, loss = 0.89248647\n",
      "Iteration 8, loss = 0.89487780\n",
      "Iteration 9, loss = 0.94626577\n",
      "Iteration 10, loss = 0.89771990\n",
      "Iteration 1, loss = 1.23162481\n",
      "Iteration 2, loss = 1.03658927\n",
      "Iteration 3, loss = 0.98613922\n",
      "Iteration 4, loss = 0.97501743\n",
      "Iteration 5, loss = 1.00091840\n",
      "Iteration 6, loss = 0.95378241\n",
      "Iteration 7, loss = 0.95675673\n",
      "Iteration 8, loss = 0.96009077\n",
      "Iteration 9, loss = 0.93005249\n",
      "Iteration 10, loss = 0.91375591\n",
      "Iteration 1, loss = 1.19704390\n",
      "Iteration 2, loss = 1.05976697\n",
      "Iteration 3, loss = 1.03467142\n",
      "Iteration 4, loss = 0.99257980\n",
      "Iteration 5, loss = 1.05407634\n",
      "Iteration 6, loss = 1.06171954\n",
      "Iteration 4, loss = 0.97501743\n",
      "Iteration 5, loss = 1.00091840\n",
      "Iteration 6, loss = 0.95378241\n",
      "Iteration 7, loss = 0.95675673\n",
      "Iteration 8, loss = 0.96009077\n",
      "Iteration 9, loss = 0.93005249\n",
      "Iteration 10, loss = 0.91375591\n",
      "Iteration 1, loss = 1.19704390\n",
      "Iteration 2, loss = 1.05976697\n",
      "Iteration 3, loss = 1.03467142\n",
      "Iteration 4, loss = 0.99257980\n",
      "Iteration 5, loss = 1.05407634\n",
      "Iteration 6, loss = 1.06171954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.02050045\n",
      "Iteration 8, loss = 1.02441699\n",
      "Iteration 9, loss = 0.99100170\n",
      "Iteration 10, loss = 0.99757114\n",
      "Iteration 1, loss = 1.17821490\n",
      "Iteration 2, loss = 1.06408951\n",
      "Iteration 3, loss = 0.99985759\n",
      "Iteration 4, loss = 0.97472654\n",
      "Iteration 5, loss = 1.01839053\n",
      "Iteration 6, loss = 0.98137982\n",
      "Iteration 7, loss = 0.93818562\n",
      "Iteration 7, loss = 1.02050045\n",
      "Iteration 8, loss = 1.02441699\n",
      "Iteration 9, loss = 0.99100170\n",
      "Iteration 10, loss = 0.99757114\n",
      "Iteration 1, loss = 1.17821490\n",
      "Iteration 2, loss = 1.06408951\n",
      "Iteration 3, loss = 0.99985759\n",
      "Iteration 4, loss = 0.97472654\n",
      "Iteration 5, loss = 1.01839053\n",
      "Iteration 6, loss = 0.98137982\n",
      "Iteration 7, loss = 0.93818562\n",
      "Iteration 8, loss = 0.96954009\n",
      "Iteration 9, loss = 0.92701369\n",
      "Iteration 10, loss = 0.93462357\n",
      "Iteration 1, loss = 1.24130168\n",
      "Iteration 2, loss = 1.09680862\n",
      "Iteration 3, loss = 1.00600462\n",
      "Iteration 4, loss = 0.99822181\n",
      "Iteration 5, loss = 0.96519139\n",
      "Iteration 6, loss = 0.98338087\n",
      "Iteration 7, loss = 0.96038599\n",
      "Iteration 8, loss = 0.93991611\n",
      "Iteration 9, loss = 0.96237577\n",
      "Iteration 10, loss = 0.95443451\n",
      "Iteration 8, loss = 0.96954009\n",
      "Iteration 9, loss = 0.92701369\n",
      "Iteration 10, loss = 0.93462357\n",
      "Iteration 1, loss = 1.24130168\n",
      "Iteration 2, loss = 1.09680862\n",
      "Iteration 3, loss = 1.00600462\n",
      "Iteration 4, loss = 0.99822181\n",
      "Iteration 5, loss = 0.96519139\n",
      "Iteration 6, loss = 0.98338087\n",
      "Iteration 7, loss = 0.96038599\n",
      "Iteration 8, loss = 0.93991611\n",
      "Iteration 9, loss = 0.96237577\n",
      "Iteration 10, loss = 0.95443451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.97104697\n",
      "Iteration 12, loss = 0.94074485\n",
      "Iteration 13, loss = 0.93709410\n",
      "Iteration 14, loss = 0.91713196\n",
      "Iteration 15, loss = 0.91208405\n",
      "Iteration 16, loss = 0.90466848\n",
      "Iteration 17, loss = 0.92599568\n",
      "Iteration 18, loss = 0.89774921\n",
      "Iteration 19, loss = 0.93646149\n",
      "Iteration 20, loss = 0.89917445\n",
      "Iteration 21, loss = 0.90966563\n",
      "Iteration 22, loss = 0.89446096\n",
      "Iteration 23, loss = 0.92206184\n",
      "Iteration 24, loss = 0.88756844\n",
      "Iteration 25, loss = 0.86562829\n",
      "Iteration 11, loss = 0.97104697\n",
      "Iteration 12, loss = 0.94074485\n",
      "Iteration 13, loss = 0.93709410\n",
      "Iteration 14, loss = 0.91713196\n",
      "Iteration 15, loss = 0.91208405\n",
      "Iteration 16, loss = 0.90466848\n",
      "Iteration 17, loss = 0.92599568\n",
      "Iteration 18, loss = 0.89774921\n",
      "Iteration 19, loss = 0.93646149\n",
      "Iteration 20, loss = 0.89917445\n",
      "Iteration 21, loss = 0.90966563\n",
      "Iteration 22, loss = 0.89446096\n",
      "Iteration 23, loss = 0.92206184\n",
      "Iteration 24, loss = 0.88756844\n",
      "Iteration 25, loss = 0.86562829\n",
      "Iteration 26, loss = 0.86526939\n",
      "Iteration 27, loss = 0.88328923\n",
      "Iteration 28, loss = 0.86257860\n",
      "Iteration 29, loss = 0.87080421\n",
      "Iteration 30, loss = 0.93073897\n",
      "Iteration 31, loss = 0.87640071\n",
      "Iteration 32, loss = 0.88568198\n",
      "Iteration 33, loss = 0.91801609\n",
      "Iteration 34, loss = 0.86780624\n",
      "Iteration 35, loss = 0.90645958\n",
      "Iteration 36, loss = 0.86346747\n",
      "Iteration 37, loss = 0.88109532\n",
      "Iteration 38, loss = 0.87885168\n",
      "Iteration 39, loss = 0.85013014\n",
      "Iteration 40, loss = 0.90424169\n",
      "Iteration 26, loss = 0.86526939\n",
      "Iteration 27, loss = 0.88328923\n",
      "Iteration 28, loss = 0.86257860\n",
      "Iteration 29, loss = 0.87080421\n",
      "Iteration 30, loss = 0.93073897\n",
      "Iteration 31, loss = 0.87640071\n",
      "Iteration 32, loss = 0.88568198\n",
      "Iteration 33, loss = 0.91801609\n",
      "Iteration 34, loss = 0.86780624\n",
      "Iteration 35, loss = 0.90645958\n",
      "Iteration 36, loss = 0.86346747\n",
      "Iteration 37, loss = 0.88109532\n",
      "Iteration 38, loss = 0.87885168\n",
      "Iteration 39, loss = 0.85013014\n",
      "Iteration 40, loss = 0.90424169\n",
      "Iteration 41, loss = 0.84471702\n",
      "Iteration 42, loss = 0.81217721\n",
      "Iteration 43, loss = 0.81379802\n",
      "Iteration 44, loss = 0.82753546\n",
      "Iteration 45, loss = 0.81569648\n",
      "Iteration 46, loss = 0.87956678\n",
      "Iteration 47, loss = 0.80932982\n",
      "Iteration 48, loss = 0.85528505\n",
      "Iteration 49, loss = 0.83594109\n",
      "Iteration 50, loss = 0.85804467\n",
      "Iteration 1, loss = 1.21483003\n",
      "Iteration 2, loss = 1.00280333\n",
      "Iteration 3, loss = 0.94633122\n",
      "Iteration 4, loss = 0.94369185\n",
      "Iteration 5, loss = 0.90911808\n",
      "Iteration 41, loss = 0.84471702\n",
      "Iteration 42, loss = 0.81217721\n",
      "Iteration 43, loss = 0.81379802\n",
      "Iteration 44, loss = 0.82753546\n",
      "Iteration 45, loss = 0.81569648\n",
      "Iteration 46, loss = 0.87956678\n",
      "Iteration 47, loss = 0.80932982\n",
      "Iteration 48, loss = 0.85528505\n",
      "Iteration 49, loss = 0.83594109\n",
      "Iteration 50, loss = 0.85804467\n",
      "Iteration 1, loss = 1.21483003\n",
      "Iteration 2, loss = 1.00280333\n",
      "Iteration 3, loss = 0.94633122\n",
      "Iteration 4, loss = 0.94369185\n",
      "Iteration 5, loss = 0.90911808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.92656774\n",
      "Iteration 7, loss = 0.89248647\n",
      "Iteration 8, loss = 0.89487780\n",
      "Iteration 9, loss = 0.94626577\n",
      "Iteration 10, loss = 0.89771990\n",
      "Iteration 11, loss = 0.92759326\n",
      "Iteration 12, loss = 0.93143672\n",
      "Iteration 13, loss = 0.89232485\n",
      "Iteration 14, loss = 0.88915996\n",
      "Iteration 15, loss = 0.87456467\n",
      "Iteration 16, loss = 0.88176906\n",
      "Iteration 17, loss = 0.88599227\n",
      "Iteration 18, loss = 0.89078244\n",
      "Iteration 19, loss = 0.87307780\n",
      "Iteration 6, loss = 0.92656774\n",
      "Iteration 7, loss = 0.89248647\n",
      "Iteration 8, loss = 0.89487780\n",
      "Iteration 9, loss = 0.94626577\n",
      "Iteration 10, loss = 0.89771990\n",
      "Iteration 11, loss = 0.92759326\n",
      "Iteration 12, loss = 0.93143672\n",
      "Iteration 13, loss = 0.89232485\n",
      "Iteration 14, loss = 0.88915996\n",
      "Iteration 15, loss = 0.87456467\n",
      "Iteration 16, loss = 0.88176906\n",
      "Iteration 17, loss = 0.88599227\n",
      "Iteration 18, loss = 0.89078244\n",
      "Iteration 19, loss = 0.87307780\n",
      "Iteration 20, loss = 0.88117032\n",
      "Iteration 21, loss = 0.83482153\n",
      "Iteration 22, loss = 0.86249670\n",
      "Iteration 23, loss = 0.83827702\n",
      "Iteration 24, loss = 0.86652246\n",
      "Iteration 25, loss = 0.82968896\n",
      "Iteration 26, loss = 0.83448704\n",
      "Iteration 27, loss = 0.87992337\n",
      "Iteration 28, loss = 0.97281544\n",
      "Iteration 29, loss = 0.88934258\n",
      "Iteration 30, loss = 0.84627833\n",
      "Iteration 31, loss = 0.84352832\n",
      "Iteration 32, loss = 0.84758789\n",
      "Iteration 33, loss = 0.83878578\n",
      "Iteration 34, loss = 0.79737388\n",
      "Iteration 35, loss = 0.84128720\n",
      "Iteration 20, loss = 0.88117032\n",
      "Iteration 21, loss = 0.83482153\n",
      "Iteration 22, loss = 0.86249670\n",
      "Iteration 23, loss = 0.83827702\n",
      "Iteration 24, loss = 0.86652246\n",
      "Iteration 25, loss = 0.82968896\n",
      "Iteration 26, loss = 0.83448704\n",
      "Iteration 27, loss = 0.87992337\n",
      "Iteration 28, loss = 0.97281544\n",
      "Iteration 29, loss = 0.88934258\n",
      "Iteration 30, loss = 0.84627833\n",
      "Iteration 31, loss = 0.84352832\n",
      "Iteration 32, loss = 0.84758789\n",
      "Iteration 33, loss = 0.83878578\n",
      "Iteration 34, loss = 0.79737388\n",
      "Iteration 35, loss = 0.84128720\n",
      "Iteration 36, loss = 0.80136518\n",
      "Iteration 37, loss = 0.80693554\n",
      "Iteration 38, loss = 0.79891759\n",
      "Iteration 39, loss = 0.83681305\n",
      "Iteration 40, loss = 0.81674185\n",
      "Iteration 41, loss = 0.81378220\n",
      "Iteration 42, loss = 0.77391072\n",
      "Iteration 43, loss = 0.81621276\n",
      "Iteration 44, loss = 0.77762910\n",
      "Iteration 45, loss = 0.77708279\n",
      "Iteration 46, loss = 0.79593858\n",
      "Iteration 47, loss = 0.76583454\n",
      "Iteration 48, loss = 0.82045533\n",
      "Iteration 49, loss = 0.79706775\n",
      "Iteration 50, loss = 0.78103576\n",
      "Iteration 1, loss = 1.23162481\n",
      "Iteration 36, loss = 0.80136518\n",
      "Iteration 37, loss = 0.80693554\n",
      "Iteration 38, loss = 0.79891759\n",
      "Iteration 39, loss = 0.83681305\n",
      "Iteration 40, loss = 0.81674185\n",
      "Iteration 41, loss = 0.81378220\n",
      "Iteration 42, loss = 0.77391072\n",
      "Iteration 43, loss = 0.81621276\n",
      "Iteration 44, loss = 0.77762910\n",
      "Iteration 45, loss = 0.77708279\n",
      "Iteration 46, loss = 0.79593858\n",
      "Iteration 47, loss = 0.76583454\n",
      "Iteration 48, loss = 0.82045533\n",
      "Iteration 49, loss = 0.79706775\n",
      "Iteration 50, loss = 0.78103576\n",
      "Iteration 1, loss = 1.23162481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.03658927\n",
      "Iteration 3, loss = 0.98613922\n",
      "Iteration 4, loss = 0.97501743\n",
      "Iteration 5, loss = 1.00091840\n",
      "Iteration 6, loss = 0.95378241\n",
      "Iteration 7, loss = 0.95675673\n",
      "Iteration 8, loss = 0.96009077\n",
      "Iteration 9, loss = 0.93005249\n",
      "Iteration 10, loss = 0.91375591\n",
      "Iteration 11, loss = 0.94005533\n",
      "Iteration 12, loss = 0.92259912\n",
      "Iteration 13, loss = 0.91469052\n",
      "Iteration 14, loss = 0.92100945\n",
      "Iteration 15, loss = 0.91020602\n",
      "Iteration 2, loss = 1.03658927\n",
      "Iteration 3, loss = 0.98613922\n",
      "Iteration 4, loss = 0.97501743\n",
      "Iteration 5, loss = 1.00091840\n",
      "Iteration 6, loss = 0.95378241\n",
      "Iteration 7, loss = 0.95675673\n",
      "Iteration 8, loss = 0.96009077\n",
      "Iteration 9, loss = 0.93005249\n",
      "Iteration 10, loss = 0.91375591\n",
      "Iteration 11, loss = 0.94005533\n",
      "Iteration 12, loss = 0.92259912\n",
      "Iteration 13, loss = 0.91469052\n",
      "Iteration 14, loss = 0.92100945\n",
      "Iteration 15, loss = 0.91020602\n",
      "Iteration 16, loss = 0.90375871\n",
      "Iteration 17, loss = 0.90466673\n",
      "Iteration 18, loss = 0.90514516\n",
      "Iteration 19, loss = 0.89727495\n",
      "Iteration 20, loss = 0.88681853\n",
      "Iteration 21, loss = 0.87183444\n",
      "Iteration 22, loss = 0.90698271\n",
      "Iteration 23, loss = 0.89164304\n",
      "Iteration 24, loss = 0.90526418\n",
      "Iteration 25, loss = 0.89855333\n",
      "Iteration 26, loss = 0.86943222\n",
      "Iteration 27, loss = 0.85753051\n",
      "Iteration 28, loss = 1.00134941\n",
      "Iteration 29, loss = 0.91871450\n",
      "Iteration 30, loss = 0.87119645\n",
      "Iteration 31, loss = 0.85106795\n",
      "Iteration 16, loss = 0.90375871\n",
      "Iteration 17, loss = 0.90466673\n",
      "Iteration 18, loss = 0.90514516\n",
      "Iteration 19, loss = 0.89727495\n",
      "Iteration 20, loss = 0.88681853\n",
      "Iteration 21, loss = 0.87183444\n",
      "Iteration 22, loss = 0.90698271\n",
      "Iteration 23, loss = 0.89164304\n",
      "Iteration 24, loss = 0.90526418\n",
      "Iteration 25, loss = 0.89855333\n",
      "Iteration 26, loss = 0.86943222\n",
      "Iteration 27, loss = 0.85753051\n",
      "Iteration 28, loss = 1.00134941\n",
      "Iteration 29, loss = 0.91871450\n",
      "Iteration 30, loss = 0.87119645\n",
      "Iteration 31, loss = 0.85106795\n",
      "Iteration 32, loss = 0.91470003\n",
      "Iteration 33, loss = 0.89137204\n",
      "Iteration 34, loss = 0.88210824\n",
      "Iteration 35, loss = 0.91544890\n",
      "Iteration 36, loss = 0.88386233\n",
      "Iteration 37, loss = 0.87597686\n",
      "Iteration 38, loss = 0.88241281\n",
      "Iteration 39, loss = 0.86371693\n",
      "Iteration 40, loss = 0.86100047\n",
      "Iteration 41, loss = 0.85965738\n",
      "Iteration 42, loss = 0.87679496\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19704390\n",
      "Iteration 2, loss = 1.05976697\n",
      "Iteration 3, loss = 1.03467142\n",
      "Iteration 32, loss = 0.91470003\n",
      "Iteration 33, loss = 0.89137204\n",
      "Iteration 34, loss = 0.88210824\n",
      "Iteration 35, loss = 0.91544890\n",
      "Iteration 36, loss = 0.88386233\n",
      "Iteration 37, loss = 0.87597686\n",
      "Iteration 38, loss = 0.88241281\n",
      "Iteration 39, loss = 0.86371693\n",
      "Iteration 40, loss = 0.86100047\n",
      "Iteration 41, loss = 0.85965738\n",
      "Iteration 42, loss = 0.87679496\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19704390\n",
      "Iteration 2, loss = 1.05976697\n",
      "Iteration 3, loss = 1.03467142\n",
      "Iteration 4, loss = 0.99257980\n",
      "Iteration 5, loss = 1.05407634\n",
      "Iteration 6, loss = 1.06171954\n",
      "Iteration 7, loss = 1.02050045\n",
      "Iteration 8, loss = 1.02441699\n",
      "Iteration 9, loss = 0.99100170\n",
      "Iteration 10, loss = 0.99757114\n",
      "Iteration 11, loss = 0.94831482\n",
      "Iteration 12, loss = 0.94620616\n",
      "Iteration 13, loss = 0.98022019\n",
      "Iteration 14, loss = 0.93750962\n",
      "Iteration 15, loss = 0.93727672\n",
      "Iteration 16, loss = 0.92730155\n",
      "Iteration 17, loss = 0.89439063\n",
      "Iteration 18, loss = 0.92734271\n",
      "Iteration 19, loss = 0.93767635\n",
      "Iteration 4, loss = 0.99257980\n",
      "Iteration 5, loss = 1.05407634\n",
      "Iteration 6, loss = 1.06171954\n",
      "Iteration 7, loss = 1.02050045\n",
      "Iteration 8, loss = 1.02441699\n",
      "Iteration 9, loss = 0.99100170\n",
      "Iteration 10, loss = 0.99757114\n",
      "Iteration 11, loss = 0.94831482\n",
      "Iteration 12, loss = 0.94620616\n",
      "Iteration 13, loss = 0.98022019\n",
      "Iteration 14, loss = 0.93750962\n",
      "Iteration 15, loss = 0.93727672\n",
      "Iteration 16, loss = 0.92730155\n",
      "Iteration 17, loss = 0.89439063\n",
      "Iteration 18, loss = 0.92734271\n",
      "Iteration 19, loss = 0.93767635\n",
      "Iteration 20, loss = 0.94052898\n",
      "Iteration 21, loss = 0.89124595\n",
      "Iteration 22, loss = 0.94169137\n",
      "Iteration 23, loss = 0.89594032\n",
      "Iteration 24, loss = 0.91986503\n",
      "Iteration 25, loss = 0.91550861\n",
      "Iteration 26, loss = 0.92892007\n",
      "Iteration 27, loss = 0.90226074\n",
      "Iteration 28, loss = 0.89856284\n",
      "Iteration 29, loss = 0.85315239\n",
      "Iteration 30, loss = 0.89601107\n",
      "Iteration 31, loss = 0.89634780\n",
      "Iteration 32, loss = 0.87661200\n",
      "Iteration 33, loss = 0.85172009\n",
      "Iteration 34, loss = 0.90332671\n",
      "Iteration 35, loss = 0.84020866\n",
      "Iteration 36, loss = 0.87138127\n",
      "Iteration 20, loss = 0.94052898\n",
      "Iteration 21, loss = 0.89124595\n",
      "Iteration 22, loss = 0.94169137\n",
      "Iteration 23, loss = 0.89594032\n",
      "Iteration 24, loss = 0.91986503\n",
      "Iteration 25, loss = 0.91550861\n",
      "Iteration 26, loss = 0.92892007\n",
      "Iteration 27, loss = 0.90226074\n",
      "Iteration 28, loss = 0.89856284\n",
      "Iteration 29, loss = 0.85315239\n",
      "Iteration 30, loss = 0.89601107\n",
      "Iteration 31, loss = 0.89634780\n",
      "Iteration 32, loss = 0.87661200\n",
      "Iteration 33, loss = 0.85172009\n",
      "Iteration 34, loss = 0.90332671\n",
      "Iteration 35, loss = 0.84020866\n",
      "Iteration 36, loss = 0.87138127\n",
      "Iteration 37, loss = 0.83519724\n",
      "Iteration 38, loss = 0.82958153\n",
      "Iteration 39, loss = 0.85527083\n",
      "Iteration 40, loss = 0.87286913\n",
      "Iteration 41, loss = 0.83875779\n",
      "Iteration 42, loss = 0.81379562\n",
      "Iteration 43, loss = 0.81313598\n",
      "Iteration 44, loss = 0.83272225\n",
      "Iteration 45, loss = 0.77779004\n",
      "Iteration 46, loss = 0.81290334\n",
      "Iteration 47, loss = 0.86496502\n",
      "Iteration 48, loss = 0.81154472\n",
      "Iteration 49, loss = 0.79694328\n",
      "Iteration 50, loss = 0.85400111\n",
      "Iteration 1, loss = 1.17821490\n",
      "Iteration 37, loss = 0.83519724\n",
      "Iteration 38, loss = 0.82958153\n",
      "Iteration 39, loss = 0.85527083\n",
      "Iteration 40, loss = 0.87286913\n",
      "Iteration 41, loss = 0.83875779\n",
      "Iteration 42, loss = 0.81379562\n",
      "Iteration 43, loss = 0.81313598\n",
      "Iteration 44, loss = 0.83272225\n",
      "Iteration 45, loss = 0.77779004\n",
      "Iteration 46, loss = 0.81290334\n",
      "Iteration 47, loss = 0.86496502\n",
      "Iteration 48, loss = 0.81154472\n",
      "Iteration 49, loss = 0.79694328\n",
      "Iteration 50, loss = 0.85400111\n",
      "Iteration 1, loss = 1.17821490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.06408951\n",
      "Iteration 3, loss = 0.99985759\n",
      "Iteration 4, loss = 0.97472654\n",
      "Iteration 5, loss = 1.01839053\n",
      "Iteration 6, loss = 0.98137982\n",
      "Iteration 7, loss = 0.93818562\n",
      "Iteration 8, loss = 0.96954009\n",
      "Iteration 9, loss = 0.92701369\n",
      "Iteration 10, loss = 0.93462357\n",
      "Iteration 11, loss = 0.92133652\n",
      "Iteration 12, loss = 0.91208420\n",
      "Iteration 13, loss = 0.93044037\n",
      "Iteration 2, loss = 1.06408951\n",
      "Iteration 3, loss = 0.99985759\n",
      "Iteration 4, loss = 0.97472654\n",
      "Iteration 5, loss = 1.01839053\n",
      "Iteration 6, loss = 0.98137982\n",
      "Iteration 7, loss = 0.93818562\n",
      "Iteration 8, loss = 0.96954009\n",
      "Iteration 9, loss = 0.92701369\n",
      "Iteration 10, loss = 0.93462357\n",
      "Iteration 11, loss = 0.92133652\n",
      "Iteration 12, loss = 0.91208420\n",
      "Iteration 13, loss = 0.93044037\n",
      "Iteration 14, loss = 0.94911866\n",
      "Iteration 15, loss = 0.93332202\n",
      "Iteration 16, loss = 0.90034826\n",
      "Iteration 17, loss = 0.91982643\n",
      "Iteration 18, loss = 0.91521096\n",
      "Iteration 19, loss = 0.90777847\n",
      "Iteration 20, loss = 0.89719672\n",
      "Iteration 21, loss = 0.86906465\n",
      "Iteration 22, loss = 0.86792195\n",
      "Iteration 23, loss = 0.88810735\n",
      "Iteration 24, loss = 1.01200947\n",
      "Iteration 25, loss = 0.89040957\n",
      "Iteration 26, loss = 0.94277679\n",
      "Iteration 27, loss = 0.86724967\n",
      "Iteration 28, loss = 0.85780072\n",
      "Iteration 29, loss = 0.88484884\n",
      "Iteration 14, loss = 0.94911866\n",
      "Iteration 15, loss = 0.93332202\n",
      "Iteration 16, loss = 0.90034826\n",
      "Iteration 17, loss = 0.91982643\n",
      "Iteration 18, loss = 0.91521096\n",
      "Iteration 19, loss = 0.90777847\n",
      "Iteration 20, loss = 0.89719672\n",
      "Iteration 21, loss = 0.86906465\n",
      "Iteration 22, loss = 0.86792195\n",
      "Iteration 23, loss = 0.88810735\n",
      "Iteration 24, loss = 1.01200947\n",
      "Iteration 25, loss = 0.89040957\n",
      "Iteration 26, loss = 0.94277679\n",
      "Iteration 27, loss = 0.86724967\n",
      "Iteration 28, loss = 0.85780072\n",
      "Iteration 29, loss = 0.88484884\n",
      "Iteration 30, loss = 0.86364753\n",
      "Iteration 31, loss = 0.89887328\n",
      "Iteration 32, loss = 0.87688101\n",
      "Iteration 33, loss = 0.85518993\n",
      "Iteration 34, loss = 0.90251894\n",
      "Iteration 35, loss = 0.84745053\n",
      "Iteration 36, loss = 0.88392722\n",
      "Iteration 37, loss = 0.83084734\n",
      "Iteration 38, loss = 0.83298015\n",
      "Iteration 39, loss = 0.83996018\n",
      "Iteration 40, loss = 0.85792460\n",
      "Iteration 41, loss = 0.83793415\n",
      "Iteration 42, loss = 0.82923623\n",
      "Iteration 43, loss = 0.82994384\n",
      "Iteration 44, loss = 0.82761422\n",
      "Iteration 45, loss = 0.80720984\n",
      "Iteration 30, loss = 0.86364753\n",
      "Iteration 31, loss = 0.89887328\n",
      "Iteration 32, loss = 0.87688101\n",
      "Iteration 33, loss = 0.85518993\n",
      "Iteration 34, loss = 0.90251894\n",
      "Iteration 35, loss = 0.84745053\n",
      "Iteration 36, loss = 0.88392722\n",
      "Iteration 37, loss = 0.83084734\n",
      "Iteration 38, loss = 0.83298015\n",
      "Iteration 39, loss = 0.83996018\n",
      "Iteration 40, loss = 0.85792460\n",
      "Iteration 41, loss = 0.83793415\n",
      "Iteration 42, loss = 0.82923623\n",
      "Iteration 43, loss = 0.82994384\n",
      "Iteration 44, loss = 0.82761422\n",
      "Iteration 45, loss = 0.80720984\n",
      "Iteration 46, loss = 0.79931367\n",
      "Iteration 47, loss = 0.81647141\n",
      "Iteration 48, loss = 0.83776764\n",
      "Iteration 49, loss = 0.82419646\n",
      "Iteration 50, loss = 0.81860733\n",
      "Iteration 1, loss = 1.24130168\n",
      "Iteration 2, loss = 1.09680862\n",
      "Iteration 3, loss = 1.00600462\n",
      "Iteration 4, loss = 0.99822181\n",
      "Iteration 5, loss = 0.96519139\n",
      "Iteration 6, loss = 0.98338087\n",
      "Iteration 7, loss = 0.96038599\n",
      "Iteration 8, loss = 0.93991611\n",
      "Iteration 46, loss = 0.79931367\n",
      "Iteration 47, loss = 0.81647141\n",
      "Iteration 48, loss = 0.83776764\n",
      "Iteration 49, loss = 0.82419646\n",
      "Iteration 50, loss = 0.81860733\n",
      "Iteration 1, loss = 1.24130168\n",
      "Iteration 2, loss = 1.09680862\n",
      "Iteration 3, loss = 1.00600462\n",
      "Iteration 4, loss = 0.99822181\n",
      "Iteration 5, loss = 0.96519139\n",
      "Iteration 6, loss = 0.98338087\n",
      "Iteration 7, loss = 0.96038599\n",
      "Iteration 8, loss = 0.93991611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.96237577\n",
      "Iteration 10, loss = 0.95443451\n",
      "Iteration 11, loss = 0.97104697\n",
      "Iteration 12, loss = 0.94074485\n",
      "Iteration 13, loss = 0.93709410\n",
      "Iteration 14, loss = 0.91713196\n",
      "Iteration 15, loss = 0.91208405\n",
      "Iteration 16, loss = 0.90466848\n",
      "Iteration 17, loss = 0.92599568\n",
      "Iteration 18, loss = 0.89774921\n",
      "Iteration 19, loss = 0.93646149\n",
      "Iteration 20, loss = 0.89917445\n",
      "Iteration 21, loss = 0.90966563\n",
      "Iteration 22, loss = 0.89446096\n",
      "Iteration 23, loss = 0.92206184\n",
      "Iteration 9, loss = 0.96237577\n",
      "Iteration 10, loss = 0.95443451\n",
      "Iteration 11, loss = 0.97104697\n",
      "Iteration 12, loss = 0.94074485\n",
      "Iteration 13, loss = 0.93709410\n",
      "Iteration 14, loss = 0.91713196\n",
      "Iteration 15, loss = 0.91208405\n",
      "Iteration 16, loss = 0.90466848\n",
      "Iteration 17, loss = 0.92599568\n",
      "Iteration 18, loss = 0.89774921\n",
      "Iteration 19, loss = 0.93646149\n",
      "Iteration 20, loss = 0.89917445\n",
      "Iteration 21, loss = 0.90966563\n",
      "Iteration 22, loss = 0.89446096\n",
      "Iteration 23, loss = 0.92206184\n",
      "Iteration 24, loss = 0.88756844\n",
      "Iteration 25, loss = 0.86562829\n",
      "Iteration 26, loss = 0.86526939\n",
      "Iteration 27, loss = 0.88328923\n",
      "Iteration 28, loss = 0.86257860\n",
      "Iteration 29, loss = 0.87080421\n",
      "Iteration 30, loss = 0.93073897\n",
      "Iteration 31, loss = 0.87640071\n",
      "Iteration 32, loss = 0.88568198\n",
      "Iteration 33, loss = 0.91801609\n",
      "Iteration 34, loss = 0.86780624\n",
      "Iteration 35, loss = 0.90645958\n",
      "Iteration 36, loss = 0.86346747\n",
      "Iteration 37, loss = 0.88109532\n",
      "Iteration 38, loss = 0.87885168\n",
      "Iteration 39, loss = 0.85013014\n",
      "Iteration 24, loss = 0.88756844\n",
      "Iteration 25, loss = 0.86562829\n",
      "Iteration 26, loss = 0.86526939\n",
      "Iteration 27, loss = 0.88328923\n",
      "Iteration 28, loss = 0.86257860\n",
      "Iteration 29, loss = 0.87080421\n",
      "Iteration 30, loss = 0.93073897\n",
      "Iteration 31, loss = 0.87640071\n",
      "Iteration 32, loss = 0.88568198\n",
      "Iteration 33, loss = 0.91801609\n",
      "Iteration 34, loss = 0.86780624\n",
      "Iteration 35, loss = 0.90645958\n",
      "Iteration 36, loss = 0.86346747\n",
      "Iteration 37, loss = 0.88109532\n",
      "Iteration 38, loss = 0.87885168\n",
      "Iteration 39, loss = 0.85013014\n",
      "Iteration 40, loss = 0.90424169\n",
      "Iteration 41, loss = 0.84471702\n",
      "Iteration 42, loss = 0.81217721\n",
      "Iteration 43, loss = 0.81379802\n",
      "Iteration 44, loss = 0.82753546\n",
      "Iteration 45, loss = 0.81569648\n",
      "Iteration 46, loss = 0.87956678\n",
      "Iteration 47, loss = 0.80932982\n",
      "Iteration 48, loss = 0.85528505\n",
      "Iteration 49, loss = 0.83594109\n",
      "Iteration 50, loss = 0.85804467\n",
      "Iteration 51, loss = 0.81628739\n",
      "Iteration 52, loss = 0.84821341\n",
      "Iteration 53, loss = 0.80927823\n",
      "Iteration 54, loss = 0.82625476\n",
      "Iteration 40, loss = 0.90424169\n",
      "Iteration 41, loss = 0.84471702\n",
      "Iteration 42, loss = 0.81217721\n",
      "Iteration 43, loss = 0.81379802\n",
      "Iteration 44, loss = 0.82753546\n",
      "Iteration 45, loss = 0.81569648\n",
      "Iteration 46, loss = 0.87956678\n",
      "Iteration 47, loss = 0.80932982\n",
      "Iteration 48, loss = 0.85528505\n",
      "Iteration 49, loss = 0.83594109\n",
      "Iteration 50, loss = 0.85804467\n",
      "Iteration 51, loss = 0.81628739\n",
      "Iteration 52, loss = 0.84821341\n",
      "Iteration 53, loss = 0.80927823\n",
      "Iteration 54, loss = 0.82625476\n",
      "Iteration 55, loss = 0.83717404\n",
      "Iteration 56, loss = 0.89482373\n",
      "Iteration 57, loss = 0.85190388\n",
      "Iteration 58, loss = 0.77181847\n",
      "Iteration 59, loss = 0.80167496\n",
      "Iteration 60, loss = 0.83183023\n",
      "Iteration 61, loss = 0.82808274\n",
      "Iteration 62, loss = 0.80905639\n",
      "Iteration 63, loss = 0.86709483\n",
      "Iteration 64, loss = 0.80990491\n",
      "Iteration 65, loss = 0.82660321\n",
      "Iteration 66, loss = 0.79453926\n",
      "Iteration 67, loss = 0.80042744\n",
      "Iteration 68, loss = 0.77782881\n",
      "Iteration 69, loss = 0.77329356\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21483003\n",
      "Iteration 55, loss = 0.83717404\n",
      "Iteration 56, loss = 0.89482373\n",
      "Iteration 57, loss = 0.85190388\n",
      "Iteration 58, loss = 0.77181847\n",
      "Iteration 59, loss = 0.80167496\n",
      "Iteration 60, loss = 0.83183023\n",
      "Iteration 61, loss = 0.82808274\n",
      "Iteration 62, loss = 0.80905639\n",
      "Iteration 63, loss = 0.86709483\n",
      "Iteration 64, loss = 0.80990491\n",
      "Iteration 65, loss = 0.82660321\n",
      "Iteration 66, loss = 0.79453926\n",
      "Iteration 67, loss = 0.80042744\n",
      "Iteration 68, loss = 0.77782881\n",
      "Iteration 69, loss = 0.77329356\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21483003\n",
      "Iteration 2, loss = 1.00280333\n",
      "Iteration 3, loss = 0.94633122\n",
      "Iteration 4, loss = 0.94369185\n",
      "Iteration 5, loss = 0.90911808\n",
      "Iteration 6, loss = 0.92656774\n",
      "Iteration 7, loss = 0.89248647\n",
      "Iteration 8, loss = 0.89487780\n",
      "Iteration 9, loss = 0.94626577\n",
      "Iteration 10, loss = 0.89771990\n",
      "Iteration 11, loss = 0.92759326\n",
      "Iteration 12, loss = 0.93143672\n",
      "Iteration 13, loss = 0.89232485\n",
      "Iteration 14, loss = 0.88915996\n",
      "Iteration 15, loss = 0.87456467\n",
      "Iteration 2, loss = 1.00280333\n",
      "Iteration 3, loss = 0.94633122\n",
      "Iteration 4, loss = 0.94369185\n",
      "Iteration 5, loss = 0.90911808\n",
      "Iteration 6, loss = 0.92656774\n",
      "Iteration 7, loss = 0.89248647\n",
      "Iteration 8, loss = 0.89487780\n",
      "Iteration 9, loss = 0.94626577\n",
      "Iteration 10, loss = 0.89771990\n",
      "Iteration 11, loss = 0.92759326\n",
      "Iteration 12, loss = 0.93143672\n",
      "Iteration 13, loss = 0.89232485\n",
      "Iteration 14, loss = 0.88915996\n",
      "Iteration 15, loss = 0.87456467\n",
      "Iteration 16, loss = 0.88176906\n",
      "Iteration 17, loss = 0.88599227\n",
      "Iteration 18, loss = 0.89078244\n",
      "Iteration 19, loss = 0.87307780\n",
      "Iteration 20, loss = 0.88117032\n",
      "Iteration 21, loss = 0.83482153\n",
      "Iteration 22, loss = 0.86249670\n",
      "Iteration 23, loss = 0.83827702\n",
      "Iteration 24, loss = 0.86652246\n",
      "Iteration 25, loss = 0.82968896\n",
      "Iteration 26, loss = 0.83448704\n",
      "Iteration 27, loss = 0.87992337\n",
      "Iteration 28, loss = 0.97281544\n",
      "Iteration 29, loss = 0.88934258\n",
      "Iteration 30, loss = 0.84627833\n",
      "Iteration 31, loss = 0.84352832\n",
      "Iteration 16, loss = 0.88176906\n",
      "Iteration 17, loss = 0.88599227\n",
      "Iteration 18, loss = 0.89078244\n",
      "Iteration 19, loss = 0.87307780\n",
      "Iteration 20, loss = 0.88117032\n",
      "Iteration 21, loss = 0.83482153\n",
      "Iteration 22, loss = 0.86249670\n",
      "Iteration 23, loss = 0.83827702\n",
      "Iteration 24, loss = 0.86652246\n",
      "Iteration 25, loss = 0.82968896\n",
      "Iteration 26, loss = 0.83448704\n",
      "Iteration 27, loss = 0.87992337\n",
      "Iteration 28, loss = 0.97281544\n",
      "Iteration 29, loss = 0.88934258\n",
      "Iteration 30, loss = 0.84627833\n",
      "Iteration 31, loss = 0.84352832\n",
      "Iteration 32, loss = 0.84758789\n",
      "Iteration 33, loss = 0.83878578\n",
      "Iteration 34, loss = 0.79737388\n",
      "Iteration 35, loss = 0.84128720\n",
      "Iteration 36, loss = 0.80136518\n",
      "Iteration 37, loss = 0.80693554\n",
      "Iteration 38, loss = 0.79891759\n",
      "Iteration 39, loss = 0.83681305\n",
      "Iteration 40, loss = 0.81674185\n",
      "Iteration 41, loss = 0.81378220\n",
      "Iteration 42, loss = 0.77391072\n",
      "Iteration 43, loss = 0.81621276\n",
      "Iteration 44, loss = 0.77762910\n",
      "Iteration 45, loss = 0.77708279\n",
      "Iteration 46, loss = 0.79593858\n",
      "Iteration 47, loss = 0.76583454\n",
      "Iteration 32, loss = 0.84758789\n",
      "Iteration 33, loss = 0.83878578\n",
      "Iteration 34, loss = 0.79737388\n",
      "Iteration 35, loss = 0.84128720\n",
      "Iteration 36, loss = 0.80136518\n",
      "Iteration 37, loss = 0.80693554\n",
      "Iteration 38, loss = 0.79891759\n",
      "Iteration 39, loss = 0.83681305\n",
      "Iteration 40, loss = 0.81674185\n",
      "Iteration 41, loss = 0.81378220\n",
      "Iteration 42, loss = 0.77391072\n",
      "Iteration 43, loss = 0.81621276\n",
      "Iteration 44, loss = 0.77762910\n",
      "Iteration 45, loss = 0.77708279\n",
      "Iteration 46, loss = 0.79593858\n",
      "Iteration 47, loss = 0.76583454\n",
      "Iteration 48, loss = 0.82045533\n",
      "Iteration 49, loss = 0.79706775\n",
      "Iteration 50, loss = 0.78103576\n",
      "Iteration 51, loss = 0.74470464\n",
      "Iteration 52, loss = 0.77105701\n",
      "Iteration 53, loss = 0.75639936\n",
      "Iteration 54, loss = 0.75990704\n",
      "Iteration 55, loss = 0.73369402\n",
      "Iteration 56, loss = 0.75495971\n",
      "Iteration 57, loss = 0.73756618\n",
      "Iteration 58, loss = 0.74159578\n",
      "Iteration 59, loss = 0.82708530\n",
      "Iteration 60, loss = 0.75012409\n",
      "Iteration 61, loss = 0.73519964\n",
      "Iteration 62, loss = 0.72517700\n",
      "Iteration 63, loss = 0.78539677\n",
      "Iteration 48, loss = 0.82045533\n",
      "Iteration 49, loss = 0.79706775\n",
      "Iteration 50, loss = 0.78103576\n",
      "Iteration 51, loss = 0.74470464\n",
      "Iteration 52, loss = 0.77105701\n",
      "Iteration 53, loss = 0.75639936\n",
      "Iteration 54, loss = 0.75990704\n",
      "Iteration 55, loss = 0.73369402\n",
      "Iteration 56, loss = 0.75495971\n",
      "Iteration 57, loss = 0.73756618\n",
      "Iteration 58, loss = 0.74159578\n",
      "Iteration 59, loss = 0.82708530\n",
      "Iteration 60, loss = 0.75012409\n",
      "Iteration 61, loss = 0.73519964\n",
      "Iteration 62, loss = 0.72517700\n",
      "Iteration 63, loss = 0.78539677\n",
      "Iteration 64, loss = 0.71994406\n",
      "Iteration 65, loss = 0.74102633\n",
      "Iteration 66, loss = 0.73279356\n",
      "Iteration 67, loss = 0.74564637\n",
      "Iteration 68, loss = 0.73468024\n",
      "Iteration 69, loss = 0.74261119\n",
      "Iteration 70, loss = 0.74635397\n",
      "Iteration 71, loss = 0.69441153\n",
      "Iteration 72, loss = 0.71886808\n",
      "Iteration 73, loss = 0.71228116\n",
      "Iteration 74, loss = 0.67145278\n",
      "Iteration 75, loss = 0.70020698\n",
      "Iteration 76, loss = 0.65393789\n",
      "Iteration 77, loss = 0.71917940\n",
      "Iteration 78, loss = 0.73972290\n",
      "Iteration 79, loss = 0.70400120\n",
      "Iteration 64, loss = 0.71994406\n",
      "Iteration 65, loss = 0.74102633\n",
      "Iteration 66, loss = 0.73279356\n",
      "Iteration 67, loss = 0.74564637\n",
      "Iteration 68, loss = 0.73468024\n",
      "Iteration 69, loss = 0.74261119\n",
      "Iteration 70, loss = 0.74635397\n",
      "Iteration 71, loss = 0.69441153\n",
      "Iteration 72, loss = 0.71886808\n",
      "Iteration 73, loss = 0.71228116\n",
      "Iteration 74, loss = 0.67145278\n",
      "Iteration 75, loss = 0.70020698\n",
      "Iteration 76, loss = 0.65393789\n",
      "Iteration 77, loss = 0.71917940\n",
      "Iteration 78, loss = 0.73972290\n",
      "Iteration 79, loss = 0.70400120\n",
      "Iteration 80, loss = 0.68210056\n",
      "Iteration 81, loss = 0.70049326\n",
      "Iteration 82, loss = 0.68341934\n",
      "Iteration 83, loss = 0.67219754\n",
      "Iteration 84, loss = 0.68903749\n",
      "Iteration 85, loss = 0.69175305\n",
      "Iteration 86, loss = 0.68698913\n",
      "Iteration 87, loss = 0.72081488\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23162481\n",
      "Iteration 2, loss = 1.03658927\n",
      "Iteration 3, loss = 0.98613922\n",
      "Iteration 4, loss = 0.97501743\n",
      "Iteration 5, loss = 1.00091840\n",
      "Iteration 6, loss = 0.95378241\n",
      "Iteration 7, loss = 0.95675673\n",
      "Iteration 80, loss = 0.68210056\n",
      "Iteration 81, loss = 0.70049326\n",
      "Iteration 82, loss = 0.68341934\n",
      "Iteration 83, loss = 0.67219754\n",
      "Iteration 84, loss = 0.68903749\n",
      "Iteration 85, loss = 0.69175305\n",
      "Iteration 86, loss = 0.68698913\n",
      "Iteration 87, loss = 0.72081488\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23162481\n",
      "Iteration 2, loss = 1.03658927\n",
      "Iteration 3, loss = 0.98613922\n",
      "Iteration 4, loss = 0.97501743\n",
      "Iteration 5, loss = 1.00091840\n",
      "Iteration 6, loss = 0.95378241\n",
      "Iteration 7, loss = 0.95675673\n",
      "Iteration 8, loss = 0.96009077\n",
      "Iteration 9, loss = 0.93005249\n",
      "Iteration 10, loss = 0.91375591\n",
      "Iteration 11, loss = 0.94005533\n",
      "Iteration 12, loss = 0.92259912\n",
      "Iteration 13, loss = 0.91469052\n",
      "Iteration 14, loss = 0.92100945\n",
      "Iteration 15, loss = 0.91020602\n",
      "Iteration 16, loss = 0.90375871\n",
      "Iteration 17, loss = 0.90466673\n",
      "Iteration 18, loss = 0.90514516\n",
      "Iteration 19, loss = 0.89727495\n",
      "Iteration 20, loss = 0.88681853\n",
      "Iteration 21, loss = 0.87183444\n",
      "Iteration 22, loss = 0.90698271\n",
      "Iteration 8, loss = 0.96009077\n",
      "Iteration 9, loss = 0.93005249\n",
      "Iteration 10, loss = 0.91375591\n",
      "Iteration 11, loss = 0.94005533\n",
      "Iteration 12, loss = 0.92259912\n",
      "Iteration 13, loss = 0.91469052\n",
      "Iteration 14, loss = 0.92100945\n",
      "Iteration 15, loss = 0.91020602\n",
      "Iteration 16, loss = 0.90375871\n",
      "Iteration 17, loss = 0.90466673\n",
      "Iteration 18, loss = 0.90514516\n",
      "Iteration 19, loss = 0.89727495\n",
      "Iteration 20, loss = 0.88681853\n",
      "Iteration 21, loss = 0.87183444\n",
      "Iteration 22, loss = 0.90698271\n",
      "Iteration 23, loss = 0.89164304\n",
      "Iteration 24, loss = 0.90526418\n",
      "Iteration 25, loss = 0.89855333\n",
      "Iteration 26, loss = 0.86943222\n",
      "Iteration 27, loss = 0.85753051\n",
      "Iteration 28, loss = 1.00134941\n",
      "Iteration 29, loss = 0.91871450\n",
      "Iteration 30, loss = 0.87119645\n",
      "Iteration 31, loss = 0.85106795\n",
      "Iteration 32, loss = 0.91470003\n",
      "Iteration 33, loss = 0.89137204\n",
      "Iteration 34, loss = 0.88210824\n",
      "Iteration 35, loss = 0.91544890\n",
      "Iteration 36, loss = 0.88386233\n",
      "Iteration 37, loss = 0.87597686\n",
      "Iteration 38, loss = 0.88241281\n",
      "Iteration 23, loss = 0.89164304\n",
      "Iteration 24, loss = 0.90526418\n",
      "Iteration 25, loss = 0.89855333\n",
      "Iteration 26, loss = 0.86943222\n",
      "Iteration 27, loss = 0.85753051\n",
      "Iteration 28, loss = 1.00134941\n",
      "Iteration 29, loss = 0.91871450\n",
      "Iteration 30, loss = 0.87119645\n",
      "Iteration 31, loss = 0.85106795\n",
      "Iteration 32, loss = 0.91470003\n",
      "Iteration 33, loss = 0.89137204\n",
      "Iteration 34, loss = 0.88210824\n",
      "Iteration 35, loss = 0.91544890\n",
      "Iteration 36, loss = 0.88386233\n",
      "Iteration 37, loss = 0.87597686\n",
      "Iteration 38, loss = 0.88241281\n",
      "Iteration 39, loss = 0.86371693\n",
      "Iteration 40, loss = 0.86100047\n",
      "Iteration 41, loss = 0.85965738\n",
      "Iteration 42, loss = 0.87679496\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19704390\n",
      "Iteration 2, loss = 1.05976697\n",
      "Iteration 3, loss = 1.03467142\n",
      "Iteration 4, loss = 0.99257980\n",
      "Iteration 5, loss = 1.05407634\n",
      "Iteration 6, loss = 1.06171954\n",
      "Iteration 7, loss = 1.02050045\n",
      "Iteration 8, loss = 1.02441699\n",
      "Iteration 9, loss = 0.99100170\n",
      "Iteration 10, loss = 0.99757114\n",
      "Iteration 39, loss = 0.86371693\n",
      "Iteration 40, loss = 0.86100047\n",
      "Iteration 41, loss = 0.85965738\n",
      "Iteration 42, loss = 0.87679496\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19704390\n",
      "Iteration 2, loss = 1.05976697\n",
      "Iteration 3, loss = 1.03467142\n",
      "Iteration 4, loss = 0.99257980\n",
      "Iteration 5, loss = 1.05407634\n",
      "Iteration 6, loss = 1.06171954\n",
      "Iteration 7, loss = 1.02050045\n",
      "Iteration 8, loss = 1.02441699\n",
      "Iteration 9, loss = 0.99100170\n",
      "Iteration 10, loss = 0.99757114\n",
      "Iteration 11, loss = 0.94831482\n",
      "Iteration 12, loss = 0.94620616\n",
      "Iteration 13, loss = 0.98022019\n",
      "Iteration 14, loss = 0.93750962\n",
      "Iteration 15, loss = 0.93727672\n",
      "Iteration 16, loss = 0.92730155\n",
      "Iteration 17, loss = 0.89439063\n",
      "Iteration 18, loss = 0.92734271\n",
      "Iteration 19, loss = 0.93767635\n",
      "Iteration 20, loss = 0.94052898\n",
      "Iteration 21, loss = 0.89124595\n",
      "Iteration 22, loss = 0.94169137\n",
      "Iteration 23, loss = 0.89594032\n",
      "Iteration 24, loss = 0.91986503\n",
      "Iteration 25, loss = 0.91550861\n",
      "Iteration 11, loss = 0.94831482\n",
      "Iteration 12, loss = 0.94620616\n",
      "Iteration 13, loss = 0.98022019\n",
      "Iteration 14, loss = 0.93750962\n",
      "Iteration 15, loss = 0.93727672\n",
      "Iteration 16, loss = 0.92730155\n",
      "Iteration 17, loss = 0.89439063\n",
      "Iteration 18, loss = 0.92734271\n",
      "Iteration 19, loss = 0.93767635\n",
      "Iteration 20, loss = 0.94052898\n",
      "Iteration 21, loss = 0.89124595\n",
      "Iteration 22, loss = 0.94169137\n",
      "Iteration 23, loss = 0.89594032\n",
      "Iteration 24, loss = 0.91986503\n",
      "Iteration 25, loss = 0.91550861\n",
      "Iteration 26, loss = 0.92892007\n",
      "Iteration 27, loss = 0.90226074\n",
      "Iteration 28, loss = 0.89856284\n",
      "Iteration 29, loss = 0.85315239\n",
      "Iteration 30, loss = 0.89601107\n",
      "Iteration 31, loss = 0.89634780\n",
      "Iteration 32, loss = 0.87661200\n",
      "Iteration 33, loss = 0.85172009\n",
      "Iteration 34, loss = 0.90332671\n",
      "Iteration 35, loss = 0.84020866\n",
      "Iteration 36, loss = 0.87138127\n",
      "Iteration 37, loss = 0.83519724\n",
      "Iteration 38, loss = 0.82958153\n",
      "Iteration 39, loss = 0.85527083\n",
      "Iteration 40, loss = 0.87286913\n",
      "Iteration 26, loss = 0.92892007\n",
      "Iteration 27, loss = 0.90226074\n",
      "Iteration 28, loss = 0.89856284\n",
      "Iteration 29, loss = 0.85315239\n",
      "Iteration 30, loss = 0.89601107\n",
      "Iteration 31, loss = 0.89634780\n",
      "Iteration 32, loss = 0.87661200\n",
      "Iteration 33, loss = 0.85172009\n",
      "Iteration 34, loss = 0.90332671\n",
      "Iteration 35, loss = 0.84020866\n",
      "Iteration 36, loss = 0.87138127\n",
      "Iteration 37, loss = 0.83519724\n",
      "Iteration 38, loss = 0.82958153\n",
      "Iteration 39, loss = 0.85527083\n",
      "Iteration 40, loss = 0.87286913\n",
      "Iteration 41, loss = 0.83875779\n",
      "Iteration 42, loss = 0.81379562\n",
      "Iteration 43, loss = 0.81313598\n",
      "Iteration 44, loss = 0.83272225\n",
      "Iteration 45, loss = 0.77779004\n",
      "Iteration 46, loss = 0.81290334\n",
      "Iteration 47, loss = 0.86496502\n",
      "Iteration 48, loss = 0.81154472\n",
      "Iteration 49, loss = 0.79694328\n",
      "Iteration 50, loss = 0.85400111\n",
      "Iteration 51, loss = 0.77710172\n",
      "Iteration 52, loss = 0.77947893\n",
      "Iteration 53, loss = 0.80212249\n",
      "Iteration 54, loss = 0.78044012\n",
      "Iteration 55, loss = 0.77979246\n",
      "Iteration 56, loss = 0.73709088\n",
      "Iteration 41, loss = 0.83875779\n",
      "Iteration 42, loss = 0.81379562\n",
      "Iteration 43, loss = 0.81313598\n",
      "Iteration 44, loss = 0.83272225\n",
      "Iteration 45, loss = 0.77779004\n",
      "Iteration 46, loss = 0.81290334\n",
      "Iteration 47, loss = 0.86496502\n",
      "Iteration 48, loss = 0.81154472\n",
      "Iteration 49, loss = 0.79694328\n",
      "Iteration 50, loss = 0.85400111\n",
      "Iteration 51, loss = 0.77710172\n",
      "Iteration 52, loss = 0.77947893\n",
      "Iteration 53, loss = 0.80212249\n",
      "Iteration 54, loss = 0.78044012\n",
      "Iteration 55, loss = 0.77979246\n",
      "Iteration 56, loss = 0.73709088\n",
      "Iteration 57, loss = 0.81076632\n",
      "Iteration 58, loss = 0.78993324\n",
      "Iteration 59, loss = 0.82243125\n",
      "Iteration 60, loss = 0.78622475\n",
      "Iteration 61, loss = 0.81147699\n",
      "Iteration 62, loss = 0.82728905\n",
      "Iteration 63, loss = 0.80700451\n",
      "Iteration 64, loss = 0.84627601\n",
      "Iteration 65, loss = 0.85503915\n",
      "Iteration 66, loss = 0.76988091\n",
      "Iteration 67, loss = 0.75282313\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17821490\n",
      "Iteration 2, loss = 1.06408951\n",
      "Iteration 3, loss = 0.99985759\n",
      "Iteration 57, loss = 0.81076632\n",
      "Iteration 58, loss = 0.78993324\n",
      "Iteration 59, loss = 0.82243125\n",
      "Iteration 60, loss = 0.78622475\n",
      "Iteration 61, loss = 0.81147699\n",
      "Iteration 62, loss = 0.82728905\n",
      "Iteration 63, loss = 0.80700451\n",
      "Iteration 64, loss = 0.84627601\n",
      "Iteration 65, loss = 0.85503915\n",
      "Iteration 66, loss = 0.76988091\n",
      "Iteration 67, loss = 0.75282313\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17821490\n",
      "Iteration 2, loss = 1.06408951\n",
      "Iteration 3, loss = 0.99985759\n",
      "Iteration 4, loss = 0.97472654\n",
      "Iteration 5, loss = 1.01839053\n",
      "Iteration 6, loss = 0.98137982\n",
      "Iteration 7, loss = 0.93818562\n",
      "Iteration 8, loss = 0.96954009\n",
      "Iteration 9, loss = 0.92701369\n",
      "Iteration 10, loss = 0.93462357\n",
      "Iteration 11, loss = 0.92133652\n",
      "Iteration 12, loss = 0.91208420\n",
      "Iteration 13, loss = 0.93044037\n",
      "Iteration 14, loss = 0.94911866\n",
      "Iteration 15, loss = 0.93332202\n",
      "Iteration 16, loss = 0.90034826\n",
      "Iteration 17, loss = 0.91982643\n",
      "Iteration 18, loss = 0.91521096\n",
      "Iteration 4, loss = 0.97472654\n",
      "Iteration 5, loss = 1.01839053\n",
      "Iteration 6, loss = 0.98137982\n",
      "Iteration 7, loss = 0.93818562\n",
      "Iteration 8, loss = 0.96954009\n",
      "Iteration 9, loss = 0.92701369\n",
      "Iteration 10, loss = 0.93462357\n",
      "Iteration 11, loss = 0.92133652\n",
      "Iteration 12, loss = 0.91208420\n",
      "Iteration 13, loss = 0.93044037\n",
      "Iteration 14, loss = 0.94911866\n",
      "Iteration 15, loss = 0.93332202\n",
      "Iteration 16, loss = 0.90034826\n",
      "Iteration 17, loss = 0.91982643\n",
      "Iteration 18, loss = 0.91521096\n",
      "Iteration 19, loss = 0.90777847\n",
      "Iteration 20, loss = 0.89719672\n",
      "Iteration 21, loss = 0.86906465\n",
      "Iteration 22, loss = 0.86792195\n",
      "Iteration 23, loss = 0.88810735\n",
      "Iteration 24, loss = 1.01200947\n",
      "Iteration 25, loss = 0.89040957\n",
      "Iteration 26, loss = 0.94277679\n",
      "Iteration 27, loss = 0.86724967\n",
      "Iteration 28, loss = 0.85780072\n",
      "Iteration 29, loss = 0.88484884\n",
      "Iteration 30, loss = 0.86364753\n",
      "Iteration 31, loss = 0.89887328\n",
      "Iteration 32, loss = 0.87688101\n",
      "Iteration 33, loss = 0.85518993\n",
      "Iteration 34, loss = 0.90251894\n",
      "Iteration 19, loss = 0.90777847\n",
      "Iteration 20, loss = 0.89719672\n",
      "Iteration 21, loss = 0.86906465\n",
      "Iteration 22, loss = 0.86792195\n",
      "Iteration 23, loss = 0.88810735\n",
      "Iteration 24, loss = 1.01200947\n",
      "Iteration 25, loss = 0.89040957\n",
      "Iteration 26, loss = 0.94277679\n",
      "Iteration 27, loss = 0.86724967\n",
      "Iteration 28, loss = 0.85780072\n",
      "Iteration 29, loss = 0.88484884\n",
      "Iteration 30, loss = 0.86364753\n",
      "Iteration 31, loss = 0.89887328\n",
      "Iteration 32, loss = 0.87688101\n",
      "Iteration 33, loss = 0.85518993\n",
      "Iteration 34, loss = 0.90251894\n",
      "Iteration 35, loss = 0.84745053\n",
      "Iteration 36, loss = 0.88392722\n",
      "Iteration 37, loss = 0.83084734\n",
      "Iteration 38, loss = 0.83298015\n",
      "Iteration 39, loss = 0.83996018\n",
      "Iteration 40, loss = 0.85792460\n",
      "Iteration 41, loss = 0.83793415\n",
      "Iteration 42, loss = 0.82923623\n",
      "Iteration 43, loss = 0.82994384\n",
      "Iteration 44, loss = 0.82761422\n",
      "Iteration 45, loss = 0.80720984\n",
      "Iteration 46, loss = 0.79931367\n",
      "Iteration 47, loss = 0.81647141\n",
      "Iteration 48, loss = 0.83776764\n",
      "Iteration 49, loss = 0.82419646\n",
      "Iteration 50, loss = 0.81860733\n",
      "Iteration 35, loss = 0.84745053\n",
      "Iteration 36, loss = 0.88392722\n",
      "Iteration 37, loss = 0.83084734\n",
      "Iteration 38, loss = 0.83298015\n",
      "Iteration 39, loss = 0.83996018\n",
      "Iteration 40, loss = 0.85792460\n",
      "Iteration 41, loss = 0.83793415\n",
      "Iteration 42, loss = 0.82923623\n",
      "Iteration 43, loss = 0.82994384\n",
      "Iteration 44, loss = 0.82761422\n",
      "Iteration 45, loss = 0.80720984\n",
      "Iteration 46, loss = 0.79931367\n",
      "Iteration 47, loss = 0.81647141\n",
      "Iteration 48, loss = 0.83776764\n",
      "Iteration 49, loss = 0.82419646\n",
      "Iteration 50, loss = 0.81860733\n",
      "Iteration 51, loss = 0.78444397\n",
      "Iteration 52, loss = 0.83898488\n",
      "Iteration 53, loss = 0.79196239\n",
      "Iteration 54, loss = 0.83865978\n",
      "Iteration 55, loss = 0.77914953\n",
      "Iteration 56, loss = 0.85345155\n",
      "Iteration 57, loss = 0.83984985\n",
      "Iteration 58, loss = 0.77819100\n",
      "Iteration 59, loss = 0.78922836\n",
      "Iteration 60, loss = 0.78506456\n",
      "Iteration 61, loss = 0.82581455\n",
      "Iteration 62, loss = 0.78905957\n",
      "Iteration 63, loss = 0.78369048\n",
      "Iteration 64, loss = 0.81073279\n",
      "Iteration 65, loss = 0.78744444\n",
      "Iteration 66, loss = 0.79385174\n",
      "Iteration 51, loss = 0.78444397\n",
      "Iteration 52, loss = 0.83898488\n",
      "Iteration 53, loss = 0.79196239\n",
      "Iteration 54, loss = 0.83865978\n",
      "Iteration 55, loss = 0.77914953\n",
      "Iteration 56, loss = 0.85345155\n",
      "Iteration 57, loss = 0.83984985\n",
      "Iteration 58, loss = 0.77819100\n",
      "Iteration 59, loss = 0.78922836\n",
      "Iteration 60, loss = 0.78506456\n",
      "Iteration 61, loss = 0.82581455\n",
      "Iteration 62, loss = 0.78905957\n",
      "Iteration 63, loss = 0.78369048\n",
      "Iteration 64, loss = 0.81073279\n",
      "Iteration 65, loss = 0.78744444\n",
      "Iteration 66, loss = 0.79385174\n",
      "Iteration 67, loss = 0.76611895\n",
      "Iteration 68, loss = 0.76167826\n",
      "Iteration 69, loss = 0.82380920\n",
      "Iteration 70, loss = 0.76862301\n",
      "Iteration 71, loss = 0.77495717\n",
      "Iteration 72, loss = 0.79303328\n",
      "Iteration 73, loss = 0.80921073\n",
      "Iteration 74, loss = 0.74616483\n",
      "Iteration 75, loss = 0.77336644\n",
      "Iteration 76, loss = 0.74009120\n",
      "Iteration 77, loss = 0.74599097\n",
      "Iteration 78, loss = 0.80430899\n",
      "Iteration 79, loss = 0.75666715\n",
      "Iteration 80, loss = 0.77155606\n",
      "Iteration 81, loss = 0.79398779\n",
      "Iteration 82, loss = 0.75528052\n",
      "Iteration 83, loss = 0.76126431\n",
      "Iteration 67, loss = 0.76611895\n",
      "Iteration 68, loss = 0.76167826\n",
      "Iteration 69, loss = 0.82380920\n",
      "Iteration 70, loss = 0.76862301\n",
      "Iteration 71, loss = 0.77495717\n",
      "Iteration 72, loss = 0.79303328\n",
      "Iteration 73, loss = 0.80921073\n",
      "Iteration 74, loss = 0.74616483\n",
      "Iteration 75, loss = 0.77336644\n",
      "Iteration 76, loss = 0.74009120\n",
      "Iteration 77, loss = 0.74599097\n",
      "Iteration 78, loss = 0.80430899\n",
      "Iteration 79, loss = 0.75666715\n",
      "Iteration 80, loss = 0.77155606\n",
      "Iteration 81, loss = 0.79398779\n",
      "Iteration 82, loss = 0.75528052\n",
      "Iteration 83, loss = 0.76126431\n",
      "Iteration 84, loss = 0.78191346\n",
      "Iteration 85, loss = 0.75840528\n",
      "Iteration 86, loss = 0.76228694\n",
      "Iteration 87, loss = 0.73213700\n",
      "Iteration 88, loss = 0.74719712\n",
      "Iteration 89, loss = 0.72681230\n",
      "Iteration 90, loss = 0.75305657\n",
      "Iteration 91, loss = 0.75956439\n",
      "Iteration 92, loss = 0.85910562\n",
      "Iteration 93, loss = 0.76838972\n",
      "Iteration 94, loss = 0.92517539\n",
      "Iteration 95, loss = 0.79279980\n",
      "Iteration 96, loss = 0.87812001\n",
      "Iteration 97, loss = 0.75310384\n",
      "Iteration 98, loss = 0.77932596\n",
      "Iteration 84, loss = 0.78191346\n",
      "Iteration 85, loss = 0.75840528\n",
      "Iteration 86, loss = 0.76228694\n",
      "Iteration 87, loss = 0.73213700\n",
      "Iteration 88, loss = 0.74719712\n",
      "Iteration 89, loss = 0.72681230\n",
      "Iteration 90, loss = 0.75305657\n",
      "Iteration 91, loss = 0.75956439\n",
      "Iteration 92, loss = 0.85910562\n",
      "Iteration 93, loss = 0.76838972\n",
      "Iteration 94, loss = 0.92517539\n",
      "Iteration 95, loss = 0.79279980\n",
      "Iteration 96, loss = 0.87812001\n",
      "Iteration 97, loss = 0.75310384\n",
      "Iteration 98, loss = 0.77932596\n",
      "Iteration 99, loss = 0.73332136\n",
      "Iteration 100, loss = 0.77672816\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25078828\n",
      "Iteration 2, loss = 1.14638879\n",
      "Iteration 3, loss = 1.06357973\n",
      "Iteration 4, loss = 1.03610130\n",
      "Iteration 5, loss = 0.98165768\n",
      "Iteration 6, loss = 1.00277796\n",
      "Iteration 7, loss = 1.01734880\n",
      "Iteration 8, loss = 0.99663846\n",
      "Iteration 9, loss = 0.98694022\n",
      "Iteration 10, loss = 1.00822948\n",
      "Iteration 1, loss = 1.20109775\n",
      "Iteration 2, loss = 1.06880719\n",
      "Iteration 99, loss = 0.73332136\n",
      "Iteration 100, loss = 0.77672816\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25078828\n",
      "Iteration 2, loss = 1.14638879\n",
      "Iteration 3, loss = 1.06357973\n",
      "Iteration 4, loss = 1.03610130\n",
      "Iteration 5, loss = 0.98165768\n",
      "Iteration 6, loss = 1.00277796\n",
      "Iteration 7, loss = 1.01734880\n",
      "Iteration 8, loss = 0.99663846\n",
      "Iteration 9, loss = 0.98694022\n",
      "Iteration 10, loss = 1.00822948\n",
      "Iteration 1, loss = 1.20109775\n",
      "Iteration 2, loss = 1.06880719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.13497031\n",
      "Iteration 4, loss = 0.99281907\n",
      "Iteration 5, loss = 0.96446212\n",
      "Iteration 6, loss = 1.03258544\n",
      "Iteration 7, loss = 1.02914461\n",
      "Iteration 8, loss = 0.97377353\n",
      "Iteration 9, loss = 0.94110639\n",
      "Iteration 10, loss = 0.93867158\n",
      "Iteration 1, loss = 1.17775341\n",
      "Iteration 2, loss = 1.13004435\n",
      "Iteration 3, loss = 0.99001181\n",
      "Iteration 4, loss = 0.98505217\n",
      "Iteration 5, loss = 0.97744730\n",
      "Iteration 3, loss = 1.13497031\n",
      "Iteration 4, loss = 0.99281907\n",
      "Iteration 5, loss = 0.96446212\n",
      "Iteration 6, loss = 1.03258544\n",
      "Iteration 7, loss = 1.02914461\n",
      "Iteration 8, loss = 0.97377353\n",
      "Iteration 9, loss = 0.94110639\n",
      "Iteration 10, loss = 0.93867158\n",
      "Iteration 1, loss = 1.17775341\n",
      "Iteration 2, loss = 1.13004435\n",
      "Iteration 3, loss = 0.99001181\n",
      "Iteration 4, loss = 0.98505217\n",
      "Iteration 5, loss = 0.97744730\n",
      "Iteration 6, loss = 0.99201666\n",
      "Iteration 7, loss = 0.97568632\n",
      "Iteration 8, loss = 0.98338916\n",
      "Iteration 9, loss = 0.95272910\n",
      "Iteration 10, loss = 0.94608479\n",
      "Iteration 1, loss = 1.20423511\n",
      "Iteration 2, loss = 1.05325393\n",
      "Iteration 3, loss = 1.04570916\n",
      "Iteration 4, loss = 0.99595580\n",
      "Iteration 5, loss = 1.07909869\n",
      "Iteration 6, loss = 1.04169768\n",
      "Iteration 7, loss = 1.03386294\n",
      "Iteration 8, loss = 1.04908337\n",
      "Iteration 9, loss = 1.02968149\n",
      "Iteration 6, loss = 0.99201666\n",
      "Iteration 7, loss = 0.97568632\n",
      "Iteration 8, loss = 0.98338916\n",
      "Iteration 9, loss = 0.95272910\n",
      "Iteration 10, loss = 0.94608479\n",
      "Iteration 1, loss = 1.20423511\n",
      "Iteration 2, loss = 1.05325393\n",
      "Iteration 3, loss = 1.04570916\n",
      "Iteration 4, loss = 0.99595580\n",
      "Iteration 5, loss = 1.07909869\n",
      "Iteration 6, loss = 1.04169768\n",
      "Iteration 7, loss = 1.03386294\n",
      "Iteration 8, loss = 1.04908337\n",
      "Iteration 9, loss = 1.02968149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.98421640\n",
      "Iteration 1, loss = 1.16826477\n",
      "Iteration 2, loss = 1.08872719\n",
      "Iteration 3, loss = 1.07367922\n",
      "Iteration 4, loss = 0.99819360\n",
      "Iteration 5, loss = 1.06781917\n",
      "Iteration 6, loss = 1.00934803\n",
      "Iteration 7, loss = 0.97929890\n",
      "Iteration 8, loss = 1.04386723\n",
      "Iteration 9, loss = 0.99952222\n",
      "Iteration 10, loss = 0.96362599\n",
      "Iteration 10, loss = 0.98421640\n",
      "Iteration 1, loss = 1.16826477\n",
      "Iteration 2, loss = 1.08872719\n",
      "Iteration 3, loss = 1.07367922\n",
      "Iteration 4, loss = 0.99819360\n",
      "Iteration 5, loss = 1.06781917\n",
      "Iteration 6, loss = 1.00934803\n",
      "Iteration 7, loss = 0.97929890\n",
      "Iteration 8, loss = 1.04386723\n",
      "Iteration 9, loss = 0.99952222\n",
      "Iteration 10, loss = 0.96362599\n",
      "Iteration 1, loss = 1.25078828\n",
      "Iteration 2, loss = 1.14638879\n",
      "Iteration 3, loss = 1.06357973\n",
      "Iteration 4, loss = 1.03610130\n",
      "Iteration 5, loss = 0.98165768\n",
      "Iteration 6, loss = 1.00277796\n",
      "Iteration 7, loss = 1.01734880\n",
      "Iteration 8, loss = 0.99663846\n",
      "Iteration 9, loss = 0.98694022\n",
      "Iteration 10, loss = 1.00822948\n",
      "Iteration 11, loss = 1.10891240\n",
      "Iteration 12, loss = 1.10397757\n",
      "Iteration 13, loss = 1.01029760\n",
      "Iteration 1, loss = 1.25078828\n",
      "Iteration 2, loss = 1.14638879\n",
      "Iteration 3, loss = 1.06357973\n",
      "Iteration 4, loss = 1.03610130\n",
      "Iteration 5, loss = 0.98165768\n",
      "Iteration 6, loss = 1.00277796\n",
      "Iteration 7, loss = 1.01734880\n",
      "Iteration 8, loss = 0.99663846\n",
      "Iteration 9, loss = 0.98694022\n",
      "Iteration 10, loss = 1.00822948\n",
      "Iteration 11, loss = 1.10891240\n",
      "Iteration 12, loss = 1.10397757\n",
      "Iteration 13, loss = 1.01029760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 1.00267691\n",
      "Iteration 15, loss = 0.95659729\n",
      "Iteration 16, loss = 0.96072861\n",
      "Iteration 17, loss = 1.02650615\n",
      "Iteration 18, loss = 0.99271866\n",
      "Iteration 19, loss = 0.97962714\n",
      "Iteration 20, loss = 0.97810734\n",
      "Iteration 21, loss = 1.00012028\n",
      "Iteration 22, loss = 1.00613973\n",
      "Iteration 23, loss = 0.97329272\n",
      "Iteration 24, loss = 0.96403144\n",
      "Iteration 25, loss = 0.96199690\n",
      "Iteration 26, loss = 0.94897911\n",
      "Iteration 27, loss = 0.92801922\n",
      "Iteration 28, loss = 0.97892599\n",
      "Iteration 29, loss = 0.96335355\n",
      "Iteration 14, loss = 1.00267691\n",
      "Iteration 15, loss = 0.95659729\n",
      "Iteration 16, loss = 0.96072861\n",
      "Iteration 17, loss = 1.02650615\n",
      "Iteration 18, loss = 0.99271866\n",
      "Iteration 19, loss = 0.97962714\n",
      "Iteration 20, loss = 0.97810734\n",
      "Iteration 21, loss = 1.00012028\n",
      "Iteration 22, loss = 1.00613973\n",
      "Iteration 23, loss = 0.97329272\n",
      "Iteration 24, loss = 0.96403144\n",
      "Iteration 25, loss = 0.96199690\n",
      "Iteration 26, loss = 0.94897911\n",
      "Iteration 27, loss = 0.92801922\n",
      "Iteration 28, loss = 0.97892599\n",
      "Iteration 29, loss = 0.96335355\n",
      "Iteration 30, loss = 0.98737610\n",
      "Iteration 31, loss = 0.95525174\n",
      "Iteration 32, loss = 0.93633934\n",
      "Iteration 33, loss = 0.94014613\n",
      "Iteration 34, loss = 0.94014494\n",
      "Iteration 35, loss = 0.99315492\n",
      "Iteration 36, loss = 0.96735528\n",
      "Iteration 37, loss = 0.93781023\n",
      "Iteration 38, loss = 0.96768038\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20109775\n",
      "Iteration 2, loss = 1.06880719\n",
      "Iteration 3, loss = 1.13497031\n",
      "Iteration 4, loss = 0.99281907\n",
      "Iteration 5, loss = 0.96446212\n",
      "Iteration 30, loss = 0.98737610\n",
      "Iteration 31, loss = 0.95525174\n",
      "Iteration 32, loss = 0.93633934\n",
      "Iteration 33, loss = 0.94014613\n",
      "Iteration 34, loss = 0.94014494\n",
      "Iteration 35, loss = 0.99315492\n",
      "Iteration 36, loss = 0.96735528\n",
      "Iteration 37, loss = 0.93781023\n",
      "Iteration 38, loss = 0.96768038\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20109775\n",
      "Iteration 2, loss = 1.06880719\n",
      "Iteration 3, loss = 1.13497031\n",
      "Iteration 4, loss = 0.99281907\n",
      "Iteration 5, loss = 0.96446212\n",
      "Iteration 6, loss = 1.03258544\n",
      "Iteration 7, loss = 1.02914461\n",
      "Iteration 8, loss = 0.97377353\n",
      "Iteration 9, loss = 0.94110639\n",
      "Iteration 10, loss = 0.93867158\n",
      "Iteration 11, loss = 0.95252640\n",
      "Iteration 12, loss = 0.94402348\n",
      "Iteration 13, loss = 0.93540983\n",
      "Iteration 14, loss = 0.92963961\n",
      "Iteration 15, loss = 0.92464838\n",
      "Iteration 16, loss = 0.93869761\n",
      "Iteration 17, loss = 0.93063186\n",
      "Iteration 18, loss = 0.91769536\n",
      "Iteration 19, loss = 0.92302020\n",
      "Iteration 20, loss = 0.91904319\n",
      "Iteration 6, loss = 1.03258544\n",
      "Iteration 7, loss = 1.02914461\n",
      "Iteration 8, loss = 0.97377353\n",
      "Iteration 9, loss = 0.94110639\n",
      "Iteration 10, loss = 0.93867158\n",
      "Iteration 11, loss = 0.95252640\n",
      "Iteration 12, loss = 0.94402348\n",
      "Iteration 13, loss = 0.93540983\n",
      "Iteration 14, loss = 0.92963961\n",
      "Iteration 15, loss = 0.92464838\n",
      "Iteration 16, loss = 0.93869761\n",
      "Iteration 17, loss = 0.93063186\n",
      "Iteration 18, loss = 0.91769536\n",
      "Iteration 19, loss = 0.92302020\n",
      "Iteration 20, loss = 0.91904319\n",
      "Iteration 21, loss = 0.92236900\n",
      "Iteration 22, loss = 0.92721694\n",
      "Iteration 23, loss = 0.91099721\n",
      "Iteration 24, loss = 0.95040159\n",
      "Iteration 25, loss = 0.97544729\n",
      "Iteration 26, loss = 0.95465113\n",
      "Iteration 27, loss = 0.94472243\n",
      "Iteration 28, loss = 0.95673730\n",
      "Iteration 29, loss = 0.93202657\n",
      "Iteration 30, loss = 0.92880157\n",
      "Iteration 31, loss = 0.92220105\n",
      "Iteration 32, loss = 0.93188290\n",
      "Iteration 33, loss = 0.92760153\n",
      "Iteration 34, loss = 0.93568763\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17775341\n",
      "Iteration 2, loss = 1.13004435\n",
      "Iteration 21, loss = 0.92236900\n",
      "Iteration 22, loss = 0.92721694\n",
      "Iteration 23, loss = 0.91099721\n",
      "Iteration 24, loss = 0.95040159\n",
      "Iteration 25, loss = 0.97544729\n",
      "Iteration 26, loss = 0.95465113\n",
      "Iteration 27, loss = 0.94472243\n",
      "Iteration 28, loss = 0.95673730\n",
      "Iteration 29, loss = 0.93202657\n",
      "Iteration 30, loss = 0.92880157\n",
      "Iteration 31, loss = 0.92220105\n",
      "Iteration 32, loss = 0.93188290\n",
      "Iteration 33, loss = 0.92760153\n",
      "Iteration 34, loss = 0.93568763\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17775341\n",
      "Iteration 2, loss = 1.13004435\n",
      "Iteration 3, loss = 0.99001181\n",
      "Iteration 4, loss = 0.98505217\n",
      "Iteration 5, loss = 0.97744730\n",
      "Iteration 6, loss = 0.99201666\n",
      "Iteration 7, loss = 0.97568632\n",
      "Iteration 8, loss = 0.98338916\n",
      "Iteration 9, loss = 0.95272910\n",
      "Iteration 10, loss = 0.94608479\n",
      "Iteration 11, loss = 0.94937090\n",
      "Iteration 12, loss = 0.94362837\n",
      "Iteration 13, loss = 0.94078774\n",
      "Iteration 14, loss = 0.96315935\n",
      "Iteration 15, loss = 0.93974319\n",
      "Iteration 16, loss = 0.93648189\n",
      "Iteration 17, loss = 1.07078576\n",
      "Iteration 3, loss = 0.99001181\n",
      "Iteration 4, loss = 0.98505217\n",
      "Iteration 5, loss = 0.97744730\n",
      "Iteration 6, loss = 0.99201666\n",
      "Iteration 7, loss = 0.97568632\n",
      "Iteration 8, loss = 0.98338916\n",
      "Iteration 9, loss = 0.95272910\n",
      "Iteration 10, loss = 0.94608479\n",
      "Iteration 11, loss = 0.94937090\n",
      "Iteration 12, loss = 0.94362837\n",
      "Iteration 13, loss = 0.94078774\n",
      "Iteration 14, loss = 0.96315935\n",
      "Iteration 15, loss = 0.93974319\n",
      "Iteration 16, loss = 0.93648189\n",
      "Iteration 17, loss = 1.07078576\n",
      "Iteration 18, loss = 0.95952947\n",
      "Iteration 19, loss = 0.94232817\n",
      "Iteration 20, loss = 0.91108983\n",
      "Iteration 21, loss = 0.91394198\n",
      "Iteration 22, loss = 0.94793534\n",
      "Iteration 23, loss = 0.94948176\n",
      "Iteration 24, loss = 0.94680356\n",
      "Iteration 25, loss = 0.92639888\n",
      "Iteration 26, loss = 0.92830476\n",
      "Iteration 27, loss = 0.90900827\n",
      "Iteration 28, loss = 0.92266427\n",
      "Iteration 29, loss = 0.91224066\n",
      "Iteration 30, loss = 0.91323403\n",
      "Iteration 31, loss = 0.91007497\n",
      "Iteration 32, loss = 0.95138899\n",
      "Iteration 33, loss = 0.93624379\n",
      "Iteration 18, loss = 0.95952947\n",
      "Iteration 19, loss = 0.94232817\n",
      "Iteration 20, loss = 0.91108983\n",
      "Iteration 21, loss = 0.91394198\n",
      "Iteration 22, loss = 0.94793534\n",
      "Iteration 23, loss = 0.94948176\n",
      "Iteration 24, loss = 0.94680356\n",
      "Iteration 25, loss = 0.92639888\n",
      "Iteration 26, loss = 0.92830476\n",
      "Iteration 27, loss = 0.90900827\n",
      "Iteration 28, loss = 0.92266427\n",
      "Iteration 29, loss = 0.91224066\n",
      "Iteration 30, loss = 0.91323403\n",
      "Iteration 31, loss = 0.91007497\n",
      "Iteration 32, loss = 0.95138899\n",
      "Iteration 33, loss = 0.93624379\n",
      "Iteration 34, loss = 0.95093661\n",
      "Iteration 35, loss = 0.93925628\n",
      "Iteration 36, loss = 0.92723637\n",
      "Iteration 37, loss = 0.91417817\n",
      "Iteration 38, loss = 0.92306955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20423511\n",
      "Iteration 2, loss = 1.05325393\n",
      "Iteration 3, loss = 1.04570916\n",
      "Iteration 4, loss = 0.99595580\n",
      "Iteration 5, loss = 1.07909869\n",
      "Iteration 6, loss = 1.04169768\n",
      "Iteration 7, loss = 1.03386294\n",
      "Iteration 8, loss = 1.04908337\n",
      "Iteration 9, loss = 1.02968149\n",
      "Iteration 34, loss = 0.95093661\n",
      "Iteration 35, loss = 0.93925628\n",
      "Iteration 36, loss = 0.92723637\n",
      "Iteration 37, loss = 0.91417817\n",
      "Iteration 38, loss = 0.92306955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20423511\n",
      "Iteration 2, loss = 1.05325393\n",
      "Iteration 3, loss = 1.04570916\n",
      "Iteration 4, loss = 0.99595580\n",
      "Iteration 5, loss = 1.07909869\n",
      "Iteration 6, loss = 1.04169768\n",
      "Iteration 7, loss = 1.03386294\n",
      "Iteration 8, loss = 1.04908337\n",
      "Iteration 9, loss = 1.02968149\n",
      "Iteration 10, loss = 0.98421640\n",
      "Iteration 11, loss = 1.07124276\n",
      "Iteration 12, loss = 1.06613671\n",
      "Iteration 13, loss = 1.05062011\n",
      "Iteration 14, loss = 1.07415006\n",
      "Iteration 15, loss = 1.07219853\n",
      "Iteration 16, loss = 1.02469382\n",
      "Iteration 17, loss = 0.98229771\n",
      "Iteration 18, loss = 1.00364601\n",
      "Iteration 19, loss = 0.98607879\n",
      "Iteration 20, loss = 0.98574251\n",
      "Iteration 21, loss = 0.96849777\n",
      "Iteration 22, loss = 1.01405171\n",
      "Iteration 23, loss = 1.02374691\n",
      "Iteration 24, loss = 1.00197290\n",
      "Iteration 25, loss = 1.04472103\n",
      "Iteration 26, loss = 0.98380974\n",
      "Iteration 10, loss = 0.98421640\n",
      "Iteration 11, loss = 1.07124276\n",
      "Iteration 12, loss = 1.06613671\n",
      "Iteration 13, loss = 1.05062011\n",
      "Iteration 14, loss = 1.07415006\n",
      "Iteration 15, loss = 1.07219853\n",
      "Iteration 16, loss = 1.02469382\n",
      "Iteration 17, loss = 0.98229771\n",
      "Iteration 18, loss = 1.00364601\n",
      "Iteration 19, loss = 0.98607879\n",
      "Iteration 20, loss = 0.98574251\n",
      "Iteration 21, loss = 0.96849777\n",
      "Iteration 22, loss = 1.01405171\n",
      "Iteration 23, loss = 1.02374691\n",
      "Iteration 24, loss = 1.00197290\n",
      "Iteration 25, loss = 1.04472103\n",
      "Iteration 26, loss = 0.98380974\n",
      "Iteration 27, loss = 0.99191746\n",
      "Iteration 28, loss = 1.00499996\n",
      "Iteration 29, loss = 0.97503346\n",
      "Iteration 30, loss = 0.96020941\n",
      "Iteration 31, loss = 1.10889808\n",
      "Iteration 32, loss = 1.01549751\n",
      "Iteration 33, loss = 1.00263284\n",
      "Iteration 34, loss = 0.98615861\n",
      "Iteration 35, loss = 0.98372015\n",
      "Iteration 36, loss = 1.02722232\n",
      "Iteration 37, loss = 0.98459037\n",
      "Iteration 38, loss = 0.95737609\n",
      "Iteration 39, loss = 0.99463744\n",
      "Iteration 40, loss = 0.95493617\n",
      "Iteration 41, loss = 0.94539103\n",
      "Iteration 27, loss = 0.99191746\n",
      "Iteration 28, loss = 1.00499996\n",
      "Iteration 29, loss = 0.97503346\n",
      "Iteration 30, loss = 0.96020941\n",
      "Iteration 31, loss = 1.10889808\n",
      "Iteration 32, loss = 1.01549751\n",
      "Iteration 33, loss = 1.00263284\n",
      "Iteration 34, loss = 0.98615861\n",
      "Iteration 35, loss = 0.98372015\n",
      "Iteration 36, loss = 1.02722232\n",
      "Iteration 37, loss = 0.98459037\n",
      "Iteration 38, loss = 0.95737609\n",
      "Iteration 39, loss = 0.99463744\n",
      "Iteration 40, loss = 0.95493617\n",
      "Iteration 41, loss = 0.94539103\n",
      "Iteration 42, loss = 0.98193898\n",
      "Iteration 43, loss = 1.06820648\n",
      "Iteration 44, loss = 0.99377845\n",
      "Iteration 45, loss = 0.97275793\n",
      "Iteration 46, loss = 0.95444596\n",
      "Iteration 47, loss = 0.91782178\n",
      "Iteration 48, loss = 1.05480383\n",
      "Iteration 49, loss = 0.99967155\n",
      "Iteration 50, loss = 1.03476807\n",
      "Iteration 1, loss = 1.16826477\n",
      "Iteration 2, loss = 1.08872719\n",
      "Iteration 3, loss = 1.07367922\n",
      "Iteration 4, loss = 0.99819360\n",
      "Iteration 5, loss = 1.06781917\n",
      "Iteration 6, loss = 1.00934803\n",
      "Iteration 7, loss = 0.97929890Iteration 42, loss = 0.98193898\n",
      "Iteration 43, loss = 1.06820648\n",
      "Iteration 44, loss = 0.99377845\n",
      "Iteration 45, loss = 0.97275793\n",
      "Iteration 46, loss = 0.95444596\n",
      "Iteration 47, loss = 0.91782178\n",
      "Iteration 48, loss = 1.05480383\n",
      "Iteration 49, loss = 0.99967155\n",
      "Iteration 50, loss = 1.03476807\n",
      "Iteration 1, loss = 1.16826477\n",
      "Iteration 2, loss = 1.08872719\n",
      "Iteration 3, loss = 1.07367922\n",
      "Iteration 4, loss = 0.99819360\n",
      "Iteration 5, loss = 1.06781917\n",
      "Iteration 6, loss = 1.00934803\n",
      "Iteration 7, loss = 0.97929890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 8, loss = 1.04386723\n",
      "Iteration 9, loss = 0.99952222\n",
      "Iteration 10, loss = 0.96362599\n",
      "Iteration 11, loss = 1.01680793\n",
      "Iteration 12, loss = 0.95971501\n",
      "Iteration 13, loss = 0.99000186\n",
      "Iteration 14, loss = 1.01863091\n",
      "Iteration 15, loss = 1.03794847\n",
      "Iteration 16, loss = 1.03282254\n",
      "Iteration 17, loss = 1.00549540\n",
      "Iteration 18, loss = 0.99554635\n",
      "Iteration 19, loss = 0.97831416\n",
      "Iteration 20, loss = 0.98724460\n",
      "Iteration 21, loss = 0.96627610\n",
      "\n",
      "Iteration 8, loss = 1.04386723\n",
      "Iteration 9, loss = 0.99952222\n",
      "Iteration 10, loss = 0.96362599\n",
      "Iteration 11, loss = 1.01680793\n",
      "Iteration 12, loss = 0.95971501\n",
      "Iteration 13, loss = 0.99000186\n",
      "Iteration 14, loss = 1.01863091\n",
      "Iteration 15, loss = 1.03794847\n",
      "Iteration 16, loss = 1.03282254\n",
      "Iteration 17, loss = 1.00549540\n",
      "Iteration 18, loss = 0.99554635\n",
      "Iteration 19, loss = 0.97831416\n",
      "Iteration 20, loss = 0.98724460\n",
      "Iteration 21, loss = 0.96627610\n",
      "Iteration 22, loss = 0.96566015\n",
      "Iteration 23, loss = 0.99024291\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25078828\n",
      "Iteration 2, loss = 1.14638879\n",
      "Iteration 3, loss = 1.06357973\n",
      "Iteration 4, loss = 1.03610130\n",
      "Iteration 5, loss = 0.98165768\n",
      "Iteration 6, loss = 1.00277796\n",
      "Iteration 7, loss = 1.01734880\n",
      "Iteration 8, loss = 0.99663846\n",
      "Iteration 9, loss = 0.98694022\n",
      "Iteration 22, loss = 0.96566015\n",
      "Iteration 23, loss = 0.99024291\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25078828\n",
      "Iteration 2, loss = 1.14638879\n",
      "Iteration 3, loss = 1.06357973\n",
      "Iteration 4, loss = 1.03610130\n",
      "Iteration 5, loss = 0.98165768\n",
      "Iteration 6, loss = 1.00277796\n",
      "Iteration 7, loss = 1.01734880\n",
      "Iteration 8, loss = 0.99663846\n",
      "Iteration 9, loss = 0.98694022\n",
      "Iteration 10, loss = 1.00822948\n",
      "Iteration 11, loss = 1.10891240\n",
      "Iteration 12, loss = 1.10397757\n",
      "Iteration 13, loss = 1.01029760\n",
      "Iteration 14, loss = 1.00267691\n",
      "Iteration 15, loss = 0.95659729\n",
      "Iteration 16, loss = 0.96072861\n",
      "Iteration 17, loss = 1.02650615\n",
      "Iteration 18, loss = 0.99271866\n",
      "Iteration 19, loss = 0.97962714\n",
      "Iteration 20, loss = 0.97810734\n",
      "Iteration 21, loss = 1.00012028\n",
      "Iteration 22, loss = 1.00613973\n",
      "Iteration 23, loss = 0.97329272\n",
      "Iteration 24, loss = 0.96403144\n",
      "Iteration 25, loss = 0.96199690\n",
      "Iteration 10, loss = 1.00822948\n",
      "Iteration 11, loss = 1.10891240\n",
      "Iteration 12, loss = 1.10397757\n",
      "Iteration 13, loss = 1.01029760\n",
      "Iteration 14, loss = 1.00267691\n",
      "Iteration 15, loss = 0.95659729\n",
      "Iteration 16, loss = 0.96072861\n",
      "Iteration 17, loss = 1.02650615\n",
      "Iteration 18, loss = 0.99271866\n",
      "Iteration 19, loss = 0.97962714\n",
      "Iteration 20, loss = 0.97810734\n",
      "Iteration 21, loss = 1.00012028\n",
      "Iteration 22, loss = 1.00613973\n",
      "Iteration 23, loss = 0.97329272\n",
      "Iteration 24, loss = 0.96403144\n",
      "Iteration 25, loss = 0.96199690\n",
      "Iteration 26, loss = 0.94897911\n",
      "Iteration 27, loss = 0.92801922\n",
      "Iteration 28, loss = 0.97892599\n",
      "Iteration 29, loss = 0.96335355\n",
      "Iteration 30, loss = 0.98737610\n",
      "Iteration 31, loss = 0.95525174\n",
      "Iteration 32, loss = 0.93633934\n",
      "Iteration 33, loss = 0.94014613\n",
      "Iteration 34, loss = 0.94014494\n",
      "Iteration 35, loss = 0.99315492\n",
      "Iteration 36, loss = 0.96735528\n",
      "Iteration 37, loss = 0.93781023\n",
      "Iteration 38, loss = 0.96768038\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20109775\n",
      "Iteration 26, loss = 0.94897911\n",
      "Iteration 27, loss = 0.92801922\n",
      "Iteration 28, loss = 0.97892599\n",
      "Iteration 29, loss = 0.96335355\n",
      "Iteration 30, loss = 0.98737610\n",
      "Iteration 31, loss = 0.95525174\n",
      "Iteration 32, loss = 0.93633934\n",
      "Iteration 33, loss = 0.94014613\n",
      "Iteration 34, loss = 0.94014494\n",
      "Iteration 35, loss = 0.99315492\n",
      "Iteration 36, loss = 0.96735528\n",
      "Iteration 37, loss = 0.93781023\n",
      "Iteration 38, loss = 0.96768038\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20109775\n",
      "Iteration 2, loss = 1.06880719\n",
      "Iteration 3, loss = 1.13497031\n",
      "Iteration 4, loss = 0.99281907\n",
      "Iteration 5, loss = 0.96446212\n",
      "Iteration 6, loss = 1.03258544\n",
      "Iteration 7, loss = 1.02914461\n",
      "Iteration 8, loss = 0.97377353\n",
      "Iteration 9, loss = 0.94110639\n",
      "Iteration 10, loss = 0.93867158\n",
      "Iteration 11, loss = 0.95252640\n",
      "Iteration 12, loss = 0.94402348\n",
      "Iteration 13, loss = 0.93540983\n",
      "Iteration 14, loss = 0.92963961\n",
      "Iteration 15, loss = 0.92464838\n",
      "Iteration 2, loss = 1.06880719\n",
      "Iteration 3, loss = 1.13497031\n",
      "Iteration 4, loss = 0.99281907\n",
      "Iteration 5, loss = 0.96446212\n",
      "Iteration 6, loss = 1.03258544\n",
      "Iteration 7, loss = 1.02914461\n",
      "Iteration 8, loss = 0.97377353\n",
      "Iteration 9, loss = 0.94110639\n",
      "Iteration 10, loss = 0.93867158\n",
      "Iteration 11, loss = 0.95252640\n",
      "Iteration 12, loss = 0.94402348\n",
      "Iteration 13, loss = 0.93540983\n",
      "Iteration 14, loss = 0.92963961\n",
      "Iteration 15, loss = 0.92464838\n",
      "Iteration 16, loss = 0.93869761\n",
      "Iteration 17, loss = 0.93063186\n",
      "Iteration 18, loss = 0.91769536\n",
      "Iteration 19, loss = 0.92302020\n",
      "Iteration 20, loss = 0.91904319\n",
      "Iteration 21, loss = 0.92236900\n",
      "Iteration 22, loss = 0.92721694\n",
      "Iteration 23, loss = 0.91099721\n",
      "Iteration 24, loss = 0.95040159\n",
      "Iteration 25, loss = 0.97544729\n",
      "Iteration 26, loss = 0.95465113\n",
      "Iteration 27, loss = 0.94472243\n",
      "Iteration 28, loss = 0.95673730\n",
      "Iteration 29, loss = 0.93202657\n",
      "Iteration 30, loss = 0.92880157\n",
      "Iteration 16, loss = 0.93869761\n",
      "Iteration 17, loss = 0.93063186\n",
      "Iteration 18, loss = 0.91769536\n",
      "Iteration 19, loss = 0.92302020\n",
      "Iteration 20, loss = 0.91904319\n",
      "Iteration 21, loss = 0.92236900\n",
      "Iteration 22, loss = 0.92721694\n",
      "Iteration 23, loss = 0.91099721\n",
      "Iteration 24, loss = 0.95040159\n",
      "Iteration 25, loss = 0.97544729\n",
      "Iteration 26, loss = 0.95465113\n",
      "Iteration 27, loss = 0.94472243\n",
      "Iteration 28, loss = 0.95673730\n",
      "Iteration 29, loss = 0.93202657\n",
      "Iteration 30, loss = 0.92880157\n",
      "Iteration 31, loss = 0.92220105\n",
      "Iteration 32, loss = 0.93188290\n",
      "Iteration 33, loss = 0.92760153\n",
      "Iteration 34, loss = 0.93568763\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17775341\n",
      "Iteration 2, loss = 1.13004435\n",
      "Iteration 3, loss = 0.99001181\n",
      "Iteration 4, loss = 0.98505217\n",
      "Iteration 5, loss = 0.97744730\n",
      "Iteration 6, loss = 0.99201666\n",
      "Iteration 7, loss = 0.97568632\n",
      "Iteration 8, loss = 0.98338916\n",
      "Iteration 9, loss = 0.95272910\n",
      "Iteration 10, loss = 0.94608479\n",
      "Iteration 31, loss = 0.92220105\n",
      "Iteration 32, loss = 0.93188290\n",
      "Iteration 33, loss = 0.92760153\n",
      "Iteration 34, loss = 0.93568763\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17775341\n",
      "Iteration 2, loss = 1.13004435\n",
      "Iteration 3, loss = 0.99001181\n",
      "Iteration 4, loss = 0.98505217\n",
      "Iteration 5, loss = 0.97744730\n",
      "Iteration 6, loss = 0.99201666\n",
      "Iteration 7, loss = 0.97568632\n",
      "Iteration 8, loss = 0.98338916\n",
      "Iteration 9, loss = 0.95272910\n",
      "Iteration 10, loss = 0.94608479\n",
      "Iteration 11, loss = 0.94937090\n",
      "Iteration 12, loss = 0.94362837\n",
      "Iteration 13, loss = 0.94078774\n",
      "Iteration 14, loss = 0.96315935\n",
      "Iteration 15, loss = 0.93974319\n",
      "Iteration 16, loss = 0.93648189\n",
      "Iteration 17, loss = 1.07078576\n",
      "Iteration 18, loss = 0.95952947\n",
      "Iteration 19, loss = 0.94232817\n",
      "Iteration 20, loss = 0.91108983\n",
      "Iteration 21, loss = 0.91394198\n",
      "Iteration 22, loss = 0.94793534\n",
      "Iteration 23, loss = 0.94948176\n",
      "Iteration 24, loss = 0.94680356\n",
      "Iteration 25, loss = 0.92639888\n",
      "Iteration 11, loss = 0.94937090\n",
      "Iteration 12, loss = 0.94362837\n",
      "Iteration 13, loss = 0.94078774\n",
      "Iteration 14, loss = 0.96315935\n",
      "Iteration 15, loss = 0.93974319\n",
      "Iteration 16, loss = 0.93648189\n",
      "Iteration 17, loss = 1.07078576\n",
      "Iteration 18, loss = 0.95952947\n",
      "Iteration 19, loss = 0.94232817\n",
      "Iteration 20, loss = 0.91108983\n",
      "Iteration 21, loss = 0.91394198\n",
      "Iteration 22, loss = 0.94793534\n",
      "Iteration 23, loss = 0.94948176\n",
      "Iteration 24, loss = 0.94680356\n",
      "Iteration 25, loss = 0.92639888\n",
      "Iteration 26, loss = 0.92830476\n",
      "Iteration 27, loss = 0.90900827\n",
      "Iteration 28, loss = 0.92266427\n",
      "Iteration 29, loss = 0.91224066\n",
      "Iteration 30, loss = 0.91323403\n",
      "Iteration 31, loss = 0.91007497\n",
      "Iteration 32, loss = 0.95138899\n",
      "Iteration 33, loss = 0.93624379\n",
      "Iteration 34, loss = 0.95093661\n",
      "Iteration 35, loss = 0.93925628\n",
      "Iteration 36, loss = 0.92723637\n",
      "Iteration 37, loss = 0.91417817\n",
      "Iteration 38, loss = 0.92306955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20423511\n",
      "Iteration 26, loss = 0.92830476\n",
      "Iteration 27, loss = 0.90900827\n",
      "Iteration 28, loss = 0.92266427\n",
      "Iteration 29, loss = 0.91224066\n",
      "Iteration 30, loss = 0.91323403\n",
      "Iteration 31, loss = 0.91007497\n",
      "Iteration 32, loss = 0.95138899\n",
      "Iteration 33, loss = 0.93624379\n",
      "Iteration 34, loss = 0.95093661\n",
      "Iteration 35, loss = 0.93925628\n",
      "Iteration 36, loss = 0.92723637\n",
      "Iteration 37, loss = 0.91417817\n",
      "Iteration 38, loss = 0.92306955\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20423511\n",
      "Iteration 2, loss = 1.05325393\n",
      "Iteration 3, loss = 1.04570916\n",
      "Iteration 4, loss = 0.99595580\n",
      "Iteration 5, loss = 1.07909869\n",
      "Iteration 6, loss = 1.04169768\n",
      "Iteration 7, loss = 1.03386294\n",
      "Iteration 8, loss = 1.04908337\n",
      "Iteration 9, loss = 1.02968149\n",
      "Iteration 10, loss = 0.98421640\n",
      "Iteration 11, loss = 1.07124276\n",
      "Iteration 12, loss = 1.06613671\n",
      "Iteration 13, loss = 1.05062011\n",
      "Iteration 14, loss = 1.07415006\n",
      "Iteration 15, loss = 1.07219853\n",
      "Iteration 16, loss = 1.02469382\n",
      "Iteration 2, loss = 1.05325393\n",
      "Iteration 3, loss = 1.04570916\n",
      "Iteration 4, loss = 0.99595580\n",
      "Iteration 5, loss = 1.07909869\n",
      "Iteration 6, loss = 1.04169768\n",
      "Iteration 7, loss = 1.03386294\n",
      "Iteration 8, loss = 1.04908337\n",
      "Iteration 9, loss = 1.02968149\n",
      "Iteration 10, loss = 0.98421640\n",
      "Iteration 11, loss = 1.07124276\n",
      "Iteration 12, loss = 1.06613671\n",
      "Iteration 13, loss = 1.05062011\n",
      "Iteration 14, loss = 1.07415006\n",
      "Iteration 15, loss = 1.07219853\n",
      "Iteration 16, loss = 1.02469382\n",
      "Iteration 17, loss = 0.98229771\n",
      "Iteration 18, loss = 1.00364601\n",
      "Iteration 19, loss = 0.98607879\n",
      "Iteration 20, loss = 0.98574251\n",
      "Iteration 21, loss = 0.96849777\n",
      "Iteration 22, loss = 1.01405171\n",
      "Iteration 23, loss = 1.02374691\n",
      "Iteration 24, loss = 1.00197290\n",
      "Iteration 25, loss = 1.04472103\n",
      "Iteration 26, loss = 0.98380974\n",
      "Iteration 27, loss = 0.99191746\n",
      "Iteration 28, loss = 1.00499996\n",
      "Iteration 29, loss = 0.97503346\n",
      "Iteration 30, loss = 0.96020941\n",
      "Iteration 17, loss = 0.98229771\n",
      "Iteration 18, loss = 1.00364601\n",
      "Iteration 19, loss = 0.98607879\n",
      "Iteration 20, loss = 0.98574251\n",
      "Iteration 21, loss = 0.96849777\n",
      "Iteration 22, loss = 1.01405171\n",
      "Iteration 23, loss = 1.02374691\n",
      "Iteration 24, loss = 1.00197290\n",
      "Iteration 25, loss = 1.04472103\n",
      "Iteration 26, loss = 0.98380974\n",
      "Iteration 27, loss = 0.99191746\n",
      "Iteration 28, loss = 1.00499996\n",
      "Iteration 29, loss = 0.97503346\n",
      "Iteration 30, loss = 0.96020941\n",
      "Iteration 31, loss = 1.10889808\n",
      "Iteration 32, loss = 1.01549751\n",
      "Iteration 33, loss = 1.00263284\n",
      "Iteration 34, loss = 0.98615861\n",
      "Iteration 35, loss = 0.98372015\n",
      "Iteration 36, loss = 1.02722232\n",
      "Iteration 37, loss = 0.98459037\n",
      "Iteration 38, loss = 0.95737609\n",
      "Iteration 39, loss = 0.99463744\n",
      "Iteration 40, loss = 0.95493617\n",
      "Iteration 41, loss = 0.94539103\n",
      "Iteration 42, loss = 0.98193898\n",
      "Iteration 43, loss = 1.06820648\n",
      "Iteration 44, loss = 0.99377845\n",
      "Iteration 31, loss = 1.10889808\n",
      "Iteration 32, loss = 1.01549751\n",
      "Iteration 33, loss = 1.00263284\n",
      "Iteration 34, loss = 0.98615861\n",
      "Iteration 35, loss = 0.98372015\n",
      "Iteration 36, loss = 1.02722232\n",
      "Iteration 37, loss = 0.98459037\n",
      "Iteration 38, loss = 0.95737609\n",
      "Iteration 39, loss = 0.99463744\n",
      "Iteration 40, loss = 0.95493617\n",
      "Iteration 41, loss = 0.94539103\n",
      "Iteration 42, loss = 0.98193898\n",
      "Iteration 43, loss = 1.06820648\n",
      "Iteration 44, loss = 0.99377845\n",
      "Iteration 45, loss = 0.97275793\n",
      "Iteration 46, loss = 0.95444596\n",
      "Iteration 47, loss = 0.91782178\n",
      "Iteration 48, loss = 1.05480383\n",
      "Iteration 49, loss = 0.99967155\n",
      "Iteration 50, loss = 1.03476807\n",
      "Iteration 51, loss = 1.01003461\n",
      "Iteration 52, loss = 0.92775568\n",
      "Iteration 53, loss = 0.99776662\n",
      "Iteration 54, loss = 0.98245684\n",
      "Iteration 55, loss = 0.93423500\n",
      "Iteration 56, loss = 0.93700632\n",
      "Iteration 57, loss = 0.94674033\n",
      "Iteration 58, loss = 0.92048755\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16826477\n",
      "Iteration 45, loss = 0.97275793\n",
      "Iteration 46, loss = 0.95444596\n",
      "Iteration 47, loss = 0.91782178\n",
      "Iteration 48, loss = 1.05480383\n",
      "Iteration 49, loss = 0.99967155\n",
      "Iteration 50, loss = 1.03476807\n",
      "Iteration 51, loss = 1.01003461\n",
      "Iteration 52, loss = 0.92775568\n",
      "Iteration 53, loss = 0.99776662\n",
      "Iteration 54, loss = 0.98245684\n",
      "Iteration 55, loss = 0.93423500\n",
      "Iteration 56, loss = 0.93700632\n",
      "Iteration 57, loss = 0.94674033\n",
      "Iteration 58, loss = 0.92048755\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16826477\n",
      "Iteration 2, loss = 1.08872719\n",
      "Iteration 3, loss = 1.07367922\n",
      "Iteration 4, loss = 0.99819360\n",
      "Iteration 5, loss = 1.06781917\n",
      "Iteration 6, loss = 1.00934803\n",
      "Iteration 7, loss = 0.97929890\n",
      "Iteration 8, loss = 1.04386723\n",
      "Iteration 9, loss = 0.99952222\n",
      "Iteration 10, loss = 0.96362599\n",
      "Iteration 11, loss = 1.01680793\n",
      "Iteration 12, loss = 0.95971501\n",
      "Iteration 13, loss = 0.99000186\n",
      "Iteration 2, loss = 1.08872719\n",
      "Iteration 3, loss = 1.07367922\n",
      "Iteration 4, loss = 0.99819360\n",
      "Iteration 5, loss = 1.06781917\n",
      "Iteration 6, loss = 1.00934803\n",
      "Iteration 7, loss = 0.97929890\n",
      "Iteration 8, loss = 1.04386723\n",
      "Iteration 9, loss = 0.99952222\n",
      "Iteration 10, loss = 0.96362599\n",
      "Iteration 11, loss = 1.01680793\n",
      "Iteration 12, loss = 0.95971501\n",
      "Iteration 13, loss = 0.99000186\n",
      "Iteration 14, loss = 1.01863091\n",
      "Iteration 15, loss = 1.03794847\n",
      "Iteration 16, loss = 1.03282254\n",
      "Iteration 17, loss = 1.00549540\n",
      "Iteration 18, loss = 0.99554635\n",
      "Iteration 19, loss = 0.97831416\n",
      "Iteration 20, loss = 0.98724460\n",
      "Iteration 21, loss = 0.96627610\n",
      "Iteration 22, loss = 0.96566015\n",
      "Iteration 23, loss = 0.99024291\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26216079\n",
      "Iteration 2, loss = 1.07034172\n",
      "Iteration 14, loss = 1.01863091\n",
      "Iteration 15, loss = 1.03794847\n",
      "Iteration 16, loss = 1.03282254\n",
      "Iteration 17, loss = 1.00549540\n",
      "Iteration 18, loss = 0.99554635\n",
      "Iteration 19, loss = 0.97831416\n",
      "Iteration 20, loss = 0.98724460\n",
      "Iteration 21, loss = 0.96627610\n",
      "Iteration 22, loss = 0.96566015\n",
      "Iteration 23, loss = 0.99024291\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26216079\n",
      "Iteration 2, loss = 1.07034172\n",
      "Iteration 3, loss = 1.02127022\n",
      "Iteration 4, loss = 1.09170067\n",
      "Iteration 5, loss = 1.00077516\n",
      "Iteration 6, loss = 1.06760702\n",
      "Iteration 7, loss = 1.09631434\n",
      "Iteration 8, loss = 1.25736668\n",
      "Iteration 9, loss = 1.25930237\n",
      "Iteration 10, loss = 1.25938307\n",
      "Iteration 1, loss = 1.19769613\n",
      "Iteration 2, loss = 1.06785797\n",
      "Iteration 3, loss = 1.20947072\n",
      "Iteration 3, loss = 1.02127022\n",
      "Iteration 4, loss = 1.09170067\n",
      "Iteration 5, loss = 1.00077516\n",
      "Iteration 6, loss = 1.06760702\n",
      "Iteration 7, loss = 1.09631434\n",
      "Iteration 8, loss = 1.25736668\n",
      "Iteration 9, loss = 1.25930237\n",
      "Iteration 10, loss = 1.25938307\n",
      "Iteration 1, loss = 1.19769613\n",
      "Iteration 2, loss = 1.06785797\n",
      "Iteration 3, loss = 1.20947072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.24913181\n",
      "Iteration 5, loss = 1.25571437\n",
      "Iteration 6, loss = 1.25028813\n",
      "Iteration 7, loss = 1.24672998\n",
      "Iteration 8, loss = 1.25429203\n",
      "Iteration 9, loss = 1.27722007\n",
      "Iteration 10, loss = 1.25255428\n",
      "Iteration 1, loss = 1.16651293\n",
      "Iteration 2, loss = 1.24299109\n",
      "Iteration 4, loss = 1.24913181\n",
      "Iteration 5, loss = 1.25571437\n",
      "Iteration 6, loss = 1.25028813\n",
      "Iteration 7, loss = 1.24672998\n",
      "Iteration 8, loss = 1.25429203\n",
      "Iteration 9, loss = 1.27722007\n",
      "Iteration 10, loss = 1.25255428\n",
      "Iteration 1, loss = 1.16651293\n",
      "Iteration 2, loss = 1.24299109\n",
      "Iteration 3, loss = 1.17307711\n",
      "Iteration 4, loss = 1.03329467\n",
      "Iteration 5, loss = 1.03519201\n",
      "Iteration 6, loss = 1.06549118\n",
      "Iteration 7, loss = 1.02669914\n",
      "Iteration 8, loss = 0.97193785\n",
      "Iteration 9, loss = 0.99632888\n",
      "Iteration 10, loss = 0.99553168\n",
      "Iteration 1, loss = 1.20872743\n",
      "Iteration 2, loss = 1.05501455\n",
      "Iteration 3, loss = 1.06544058\n",
      "Iteration 4, loss = 1.06888392\n",
      "Iteration 3, loss = 1.17307711\n",
      "Iteration 4, loss = 1.03329467\n",
      "Iteration 5, loss = 1.03519201\n",
      "Iteration 6, loss = 1.06549118\n",
      "Iteration 7, loss = 1.02669914\n",
      "Iteration 8, loss = 0.97193785\n",
      "Iteration 9, loss = 0.99632888\n",
      "Iteration 10, loss = 0.99553168\n",
      "Iteration 1, loss = 1.20872743\n",
      "Iteration 2, loss = 1.05501455\n",
      "Iteration 3, loss = 1.06544058\n",
      "Iteration 4, loss = 1.06888392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.16901313\n",
      "Iteration 6, loss = 1.17895580\n",
      "Iteration 7, loss = 1.15471474\n",
      "Iteration 8, loss = 1.17220344\n",
      "Iteration 9, loss = 1.23282217\n",
      "Iteration 10, loss = 1.24934747\n",
      "Iteration 1, loss = 1.19844672\n",
      "Iteration 2, loss = 1.05064333\n",
      "Iteration 3, loss = 1.23065678\n",
      "Iteration 4, loss = 1.07726682\n",
      "Iteration 5, loss = 1.16901313\n",
      "Iteration 6, loss = 1.17895580\n",
      "Iteration 7, loss = 1.15471474\n",
      "Iteration 8, loss = 1.17220344\n",
      "Iteration 9, loss = 1.23282217\n",
      "Iteration 10, loss = 1.24934747\n",
      "Iteration 1, loss = 1.19844672\n",
      "Iteration 2, loss = 1.05064333\n",
      "Iteration 3, loss = 1.23065678\n",
      "Iteration 4, loss = 1.07726682\n",
      "Iteration 5, loss = 1.14269341\n",
      "Iteration 6, loss = 1.12334240\n",
      "Iteration 7, loss = 1.03781511\n",
      "Iteration 8, loss = 1.09711445\n",
      "Iteration 9, loss = 1.01327241\n",
      "Iteration 10, loss = 1.03915312\n",
      "Iteration 1, loss = 1.26216079\n",
      "Iteration 2, loss = 1.07034172\n",
      "Iteration 3, loss = 1.02127022\n",
      "Iteration 4, loss = 1.09170067\n",
      "Iteration 5, loss = 1.00077516\n",
      "Iteration 6, loss = 1.06760702\n",
      "Iteration 5, loss = 1.14269341\n",
      "Iteration 6, loss = 1.12334240\n",
      "Iteration 7, loss = 1.03781511\n",
      "Iteration 8, loss = 1.09711445\n",
      "Iteration 9, loss = 1.01327241\n",
      "Iteration 10, loss = 1.03915312\n",
      "Iteration 1, loss = 1.26216079\n",
      "Iteration 2, loss = 1.07034172\n",
      "Iteration 3, loss = 1.02127022\n",
      "Iteration 4, loss = 1.09170067\n",
      "Iteration 5, loss = 1.00077516\n",
      "Iteration 6, loss = 1.06760702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.09631434\n",
      "Iteration 8, loss = 1.25736668\n",
      "Iteration 9, loss = 1.25930237\n",
      "Iteration 10, loss = 1.25938307\n",
      "Iteration 11, loss = 1.25437769\n",
      "Iteration 12, loss = 1.24944953\n",
      "Iteration 13, loss = 1.25785929\n",
      "Iteration 14, loss = 1.24030074\n",
      "Iteration 15, loss = 1.24670480\n",
      "Iteration 16, loss = 1.25049847\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19769613\n",
      "Iteration 2, loss = 1.06785797\n",
      "Iteration 3, loss = 1.20947072\n",
      "Iteration 7, loss = 1.09631434\n",
      "Iteration 8, loss = 1.25736668\n",
      "Iteration 9, loss = 1.25930237\n",
      "Iteration 10, loss = 1.25938307\n",
      "Iteration 11, loss = 1.25437769\n",
      "Iteration 12, loss = 1.24944953\n",
      "Iteration 13, loss = 1.25785929\n",
      "Iteration 14, loss = 1.24030074\n",
      "Iteration 15, loss = 1.24670480\n",
      "Iteration 16, loss = 1.25049847\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19769613\n",
      "Iteration 2, loss = 1.06785797\n",
      "Iteration 3, loss = 1.20947072\n",
      "Iteration 4, loss = 1.24913181\n",
      "Iteration 5, loss = 1.25571437\n",
      "Iteration 6, loss = 1.25028813\n",
      "Iteration 7, loss = 1.24672998\n",
      "Iteration 8, loss = 1.25429203\n",
      "Iteration 9, loss = 1.27722007\n",
      "Iteration 10, loss = 1.25255428\n",
      "Iteration 11, loss = 1.24816205\n",
      "Iteration 12, loss = 1.26084616\n",
      "Iteration 13, loss = 1.25265377\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16651293\n",
      "Iteration 2, loss = 1.24299109\n",
      "Iteration 4, loss = 1.24913181\n",
      "Iteration 5, loss = 1.25571437\n",
      "Iteration 6, loss = 1.25028813\n",
      "Iteration 7, loss = 1.24672998\n",
      "Iteration 8, loss = 1.25429203\n",
      "Iteration 9, loss = 1.27722007\n",
      "Iteration 10, loss = 1.25255428\n",
      "Iteration 11, loss = 1.24816205\n",
      "Iteration 12, loss = 1.26084616\n",
      "Iteration 13, loss = 1.25265377\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16651293\n",
      "Iteration 2, loss = 1.24299109\n",
      "Iteration 3, loss = 1.17307711\n",
      "Iteration 4, loss = 1.03329467\n",
      "Iteration 5, loss = 1.03519201\n",
      "Iteration 6, loss = 1.06549118\n",
      "Iteration 7, loss = 1.02669914\n",
      "Iteration 8, loss = 0.97193785\n",
      "Iteration 9, loss = 0.99632888\n",
      "Iteration 10, loss = 0.99553168\n",
      "Iteration 11, loss = 1.00159820\n",
      "Iteration 12, loss = 0.96328350\n",
      "Iteration 13, loss = 1.01715871\n",
      "Iteration 14, loss = 1.14732448\n",
      "Iteration 15, loss = 1.27091591\n",
      "Iteration 16, loss = 1.26914843\n",
      "Iteration 17, loss = 1.26602473\n",
      "Iteration 3, loss = 1.17307711\n",
      "Iteration 4, loss = 1.03329467\n",
      "Iteration 5, loss = 1.03519201\n",
      "Iteration 6, loss = 1.06549118\n",
      "Iteration 7, loss = 1.02669914\n",
      "Iteration 8, loss = 0.97193785\n",
      "Iteration 9, loss = 0.99632888\n",
      "Iteration 10, loss = 0.99553168\n",
      "Iteration 11, loss = 1.00159820\n",
      "Iteration 12, loss = 0.96328350\n",
      "Iteration 13, loss = 1.01715871\n",
      "Iteration 14, loss = 1.14732448\n",
      "Iteration 15, loss = 1.27091591\n",
      "Iteration 16, loss = 1.26914843\n",
      "Iteration 17, loss = 1.26602473\n",
      "Iteration 18, loss = 1.27889754\n",
      "Iteration 19, loss = 1.27465484\n",
      "Iteration 20, loss = 1.26424759\n",
      "Iteration 21, loss = 1.27714079\n",
      "Iteration 22, loss = 1.28041979\n",
      "Iteration 23, loss = 1.26266722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20872743\n",
      "Iteration 2, loss = 1.05501455\n",
      "Iteration 3, loss = 1.06544058\n",
      "Iteration 4, loss = 1.06888392\n",
      "Iteration 5, loss = 1.16901313\n",
      "Iteration 6, loss = 1.17895580\n",
      "Iteration 7, loss = 1.15471474\n",
      "Iteration 18, loss = 1.27889754\n",
      "Iteration 19, loss = 1.27465484\n",
      "Iteration 20, loss = 1.26424759\n",
      "Iteration 21, loss = 1.27714079\n",
      "Iteration 22, loss = 1.28041979\n",
      "Iteration 23, loss = 1.26266722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20872743\n",
      "Iteration 2, loss = 1.05501455\n",
      "Iteration 3, loss = 1.06544058\n",
      "Iteration 4, loss = 1.06888392\n",
      "Iteration 5, loss = 1.16901313\n",
      "Iteration 6, loss = 1.17895580\n",
      "Iteration 7, loss = 1.15471474\n",
      "Iteration 8, loss = 1.17220344\n",
      "Iteration 9, loss = 1.23282217\n",
      "Iteration 10, loss = 1.24934747\n",
      "Iteration 11, loss = 1.20805411\n",
      "Iteration 12, loss = 1.20377677\n",
      "Iteration 13, loss = 1.26370399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19844672\n",
      "Iteration 2, loss = 1.05064333\n",
      "Iteration 3, loss = 1.23065678\n",
      "Iteration 4, loss = 1.07726682\n",
      "Iteration 5, loss = 1.14269341\n",
      "Iteration 6, loss = 1.12334240\n",
      "Iteration 8, loss = 1.17220344\n",
      "Iteration 9, loss = 1.23282217\n",
      "Iteration 10, loss = 1.24934747\n",
      "Iteration 11, loss = 1.20805411\n",
      "Iteration 12, loss = 1.20377677\n",
      "Iteration 13, loss = 1.26370399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19844672\n",
      "Iteration 2, loss = 1.05064333\n",
      "Iteration 3, loss = 1.23065678\n",
      "Iteration 4, loss = 1.07726682\n",
      "Iteration 5, loss = 1.14269341\n",
      "Iteration 6, loss = 1.12334240\n",
      "Iteration 7, loss = 1.03781511\n",
      "Iteration 8, loss = 1.09711445\n",
      "Iteration 9, loss = 1.01327241\n",
      "Iteration 10, loss = 1.03915312\n",
      "Iteration 11, loss = 1.02562817\n",
      "Iteration 12, loss = 1.00896680\n",
      "Iteration 13, loss = 1.22631395\n",
      "Iteration 14, loss = 1.28473972\n",
      "Iteration 15, loss = 1.19566227\n",
      "Iteration 16, loss = 1.27431839\n",
      "Iteration 17, loss = 1.28244658\n",
      "Iteration 18, loss = 1.27476012\n",
      "Iteration 19, loss = 1.27389286\n",
      "Iteration 20, loss = 1.27604599\n",
      "Iteration 7, loss = 1.03781511\n",
      "Iteration 8, loss = 1.09711445\n",
      "Iteration 9, loss = 1.01327241\n",
      "Iteration 10, loss = 1.03915312\n",
      "Iteration 11, loss = 1.02562817\n",
      "Iteration 12, loss = 1.00896680\n",
      "Iteration 13, loss = 1.22631395\n",
      "Iteration 14, loss = 1.28473972\n",
      "Iteration 15, loss = 1.19566227\n",
      "Iteration 16, loss = 1.27431839\n",
      "Iteration 17, loss = 1.28244658\n",
      "Iteration 18, loss = 1.27476012\n",
      "Iteration 19, loss = 1.27389286\n",
      "Iteration 20, loss = 1.27604599\n",
      "Iteration 21, loss = 1.29013649\n",
      "Iteration 22, loss = 1.28904377\n",
      "Iteration 23, loss = 1.27899318\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26216079\n",
      "Iteration 2, loss = 1.07034172\n",
      "Iteration 3, loss = 1.02127022\n",
      "Iteration 4, loss = 1.09170067\n",
      "Iteration 5, loss = 1.00077516\n",
      "Iteration 6, loss = 1.06760702\n",
      "Iteration 7, loss = 1.09631434\n",
      "Iteration 8, loss = 1.25736668\n",
      "Iteration 9, loss = 1.25930237\n",
      "Iteration 10, loss = 1.25938307\n",
      "Iteration 21, loss = 1.29013649\n",
      "Iteration 22, loss = 1.28904377\n",
      "Iteration 23, loss = 1.27899318\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26216079\n",
      "Iteration 2, loss = 1.07034172\n",
      "Iteration 3, loss = 1.02127022\n",
      "Iteration 4, loss = 1.09170067\n",
      "Iteration 5, loss = 1.00077516\n",
      "Iteration 6, loss = 1.06760702\n",
      "Iteration 7, loss = 1.09631434\n",
      "Iteration 8, loss = 1.25736668\n",
      "Iteration 9, loss = 1.25930237\n",
      "Iteration 10, loss = 1.25938307\n",
      "Iteration 11, loss = 1.25437769\n",
      "Iteration 12, loss = 1.24944953\n",
      "Iteration 13, loss = 1.25785929\n",
      "Iteration 14, loss = 1.24030074\n",
      "Iteration 15, loss = 1.24670480\n",
      "Iteration 16, loss = 1.25049847\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19769613\n",
      "Iteration 2, loss = 1.06785797\n",
      "Iteration 3, loss = 1.20947072\n",
      "Iteration 4, loss = 1.24913181\n",
      "Iteration 5, loss = 1.25571437\n",
      "Iteration 11, loss = 1.25437769\n",
      "Iteration 12, loss = 1.24944953\n",
      "Iteration 13, loss = 1.25785929\n",
      "Iteration 14, loss = 1.24030074\n",
      "Iteration 15, loss = 1.24670480\n",
      "Iteration 16, loss = 1.25049847\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19769613\n",
      "Iteration 2, loss = 1.06785797\n",
      "Iteration 3, loss = 1.20947072\n",
      "Iteration 4, loss = 1.24913181\n",
      "Iteration 5, loss = 1.25571437\n",
      "Iteration 6, loss = 1.25028813\n",
      "Iteration 7, loss = 1.24672998\n",
      "Iteration 8, loss = 1.25429203\n",
      "Iteration 9, loss = 1.27722007\n",
      "Iteration 10, loss = 1.25255428\n",
      "Iteration 11, loss = 1.24816205\n",
      "Iteration 12, loss = 1.26084616\n",
      "Iteration 13, loss = 1.25265377\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16651293\n",
      "Iteration 2, loss = 1.24299109\n",
      "Iteration 3, loss = 1.17307711\n",
      "Iteration 4, loss = 1.03329467\n",
      "Iteration 6, loss = 1.25028813\n",
      "Iteration 7, loss = 1.24672998\n",
      "Iteration 8, loss = 1.25429203\n",
      "Iteration 9, loss = 1.27722007\n",
      "Iteration 10, loss = 1.25255428\n",
      "Iteration 11, loss = 1.24816205\n",
      "Iteration 12, loss = 1.26084616\n",
      "Iteration 13, loss = 1.25265377\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16651293\n",
      "Iteration 2, loss = 1.24299109\n",
      "Iteration 3, loss = 1.17307711\n",
      "Iteration 4, loss = 1.03329467\n",
      "Iteration 5, loss = 1.03519201\n",
      "Iteration 6, loss = 1.06549118\n",
      "Iteration 7, loss = 1.02669914\n",
      "Iteration 8, loss = 0.97193785\n",
      "Iteration 9, loss = 0.99632888\n",
      "Iteration 10, loss = 0.99553168\n",
      "Iteration 11, loss = 1.00159820\n",
      "Iteration 12, loss = 0.96328350\n",
      "Iteration 13, loss = 1.01715871\n",
      "Iteration 14, loss = 1.14732448\n",
      "Iteration 15, loss = 1.27091591\n",
      "Iteration 16, loss = 1.26914843\n",
      "Iteration 17, loss = 1.26602473\n",
      "Iteration 5, loss = 1.03519201\n",
      "Iteration 6, loss = 1.06549118\n",
      "Iteration 7, loss = 1.02669914\n",
      "Iteration 8, loss = 0.97193785\n",
      "Iteration 9, loss = 0.99632888\n",
      "Iteration 10, loss = 0.99553168\n",
      "Iteration 11, loss = 1.00159820\n",
      "Iteration 12, loss = 0.96328350\n",
      "Iteration 13, loss = 1.01715871\n",
      "Iteration 14, loss = 1.14732448\n",
      "Iteration 15, loss = 1.27091591\n",
      "Iteration 16, loss = 1.26914843\n",
      "Iteration 17, loss = 1.26602473\n",
      "Iteration 18, loss = 1.27889754\n",
      "Iteration 19, loss = 1.27465484\n",
      "Iteration 20, loss = 1.26424759\n",
      "Iteration 21, loss = 1.27714079\n",
      "Iteration 22, loss = 1.28041979\n",
      "Iteration 23, loss = 1.26266722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20872743\n",
      "Iteration 2, loss = 1.05501455\n",
      "Iteration 3, loss = 1.06544058\n",
      "Iteration 4, loss = 1.06888392\n",
      "Iteration 5, loss = 1.16901313\n",
      "Iteration 6, loss = 1.17895580\n",
      "Iteration 7, loss = 1.15471474\n",
      "Iteration 8, loss = 1.17220344\n",
      "Iteration 18, loss = 1.27889754\n",
      "Iteration 19, loss = 1.27465484\n",
      "Iteration 20, loss = 1.26424759\n",
      "Iteration 21, loss = 1.27714079\n",
      "Iteration 22, loss = 1.28041979\n",
      "Iteration 23, loss = 1.26266722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20872743\n",
      "Iteration 2, loss = 1.05501455\n",
      "Iteration 3, loss = 1.06544058\n",
      "Iteration 4, loss = 1.06888392\n",
      "Iteration 5, loss = 1.16901313\n",
      "Iteration 6, loss = 1.17895580\n",
      "Iteration 7, loss = 1.15471474\n",
      "Iteration 8, loss = 1.17220344\n",
      "Iteration 9, loss = 1.23282217\n",
      "Iteration 10, loss = 1.24934747\n",
      "Iteration 11, loss = 1.20805411\n",
      "Iteration 12, loss = 1.20377677\n",
      "Iteration 13, loss = 1.26370399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19844672\n",
      "Iteration 2, loss = 1.05064333\n",
      "Iteration 3, loss = 1.23065678\n",
      "Iteration 4, loss = 1.07726682\n",
      "Iteration 5, loss = 1.14269341\n",
      "Iteration 9, loss = 1.23282217\n",
      "Iteration 10, loss = 1.24934747\n",
      "Iteration 11, loss = 1.20805411\n",
      "Iteration 12, loss = 1.20377677\n",
      "Iteration 13, loss = 1.26370399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19844672\n",
      "Iteration 2, loss = 1.05064333\n",
      "Iteration 3, loss = 1.23065678\n",
      "Iteration 4, loss = 1.07726682\n",
      "Iteration 5, loss = 1.14269341\n",
      "Iteration 6, loss = 1.12334240\n",
      "Iteration 7, loss = 1.03781511\n",
      "Iteration 8, loss = 1.09711445\n",
      "Iteration 9, loss = 1.01327241\n",
      "Iteration 10, loss = 1.03915312\n",
      "Iteration 11, loss = 1.02562817\n",
      "Iteration 12, loss = 1.00896680\n",
      "Iteration 13, loss = 1.22631395\n",
      "Iteration 14, loss = 1.28473972\n",
      "Iteration 15, loss = 1.19566227\n",
      "Iteration 16, loss = 1.27431839\n",
      "Iteration 17, loss = 1.28244658\n",
      "Iteration 18, loss = 1.27476012\n",
      "Iteration 19, loss = 1.27389286\n",
      "Iteration 6, loss = 1.12334240\n",
      "Iteration 7, loss = 1.03781511\n",
      "Iteration 8, loss = 1.09711445\n",
      "Iteration 9, loss = 1.01327241\n",
      "Iteration 10, loss = 1.03915312\n",
      "Iteration 11, loss = 1.02562817\n",
      "Iteration 12, loss = 1.00896680\n",
      "Iteration 13, loss = 1.22631395\n",
      "Iteration 14, loss = 1.28473972\n",
      "Iteration 15, loss = 1.19566227\n",
      "Iteration 16, loss = 1.27431839\n",
      "Iteration 17, loss = 1.28244658\n",
      "Iteration 18, loss = 1.27476012\n",
      "Iteration 19, loss = 1.27389286\n",
      "Iteration 20, loss = 1.27604599\n",
      "Iteration 21, loss = 1.29013649\n",
      "Iteration 22, loss = 1.28904377\n",
      "Iteration 23, loss = 1.27899318\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26908846\n",
      "Iteration 2, loss = 1.06226763\n",
      "Iteration 3, loss = 1.08669706\n",
      "Iteration 4, loss = 1.05071041\n",
      "Iteration 5, loss = 1.01431131\n",
      "Iteration 6, loss = 1.03316623\n",
      "Iteration 7, loss = 1.02913180\n",
      "Iteration 8, loss = 1.01361880\n",
      "Iteration 9, loss = 1.00532576\n",
      "Iteration 20, loss = 1.27604599\n",
      "Iteration 21, loss = 1.29013649\n",
      "Iteration 22, loss = 1.28904377\n",
      "Iteration 23, loss = 1.27899318\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26908846\n",
      "Iteration 2, loss = 1.06226763\n",
      "Iteration 3, loss = 1.08669706\n",
      "Iteration 4, loss = 1.05071041\n",
      "Iteration 5, loss = 1.01431131\n",
      "Iteration 6, loss = 1.03316623\n",
      "Iteration 7, loss = 1.02913180\n",
      "Iteration 8, loss = 1.01361880\n",
      "Iteration 9, loss = 1.00532576\n",
      "Iteration 10, loss = 1.01019077\n",
      "Iteration 1, loss = 1.24244278\n",
      "Iteration 2, loss = 1.13809259\n",
      "Iteration 3, loss = 1.21495283\n",
      "Iteration 4, loss = 1.25287567\n",
      "Iteration 5, loss = 1.25736703\n",
      "Iteration 6, loss = 1.24589980\n",
      "Iteration 7, loss = 1.24768662\n",
      "Iteration 8, loss = 1.25906092\n",
      "Iteration 9, loss = 1.28855901\n",
      "Iteration 10, loss = 1.25356984\n",
      "Iteration 1, loss = 1.13486892\n",
      "Iteration 10, loss = 1.01019077\n",
      "Iteration 1, loss = 1.24244278\n",
      "Iteration 2, loss = 1.13809259\n",
      "Iteration 3, loss = 1.21495283\n",
      "Iteration 4, loss = 1.25287567\n",
      "Iteration 5, loss = 1.25736703\n",
      "Iteration 6, loss = 1.24589980\n",
      "Iteration 7, loss = 1.24768662\n",
      "Iteration 8, loss = 1.25906092\n",
      "Iteration 9, loss = 1.28855901\n",
      "Iteration 10, loss = 1.25356984\n",
      "Iteration 1, loss = 1.13486892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.07427711\n",
      "Iteration 3, loss = 1.02577034\n",
      "Iteration 4, loss = 1.04255439\n",
      "Iteration 5, loss = 1.27950796\n",
      "Iteration 6, loss = 1.27118754\n",
      "Iteration 7, loss = 1.26703429\n",
      "Iteration 8, loss = 1.29035294\n",
      "Iteration 9, loss = 1.29361732\n",
      "Iteration 10, loss = 1.26934704\n",
      "Iteration 1, loss = 1.16355945\n",
      "Iteration 2, loss = 1.14682225\n",
      "Iteration 3, loss = 1.26878052\n",
      "Iteration 4, loss = 1.28773580\n",
      "Iteration 2, loss = 1.07427711\n",
      "Iteration 3, loss = 1.02577034\n",
      "Iteration 4, loss = 1.04255439\n",
      "Iteration 5, loss = 1.27950796\n",
      "Iteration 6, loss = 1.27118754\n",
      "Iteration 7, loss = 1.26703429\n",
      "Iteration 8, loss = 1.29035294\n",
      "Iteration 9, loss = 1.29361732\n",
      "Iteration 10, loss = 1.26934704\n",
      "Iteration 1, loss = 1.16355945\n",
      "Iteration 2, loss = 1.14682225\n",
      "Iteration 3, loss = 1.26878052\n",
      "Iteration 4, loss = 1.28773580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.27964901\n",
      "Iteration 6, loss = 1.26540754\n",
      "Iteration 7, loss = 1.25329758\n",
      "Iteration 8, loss = 1.27689382\n",
      "Iteration 9, loss = 1.27361473\n",
      "Iteration 10, loss = 1.26799053\n",
      "Iteration 1, loss = 1.19200249\n",
      "Iteration 2, loss = 1.15247875\n",
      "Iteration 3, loss = 1.25457485\n",
      "Iteration 4, loss = 1.22698057\n",
      "Iteration 5, loss = 1.16126698\n",
      "Iteration 6, loss = 1.08564631\n",
      "Iteration 7, loss = 1.02150319\n",
      "Iteration 8, loss = 1.04504696\n",
      "Iteration 5, loss = 1.27964901\n",
      "Iteration 6, loss = 1.26540754\n",
      "Iteration 7, loss = 1.25329758\n",
      "Iteration 8, loss = 1.27689382\n",
      "Iteration 9, loss = 1.27361473\n",
      "Iteration 10, loss = 1.26799053\n",
      "Iteration 1, loss = 1.19200249\n",
      "Iteration 2, loss = 1.15247875\n",
      "Iteration 3, loss = 1.25457485\n",
      "Iteration 4, loss = 1.22698057\n",
      "Iteration 5, loss = 1.16126698\n",
      "Iteration 6, loss = 1.08564631\n",
      "Iteration 7, loss = 1.02150319\n",
      "Iteration 8, loss = 1.04504696\n",
      "Iteration 9, loss = 1.10393728\n",
      "Iteration 10, loss = 1.08383253\n",
      "Iteration 1, loss = 1.26908846\n",
      "Iteration 2, loss = 1.06226763\n",
      "Iteration 3, loss = 1.08669706\n",
      "Iteration 4, loss = 1.05071041\n",
      "Iteration 5, loss = 1.01431131\n",
      "Iteration 6, loss = 1.03316623\n",
      "Iteration 7, loss = 1.02913180\n",
      "Iteration 8, loss = 1.01361880\n",
      "Iteration 9, loss = 1.00532576\n",
      "Iteration 10, loss = 1.01019077\n",
      "Iteration 11, loss = 1.02189379\n",
      "Iteration 9, loss = 1.10393728\n",
      "Iteration 10, loss = 1.08383253\n",
      "Iteration 1, loss = 1.26908846\n",
      "Iteration 2, loss = 1.06226763\n",
      "Iteration 3, loss = 1.08669706\n",
      "Iteration 4, loss = 1.05071041\n",
      "Iteration 5, loss = 1.01431131\n",
      "Iteration 6, loss = 1.03316623\n",
      "Iteration 7, loss = 1.02913180\n",
      "Iteration 8, loss = 1.01361880\n",
      "Iteration 9, loss = 1.00532576\n",
      "Iteration 10, loss = 1.01019077\n",
      "Iteration 11, loss = 1.02189379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.99447059\n",
      "Iteration 13, loss = 1.02068033\n",
      "Iteration 14, loss = 0.98970100\n",
      "Iteration 15, loss = 0.98475396\n",
      "Iteration 16, loss = 0.98935831\n",
      "Iteration 17, loss = 0.99449208\n",
      "Iteration 18, loss = 0.99021821\n",
      "Iteration 19, loss = 0.99573029\n",
      "Iteration 20, loss = 1.00713891\n",
      "Iteration 21, loss = 0.99241897\n",
      "Iteration 22, loss = 0.97906256\n",
      "Iteration 23, loss = 1.04583400\n",
      "Iteration 24, loss = 1.02828230\n",
      "Iteration 25, loss = 1.12604159\n",
      "Iteration 26, loss = 1.27951740\n",
      "Iteration 27, loss = 1.25797395\n",
      "Iteration 12, loss = 0.99447059\n",
      "Iteration 13, loss = 1.02068033\n",
      "Iteration 14, loss = 0.98970100\n",
      "Iteration 15, loss = 0.98475396\n",
      "Iteration 16, loss = 0.98935831\n",
      "Iteration 17, loss = 0.99449208\n",
      "Iteration 18, loss = 0.99021821\n",
      "Iteration 19, loss = 0.99573029\n",
      "Iteration 20, loss = 1.00713891\n",
      "Iteration 21, loss = 0.99241897\n",
      "Iteration 22, loss = 0.97906256\n",
      "Iteration 23, loss = 1.04583400\n",
      "Iteration 24, loss = 1.02828230\n",
      "Iteration 25, loss = 1.12604159\n",
      "Iteration 26, loss = 1.27951740\n",
      "Iteration 27, loss = 1.25797395\n",
      "Iteration 28, loss = 1.26741854\n",
      "Iteration 29, loss = 1.26635596\n",
      "Iteration 30, loss = 1.25559069\n",
      "Iteration 31, loss = 1.26652461\n",
      "Iteration 32, loss = 1.28095939\n",
      "Iteration 33, loss = 1.25772326\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24244278\n",
      "Iteration 2, loss = 1.13809259\n",
      "Iteration 3, loss = 1.21495283\n",
      "Iteration 4, loss = 1.25287567\n",
      "Iteration 5, loss = 1.25736703\n",
      "Iteration 6, loss = 1.24589980\n",
      "Iteration 7, loss = 1.24768662\n",
      "Iteration 8, loss = 1.25906092\n",
      "Iteration 28, loss = 1.26741854\n",
      "Iteration 29, loss = 1.26635596\n",
      "Iteration 30, loss = 1.25559069\n",
      "Iteration 31, loss = 1.26652461\n",
      "Iteration 32, loss = 1.28095939\n",
      "Iteration 33, loss = 1.25772326\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24244278\n",
      "Iteration 2, loss = 1.13809259\n",
      "Iteration 3, loss = 1.21495283\n",
      "Iteration 4, loss = 1.25287567\n",
      "Iteration 5, loss = 1.25736703\n",
      "Iteration 6, loss = 1.24589980\n",
      "Iteration 7, loss = 1.24768662\n",
      "Iteration 8, loss = 1.25906092\n",
      "Iteration 9, loss = 1.28855901\n",
      "Iteration 10, loss = 1.25356984\n",
      "Iteration 11, loss = 1.24955142\n",
      "Iteration 12, loss = 1.25883265\n",
      "Iteration 13, loss = 1.25365553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13486892\n",
      "Iteration 2, loss = 1.07427711\n",
      "Iteration 3, loss = 1.02577034\n",
      "Iteration 4, loss = 1.04255439\n",
      "Iteration 5, loss = 1.27950796\n",
      "Iteration 6, loss = 1.27118754\n",
      "Iteration 7, loss = 1.26703429\n",
      "Iteration 8, loss = 1.29035294\n",
      "Iteration 9, loss = 1.29361732\n",
      "Iteration 9, loss = 1.28855901\n",
      "Iteration 10, loss = 1.25356984\n",
      "Iteration 11, loss = 1.24955142\n",
      "Iteration 12, loss = 1.25883265\n",
      "Iteration 13, loss = 1.25365553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13486892\n",
      "Iteration 2, loss = 1.07427711\n",
      "Iteration 3, loss = 1.02577034\n",
      "Iteration 4, loss = 1.04255439\n",
      "Iteration 5, loss = 1.27950796\n",
      "Iteration 6, loss = 1.27118754\n",
      "Iteration 7, loss = 1.26703429\n",
      "Iteration 8, loss = 1.29035294\n",
      "Iteration 9, loss = 1.29361732\n",
      "Iteration 10, loss = 1.26934704\n",
      "Iteration 11, loss = 1.26654339\n",
      "Iteration 12, loss = 1.26216731\n",
      "Iteration 13, loss = 1.27105540\n",
      "Iteration 14, loss = 1.25786333\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16355945\n",
      "Iteration 2, loss = 1.14682225\n",
      "Iteration 3, loss = 1.26878052\n",
      "Iteration 4, loss = 1.28773580\n",
      "Iteration 5, loss = 1.27964901\n",
      "Iteration 6, loss = 1.26540754\n",
      "Iteration 7, loss = 1.25329758\n",
      "Iteration 8, loss = 1.27689382\n",
      "Iteration 9, loss = 1.27361473\n",
      "Iteration 10, loss = 1.26934704\n",
      "Iteration 11, loss = 1.26654339\n",
      "Iteration 12, loss = 1.26216731\n",
      "Iteration 13, loss = 1.27105540\n",
      "Iteration 14, loss = 1.25786333\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16355945\n",
      "Iteration 2, loss = 1.14682225\n",
      "Iteration 3, loss = 1.26878052\n",
      "Iteration 4, loss = 1.28773580\n",
      "Iteration 5, loss = 1.27964901\n",
      "Iteration 6, loss = 1.26540754\n",
      "Iteration 7, loss = 1.25329758\n",
      "Iteration 8, loss = 1.27689382\n",
      "Iteration 9, loss = 1.27361473\n",
      "Iteration 10, loss = 1.26799053\n",
      "Iteration 11, loss = 1.24624887\n",
      "Iteration 12, loss = 1.26334111\n",
      "Iteration 13, loss = 1.26384946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19200249\n",
      "Iteration 2, loss = 1.15247875\n",
      "Iteration 3, loss = 1.25457485\n",
      "Iteration 4, loss = 1.22698057\n",
      "Iteration 5, loss = 1.16126698\n",
      "Iteration 6, loss = 1.08564631\n",
      "Iteration 7, loss = 1.02150319\n",
      "Iteration 8, loss = 1.04504696\n",
      "Iteration 10, loss = 1.26799053\n",
      "Iteration 11, loss = 1.24624887\n",
      "Iteration 12, loss = 1.26334111\n",
      "Iteration 13, loss = 1.26384946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19200249\n",
      "Iteration 2, loss = 1.15247875\n",
      "Iteration 3, loss = 1.25457485\n",
      "Iteration 4, loss = 1.22698057\n",
      "Iteration 5, loss = 1.16126698\n",
      "Iteration 6, loss = 1.08564631\n",
      "Iteration 7, loss = 1.02150319\n",
      "Iteration 8, loss = 1.04504696\n",
      "Iteration 9, loss = 1.10393728\n",
      "Iteration 10, loss = 1.08383253\n",
      "Iteration 11, loss = 1.02643304\n",
      "Iteration 12, loss = 1.02301101\n",
      "Iteration 13, loss = 1.06001987\n",
      "Iteration 14, loss = 1.05714323\n",
      "Iteration 15, loss = 1.05327460\n",
      "Iteration 16, loss = 1.05248137\n",
      "Iteration 17, loss = 1.05107244\n",
      "Iteration 18, loss = 1.04238825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26908846\n",
      "Iteration 2, loss = 1.06226763\n",
      "Iteration 3, loss = 1.08669706\n",
      "Iteration 4, loss = 1.05071041\n",
      "Iteration 9, loss = 1.10393728\n",
      "Iteration 10, loss = 1.08383253\n",
      "Iteration 11, loss = 1.02643304\n",
      "Iteration 12, loss = 1.02301101\n",
      "Iteration 13, loss = 1.06001987\n",
      "Iteration 14, loss = 1.05714323\n",
      "Iteration 15, loss = 1.05327460\n",
      "Iteration 16, loss = 1.05248137\n",
      "Iteration 17, loss = 1.05107244\n",
      "Iteration 18, loss = 1.04238825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26908846\n",
      "Iteration 2, loss = 1.06226763\n",
      "Iteration 3, loss = 1.08669706\n",
      "Iteration 4, loss = 1.05071041\n",
      "Iteration 5, loss = 1.01431131\n",
      "Iteration 6, loss = 1.03316623\n",
      "Iteration 7, loss = 1.02913180\n",
      "Iteration 8, loss = 1.01361880\n",
      "Iteration 9, loss = 1.00532576\n",
      "Iteration 10, loss = 1.01019077\n",
      "Iteration 11, loss = 1.02189379\n",
      "Iteration 12, loss = 0.99447059\n",
      "Iteration 13, loss = 1.02068033\n",
      "Iteration 14, loss = 0.98970100\n",
      "Iteration 15, loss = 0.98475396\n",
      "Iteration 16, loss = 0.98935831\n",
      "Iteration 17, loss = 0.99449208\n",
      "Iteration 18, loss = 0.99021821\n",
      "Iteration 19, loss = 0.99573029\n",
      "Iteration 5, loss = 1.01431131\n",
      "Iteration 6, loss = 1.03316623\n",
      "Iteration 7, loss = 1.02913180\n",
      "Iteration 8, loss = 1.01361880\n",
      "Iteration 9, loss = 1.00532576\n",
      "Iteration 10, loss = 1.01019077\n",
      "Iteration 11, loss = 1.02189379\n",
      "Iteration 12, loss = 0.99447059\n",
      "Iteration 13, loss = 1.02068033\n",
      "Iteration 14, loss = 0.98970100\n",
      "Iteration 15, loss = 0.98475396\n",
      "Iteration 16, loss = 0.98935831\n",
      "Iteration 17, loss = 0.99449208\n",
      "Iteration 18, loss = 0.99021821\n",
      "Iteration 19, loss = 0.99573029\n",
      "Iteration 20, loss = 1.00713891\n",
      "Iteration 21, loss = 0.99241897\n",
      "Iteration 22, loss = 0.97906256\n",
      "Iteration 23, loss = 1.04583400\n",
      "Iteration 24, loss = 1.02828230\n",
      "Iteration 25, loss = 1.12604159\n",
      "Iteration 26, loss = 1.27951740\n",
      "Iteration 27, loss = 1.25797395\n",
      "Iteration 28, loss = 1.26741854\n",
      "Iteration 29, loss = 1.26635596\n",
      "Iteration 30, loss = 1.25559069\n",
      "Iteration 31, loss = 1.26652461\n",
      "Iteration 32, loss = 1.28095939\n",
      "Iteration 33, loss = 1.25772326\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24244278\n",
      "Iteration 20, loss = 1.00713891\n",
      "Iteration 21, loss = 0.99241897\n",
      "Iteration 22, loss = 0.97906256\n",
      "Iteration 23, loss = 1.04583400\n",
      "Iteration 24, loss = 1.02828230\n",
      "Iteration 25, loss = 1.12604159\n",
      "Iteration 26, loss = 1.27951740\n",
      "Iteration 27, loss = 1.25797395\n",
      "Iteration 28, loss = 1.26741854\n",
      "Iteration 29, loss = 1.26635596\n",
      "Iteration 30, loss = 1.25559069\n",
      "Iteration 31, loss = 1.26652461\n",
      "Iteration 32, loss = 1.28095939\n",
      "Iteration 33, loss = 1.25772326\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24244278\n",
      "Iteration 2, loss = 1.13809259\n",
      "Iteration 3, loss = 1.21495283\n",
      "Iteration 4, loss = 1.25287567\n",
      "Iteration 5, loss = 1.25736703\n",
      "Iteration 6, loss = 1.24589980\n",
      "Iteration 7, loss = 1.24768662\n",
      "Iteration 8, loss = 1.25906092\n",
      "Iteration 9, loss = 1.28855901\n",
      "Iteration 10, loss = 1.25356984\n",
      "Iteration 11, loss = 1.24955142\n",
      "Iteration 12, loss = 1.25883265\n",
      "Iteration 13, loss = 1.25365553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13486892\n",
      "Iteration 2, loss = 1.07427711\n",
      "Iteration 2, loss = 1.13809259\n",
      "Iteration 3, loss = 1.21495283\n",
      "Iteration 4, loss = 1.25287567\n",
      "Iteration 5, loss = 1.25736703\n",
      "Iteration 6, loss = 1.24589980\n",
      "Iteration 7, loss = 1.24768662\n",
      "Iteration 8, loss = 1.25906092\n",
      "Iteration 9, loss = 1.28855901\n",
      "Iteration 10, loss = 1.25356984\n",
      "Iteration 11, loss = 1.24955142\n",
      "Iteration 12, loss = 1.25883265\n",
      "Iteration 13, loss = 1.25365553\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13486892\n",
      "Iteration 2, loss = 1.07427711\n",
      "Iteration 3, loss = 1.02577034\n",
      "Iteration 4, loss = 1.04255439\n",
      "Iteration 5, loss = 1.27950796\n",
      "Iteration 6, loss = 1.27118754\n",
      "Iteration 7, loss = 1.26703429\n",
      "Iteration 8, loss = 1.29035294\n",
      "Iteration 9, loss = 1.29361732\n",
      "Iteration 10, loss = 1.26934704\n",
      "Iteration 11, loss = 1.26654339\n",
      "Iteration 12, loss = 1.26216731\n",
      "Iteration 13, loss = 1.27105540\n",
      "Iteration 14, loss = 1.25786333\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16355945\n",
      "Iteration 2, loss = 1.14682225\n",
      "Iteration 3, loss = 1.02577034\n",
      "Iteration 4, loss = 1.04255439\n",
      "Iteration 5, loss = 1.27950796\n",
      "Iteration 6, loss = 1.27118754\n",
      "Iteration 7, loss = 1.26703429\n",
      "Iteration 8, loss = 1.29035294\n",
      "Iteration 9, loss = 1.29361732\n",
      "Iteration 10, loss = 1.26934704\n",
      "Iteration 11, loss = 1.26654339\n",
      "Iteration 12, loss = 1.26216731\n",
      "Iteration 13, loss = 1.27105540\n",
      "Iteration 14, loss = 1.25786333\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16355945\n",
      "Iteration 2, loss = 1.14682225\n",
      "Iteration 3, loss = 1.26878052\n",
      "Iteration 4, loss = 1.28773580\n",
      "Iteration 5, loss = 1.27964901\n",
      "Iteration 6, loss = 1.26540754\n",
      "Iteration 7, loss = 1.25329758\n",
      "Iteration 8, loss = 1.27689382\n",
      "Iteration 9, loss = 1.27361473\n",
      "Iteration 10, loss = 1.26799053\n",
      "Iteration 11, loss = 1.24624887\n",
      "Iteration 12, loss = 1.26334111\n",
      "Iteration 13, loss = 1.26384946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19200249\n",
      "Iteration 2, loss = 1.15247875\n",
      "Iteration 3, loss = 1.26878052\n",
      "Iteration 4, loss = 1.28773580\n",
      "Iteration 5, loss = 1.27964901\n",
      "Iteration 6, loss = 1.26540754\n",
      "Iteration 7, loss = 1.25329758\n",
      "Iteration 8, loss = 1.27689382\n",
      "Iteration 9, loss = 1.27361473\n",
      "Iteration 10, loss = 1.26799053\n",
      "Iteration 11, loss = 1.24624887\n",
      "Iteration 12, loss = 1.26334111\n",
      "Iteration 13, loss = 1.26384946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19200249\n",
      "Iteration 2, loss = 1.15247875\n",
      "Iteration 3, loss = 1.25457485\n",
      "Iteration 4, loss = 1.22698057\n",
      "Iteration 5, loss = 1.16126698\n",
      "Iteration 6, loss = 1.08564631\n",
      "Iteration 7, loss = 1.02150319\n",
      "Iteration 8, loss = 1.04504696\n",
      "Iteration 9, loss = 1.10393728\n",
      "Iteration 10, loss = 1.08383253\n",
      "Iteration 11, loss = 1.02643304\n",
      "Iteration 12, loss = 1.02301101\n",
      "Iteration 13, loss = 1.06001987\n",
      "Iteration 14, loss = 1.05714323\n",
      "Iteration 15, loss = 1.05327460\n",
      "Iteration 16, loss = 1.05248137\n",
      "Iteration 3, loss = 1.25457485\n",
      "Iteration 4, loss = 1.22698057\n",
      "Iteration 5, loss = 1.16126698\n",
      "Iteration 6, loss = 1.08564631\n",
      "Iteration 7, loss = 1.02150319\n",
      "Iteration 8, loss = 1.04504696\n",
      "Iteration 9, loss = 1.10393728\n",
      "Iteration 10, loss = 1.08383253\n",
      "Iteration 11, loss = 1.02643304\n",
      "Iteration 12, loss = 1.02301101\n",
      "Iteration 13, loss = 1.06001987\n",
      "Iteration 14, loss = 1.05714323\n",
      "Iteration 15, loss = 1.05327460\n",
      "Iteration 16, loss = 1.05248137\n",
      "Iteration 17, loss = 1.05107244\n",
      "Iteration 18, loss = 1.04238825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15674043\n",
      "Iteration 2, loss = 1.06564886\n",
      "Iteration 3, loss = 1.05113237\n",
      "Iteration 4, loss = 1.00101660\n",
      "Iteration 5, loss = 0.98688399\n",
      "Iteration 6, loss = 0.95053612\n",
      "Iteration 7, loss = 1.00659228\n",
      "Iteration 8, loss = 0.97218414\n",
      "Iteration 9, loss = 0.97235157\n",
      "Iteration 17, loss = 1.05107244\n",
      "Iteration 18, loss = 1.04238825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15674043\n",
      "Iteration 2, loss = 1.06564886\n",
      "Iteration 3, loss = 1.05113237\n",
      "Iteration 4, loss = 1.00101660\n",
      "Iteration 5, loss = 0.98688399\n",
      "Iteration 6, loss = 0.95053612\n",
      "Iteration 7, loss = 1.00659228\n",
      "Iteration 8, loss = 0.97218414\n",
      "Iteration 9, loss = 0.97235157\n",
      "Iteration 10, loss = 0.99135128\n",
      "Iteration 1, loss = 1.15522537\n",
      "Iteration 2, loss = 0.97768452\n",
      "Iteration 3, loss = 0.96887341\n",
      "Iteration 4, loss = 0.92446313\n",
      "Iteration 5, loss = 0.95164437\n",
      "Iteration 6, loss = 0.90912366\n",
      "Iteration 7, loss = 0.92014164\n",
      "Iteration 8, loss = 0.89178397\n",
      "Iteration 9, loss = 0.88828062\n",
      "Iteration 10, loss = 0.90865937\n",
      "Iteration 1, loss = 1.18684318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.99135128\n",
      "Iteration 1, loss = 1.15522537\n",
      "Iteration 2, loss = 0.97768452\n",
      "Iteration 3, loss = 0.96887341\n",
      "Iteration 4, loss = 0.92446313\n",
      "Iteration 5, loss = 0.95164437\n",
      "Iteration 6, loss = 0.90912366\n",
      "Iteration 7, loss = 0.92014164\n",
      "Iteration 8, loss = 0.89178397\n",
      "Iteration 9, loss = 0.88828062\n",
      "Iteration 10, loss = 0.90865937\n",
      "Iteration 1, loss = 1.18684318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.05930095\n",
      "Iteration 3, loss = 0.97852057\n",
      "Iteration 4, loss = 0.99010772\n",
      "Iteration 5, loss = 0.97469383\n",
      "Iteration 6, loss = 0.97166529\n",
      "Iteration 7, loss = 0.95899366\n",
      "Iteration 8, loss = 0.91528587\n",
      "Iteration 9, loss = 0.98804008\n",
      "Iteration 10, loss = 0.97669233\n",
      "Iteration 1, loss = 1.21529628\n",
      "Iteration 2, loss = 1.10797409\n",
      "Iteration 2, loss = 1.05930095\n",
      "Iteration 3, loss = 0.97852057\n",
      "Iteration 4, loss = 0.99010772\n",
      "Iteration 5, loss = 0.97469383\n",
      "Iteration 6, loss = 0.97166529\n",
      "Iteration 7, loss = 0.95899366\n",
      "Iteration 8, loss = 0.91528587\n",
      "Iteration 9, loss = 0.98804008\n",
      "Iteration 10, loss = 0.97669233\n",
      "Iteration 1, loss = 1.21529628\n",
      "Iteration 2, loss = 1.10797409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.02450797\n",
      "Iteration 4, loss = 1.00631016\n",
      "Iteration 5, loss = 1.01265221\n",
      "Iteration 6, loss = 1.02772779\n",
      "Iteration 7, loss = 0.99594649\n",
      "Iteration 8, loss = 0.95250648\n",
      "Iteration 9, loss = 0.96803693\n",
      "Iteration 10, loss = 0.96576450\n",
      "Iteration 1, loss = 1.18957910\n",
      "Iteration 2, loss = 1.05578009\n",
      "Iteration 3, loss = 0.98515103\n",
      "Iteration 4, loss = 1.00564528\n",
      "Iteration 3, loss = 1.02450797\n",
      "Iteration 4, loss = 1.00631016\n",
      "Iteration 5, loss = 1.01265221\n",
      "Iteration 6, loss = 1.02772779\n",
      "Iteration 7, loss = 0.99594649\n",
      "Iteration 8, loss = 0.95250648\n",
      "Iteration 9, loss = 0.96803693\n",
      "Iteration 10, loss = 0.96576450\n",
      "Iteration 1, loss = 1.18957910\n",
      "Iteration 2, loss = 1.05578009\n",
      "Iteration 3, loss = 0.98515103\n",
      "Iteration 4, loss = 1.00564528\n",
      "Iteration 5, loss = 0.98218623\n",
      "Iteration 6, loss = 0.96452149\n",
      "Iteration 7, loss = 0.96573193\n",
      "Iteration 8, loss = 0.93966577\n",
      "Iteration 9, loss = 0.94828770\n",
      "Iteration 10, loss = 0.92574059\n",
      "Iteration 1, loss = 1.15674043\n",
      "Iteration 2, loss = 1.06564886\n",
      "Iteration 3, loss = 1.05113237\n",
      "Iteration 4, loss = 1.00101660\n",
      "Iteration 5, loss = 0.98688399\n",
      "Iteration 6, loss = 0.95053612\n",
      "Iteration 7, loss = 1.00659228\n",
      "Iteration 5, loss = 0.98218623\n",
      "Iteration 6, loss = 0.96452149\n",
      "Iteration 7, loss = 0.96573193\n",
      "Iteration 8, loss = 0.93966577\n",
      "Iteration 9, loss = 0.94828770\n",
      "Iteration 10, loss = 0.92574059\n",
      "Iteration 1, loss = 1.15674043\n",
      "Iteration 2, loss = 1.06564886\n",
      "Iteration 3, loss = 1.05113237\n",
      "Iteration 4, loss = 1.00101660\n",
      "Iteration 5, loss = 0.98688399\n",
      "Iteration 6, loss = 0.95053612\n",
      "Iteration 7, loss = 1.00659228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.97218414\n",
      "Iteration 9, loss = 0.97235157\n",
      "Iteration 10, loss = 0.99135128\n",
      "Iteration 11, loss = 0.96908430\n",
      "Iteration 12, loss = 0.98980201\n",
      "Iteration 13, loss = 0.97331780\n",
      "Iteration 14, loss = 0.95560372\n",
      "Iteration 15, loss = 0.96691723\n",
      "Iteration 16, loss = 0.95521377\n",
      "Iteration 17, loss = 0.93805371\n",
      "Iteration 18, loss = 0.94083797\n",
      "Iteration 19, loss = 0.93458794\n",
      "Iteration 20, loss = 0.94176554\n",
      "Iteration 21, loss = 0.93471947\n",
      "Iteration 8, loss = 0.97218414\n",
      "Iteration 9, loss = 0.97235157\n",
      "Iteration 10, loss = 0.99135128\n",
      "Iteration 11, loss = 0.96908430\n",
      "Iteration 12, loss = 0.98980201\n",
      "Iteration 13, loss = 0.97331780\n",
      "Iteration 14, loss = 0.95560372\n",
      "Iteration 15, loss = 0.96691723\n",
      "Iteration 16, loss = 0.95521377\n",
      "Iteration 17, loss = 0.93805371\n",
      "Iteration 18, loss = 0.94083797\n",
      "Iteration 19, loss = 0.93458794\n",
      "Iteration 20, loss = 0.94176554\n",
      "Iteration 21, loss = 0.93471947\n",
      "Iteration 22, loss = 0.93265548\n",
      "Iteration 23, loss = 0.94360670\n",
      "Iteration 24, loss = 0.93370756\n",
      "Iteration 25, loss = 0.93598528\n",
      "Iteration 26, loss = 0.90922101\n",
      "Iteration 27, loss = 0.89528302\n",
      "Iteration 28, loss = 0.92904470\n",
      "Iteration 29, loss = 0.90564399\n",
      "Iteration 30, loss = 0.92342109\n",
      "Iteration 31, loss = 0.89189836\n",
      "Iteration 32, loss = 0.87783871\n",
      "Iteration 33, loss = 0.88343084\n",
      "Iteration 34, loss = 0.89669805\n",
      "Iteration 35, loss = 0.88010035\n",
      "Iteration 36, loss = 0.95186574\n",
      "Iteration 37, loss = 0.85463713\n",
      "Iteration 22, loss = 0.93265548\n",
      "Iteration 23, loss = 0.94360670\n",
      "Iteration 24, loss = 0.93370756\n",
      "Iteration 25, loss = 0.93598528\n",
      "Iteration 26, loss = 0.90922101\n",
      "Iteration 27, loss = 0.89528302\n",
      "Iteration 28, loss = 0.92904470\n",
      "Iteration 29, loss = 0.90564399\n",
      "Iteration 30, loss = 0.92342109\n",
      "Iteration 31, loss = 0.89189836\n",
      "Iteration 32, loss = 0.87783871\n",
      "Iteration 33, loss = 0.88343084\n",
      "Iteration 34, loss = 0.89669805\n",
      "Iteration 35, loss = 0.88010035\n",
      "Iteration 36, loss = 0.95186574\n",
      "Iteration 37, loss = 0.85463713\n",
      "Iteration 38, loss = 0.91922423\n",
      "Iteration 39, loss = 0.89828141\n",
      "Iteration 40, loss = 0.85708662\n",
      "Iteration 41, loss = 0.98567966\n",
      "Iteration 42, loss = 0.88023357\n",
      "Iteration 43, loss = 0.89503051\n",
      "Iteration 44, loss = 0.91525719\n",
      "Iteration 45, loss = 0.86533076\n",
      "Iteration 46, loss = 0.88422961\n",
      "Iteration 47, loss = 0.84062932\n",
      "Iteration 48, loss = 0.85103305\n",
      "Iteration 49, loss = 0.83168833\n",
      "Iteration 50, loss = 0.87080161\n",
      "Iteration 1, loss = 1.15522537\n",
      "Iteration 2, loss = 0.97768452\n",
      "Iteration 38, loss = 0.91922423\n",
      "Iteration 39, loss = 0.89828141\n",
      "Iteration 40, loss = 0.85708662\n",
      "Iteration 41, loss = 0.98567966\n",
      "Iteration 42, loss = 0.88023357\n",
      "Iteration 43, loss = 0.89503051\n",
      "Iteration 44, loss = 0.91525719\n",
      "Iteration 45, loss = 0.86533076\n",
      "Iteration 46, loss = 0.88422961\n",
      "Iteration 47, loss = 0.84062932\n",
      "Iteration 48, loss = 0.85103305\n",
      "Iteration 49, loss = 0.83168833\n",
      "Iteration 50, loss = 0.87080161\n",
      "Iteration 1, loss = 1.15522537\n",
      "Iteration 2, loss = 0.97768452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.96887341\n",
      "Iteration 4, loss = 0.92446313\n",
      "Iteration 5, loss = 0.95164437\n",
      "Iteration 6, loss = 0.90912366\n",
      "Iteration 7, loss = 0.92014164\n",
      "Iteration 8, loss = 0.89178397\n",
      "Iteration 9, loss = 0.88828062\n",
      "Iteration 10, loss = 0.90865937\n",
      "Iteration 11, loss = 0.88522271\n",
      "Iteration 12, loss = 0.90327966\n",
      "Iteration 13, loss = 0.87233049\n",
      "Iteration 14, loss = 0.86154098\n",
      "Iteration 15, loss = 0.89871997\n",
      "Iteration 16, loss = 0.85472544\n",
      "Iteration 17, loss = 0.85250249\n",
      "Iteration 18, loss = 0.86420392\n",
      "Iteration 3, loss = 0.96887341\n",
      "Iteration 4, loss = 0.92446313\n",
      "Iteration 5, loss = 0.95164437\n",
      "Iteration 6, loss = 0.90912366\n",
      "Iteration 7, loss = 0.92014164\n",
      "Iteration 8, loss = 0.89178397\n",
      "Iteration 9, loss = 0.88828062\n",
      "Iteration 10, loss = 0.90865937\n",
      "Iteration 11, loss = 0.88522271\n",
      "Iteration 12, loss = 0.90327966\n",
      "Iteration 13, loss = 0.87233049\n",
      "Iteration 14, loss = 0.86154098\n",
      "Iteration 15, loss = 0.89871997\n",
      "Iteration 16, loss = 0.85472544\n",
      "Iteration 17, loss = 0.85250249\n",
      "Iteration 18, loss = 0.86420392\n",
      "Iteration 19, loss = 0.83177592\n",
      "Iteration 20, loss = 0.84324878\n",
      "Iteration 21, loss = 0.83498541\n",
      "Iteration 22, loss = 0.86865822\n",
      "Iteration 23, loss = 0.88352310\n",
      "Iteration 24, loss = 0.85387551\n",
      "Iteration 25, loss = 0.82701421\n",
      "Iteration 26, loss = 0.84802983\n",
      "Iteration 27, loss = 0.84090447\n",
      "Iteration 28, loss = 0.87644538\n",
      "Iteration 29, loss = 0.83731625\n",
      "Iteration 30, loss = 0.80399441\n",
      "Iteration 31, loss = 0.79693030\n",
      "Iteration 32, loss = 0.82935762\n",
      "Iteration 33, loss = 0.83314698\n",
      "Iteration 34, loss = 0.79896656\n",
      "Iteration 19, loss = 0.83177592\n",
      "Iteration 20, loss = 0.84324878\n",
      "Iteration 21, loss = 0.83498541\n",
      "Iteration 22, loss = 0.86865822\n",
      "Iteration 23, loss = 0.88352310\n",
      "Iteration 24, loss = 0.85387551\n",
      "Iteration 25, loss = 0.82701421\n",
      "Iteration 26, loss = 0.84802983\n",
      "Iteration 27, loss = 0.84090447\n",
      "Iteration 28, loss = 0.87644538\n",
      "Iteration 29, loss = 0.83731625\n",
      "Iteration 30, loss = 0.80399441\n",
      "Iteration 31, loss = 0.79693030\n",
      "Iteration 32, loss = 0.82935762\n",
      "Iteration 33, loss = 0.83314698\n",
      "Iteration 34, loss = 0.79896656\n",
      "Iteration 35, loss = 0.82174558\n",
      "Iteration 36, loss = 0.82276607\n",
      "Iteration 37, loss = 0.80157767\n",
      "Iteration 38, loss = 0.83789722\n",
      "Iteration 39, loss = 0.81461471\n",
      "Iteration 40, loss = 0.80492339\n",
      "Iteration 41, loss = 0.83932084\n",
      "Iteration 42, loss = 0.77676192\n",
      "Iteration 43, loss = 0.78070036\n",
      "Iteration 44, loss = 0.79432432\n",
      "Iteration 45, loss = 0.79216412\n",
      "Iteration 46, loss = 0.80106958\n",
      "Iteration 47, loss = 0.78907350\n",
      "Iteration 48, loss = 0.73437364\n",
      "Iteration 49, loss = 0.75555909\n",
      "Iteration 50, loss = 0.78873678\n",
      "Iteration 35, loss = 0.82174558\n",
      "Iteration 36, loss = 0.82276607\n",
      "Iteration 37, loss = 0.80157767\n",
      "Iteration 38, loss = 0.83789722\n",
      "Iteration 39, loss = 0.81461471\n",
      "Iteration 40, loss = 0.80492339\n",
      "Iteration 41, loss = 0.83932084\n",
      "Iteration 42, loss = 0.77676192\n",
      "Iteration 43, loss = 0.78070036\n",
      "Iteration 44, loss = 0.79432432\n",
      "Iteration 45, loss = 0.79216412\n",
      "Iteration 46, loss = 0.80106958\n",
      "Iteration 47, loss = 0.78907350\n",
      "Iteration 48, loss = 0.73437364\n",
      "Iteration 49, loss = 0.75555909\n",
      "Iteration 50, loss = 0.78873678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.18684318\n",
      "Iteration 2, loss = 1.05930095\n",
      "Iteration 3, loss = 0.97852057\n",
      "Iteration 4, loss = 0.99010772\n",
      "Iteration 5, loss = 0.97469383\n",
      "Iteration 6, loss = 0.97166529\n",
      "Iteration 7, loss = 0.95899366\n",
      "Iteration 8, loss = 0.91528587\n",
      "Iteration 9, loss = 0.98804008\n",
      "Iteration 10, loss = 0.97669233\n",
      "Iteration 11, loss = 0.95546018\n",
      "Iteration 12, loss = 0.94075327\n",
      "Iteration 13, loss = 0.91698391\n",
      "Iteration 14, loss = 0.91166400\n",
      "Iteration 1, loss = 1.18684318\n",
      "Iteration 2, loss = 1.05930095\n",
      "Iteration 3, loss = 0.97852057\n",
      "Iteration 4, loss = 0.99010772\n",
      "Iteration 5, loss = 0.97469383\n",
      "Iteration 6, loss = 0.97166529\n",
      "Iteration 7, loss = 0.95899366\n",
      "Iteration 8, loss = 0.91528587\n",
      "Iteration 9, loss = 0.98804008\n",
      "Iteration 10, loss = 0.97669233\n",
      "Iteration 11, loss = 0.95546018\n",
      "Iteration 12, loss = 0.94075327\n",
      "Iteration 13, loss = 0.91698391\n",
      "Iteration 14, loss = 0.91166400\n",
      "Iteration 15, loss = 0.93124058\n",
      "Iteration 16, loss = 0.90210572\n",
      "Iteration 17, loss = 0.92158351\n",
      "Iteration 18, loss = 0.90024876\n",
      "Iteration 19, loss = 0.88233986\n",
      "Iteration 20, loss = 0.91689374\n",
      "Iteration 21, loss = 0.90676846\n",
      "Iteration 22, loss = 0.89320407\n",
      "Iteration 23, loss = 0.91768427\n",
      "Iteration 24, loss = 0.90544371\n",
      "Iteration 25, loss = 0.87435567\n",
      "Iteration 26, loss = 0.88203200\n",
      "Iteration 27, loss = 0.89588044\n",
      "Iteration 28, loss = 0.89555549\n",
      "Iteration 29, loss = 0.87784577\n",
      "Iteration 15, loss = 0.93124058\n",
      "Iteration 16, loss = 0.90210572\n",
      "Iteration 17, loss = 0.92158351\n",
      "Iteration 18, loss = 0.90024876\n",
      "Iteration 19, loss = 0.88233986\n",
      "Iteration 20, loss = 0.91689374\n",
      "Iteration 21, loss = 0.90676846\n",
      "Iteration 22, loss = 0.89320407\n",
      "Iteration 23, loss = 0.91768427\n",
      "Iteration 24, loss = 0.90544371\n",
      "Iteration 25, loss = 0.87435567\n",
      "Iteration 26, loss = 0.88203200\n",
      "Iteration 27, loss = 0.89588044\n",
      "Iteration 28, loss = 0.89555549\n",
      "Iteration 29, loss = 0.87784577\n",
      "Iteration 30, loss = 0.87907872\n",
      "Iteration 31, loss = 0.85103551\n",
      "Iteration 32, loss = 0.87132701\n",
      "Iteration 33, loss = 0.87673284\n",
      "Iteration 34, loss = 0.86304643\n",
      "Iteration 35, loss = 0.86545176\n",
      "Iteration 36, loss = 0.86675709\n",
      "Iteration 37, loss = 0.84744904\n",
      "Iteration 38, loss = 0.87750351\n",
      "Iteration 39, loss = 0.82366174\n",
      "Iteration 40, loss = 0.84650390\n",
      "Iteration 41, loss = 0.85691277\n",
      "Iteration 42, loss = 0.83106196\n",
      "Iteration 43, loss = 0.82082529\n",
      "Iteration 44, loss = 0.82835521\n",
      "Iteration 45, loss = 0.82327706\n",
      "Iteration 30, loss = 0.87907872\n",
      "Iteration 31, loss = 0.85103551\n",
      "Iteration 32, loss = 0.87132701\n",
      "Iteration 33, loss = 0.87673284\n",
      "Iteration 34, loss = 0.86304643\n",
      "Iteration 35, loss = 0.86545176\n",
      "Iteration 36, loss = 0.86675709\n",
      "Iteration 37, loss = 0.84744904\n",
      "Iteration 38, loss = 0.87750351\n",
      "Iteration 39, loss = 0.82366174\n",
      "Iteration 40, loss = 0.84650390\n",
      "Iteration 41, loss = 0.85691277\n",
      "Iteration 42, loss = 0.83106196\n",
      "Iteration 43, loss = 0.82082529\n",
      "Iteration 44, loss = 0.82835521\n",
      "Iteration 45, loss = 0.82327706\n",
      "Iteration 46, loss = 0.81859190\n",
      "Iteration 47, loss = 0.82337414\n",
      "Iteration 48, loss = 0.80055774\n",
      "Iteration 49, loss = 0.84450971\n",
      "Iteration 50, loss = 0.82253153\n",
      "Iteration 1, loss = 1.21529628\n",
      "Iteration 2, loss = 1.10797409\n",
      "Iteration 3, loss = 1.02450797\n",
      "Iteration 4, loss = 1.00631016\n",
      "Iteration 5, loss = 1.01265221\n",
      "Iteration 6, loss = 1.02772779\n",
      "Iteration 7, loss = 0.99594649\n",
      "Iteration 8, loss = 0.95250648\n",
      "Iteration 9, loss = 0.96803693\n",
      "Iteration 46, loss = 0.81859190\n",
      "Iteration 47, loss = 0.82337414\n",
      "Iteration 48, loss = 0.80055774\n",
      "Iteration 49, loss = 0.84450971\n",
      "Iteration 50, loss = 0.82253153\n",
      "Iteration 1, loss = 1.21529628\n",
      "Iteration 2, loss = 1.10797409\n",
      "Iteration 3, loss = 1.02450797\n",
      "Iteration 4, loss = 1.00631016\n",
      "Iteration 5, loss = 1.01265221\n",
      "Iteration 6, loss = 1.02772779\n",
      "Iteration 7, loss = 0.99594649\n",
      "Iteration 8, loss = 0.95250648\n",
      "Iteration 9, loss = 0.96803693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.96576450\n",
      "Iteration 11, loss = 0.98729907\n",
      "Iteration 12, loss = 0.92792048\n",
      "Iteration 13, loss = 0.92102296\n",
      "Iteration 14, loss = 0.94664518\n",
      "Iteration 15, loss = 0.90063668\n",
      "Iteration 16, loss = 0.92348613\n",
      "Iteration 17, loss = 0.89590453\n",
      "Iteration 18, loss = 0.88780230\n",
      "Iteration 19, loss = 0.87289356\n",
      "Iteration 20, loss = 0.91163804\n",
      "Iteration 21, loss = 0.88897460\n",
      "Iteration 22, loss = 0.87866899\n",
      "Iteration 23, loss = 0.88346825\n",
      "Iteration 24, loss = 0.88049795\n",
      "Iteration 10, loss = 0.96576450\n",
      "Iteration 11, loss = 0.98729907\n",
      "Iteration 12, loss = 0.92792048\n",
      "Iteration 13, loss = 0.92102296\n",
      "Iteration 14, loss = 0.94664518\n",
      "Iteration 15, loss = 0.90063668\n",
      "Iteration 16, loss = 0.92348613\n",
      "Iteration 17, loss = 0.89590453\n",
      "Iteration 18, loss = 0.88780230\n",
      "Iteration 19, loss = 0.87289356\n",
      "Iteration 20, loss = 0.91163804\n",
      "Iteration 21, loss = 0.88897460\n",
      "Iteration 22, loss = 0.87866899\n",
      "Iteration 23, loss = 0.88346825\n",
      "Iteration 24, loss = 0.88049795\n",
      "Iteration 25, loss = 0.90656749\n",
      "Iteration 26, loss = 0.87397667\n",
      "Iteration 27, loss = 0.90334067\n",
      "Iteration 28, loss = 0.90016492\n",
      "Iteration 29, loss = 0.85231967\n",
      "Iteration 30, loss = 0.89827311\n",
      "Iteration 31, loss = 0.87423172\n",
      "Iteration 32, loss = 0.88017143\n",
      "Iteration 33, loss = 0.89608744\n",
      "Iteration 34, loss = 0.85824070\n",
      "Iteration 35, loss = 0.84072747\n",
      "Iteration 36, loss = 0.84427368\n",
      "Iteration 37, loss = 0.83300690\n",
      "Iteration 38, loss = 0.84224706\n",
      "Iteration 39, loss = 0.82577274\n",
      "Iteration 25, loss = 0.90656749\n",
      "Iteration 26, loss = 0.87397667\n",
      "Iteration 27, loss = 0.90334067\n",
      "Iteration 28, loss = 0.90016492\n",
      "Iteration 29, loss = 0.85231967\n",
      "Iteration 30, loss = 0.89827311\n",
      "Iteration 31, loss = 0.87423172\n",
      "Iteration 32, loss = 0.88017143\n",
      "Iteration 33, loss = 0.89608744\n",
      "Iteration 34, loss = 0.85824070\n",
      "Iteration 35, loss = 0.84072747\n",
      "Iteration 36, loss = 0.84427368\n",
      "Iteration 37, loss = 0.83300690\n",
      "Iteration 38, loss = 0.84224706\n",
      "Iteration 39, loss = 0.82577274\n",
      "Iteration 40, loss = 0.85997117\n",
      "Iteration 41, loss = 0.83363390\n",
      "Iteration 42, loss = 0.87842848\n",
      "Iteration 43, loss = 0.85022104\n",
      "Iteration 44, loss = 0.80667706\n",
      "Iteration 45, loss = 0.79946288\n",
      "Iteration 46, loss = 0.80329810\n",
      "Iteration 47, loss = 0.80571042\n",
      "Iteration 48, loss = 0.81833208\n",
      "Iteration 49, loss = 0.80187978\n",
      "Iteration 50, loss = 0.79067416\n",
      "Iteration 1, loss = 1.18957910\n",
      "Iteration 2, loss = 1.05578009\n",
      "Iteration 40, loss = 0.85997117\n",
      "Iteration 41, loss = 0.83363390\n",
      "Iteration 42, loss = 0.87842848\n",
      "Iteration 43, loss = 0.85022104\n",
      "Iteration 44, loss = 0.80667706\n",
      "Iteration 45, loss = 0.79946288\n",
      "Iteration 46, loss = 0.80329810\n",
      "Iteration 47, loss = 0.80571042\n",
      "Iteration 48, loss = 0.81833208\n",
      "Iteration 49, loss = 0.80187978\n",
      "Iteration 50, loss = 0.79067416\n",
      "Iteration 1, loss = 1.18957910\n",
      "Iteration 2, loss = 1.05578009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.98515103\n",
      "Iteration 4, loss = 1.00564528\n",
      "Iteration 5, loss = 0.98218623\n",
      "Iteration 6, loss = 0.96452149\n",
      "Iteration 7, loss = 0.96573193\n",
      "Iteration 8, loss = 0.93966577\n",
      "Iteration 9, loss = 0.94828770\n",
      "Iteration 10, loss = 0.92574059\n",
      "Iteration 11, loss = 0.93485378\n",
      "Iteration 12, loss = 0.93765898\n",
      "Iteration 13, loss = 0.94384037\n",
      "Iteration 14, loss = 0.94797275\n",
      "Iteration 15, loss = 0.95040696\n",
      "Iteration 16, loss = 0.96953007\n",
      "Iteration 17, loss = 0.92759634\n",
      "Iteration 18, loss = 0.90811920\n",
      "Iteration 3, loss = 0.98515103\n",
      "Iteration 4, loss = 1.00564528\n",
      "Iteration 5, loss = 0.98218623\n",
      "Iteration 6, loss = 0.96452149\n",
      "Iteration 7, loss = 0.96573193\n",
      "Iteration 8, loss = 0.93966577\n",
      "Iteration 9, loss = 0.94828770\n",
      "Iteration 10, loss = 0.92574059\n",
      "Iteration 11, loss = 0.93485378\n",
      "Iteration 12, loss = 0.93765898\n",
      "Iteration 13, loss = 0.94384037\n",
      "Iteration 14, loss = 0.94797275\n",
      "Iteration 15, loss = 0.95040696\n",
      "Iteration 16, loss = 0.96953007\n",
      "Iteration 17, loss = 0.92759634\n",
      "Iteration 18, loss = 0.90811920\n",
      "Iteration 19, loss = 0.91931451\n",
      "Iteration 20, loss = 0.95061006\n",
      "Iteration 21, loss = 0.92873826\n",
      "Iteration 22, loss = 0.91839702\n",
      "Iteration 23, loss = 0.90049882\n",
      "Iteration 24, loss = 0.90006205\n",
      "Iteration 25, loss = 0.88601049\n",
      "Iteration 26, loss = 0.87245957\n",
      "Iteration 27, loss = 0.87688280\n",
      "Iteration 28, loss = 0.88830702\n",
      "Iteration 29, loss = 0.87027021\n",
      "Iteration 30, loss = 0.85744907\n",
      "Iteration 31, loss = 0.88051617\n",
      "Iteration 32, loss = 0.86260768\n",
      "Iteration 33, loss = 0.87689944\n",
      "Iteration 19, loss = 0.91931451\n",
      "Iteration 20, loss = 0.95061006\n",
      "Iteration 21, loss = 0.92873826\n",
      "Iteration 22, loss = 0.91839702\n",
      "Iteration 23, loss = 0.90049882\n",
      "Iteration 24, loss = 0.90006205\n",
      "Iteration 25, loss = 0.88601049\n",
      "Iteration 26, loss = 0.87245957\n",
      "Iteration 27, loss = 0.87688280\n",
      "Iteration 28, loss = 0.88830702\n",
      "Iteration 29, loss = 0.87027021\n",
      "Iteration 30, loss = 0.85744907\n",
      "Iteration 31, loss = 0.88051617\n",
      "Iteration 32, loss = 0.86260768\n",
      "Iteration 33, loss = 0.87689944\n",
      "Iteration 34, loss = 0.84314096\n",
      "Iteration 35, loss = 0.85028195\n",
      "Iteration 36, loss = 0.85698971\n",
      "Iteration 37, loss = 0.85449543\n",
      "Iteration 38, loss = 0.86171381\n",
      "Iteration 39, loss = 0.85032747\n",
      "Iteration 40, loss = 0.85458435\n",
      "Iteration 41, loss = 0.82695814\n",
      "Iteration 42, loss = 0.85181128\n",
      "Iteration 43, loss = 0.84683936\n",
      "Iteration 44, loss = 0.83626371\n",
      "Iteration 45, loss = 0.84922348\n",
      "Iteration 46, loss = 0.86819893\n",
      "Iteration 47, loss = 0.84421344\n",
      "Iteration 48, loss = 0.83731447\n",
      "Iteration 34, loss = 0.84314096\n",
      "Iteration 35, loss = 0.85028195\n",
      "Iteration 36, loss = 0.85698971\n",
      "Iteration 37, loss = 0.85449543\n",
      "Iteration 38, loss = 0.86171381\n",
      "Iteration 39, loss = 0.85032747\n",
      "Iteration 40, loss = 0.85458435\n",
      "Iteration 41, loss = 0.82695814\n",
      "Iteration 42, loss = 0.85181128\n",
      "Iteration 43, loss = 0.84683936\n",
      "Iteration 44, loss = 0.83626371\n",
      "Iteration 45, loss = 0.84922348\n",
      "Iteration 46, loss = 0.86819893\n",
      "Iteration 47, loss = 0.84421344\n",
      "Iteration 48, loss = 0.83731447\n",
      "Iteration 49, loss = 0.86086409\n",
      "Iteration 50, loss = 0.82212634\n",
      "Iteration 1, loss = 1.15674043\n",
      "Iteration 2, loss = 1.06564886\n",
      "Iteration 3, loss = 1.05113237\n",
      "Iteration 4, loss = 1.00101660\n",
      "Iteration 5, loss = 0.98688399\n",
      "Iteration 6, loss = 0.95053612\n",
      "Iteration 7, loss = 1.00659228\n",
      "Iteration 8, loss = 0.97218414\n",
      "Iteration 9, loss = 0.97235157\n",
      "Iteration 10, loss = 0.99135128\n",
      "Iteration 11, loss = 0.96908430\n",
      "Iteration 49, loss = 0.86086409\n",
      "Iteration 50, loss = 0.82212634\n",
      "Iteration 1, loss = 1.15674043\n",
      "Iteration 2, loss = 1.06564886\n",
      "Iteration 3, loss = 1.05113237\n",
      "Iteration 4, loss = 1.00101660\n",
      "Iteration 5, loss = 0.98688399\n",
      "Iteration 6, loss = 0.95053612\n",
      "Iteration 7, loss = 1.00659228\n",
      "Iteration 8, loss = 0.97218414\n",
      "Iteration 9, loss = 0.97235157\n",
      "Iteration 10, loss = 0.99135128\n",
      "Iteration 11, loss = 0.96908430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.98980201\n",
      "Iteration 13, loss = 0.97331780\n",
      "Iteration 14, loss = 0.95560372\n",
      "Iteration 15, loss = 0.96691723\n",
      "Iteration 16, loss = 0.95521377\n",
      "Iteration 17, loss = 0.93805371\n",
      "Iteration 18, loss = 0.94083797\n",
      "Iteration 19, loss = 0.93458794\n",
      "Iteration 20, loss = 0.94176554\n",
      "Iteration 21, loss = 0.93471947\n",
      "Iteration 22, loss = 0.93265548\n",
      "Iteration 23, loss = 0.94360670\n",
      "Iteration 24, loss = 0.93370756\n",
      "Iteration 25, loss = 0.93598528\n",
      "Iteration 26, loss = 0.90922101\n",
      "Iteration 27, loss = 0.89528302\n",
      "Iteration 12, loss = 0.98980201\n",
      "Iteration 13, loss = 0.97331780\n",
      "Iteration 14, loss = 0.95560372\n",
      "Iteration 15, loss = 0.96691723\n",
      "Iteration 16, loss = 0.95521377\n",
      "Iteration 17, loss = 0.93805371\n",
      "Iteration 18, loss = 0.94083797\n",
      "Iteration 19, loss = 0.93458794\n",
      "Iteration 20, loss = 0.94176554\n",
      "Iteration 21, loss = 0.93471947\n",
      "Iteration 22, loss = 0.93265548\n",
      "Iteration 23, loss = 0.94360670\n",
      "Iteration 24, loss = 0.93370756\n",
      "Iteration 25, loss = 0.93598528\n",
      "Iteration 26, loss = 0.90922101\n",
      "Iteration 27, loss = 0.89528302\n",
      "Iteration 28, loss = 0.92904470\n",
      "Iteration 29, loss = 0.90564399\n",
      "Iteration 30, loss = 0.92342109\n",
      "Iteration 31, loss = 0.89189836\n",
      "Iteration 32, loss = 0.87783871\n",
      "Iteration 33, loss = 0.88343084\n",
      "Iteration 34, loss = 0.89669805\n",
      "Iteration 35, loss = 0.88010035\n",
      "Iteration 36, loss = 0.95186574\n",
      "Iteration 37, loss = 0.85463713\n",
      "Iteration 38, loss = 0.91922423\n",
      "Iteration 39, loss = 0.89828141\n",
      "Iteration 40, loss = 0.85708662\n",
      "Iteration 41, loss = 0.98567966\n",
      "Iteration 42, loss = 0.88023357\n",
      "Iteration 43, loss = 0.89503051\n",
      "Iteration 28, loss = 0.92904470\n",
      "Iteration 29, loss = 0.90564399\n",
      "Iteration 30, loss = 0.92342109\n",
      "Iteration 31, loss = 0.89189836\n",
      "Iteration 32, loss = 0.87783871\n",
      "Iteration 33, loss = 0.88343084\n",
      "Iteration 34, loss = 0.89669805\n",
      "Iteration 35, loss = 0.88010035\n",
      "Iteration 36, loss = 0.95186574\n",
      "Iteration 37, loss = 0.85463713\n",
      "Iteration 38, loss = 0.91922423\n",
      "Iteration 39, loss = 0.89828141\n",
      "Iteration 40, loss = 0.85708662\n",
      "Iteration 41, loss = 0.98567966\n",
      "Iteration 42, loss = 0.88023357\n",
      "Iteration 43, loss = 0.89503051\n",
      "Iteration 44, loss = 0.91525719\n",
      "Iteration 45, loss = 0.86533076\n",
      "Iteration 46, loss = 0.88422961\n",
      "Iteration 47, loss = 0.84062932\n",
      "Iteration 48, loss = 0.85103305\n",
      "Iteration 49, loss = 0.83168833\n",
      "Iteration 50, loss = 0.87080161\n",
      "Iteration 51, loss = 0.90120441\n",
      "Iteration 52, loss = 0.91947373\n",
      "Iteration 53, loss = 0.89065205\n",
      "Iteration 54, loss = 0.90525401\n",
      "Iteration 55, loss = 0.90518903\n",
      "Iteration 56, loss = 0.85715748\n",
      "Iteration 57, loss = 0.83616463\n",
      "Iteration 58, loss = 0.85761888\n",
      "Iteration 44, loss = 0.91525719\n",
      "Iteration 45, loss = 0.86533076\n",
      "Iteration 46, loss = 0.88422961\n",
      "Iteration 47, loss = 0.84062932\n",
      "Iteration 48, loss = 0.85103305\n",
      "Iteration 49, loss = 0.83168833\n",
      "Iteration 50, loss = 0.87080161\n",
      "Iteration 51, loss = 0.90120441\n",
      "Iteration 52, loss = 0.91947373\n",
      "Iteration 53, loss = 0.89065205\n",
      "Iteration 54, loss = 0.90525401\n",
      "Iteration 55, loss = 0.90518903\n",
      "Iteration 56, loss = 0.85715748\n",
      "Iteration 57, loss = 0.83616463\n",
      "Iteration 58, loss = 0.85761888\n",
      "Iteration 59, loss = 0.84095470\n",
      "Iteration 60, loss = 0.84162599\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15522537\n",
      "Iteration 2, loss = 0.97768452\n",
      "Iteration 3, loss = 0.96887341\n",
      "Iteration 4, loss = 0.92446313\n",
      "Iteration 5, loss = 0.95164437\n",
      "Iteration 6, loss = 0.90912366\n",
      "Iteration 7, loss = 0.92014164\n",
      "Iteration 8, loss = 0.89178397\n",
      "Iteration 9, loss = 0.88828062\n",
      "Iteration 59, loss = 0.84095470\n",
      "Iteration 60, loss = 0.84162599\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15522537\n",
      "Iteration 2, loss = 0.97768452\n",
      "Iteration 3, loss = 0.96887341\n",
      "Iteration 4, loss = 0.92446313\n",
      "Iteration 5, loss = 0.95164437\n",
      "Iteration 6, loss = 0.90912366\n",
      "Iteration 7, loss = 0.92014164\n",
      "Iteration 8, loss = 0.89178397\n",
      "Iteration 9, loss = 0.88828062\n",
      "Iteration 10, loss = 0.90865937\n",
      "Iteration 11, loss = 0.88522271\n",
      "Iteration 12, loss = 0.90327966\n",
      "Iteration 13, loss = 0.87233049\n",
      "Iteration 14, loss = 0.86154098\n",
      "Iteration 15, loss = 0.89871997\n",
      "Iteration 16, loss = 0.85472544\n",
      "Iteration 17, loss = 0.85250249\n",
      "Iteration 18, loss = 0.86420392\n",
      "Iteration 19, loss = 0.83177592\n",
      "Iteration 20, loss = 0.84324878\n",
      "Iteration 21, loss = 0.83498541\n",
      "Iteration 22, loss = 0.86865822\n",
      "Iteration 23, loss = 0.88352310\n",
      "Iteration 24, loss = 0.85387551\n",
      "Iteration 10, loss = 0.90865937\n",
      "Iteration 11, loss = 0.88522271\n",
      "Iteration 12, loss = 0.90327966\n",
      "Iteration 13, loss = 0.87233049\n",
      "Iteration 14, loss = 0.86154098\n",
      "Iteration 15, loss = 0.89871997\n",
      "Iteration 16, loss = 0.85472544\n",
      "Iteration 17, loss = 0.85250249\n",
      "Iteration 18, loss = 0.86420392\n",
      "Iteration 19, loss = 0.83177592\n",
      "Iteration 20, loss = 0.84324878\n",
      "Iteration 21, loss = 0.83498541\n",
      "Iteration 22, loss = 0.86865822\n",
      "Iteration 23, loss = 0.88352310\n",
      "Iteration 24, loss = 0.85387551\n",
      "Iteration 25, loss = 0.82701421\n",
      "Iteration 26, loss = 0.84802983\n",
      "Iteration 27, loss = 0.84090447\n",
      "Iteration 28, loss = 0.87644538\n",
      "Iteration 29, loss = 0.83731625\n",
      "Iteration 30, loss = 0.80399441\n",
      "Iteration 31, loss = 0.79693030\n",
      "Iteration 32, loss = 0.82935762\n",
      "Iteration 33, loss = 0.83314698\n",
      "Iteration 34, loss = 0.79896656\n",
      "Iteration 35, loss = 0.82174558\n",
      "Iteration 36, loss = 0.82276607\n",
      "Iteration 37, loss = 0.80157767\n",
      "Iteration 38, loss = 0.83789722\n",
      "Iteration 39, loss = 0.81461471\n",
      "Iteration 25, loss = 0.82701421\n",
      "Iteration 26, loss = 0.84802983\n",
      "Iteration 27, loss = 0.84090447\n",
      "Iteration 28, loss = 0.87644538\n",
      "Iteration 29, loss = 0.83731625\n",
      "Iteration 30, loss = 0.80399441\n",
      "Iteration 31, loss = 0.79693030\n",
      "Iteration 32, loss = 0.82935762\n",
      "Iteration 33, loss = 0.83314698\n",
      "Iteration 34, loss = 0.79896656\n",
      "Iteration 35, loss = 0.82174558\n",
      "Iteration 36, loss = 0.82276607\n",
      "Iteration 37, loss = 0.80157767\n",
      "Iteration 38, loss = 0.83789722\n",
      "Iteration 39, loss = 0.81461471\n",
      "Iteration 40, loss = 0.80492339\n",
      "Iteration 41, loss = 0.83932084\n",
      "Iteration 42, loss = 0.77676192\n",
      "Iteration 43, loss = 0.78070036\n",
      "Iteration 44, loss = 0.79432432\n",
      "Iteration 45, loss = 0.79216412\n",
      "Iteration 46, loss = 0.80106958\n",
      "Iteration 47, loss = 0.78907350\n",
      "Iteration 48, loss = 0.73437364\n",
      "Iteration 49, loss = 0.75555909\n",
      "Iteration 50, loss = 0.78873678\n",
      "Iteration 51, loss = 0.78798655\n",
      "Iteration 52, loss = 0.82975790\n",
      "Iteration 53, loss = 0.80368300\n",
      "Iteration 54, loss = 0.75251581\n",
      "Iteration 55, loss = 0.73792386\n",
      "Iteration 40, loss = 0.80492339\n",
      "Iteration 41, loss = 0.83932084\n",
      "Iteration 42, loss = 0.77676192\n",
      "Iteration 43, loss = 0.78070036\n",
      "Iteration 44, loss = 0.79432432\n",
      "Iteration 45, loss = 0.79216412\n",
      "Iteration 46, loss = 0.80106958\n",
      "Iteration 47, loss = 0.78907350\n",
      "Iteration 48, loss = 0.73437364\n",
      "Iteration 49, loss = 0.75555909\n",
      "Iteration 50, loss = 0.78873678\n",
      "Iteration 51, loss = 0.78798655\n",
      "Iteration 52, loss = 0.82975790\n",
      "Iteration 53, loss = 0.80368300\n",
      "Iteration 54, loss = 0.75251581\n",
      "Iteration 55, loss = 0.73792386\n",
      "Iteration 56, loss = 0.80861168\n",
      "Iteration 57, loss = 0.76488768\n",
      "Iteration 58, loss = 0.79169905\n",
      "Iteration 59, loss = 0.76122166\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18684318\n",
      "Iteration 2, loss = 1.05930095\n",
      "Iteration 3, loss = 0.97852057\n",
      "Iteration 4, loss = 0.99010772\n",
      "Iteration 5, loss = 0.97469383\n",
      "Iteration 6, loss = 0.97166529\n",
      "Iteration 7, loss = 0.95899366\n",
      "Iteration 8, loss = 0.91528587\n",
      "Iteration 9, loss = 0.98804008\n",
      "Iteration 56, loss = 0.80861168\n",
      "Iteration 57, loss = 0.76488768\n",
      "Iteration 58, loss = 0.79169905\n",
      "Iteration 59, loss = 0.76122166\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18684318\n",
      "Iteration 2, loss = 1.05930095\n",
      "Iteration 3, loss = 0.97852057\n",
      "Iteration 4, loss = 0.99010772\n",
      "Iteration 5, loss = 0.97469383\n",
      "Iteration 6, loss = 0.97166529\n",
      "Iteration 7, loss = 0.95899366\n",
      "Iteration 8, loss = 0.91528587\n",
      "Iteration 9, loss = 0.98804008\n",
      "Iteration 10, loss = 0.97669233\n",
      "Iteration 11, loss = 0.95546018\n",
      "Iteration 12, loss = 0.94075327\n",
      "Iteration 13, loss = 0.91698391\n",
      "Iteration 14, loss = 0.91166400\n",
      "Iteration 15, loss = 0.93124058\n",
      "Iteration 16, loss = 0.90210572\n",
      "Iteration 17, loss = 0.92158351\n",
      "Iteration 18, loss = 0.90024876\n",
      "Iteration 19, loss = 0.88233986\n",
      "Iteration 20, loss = 0.91689374\n",
      "Iteration 21, loss = 0.90676846\n",
      "Iteration 22, loss = 0.89320407\n",
      "Iteration 23, loss = 0.91768427\n",
      "Iteration 24, loss = 0.90544371\n",
      "Iteration 10, loss = 0.97669233\n",
      "Iteration 11, loss = 0.95546018\n",
      "Iteration 12, loss = 0.94075327\n",
      "Iteration 13, loss = 0.91698391\n",
      "Iteration 14, loss = 0.91166400\n",
      "Iteration 15, loss = 0.93124058\n",
      "Iteration 16, loss = 0.90210572\n",
      "Iteration 17, loss = 0.92158351\n",
      "Iteration 18, loss = 0.90024876\n",
      "Iteration 19, loss = 0.88233986\n",
      "Iteration 20, loss = 0.91689374\n",
      "Iteration 21, loss = 0.90676846\n",
      "Iteration 22, loss = 0.89320407\n",
      "Iteration 23, loss = 0.91768427\n",
      "Iteration 24, loss = 0.90544371\n",
      "Iteration 25, loss = 0.87435567\n",
      "Iteration 26, loss = 0.88203200\n",
      "Iteration 27, loss = 0.89588044\n",
      "Iteration 28, loss = 0.89555549\n",
      "Iteration 29, loss = 0.87784577\n",
      "Iteration 30, loss = 0.87907872\n",
      "Iteration 31, loss = 0.85103551\n",
      "Iteration 32, loss = 0.87132701\n",
      "Iteration 33, loss = 0.87673284\n",
      "Iteration 34, loss = 0.86304643\n",
      "Iteration 35, loss = 0.86545176\n",
      "Iteration 36, loss = 0.86675709\n",
      "Iteration 37, loss = 0.84744904\n",
      "Iteration 38, loss = 0.87750351\n",
      "Iteration 39, loss = 0.82366174\n",
      "Iteration 40, loss = 0.84650390\n",
      "Iteration 25, loss = 0.87435567\n",
      "Iteration 26, loss = 0.88203200\n",
      "Iteration 27, loss = 0.89588044\n",
      "Iteration 28, loss = 0.89555549\n",
      "Iteration 29, loss = 0.87784577\n",
      "Iteration 30, loss = 0.87907872\n",
      "Iteration 31, loss = 0.85103551\n",
      "Iteration 32, loss = 0.87132701\n",
      "Iteration 33, loss = 0.87673284\n",
      "Iteration 34, loss = 0.86304643\n",
      "Iteration 35, loss = 0.86545176\n",
      "Iteration 36, loss = 0.86675709\n",
      "Iteration 37, loss = 0.84744904\n",
      "Iteration 38, loss = 0.87750351\n",
      "Iteration 39, loss = 0.82366174\n",
      "Iteration 40, loss = 0.84650390\n",
      "Iteration 41, loss = 0.85691277\n",
      "Iteration 42, loss = 0.83106196\n",
      "Iteration 43, loss = 0.82082529\n",
      "Iteration 44, loss = 0.82835521\n",
      "Iteration 45, loss = 0.82327706\n",
      "Iteration 46, loss = 0.81859190\n",
      "Iteration 47, loss = 0.82337414\n",
      "Iteration 48, loss = 0.80055774\n",
      "Iteration 49, loss = 0.84450971\n",
      "Iteration 50, loss = 0.82253153\n",
      "Iteration 51, loss = 0.79911797\n",
      "Iteration 52, loss = 0.79476894\n",
      "Iteration 53, loss = 0.77731790\n",
      "Iteration 54, loss = 0.78739409\n",
      "Iteration 55, loss = 0.86858965\n",
      "Iteration 41, loss = 0.85691277\n",
      "Iteration 42, loss = 0.83106196\n",
      "Iteration 43, loss = 0.82082529\n",
      "Iteration 44, loss = 0.82835521\n",
      "Iteration 45, loss = 0.82327706\n",
      "Iteration 46, loss = 0.81859190\n",
      "Iteration 47, loss = 0.82337414\n",
      "Iteration 48, loss = 0.80055774\n",
      "Iteration 49, loss = 0.84450971\n",
      "Iteration 50, loss = 0.82253153\n",
      "Iteration 51, loss = 0.79911797\n",
      "Iteration 52, loss = 0.79476894\n",
      "Iteration 53, loss = 0.77731790\n",
      "Iteration 54, loss = 0.78739409\n",
      "Iteration 55, loss = 0.86858965\n",
      "Iteration 56, loss = 0.80129534\n",
      "Iteration 57, loss = 0.80397922\n",
      "Iteration 58, loss = 0.85702140\n",
      "Iteration 59, loss = 0.82001774\n",
      "Iteration 60, loss = 0.83489674\n",
      "Iteration 61, loss = 0.77754339\n",
      "Iteration 62, loss = 0.84108993\n",
      "Iteration 63, loss = 0.78784141\n",
      "Iteration 64, loss = 0.78778676\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21529628\n",
      "Iteration 2, loss = 1.10797409\n",
      "Iteration 3, loss = 1.02450797\n",
      "Iteration 4, loss = 1.00631016\n",
      "Iteration 5, loss = 1.01265221\n",
      "Iteration 6, loss = 1.02772779\n",
      "Iteration 56, loss = 0.80129534\n",
      "Iteration 57, loss = 0.80397922\n",
      "Iteration 58, loss = 0.85702140\n",
      "Iteration 59, loss = 0.82001774\n",
      "Iteration 60, loss = 0.83489674\n",
      "Iteration 61, loss = 0.77754339\n",
      "Iteration 62, loss = 0.84108993\n",
      "Iteration 63, loss = 0.78784141\n",
      "Iteration 64, loss = 0.78778676\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21529628\n",
      "Iteration 2, loss = 1.10797409\n",
      "Iteration 3, loss = 1.02450797\n",
      "Iteration 4, loss = 1.00631016\n",
      "Iteration 5, loss = 1.01265221\n",
      "Iteration 6, loss = 1.02772779\n",
      "Iteration 7, loss = 0.99594649\n",
      "Iteration 8, loss = 0.95250648\n",
      "Iteration 9, loss = 0.96803693\n",
      "Iteration 10, loss = 0.96576450\n",
      "Iteration 11, loss = 0.98729907\n",
      "Iteration 12, loss = 0.92792048\n",
      "Iteration 13, loss = 0.92102296\n",
      "Iteration 14, loss = 0.94664518\n",
      "Iteration 15, loss = 0.90063668\n",
      "Iteration 16, loss = 0.92348613\n",
      "Iteration 17, loss = 0.89590453\n",
      "Iteration 18, loss = 0.88780230\n",
      "Iteration 19, loss = 0.87289356\n",
      "Iteration 20, loss = 0.91163804\n",
      "Iteration 21, loss = 0.88897460\n",
      "Iteration 22, loss = 0.87866899\n",
      "Iteration 23, loss = 0.88346825\n",
      "Iteration 7, loss = 0.99594649\n",
      "Iteration 8, loss = 0.95250648\n",
      "Iteration 9, loss = 0.96803693\n",
      "Iteration 10, loss = 0.96576450\n",
      "Iteration 11, loss = 0.98729907\n",
      "Iteration 12, loss = 0.92792048\n",
      "Iteration 13, loss = 0.92102296\n",
      "Iteration 14, loss = 0.94664518\n",
      "Iteration 15, loss = 0.90063668\n",
      "Iteration 16, loss = 0.92348613\n",
      "Iteration 17, loss = 0.89590453\n",
      "Iteration 18, loss = 0.88780230\n",
      "Iteration 19, loss = 0.87289356\n",
      "Iteration 20, loss = 0.91163804\n",
      "Iteration 21, loss = 0.88897460\n",
      "Iteration 22, loss = 0.87866899\n",
      "Iteration 23, loss = 0.88346825\n",
      "Iteration 24, loss = 0.88049795\n",
      "Iteration 25, loss = 0.90656749\n",
      "Iteration 26, loss = 0.87397667\n",
      "Iteration 27, loss = 0.90334067\n",
      "Iteration 28, loss = 0.90016492\n",
      "Iteration 29, loss = 0.85231967\n",
      "Iteration 30, loss = 0.89827311\n",
      "Iteration 31, loss = 0.87423172\n",
      "Iteration 32, loss = 0.88017143\n",
      "Iteration 33, loss = 0.89608744\n",
      "Iteration 34, loss = 0.85824070\n",
      "Iteration 35, loss = 0.84072747\n",
      "Iteration 36, loss = 0.84427368\n",
      "Iteration 37, loss = 0.83300690\n",
      "Iteration 38, loss = 0.84224706\n",
      "Iteration 39, loss = 0.82577274\n",
      "Iteration 24, loss = 0.88049795\n",
      "Iteration 25, loss = 0.90656749\n",
      "Iteration 26, loss = 0.87397667\n",
      "Iteration 27, loss = 0.90334067\n",
      "Iteration 28, loss = 0.90016492\n",
      "Iteration 29, loss = 0.85231967\n",
      "Iteration 30, loss = 0.89827311\n",
      "Iteration 31, loss = 0.87423172\n",
      "Iteration 32, loss = 0.88017143\n",
      "Iteration 33, loss = 0.89608744\n",
      "Iteration 34, loss = 0.85824070\n",
      "Iteration 35, loss = 0.84072747\n",
      "Iteration 36, loss = 0.84427368\n",
      "Iteration 37, loss = 0.83300690\n",
      "Iteration 38, loss = 0.84224706\n",
      "Iteration 39, loss = 0.82577274\n",
      "Iteration 40, loss = 0.85997117\n",
      "Iteration 41, loss = 0.83363390\n",
      "Iteration 42, loss = 0.87842848\n",
      "Iteration 43, loss = 0.85022104\n",
      "Iteration 44, loss = 0.80667706\n",
      "Iteration 45, loss = 0.79946288\n",
      "Iteration 46, loss = 0.80329810\n",
      "Iteration 47, loss = 0.80571042\n",
      "Iteration 48, loss = 0.81833208\n",
      "Iteration 49, loss = 0.80187978\n",
      "Iteration 50, loss = 0.79067416\n",
      "Iteration 51, loss = 0.77953666\n",
      "Iteration 52, loss = 0.77940878\n",
      "Iteration 53, loss = 0.79777817\n",
      "Iteration 54, loss = 0.78783770\n",
      "Iteration 40, loss = 0.85997117\n",
      "Iteration 41, loss = 0.83363390\n",
      "Iteration 42, loss = 0.87842848\n",
      "Iteration 43, loss = 0.85022104\n",
      "Iteration 44, loss = 0.80667706\n",
      "Iteration 45, loss = 0.79946288\n",
      "Iteration 46, loss = 0.80329810\n",
      "Iteration 47, loss = 0.80571042\n",
      "Iteration 48, loss = 0.81833208\n",
      "Iteration 49, loss = 0.80187978\n",
      "Iteration 50, loss = 0.79067416\n",
      "Iteration 51, loss = 0.77953666\n",
      "Iteration 52, loss = 0.77940878\n",
      "Iteration 53, loss = 0.79777817\n",
      "Iteration 54, loss = 0.78783770\n",
      "Iteration 55, loss = 0.85111924\n",
      "Iteration 56, loss = 0.82219810\n",
      "Iteration 57, loss = 0.76611366\n",
      "Iteration 58, loss = 0.79591585\n",
      "Iteration 59, loss = 0.76776146\n",
      "Iteration 60, loss = 0.79879284\n",
      "Iteration 61, loss = 0.76084339\n",
      "Iteration 62, loss = 0.81392436\n",
      "Iteration 63, loss = 0.79161328\n",
      "Iteration 64, loss = 0.79278060\n",
      "Iteration 65, loss = 0.75643863\n",
      "Iteration 66, loss = 0.76450519\n",
      "Iteration 67, loss = 0.82641155\n",
      "Iteration 68, loss = 0.74844403\n",
      "Iteration 69, loss = 0.82457383\n",
      "Iteration 70, loss = 0.76601390\n",
      "Iteration 55, loss = 0.85111924\n",
      "Iteration 56, loss = 0.82219810\n",
      "Iteration 57, loss = 0.76611366\n",
      "Iteration 58, loss = 0.79591585\n",
      "Iteration 59, loss = 0.76776146\n",
      "Iteration 60, loss = 0.79879284\n",
      "Iteration 61, loss = 0.76084339\n",
      "Iteration 62, loss = 0.81392436\n",
      "Iteration 63, loss = 0.79161328\n",
      "Iteration 64, loss = 0.79278060\n",
      "Iteration 65, loss = 0.75643863\n",
      "Iteration 66, loss = 0.76450519\n",
      "Iteration 67, loss = 0.82641155\n",
      "Iteration 68, loss = 0.74844403\n",
      "Iteration 69, loss = 0.82457383\n",
      "Iteration 70, loss = 0.76601390\n",
      "Iteration 71, loss = 0.76872228\n",
      "Iteration 72, loss = 0.71294548\n",
      "Iteration 73, loss = 0.73341685\n",
      "Iteration 74, loss = 0.72692546\n",
      "Iteration 75, loss = 0.72080716\n",
      "Iteration 76, loss = 0.72897342\n",
      "Iteration 77, loss = 0.73770844\n",
      "Iteration 78, loss = 0.71562117\n",
      "Iteration 79, loss = 0.72454684\n",
      "Iteration 80, loss = 0.69187137\n",
      "Iteration 81, loss = 0.81211715\n",
      "Iteration 82, loss = 0.79033911\n",
      "Iteration 83, loss = 0.75686628\n",
      "Iteration 84, loss = 0.77240376\n",
      "Iteration 71, loss = 0.76872228\n",
      "Iteration 72, loss = 0.71294548\n",
      "Iteration 73, loss = 0.73341685\n",
      "Iteration 74, loss = 0.72692546\n",
      "Iteration 75, loss = 0.72080716\n",
      "Iteration 76, loss = 0.72897342\n",
      "Iteration 77, loss = 0.73770844\n",
      "Iteration 78, loss = 0.71562117\n",
      "Iteration 79, loss = 0.72454684\n",
      "Iteration 80, loss = 0.69187137\n",
      "Iteration 81, loss = 0.81211715\n",
      "Iteration 82, loss = 0.79033911\n",
      "Iteration 83, loss = 0.75686628\n",
      "Iteration 84, loss = 0.77240376\n",
      "Iteration 85, loss = 0.73823801\n",
      "Iteration 86, loss = 0.73454512\n",
      "Iteration 87, loss = 0.73582382\n",
      "Iteration 88, loss = 0.73835344\n",
      "Iteration 89, loss = 0.78748006\n",
      "Iteration 90, loss = 0.73369698\n",
      "Iteration 91, loss = 0.76143350\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18957910\n",
      "Iteration 2, loss = 1.05578009\n",
      "Iteration 3, loss = 0.98515103\n",
      "Iteration 4, loss = 1.00564528\n",
      "Iteration 5, loss = 0.98218623\n",
      "Iteration 6, loss = 0.96452149\n",
      "Iteration 7, loss = 0.96573193\n",
      "Iteration 8, loss = 0.93966577\n",
      "Iteration 85, loss = 0.73823801\n",
      "Iteration 86, loss = 0.73454512\n",
      "Iteration 87, loss = 0.73582382\n",
      "Iteration 88, loss = 0.73835344\n",
      "Iteration 89, loss = 0.78748006\n",
      "Iteration 90, loss = 0.73369698\n",
      "Iteration 91, loss = 0.76143350\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18957910\n",
      "Iteration 2, loss = 1.05578009\n",
      "Iteration 3, loss = 0.98515103\n",
      "Iteration 4, loss = 1.00564528\n",
      "Iteration 5, loss = 0.98218623\n",
      "Iteration 6, loss = 0.96452149\n",
      "Iteration 7, loss = 0.96573193\n",
      "Iteration 8, loss = 0.93966577\n",
      "Iteration 9, loss = 0.94828770\n",
      "Iteration 10, loss = 0.92574059\n",
      "Iteration 11, loss = 0.93485378\n",
      "Iteration 12, loss = 0.93765898\n",
      "Iteration 13, loss = 0.94384037\n",
      "Iteration 14, loss = 0.94797275\n",
      "Iteration 15, loss = 0.95040696\n",
      "Iteration 16, loss = 0.96953007\n",
      "Iteration 17, loss = 0.92759634\n",
      "Iteration 18, loss = 0.90811920\n",
      "Iteration 19, loss = 0.91931451\n",
      "Iteration 20, loss = 0.95061006\n",
      "Iteration 21, loss = 0.92873826\n",
      "Iteration 22, loss = 0.91839702\n",
      "Iteration 23, loss = 0.90049882\n",
      "Iteration 9, loss = 0.94828770\n",
      "Iteration 10, loss = 0.92574059\n",
      "Iteration 11, loss = 0.93485378\n",
      "Iteration 12, loss = 0.93765898\n",
      "Iteration 13, loss = 0.94384037\n",
      "Iteration 14, loss = 0.94797275\n",
      "Iteration 15, loss = 0.95040696\n",
      "Iteration 16, loss = 0.96953007\n",
      "Iteration 17, loss = 0.92759634\n",
      "Iteration 18, loss = 0.90811920\n",
      "Iteration 19, loss = 0.91931451\n",
      "Iteration 20, loss = 0.95061006\n",
      "Iteration 21, loss = 0.92873826\n",
      "Iteration 22, loss = 0.91839702\n",
      "Iteration 23, loss = 0.90049882\n",
      "Iteration 24, loss = 0.90006205\n",
      "Iteration 25, loss = 0.88601049\n",
      "Iteration 26, loss = 0.87245957\n",
      "Iteration 27, loss = 0.87688280\n",
      "Iteration 28, loss = 0.88830702\n",
      "Iteration 29, loss = 0.87027021\n",
      "Iteration 30, loss = 0.85744907\n",
      "Iteration 31, loss = 0.88051617\n",
      "Iteration 32, loss = 0.86260768\n",
      "Iteration 33, loss = 0.87689944\n",
      "Iteration 34, loss = 0.84314096\n",
      "Iteration 35, loss = 0.85028195\n",
      "Iteration 36, loss = 0.85698971\n",
      "Iteration 37, loss = 0.85449543\n",
      "Iteration 38, loss = 0.86171381\n",
      "Iteration 39, loss = 0.85032747\n",
      "Iteration 24, loss = 0.90006205\n",
      "Iteration 25, loss = 0.88601049\n",
      "Iteration 26, loss = 0.87245957\n",
      "Iteration 27, loss = 0.87688280\n",
      "Iteration 28, loss = 0.88830702\n",
      "Iteration 29, loss = 0.87027021\n",
      "Iteration 30, loss = 0.85744907\n",
      "Iteration 31, loss = 0.88051617\n",
      "Iteration 32, loss = 0.86260768\n",
      "Iteration 33, loss = 0.87689944\n",
      "Iteration 34, loss = 0.84314096\n",
      "Iteration 35, loss = 0.85028195\n",
      "Iteration 36, loss = 0.85698971\n",
      "Iteration 37, loss = 0.85449543\n",
      "Iteration 38, loss = 0.86171381\n",
      "Iteration 39, loss = 0.85032747\n",
      "Iteration 40, loss = 0.85458435\n",
      "Iteration 41, loss = 0.82695814\n",
      "Iteration 42, loss = 0.85181128\n",
      "Iteration 43, loss = 0.84683936\n",
      "Iteration 44, loss = 0.83626371\n",
      "Iteration 45, loss = 0.84922348\n",
      "Iteration 46, loss = 0.86819893\n",
      "Iteration 47, loss = 0.84421344\n",
      "Iteration 48, loss = 0.83731447\n",
      "Iteration 49, loss = 0.86086409\n",
      "Iteration 50, loss = 0.82212634\n",
      "Iteration 51, loss = 0.84317426\n",
      "Iteration 52, loss = 0.83948712\n",
      "Iteration 53, loss = 0.81303968\n",
      "Iteration 54, loss = 0.84684287\n",
      "Iteration 55, loss = 0.80411757\n",
      "Iteration 40, loss = 0.85458435\n",
      "Iteration 41, loss = 0.82695814\n",
      "Iteration 42, loss = 0.85181128\n",
      "Iteration 43, loss = 0.84683936\n",
      "Iteration 44, loss = 0.83626371\n",
      "Iteration 45, loss = 0.84922348\n",
      "Iteration 46, loss = 0.86819893\n",
      "Iteration 47, loss = 0.84421344\n",
      "Iteration 48, loss = 0.83731447\n",
      "Iteration 49, loss = 0.86086409\n",
      "Iteration 50, loss = 0.82212634\n",
      "Iteration 51, loss = 0.84317426\n",
      "Iteration 52, loss = 0.83948712\n",
      "Iteration 53, loss = 0.81303968\n",
      "Iteration 54, loss = 0.84684287\n",
      "Iteration 55, loss = 0.80411757\n",
      "Iteration 56, loss = 0.84934448\n",
      "Iteration 57, loss = 0.82727657\n",
      "Iteration 58, loss = 0.82332502\n",
      "Iteration 59, loss = 0.80198498\n",
      "Iteration 60, loss = 0.80504186\n",
      "Iteration 61, loss = 0.78588443\n",
      "Iteration 62, loss = 0.77999014\n",
      "Iteration 63, loss = 0.85034222\n",
      "Iteration 64, loss = 0.81909415\n",
      "Iteration 65, loss = 0.76618965\n",
      "Iteration 66, loss = 0.79565970\n",
      "Iteration 67, loss = 0.80445831\n",
      "Iteration 68, loss = 0.77548336\n",
      "Iteration 69, loss = 0.78751832\n",
      "Iteration 70, loss = 0.79290621\n",
      "Iteration 71, loss = 0.76572126\n",
      "Iteration 56, loss = 0.84934448\n",
      "Iteration 57, loss = 0.82727657\n",
      "Iteration 58, loss = 0.82332502\n",
      "Iteration 59, loss = 0.80198498\n",
      "Iteration 60, loss = 0.80504186\n",
      "Iteration 61, loss = 0.78588443\n",
      "Iteration 62, loss = 0.77999014\n",
      "Iteration 63, loss = 0.85034222\n",
      "Iteration 64, loss = 0.81909415\n",
      "Iteration 65, loss = 0.76618965\n",
      "Iteration 66, loss = 0.79565970\n",
      "Iteration 67, loss = 0.80445831\n",
      "Iteration 68, loss = 0.77548336\n",
      "Iteration 69, loss = 0.78751832\n",
      "Iteration 70, loss = 0.79290621\n",
      "Iteration 71, loss = 0.76572126\n",
      "Iteration 72, loss = 0.78100829\n",
      "Iteration 73, loss = 0.76653661\n",
      "Iteration 74, loss = 0.75934348\n",
      "Iteration 75, loss = 0.77539087\n",
      "Iteration 76, loss = 0.75408127\n",
      "Iteration 77, loss = 0.74286333\n",
      "Iteration 78, loss = 0.76831865\n",
      "Iteration 79, loss = 0.79652266\n",
      "Iteration 80, loss = 0.75261235\n",
      "Iteration 81, loss = 0.75896006\n",
      "Iteration 82, loss = 0.80165818\n",
      "Iteration 83, loss = 0.72728124\n",
      "Iteration 84, loss = 0.73513876\n",
      "Iteration 85, loss = 0.77370811\n",
      "Iteration 86, loss = 0.74787769\n",
      "Iteration 72, loss = 0.78100829\n",
      "Iteration 73, loss = 0.76653661\n",
      "Iteration 74, loss = 0.75934348\n",
      "Iteration 75, loss = 0.77539087\n",
      "Iteration 76, loss = 0.75408127\n",
      "Iteration 77, loss = 0.74286333\n",
      "Iteration 78, loss = 0.76831865\n",
      "Iteration 79, loss = 0.79652266\n",
      "Iteration 80, loss = 0.75261235\n",
      "Iteration 81, loss = 0.75896006\n",
      "Iteration 82, loss = 0.80165818\n",
      "Iteration 83, loss = 0.72728124\n",
      "Iteration 84, loss = 0.73513876\n",
      "Iteration 85, loss = 0.77370811\n",
      "Iteration 86, loss = 0.74787769\n",
      "Iteration 87, loss = 0.75271265\n",
      "Iteration 88, loss = 0.77455545\n",
      "Iteration 89, loss = 0.71522050\n",
      "Iteration 90, loss = 0.75766622\n",
      "Iteration 91, loss = 0.73407907\n",
      "Iteration 92, loss = 0.72633369\n",
      "Iteration 93, loss = 0.72081964\n",
      "Iteration 94, loss = 0.72089365\n",
      "Iteration 95, loss = 0.73008590\n",
      "Iteration 96, loss = 0.75066154\n",
      "Iteration 97, loss = 0.71056984\n",
      "Iteration 98, loss = 0.72057989\n",
      "Iteration 99, loss = 0.72092770\n",
      "Iteration 100, loss = 0.70526087\n",
      "Iteration 1, loss = 1.18691628\n",
      "Iteration 87, loss = 0.75271265\n",
      "Iteration 88, loss = 0.77455545\n",
      "Iteration 89, loss = 0.71522050\n",
      "Iteration 90, loss = 0.75766622\n",
      "Iteration 91, loss = 0.73407907\n",
      "Iteration 92, loss = 0.72633369\n",
      "Iteration 93, loss = 0.72081964\n",
      "Iteration 94, loss = 0.72089365\n",
      "Iteration 95, loss = 0.73008590\n",
      "Iteration 96, loss = 0.75066154\n",
      "Iteration 97, loss = 0.71056984\n",
      "Iteration 98, loss = 0.72057989\n",
      "Iteration 99, loss = 0.72092770\n",
      "Iteration 100, loss = 0.70526087\n",
      "Iteration 1, loss = 1.18691628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.08477588\n",
      "Iteration 3, loss = 1.03272501\n",
      "Iteration 4, loss = 1.01152331\n",
      "Iteration 5, loss = 1.00737273\n",
      "Iteration 6, loss = 0.96995550\n",
      "Iteration 7, loss = 1.04087237\n",
      "Iteration 8, loss = 1.02613182\n",
      "Iteration 9, loss = 0.99850805\n",
      "Iteration 10, loss = 1.01627675\n",
      "Iteration 1, loss = 1.16706325\n",
      "Iteration 2, loss = 0.96892909\n",
      "Iteration 3, loss = 0.96803220\n",
      "Iteration 4, loss = 0.94912044\n",
      "Iteration 5, loss = 0.93986571\n",
      "Iteration 2, loss = 1.08477588\n",
      "Iteration 3, loss = 1.03272501\n",
      "Iteration 4, loss = 1.01152331\n",
      "Iteration 5, loss = 1.00737273\n",
      "Iteration 6, loss = 0.96995550\n",
      "Iteration 7, loss = 1.04087237\n",
      "Iteration 8, loss = 1.02613182\n",
      "Iteration 9, loss = 0.99850805\n",
      "Iteration 10, loss = 1.01627675\n",
      "Iteration 1, loss = 1.16706325\n",
      "Iteration 2, loss = 0.96892909\n",
      "Iteration 3, loss = 0.96803220\n",
      "Iteration 4, loss = 0.94912044\n",
      "Iteration 5, loss = 0.93986571\n",
      "Iteration 6, loss = 0.95343576\n",
      "Iteration 7, loss = 0.94915383\n",
      "Iteration 8, loss = 0.94145347\n",
      "Iteration 9, loss = 0.98106064\n",
      "Iteration 10, loss = 0.96857799\n",
      "Iteration 1, loss = 1.20972300\n",
      "Iteration 2, loss = 1.02267284\n",
      "Iteration 3, loss = 1.00984867\n",
      "Iteration 4, loss = 0.98481300\n",
      "Iteration 5, loss = 0.99002921\n",
      "Iteration 6, loss = 0.98481513\n",
      "Iteration 7, loss = 0.95469721\n",
      "Iteration 8, loss = 0.92813315\n",
      "Iteration 6, loss = 0.95343576\n",
      "Iteration 7, loss = 0.94915383\n",
      "Iteration 8, loss = 0.94145347\n",
      "Iteration 9, loss = 0.98106064\n",
      "Iteration 10, loss = 0.96857799\n",
      "Iteration 1, loss = 1.20972300\n",
      "Iteration 2, loss = 1.02267284\n",
      "Iteration 3, loss = 1.00984867\n",
      "Iteration 4, loss = 0.98481300\n",
      "Iteration 5, loss = 0.99002921\n",
      "Iteration 6, loss = 0.98481513\n",
      "Iteration 7, loss = 0.95469721\n",
      "Iteration 8, loss = 0.92813315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.98510596\n",
      "Iteration 10, loss = 0.95638291\n",
      "Iteration 1, loss = 1.19272814\n",
      "Iteration 2, loss = 1.07730502\n",
      "Iteration 3, loss = 1.11254056\n",
      "Iteration 4, loss = 1.07092308\n",
      "Iteration 5, loss = 1.00716636\n",
      "Iteration 6, loss = 1.06642339\n",
      "Iteration 7, loss = 1.09918969\n",
      "Iteration 8, loss = 1.00167986\n",
      "Iteration 9, loss = 1.04608944\n",
      "Iteration 10, loss = 1.03729875\n",
      "Iteration 9, loss = 0.98510596\n",
      "Iteration 10, loss = 0.95638291\n",
      "Iteration 1, loss = 1.19272814\n",
      "Iteration 2, loss = 1.07730502\n",
      "Iteration 3, loss = 1.11254056\n",
      "Iteration 4, loss = 1.07092308\n",
      "Iteration 5, loss = 1.00716636\n",
      "Iteration 6, loss = 1.06642339\n",
      "Iteration 7, loss = 1.09918969\n",
      "Iteration 8, loss = 1.00167986\n",
      "Iteration 9, loss = 1.04608944\n",
      "Iteration 10, loss = 1.03729875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.19553029\n",
      "Iteration 2, loss = 1.08118323\n",
      "Iteration 3, loss = 1.05345879\n",
      "Iteration 4, loss = 1.01186419\n",
      "Iteration 5, loss = 0.99044154\n",
      "Iteration 6, loss = 1.01650339\n",
      "Iteration 7, loss = 0.98025535\n",
      "Iteration 8, loss = 1.03239250\n",
      "Iteration 9, loss = 0.97320302\n",
      "Iteration 10, loss = 0.98484489\n",
      "Iteration 1, loss = 1.18691628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.19553029\n",
      "Iteration 2, loss = 1.08118323\n",
      "Iteration 3, loss = 1.05345879\n",
      "Iteration 4, loss = 1.01186419\n",
      "Iteration 5, loss = 0.99044154\n",
      "Iteration 6, loss = 1.01650339\n",
      "Iteration 7, loss = 0.98025535\n",
      "Iteration 8, loss = 1.03239250\n",
      "Iteration 9, loss = 0.97320302\n",
      "Iteration 10, loss = 0.98484489\n",
      "Iteration 1, loss = 1.18691628\n",
      "Iteration 2, loss = 1.08477588\n",
      "Iteration 3, loss = 1.03272501\n",
      "Iteration 4, loss = 1.01152331\n",
      "Iteration 5, loss = 1.00737273\n",
      "Iteration 6, loss = 0.96995550\n",
      "Iteration 7, loss = 1.04087237\n",
      "Iteration 8, loss = 1.02613182\n",
      "Iteration 9, loss = 0.99850805\n",
      "Iteration 10, loss = 1.01627675\n",
      "Iteration 11, loss = 0.98562186\n",
      "Iteration 12, loss = 0.98605878\n",
      "Iteration 13, loss = 0.98359036\n",
      "Iteration 14, loss = 0.96970836\n",
      "Iteration 2, loss = 1.08477588\n",
      "Iteration 3, loss = 1.03272501\n",
      "Iteration 4, loss = 1.01152331\n",
      "Iteration 5, loss = 1.00737273\n",
      "Iteration 6, loss = 0.96995550\n",
      "Iteration 7, loss = 1.04087237\n",
      "Iteration 8, loss = 1.02613182\n",
      "Iteration 9, loss = 0.99850805\n",
      "Iteration 10, loss = 1.01627675\n",
      "Iteration 11, loss = 0.98562186\n",
      "Iteration 12, loss = 0.98605878\n",
      "Iteration 13, loss = 0.98359036\n",
      "Iteration 14, loss = 0.96970836\n",
      "Iteration 15, loss = 1.00256618\n",
      "Iteration 16, loss = 0.97543770\n",
      "Iteration 17, loss = 0.97808578\n",
      "Iteration 18, loss = 0.97285786\n",
      "Iteration 19, loss = 0.94499850\n",
      "Iteration 20, loss = 0.97081806\n",
      "Iteration 21, loss = 0.95916614\n",
      "Iteration 22, loss = 0.93458005\n",
      "Iteration 23, loss = 0.96227251\n",
      "Iteration 24, loss = 1.07342256\n",
      "Iteration 25, loss = 1.00822756\n",
      "Iteration 26, loss = 0.99485509\n",
      "Iteration 27, loss = 0.97286779\n",
      "Iteration 28, loss = 1.11815931\n",
      "Iteration 29, loss = 0.97365230\n",
      "Iteration 15, loss = 1.00256618\n",
      "Iteration 16, loss = 0.97543770\n",
      "Iteration 17, loss = 0.97808578\n",
      "Iteration 18, loss = 0.97285786\n",
      "Iteration 19, loss = 0.94499850\n",
      "Iteration 20, loss = 0.97081806\n",
      "Iteration 21, loss = 0.95916614\n",
      "Iteration 22, loss = 0.93458005\n",
      "Iteration 23, loss = 0.96227251\n",
      "Iteration 24, loss = 1.07342256\n",
      "Iteration 25, loss = 1.00822756\n",
      "Iteration 26, loss = 0.99485509\n",
      "Iteration 27, loss = 0.97286779\n",
      "Iteration 28, loss = 1.11815931\n",
      "Iteration 29, loss = 0.97365230\n",
      "Iteration 30, loss = 0.98275274\n",
      "Iteration 31, loss = 0.98021257\n",
      "Iteration 32, loss = 0.96795718\n",
      "Iteration 33, loss = 0.96950946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16706325\n",
      "Iteration 2, loss = 0.96892909\n",
      "Iteration 3, loss = 0.96803220\n",
      "Iteration 4, loss = 0.94912044\n",
      "Iteration 5, loss = 0.93986571\n",
      "Iteration 6, loss = 0.95343576\n",
      "Iteration 7, loss = 0.94915383\n",
      "Iteration 8, loss = 0.94145347\n",
      "Iteration 9, loss = 0.98106064\n",
      "Iteration 10, loss = 0.96857799\n",
      "Iteration 30, loss = 0.98275274\n",
      "Iteration 31, loss = 0.98021257\n",
      "Iteration 32, loss = 0.96795718\n",
      "Iteration 33, loss = 0.96950946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16706325\n",
      "Iteration 2, loss = 0.96892909\n",
      "Iteration 3, loss = 0.96803220\n",
      "Iteration 4, loss = 0.94912044\n",
      "Iteration 5, loss = 0.93986571\n",
      "Iteration 6, loss = 0.95343576\n",
      "Iteration 7, loss = 0.94915383\n",
      "Iteration 8, loss = 0.94145347\n",
      "Iteration 9, loss = 0.98106064\n",
      "Iteration 10, loss = 0.96857799\n",
      "Iteration 11, loss = 0.91748340\n",
      "Iteration 12, loss = 1.01757264\n",
      "Iteration 13, loss = 1.04186488\n",
      "Iteration 14, loss = 0.95798598\n",
      "Iteration 15, loss = 0.97429903\n",
      "Iteration 16, loss = 0.91366803\n",
      "Iteration 17, loss = 0.91632067\n",
      "Iteration 18, loss = 0.98461576\n",
      "Iteration 19, loss = 0.91829881\n",
      "Iteration 20, loss = 0.96357988\n",
      "Iteration 21, loss = 0.89432925\n",
      "Iteration 22, loss = 0.94447849\n",
      "Iteration 23, loss = 0.94167538\n",
      "Iteration 24, loss = 0.92405998\n",
      "Iteration 25, loss = 0.91975354\n",
      "Iteration 11, loss = 0.91748340\n",
      "Iteration 12, loss = 1.01757264\n",
      "Iteration 13, loss = 1.04186488\n",
      "Iteration 14, loss = 0.95798598\n",
      "Iteration 15, loss = 0.97429903\n",
      "Iteration 16, loss = 0.91366803\n",
      "Iteration 17, loss = 0.91632067\n",
      "Iteration 18, loss = 0.98461576\n",
      "Iteration 19, loss = 0.91829881\n",
      "Iteration 20, loss = 0.96357988\n",
      "Iteration 21, loss = 0.89432925\n",
      "Iteration 22, loss = 0.94447849\n",
      "Iteration 23, loss = 0.94167538\n",
      "Iteration 24, loss = 0.92405998\n",
      "Iteration 25, loss = 0.91975354\n",
      "Iteration 26, loss = 0.91744335\n",
      "Iteration 27, loss = 0.88714270\n",
      "Iteration 28, loss = 0.89791774\n",
      "Iteration 29, loss = 0.91668362\n",
      "Iteration 30, loss = 0.93046508\n",
      "Iteration 31, loss = 0.88067163\n",
      "Iteration 32, loss = 0.86261079\n",
      "Iteration 33, loss = 0.85973830\n",
      "Iteration 34, loss = 0.95748705\n",
      "Iteration 35, loss = 1.02842874\n",
      "Iteration 36, loss = 0.98995617\n",
      "Iteration 37, loss = 0.96339522\n",
      "Iteration 38, loss = 0.93033580\n",
      "Iteration 39, loss = 0.93295445\n",
      "Iteration 40, loss = 0.89884861\n",
      "Iteration 26, loss = 0.91744335\n",
      "Iteration 27, loss = 0.88714270\n",
      "Iteration 28, loss = 0.89791774\n",
      "Iteration 29, loss = 0.91668362\n",
      "Iteration 30, loss = 0.93046508\n",
      "Iteration 31, loss = 0.88067163\n",
      "Iteration 32, loss = 0.86261079\n",
      "Iteration 33, loss = 0.85973830\n",
      "Iteration 34, loss = 0.95748705\n",
      "Iteration 35, loss = 1.02842874\n",
      "Iteration 36, loss = 0.98995617\n",
      "Iteration 37, loss = 0.96339522\n",
      "Iteration 38, loss = 0.93033580\n",
      "Iteration 39, loss = 0.93295445\n",
      "Iteration 40, loss = 0.89884861\n",
      "Iteration 41, loss = 1.01355794\n",
      "Iteration 42, loss = 0.91789553\n",
      "Iteration 43, loss = 0.97796399\n",
      "Iteration 44, loss = 0.90752986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20972300\n",
      "Iteration 2, loss = 1.02267284\n",
      "Iteration 3, loss = 1.00984867\n",
      "Iteration 4, loss = 0.98481300\n",
      "Iteration 5, loss = 0.99002921\n",
      "Iteration 6, loss = 0.98481513\n",
      "Iteration 7, loss = 0.95469721\n",
      "Iteration 8, loss = 0.92813315\n",
      "Iteration 9, loss = 0.98510596\n",
      "Iteration 10, loss = 0.95638291\n",
      "Iteration 41, loss = 1.01355794\n",
      "Iteration 42, loss = 0.91789553\n",
      "Iteration 43, loss = 0.97796399\n",
      "Iteration 44, loss = 0.90752986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20972300\n",
      "Iteration 2, loss = 1.02267284\n",
      "Iteration 3, loss = 1.00984867\n",
      "Iteration 4, loss = 0.98481300\n",
      "Iteration 5, loss = 0.99002921\n",
      "Iteration 6, loss = 0.98481513\n",
      "Iteration 7, loss = 0.95469721\n",
      "Iteration 8, loss = 0.92813315\n",
      "Iteration 9, loss = 0.98510596\n",
      "Iteration 10, loss = 0.95638291\n",
      "Iteration 11, loss = 0.95179256\n",
      "Iteration 12, loss = 0.97399284\n",
      "Iteration 13, loss = 0.93178213\n",
      "Iteration 14, loss = 0.92130294\n",
      "Iteration 15, loss = 0.93482259\n",
      "Iteration 16, loss = 0.93059286\n",
      "Iteration 17, loss = 0.95039596\n",
      "Iteration 18, loss = 0.94415941\n",
      "Iteration 19, loss = 0.92207328\n",
      "Iteration 20, loss = 0.91619774\n",
      "Iteration 21, loss = 0.92450803\n",
      "Iteration 22, loss = 0.94230061\n",
      "Iteration 23, loss = 1.05186848\n",
      "Iteration 24, loss = 0.96600304\n",
      "Iteration 11, loss = 0.95179256\n",
      "Iteration 12, loss = 0.97399284\n",
      "Iteration 13, loss = 0.93178213\n",
      "Iteration 14, loss = 0.92130294\n",
      "Iteration 15, loss = 0.93482259\n",
      "Iteration 16, loss = 0.93059286\n",
      "Iteration 17, loss = 0.95039596\n",
      "Iteration 18, loss = 0.94415941\n",
      "Iteration 19, loss = 0.92207328\n",
      "Iteration 20, loss = 0.91619774\n",
      "Iteration 21, loss = 0.92450803\n",
      "Iteration 22, loss = 0.94230061\n",
      "Iteration 23, loss = 1.05186848\n",
      "Iteration 24, loss = 0.96600304\n",
      "Iteration 25, loss = 0.90788913\n",
      "Iteration 26, loss = 0.92451047\n",
      "Iteration 27, loss = 0.90820736\n",
      "Iteration 28, loss = 0.96890120\n",
      "Iteration 29, loss = 0.95850700\n",
      "Iteration 30, loss = 0.93635338\n",
      "Iteration 31, loss = 0.91876787\n",
      "Iteration 32, loss = 0.91855582\n",
      "Iteration 33, loss = 0.90468401\n",
      "Iteration 34, loss = 0.93774054\n",
      "Iteration 35, loss = 1.00450448\n",
      "Iteration 36, loss = 0.94077613\n",
      "Iteration 37, loss = 0.92160255\n",
      "Iteration 38, loss = 0.91694502\n",
      "Iteration 39, loss = 0.89980994\n",
      "Iteration 40, loss = 0.92341234\n",
      "Iteration 25, loss = 0.90788913\n",
      "Iteration 26, loss = 0.92451047\n",
      "Iteration 27, loss = 0.90820736\n",
      "Iteration 28, loss = 0.96890120\n",
      "Iteration 29, loss = 0.95850700\n",
      "Iteration 30, loss = 0.93635338\n",
      "Iteration 31, loss = 0.91876787\n",
      "Iteration 32, loss = 0.91855582\n",
      "Iteration 33, loss = 0.90468401\n",
      "Iteration 34, loss = 0.93774054\n",
      "Iteration 35, loss = 1.00450448\n",
      "Iteration 36, loss = 0.94077613\n",
      "Iteration 37, loss = 0.92160255\n",
      "Iteration 38, loss = 0.91694502\n",
      "Iteration 39, loss = 0.89980994\n",
      "Iteration 40, loss = 0.92341234\n",
      "Iteration 41, loss = 0.91379592\n",
      "Iteration 42, loss = 0.90365719\n",
      "Iteration 43, loss = 0.93406528\n",
      "Iteration 44, loss = 0.91010591\n",
      "Iteration 45, loss = 0.90121368\n",
      "Iteration 46, loss = 0.89942151\n",
      "Iteration 47, loss = 0.87940830\n",
      "Iteration 48, loss = 0.88295680\n",
      "Iteration 49, loss = 0.89432846\n",
      "Iteration 50, loss = 0.88914668\n",
      "Iteration 1, loss = 1.19272814\n",
      "Iteration 2, loss = 1.07730502\n",
      "Iteration 3, loss = 1.11254056\n",
      "Iteration 4, loss = 1.07092308\n",
      "Iteration 5, loss = 1.00716636\n",
      "Iteration 6, loss = 1.06642339\n",
      "Iteration 41, loss = 0.91379592\n",
      "Iteration 42, loss = 0.90365719\n",
      "Iteration 43, loss = 0.93406528\n",
      "Iteration 44, loss = 0.91010591\n",
      "Iteration 45, loss = 0.90121368\n",
      "Iteration 46, loss = 0.89942151\n",
      "Iteration 47, loss = 0.87940830\n",
      "Iteration 48, loss = 0.88295680\n",
      "Iteration 49, loss = 0.89432846\n",
      "Iteration 50, loss = 0.88914668\n",
      "Iteration 1, loss = 1.19272814\n",
      "Iteration 2, loss = 1.07730502\n",
      "Iteration 3, loss = 1.11254056\n",
      "Iteration 4, loss = 1.07092308\n",
      "Iteration 5, loss = 1.00716636\n",
      "Iteration 6, loss = 1.06642339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.09918969\n",
      "Iteration 8, loss = 1.00167986\n",
      "Iteration 9, loss = 1.04608944\n",
      "Iteration 10, loss = 1.03729875\n",
      "Iteration 11, loss = 1.07332647\n",
      "Iteration 12, loss = 1.08398838\n",
      "Iteration 13, loss = 1.01555384\n",
      "Iteration 14, loss = 1.06378246\n",
      "Iteration 15, loss = 1.01078002\n",
      "Iteration 16, loss = 0.96570868\n",
      "Iteration 17, loss = 1.00302524\n",
      "Iteration 18, loss = 0.95499174\n",
      "Iteration 19, loss = 0.97639292\n",
      "Iteration 20, loss = 0.98423565\n",
      "Iteration 21, loss = 0.97041864\n",
      "Iteration 7, loss = 1.09918969\n",
      "Iteration 8, loss = 1.00167986\n",
      "Iteration 9, loss = 1.04608944\n",
      "Iteration 10, loss = 1.03729875\n",
      "Iteration 11, loss = 1.07332647\n",
      "Iteration 12, loss = 1.08398838\n",
      "Iteration 13, loss = 1.01555384\n",
      "Iteration 14, loss = 1.06378246\n",
      "Iteration 15, loss = 1.01078002\n",
      "Iteration 16, loss = 0.96570868\n",
      "Iteration 17, loss = 1.00302524\n",
      "Iteration 18, loss = 0.95499174\n",
      "Iteration 19, loss = 0.97639292\n",
      "Iteration 20, loss = 0.98423565\n",
      "Iteration 21, loss = 0.97041864\n",
      "Iteration 22, loss = 1.00613276\n",
      "Iteration 23, loss = 0.99535593\n",
      "Iteration 24, loss = 0.96374874\n",
      "Iteration 25, loss = 0.94190980\n",
      "Iteration 26, loss = 0.97906921\n",
      "Iteration 27, loss = 0.97763161\n",
      "Iteration 28, loss = 0.96745634\n",
      "Iteration 29, loss = 1.05035827\n",
      "Iteration 30, loss = 0.99658316\n",
      "Iteration 31, loss = 0.99396707\n",
      "Iteration 32, loss = 1.06387996\n",
      "Iteration 33, loss = 1.06681610\n",
      "Iteration 34, loss = 1.08143785\n",
      "Iteration 35, loss = 1.09498499\n",
      "Iteration 36, loss = 1.02864072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 1.00613276\n",
      "Iteration 23, loss = 0.99535593\n",
      "Iteration 24, loss = 0.96374874\n",
      "Iteration 25, loss = 0.94190980\n",
      "Iteration 26, loss = 0.97906921\n",
      "Iteration 27, loss = 0.97763161\n",
      "Iteration 28, loss = 0.96745634\n",
      "Iteration 29, loss = 1.05035827\n",
      "Iteration 30, loss = 0.99658316\n",
      "Iteration 31, loss = 0.99396707\n",
      "Iteration 32, loss = 1.06387996\n",
      "Iteration 33, loss = 1.06681610\n",
      "Iteration 34, loss = 1.08143785\n",
      "Iteration 35, loss = 1.09498499\n",
      "Iteration 36, loss = 1.02864072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19553029\n",
      "Iteration 2, loss = 1.08118323\n",
      "Iteration 3, loss = 1.05345879\n",
      "Iteration 4, loss = 1.01186419\n",
      "Iteration 5, loss = 0.99044154\n",
      "Iteration 6, loss = 1.01650339\n",
      "Iteration 7, loss = 0.98025535\n",
      "Iteration 8, loss = 1.03239250\n",
      "Iteration 9, loss = 0.97320302\n",
      "Iteration 10, loss = 0.98484489\n",
      "Iteration 11, loss = 1.01869785\n",
      "Iteration 12, loss = 0.96598489\n",
      "Iteration 13, loss = 1.00453505\n",
      "Iteration 14, loss = 0.96056033\n",
      "Iteration 1, loss = 1.19553029\n",
      "Iteration 2, loss = 1.08118323\n",
      "Iteration 3, loss = 1.05345879\n",
      "Iteration 4, loss = 1.01186419\n",
      "Iteration 5, loss = 0.99044154\n",
      "Iteration 6, loss = 1.01650339\n",
      "Iteration 7, loss = 0.98025535\n",
      "Iteration 8, loss = 1.03239250\n",
      "Iteration 9, loss = 0.97320302\n",
      "Iteration 10, loss = 0.98484489\n",
      "Iteration 11, loss = 1.01869785\n",
      "Iteration 12, loss = 0.96598489\n",
      "Iteration 13, loss = 1.00453505\n",
      "Iteration 14, loss = 0.96056033\n",
      "Iteration 15, loss = 1.00017452\n",
      "Iteration 16, loss = 0.93112343\n",
      "Iteration 17, loss = 0.95230737\n",
      "Iteration 18, loss = 0.98963479\n",
      "Iteration 19, loss = 1.03209011\n",
      "Iteration 20, loss = 1.02074508\n",
      "Iteration 21, loss = 1.00730848\n",
      "Iteration 22, loss = 1.03223103\n",
      "Iteration 23, loss = 1.04984976\n",
      "Iteration 24, loss = 1.04110100\n",
      "Iteration 25, loss = 0.98693413\n",
      "Iteration 26, loss = 0.99296001\n",
      "Iteration 27, loss = 0.99107757\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18691628\n",
      "Iteration 15, loss = 1.00017452\n",
      "Iteration 16, loss = 0.93112343\n",
      "Iteration 17, loss = 0.95230737\n",
      "Iteration 18, loss = 0.98963479\n",
      "Iteration 19, loss = 1.03209011\n",
      "Iteration 20, loss = 1.02074508\n",
      "Iteration 21, loss = 1.00730848\n",
      "Iteration 22, loss = 1.03223103\n",
      "Iteration 23, loss = 1.04984976\n",
      "Iteration 24, loss = 1.04110100\n",
      "Iteration 25, loss = 0.98693413\n",
      "Iteration 26, loss = 0.99296001\n",
      "Iteration 27, loss = 0.99107757\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18691628\n",
      "Iteration 2, loss = 1.08477588\n",
      "Iteration 3, loss = 1.03272501\n",
      "Iteration 4, loss = 1.01152331\n",
      "Iteration 5, loss = 1.00737273\n",
      "Iteration 6, loss = 0.96995550\n",
      "Iteration 7, loss = 1.04087237\n",
      "Iteration 8, loss = 1.02613182\n",
      "Iteration 9, loss = 0.99850805\n",
      "Iteration 10, loss = 1.01627675\n",
      "Iteration 11, loss = 0.98562186\n",
      "Iteration 12, loss = 0.98605878\n",
      "Iteration 13, loss = 0.98359036\n",
      "Iteration 14, loss = 0.96970836\n",
      "Iteration 15, loss = 1.00256618\n",
      "Iteration 2, loss = 1.08477588\n",
      "Iteration 3, loss = 1.03272501\n",
      "Iteration 4, loss = 1.01152331\n",
      "Iteration 5, loss = 1.00737273\n",
      "Iteration 6, loss = 0.96995550\n",
      "Iteration 7, loss = 1.04087237\n",
      "Iteration 8, loss = 1.02613182\n",
      "Iteration 9, loss = 0.99850805\n",
      "Iteration 10, loss = 1.01627675\n",
      "Iteration 11, loss = 0.98562186\n",
      "Iteration 12, loss = 0.98605878\n",
      "Iteration 13, loss = 0.98359036\n",
      "Iteration 14, loss = 0.96970836\n",
      "Iteration 15, loss = 1.00256618\n",
      "Iteration 16, loss = 0.97543770\n",
      "Iteration 17, loss = 0.97808578\n",
      "Iteration 18, loss = 0.97285786\n",
      "Iteration 19, loss = 0.94499850\n",
      "Iteration 20, loss = 0.97081806\n",
      "Iteration 21, loss = 0.95916614\n",
      "Iteration 22, loss = 0.93458005\n",
      "Iteration 23, loss = 0.96227251\n",
      "Iteration 24, loss = 1.07342256\n",
      "Iteration 25, loss = 1.00822756\n",
      "Iteration 26, loss = 0.99485509\n",
      "Iteration 27, loss = 0.97286779\n",
      "Iteration 28, loss = 1.11815931\n",
      "Iteration 29, loss = 0.97365230\n",
      "Iteration 30, loss = 0.98275274\n",
      "Iteration 31, loss = 0.98021257\n",
      "Iteration 16, loss = 0.97543770\n",
      "Iteration 17, loss = 0.97808578\n",
      "Iteration 18, loss = 0.97285786\n",
      "Iteration 19, loss = 0.94499850\n",
      "Iteration 20, loss = 0.97081806\n",
      "Iteration 21, loss = 0.95916614\n",
      "Iteration 22, loss = 0.93458005\n",
      "Iteration 23, loss = 0.96227251\n",
      "Iteration 24, loss = 1.07342256\n",
      "Iteration 25, loss = 1.00822756\n",
      "Iteration 26, loss = 0.99485509\n",
      "Iteration 27, loss = 0.97286779\n",
      "Iteration 28, loss = 1.11815931\n",
      "Iteration 29, loss = 0.97365230\n",
      "Iteration 30, loss = 0.98275274\n",
      "Iteration 31, loss = 0.98021257\n",
      "Iteration 32, loss = 0.96795718\n",
      "Iteration 33, loss = 0.96950946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16706325\n",
      "Iteration 2, loss = 0.96892909\n",
      "Iteration 3, loss = 0.96803220\n",
      "Iteration 4, loss = 0.94912044\n",
      "Iteration 5, loss = 0.93986571\n",
      "Iteration 6, loss = 0.95343576\n",
      "Iteration 7, loss = 0.94915383\n",
      "Iteration 8, loss = 0.94145347\n",
      "Iteration 9, loss = 0.98106064\n",
      "Iteration 10, loss = 0.96857799\n",
      "Iteration 32, loss = 0.96795718\n",
      "Iteration 33, loss = 0.96950946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16706325\n",
      "Iteration 2, loss = 0.96892909\n",
      "Iteration 3, loss = 0.96803220\n",
      "Iteration 4, loss = 0.94912044\n",
      "Iteration 5, loss = 0.93986571\n",
      "Iteration 6, loss = 0.95343576\n",
      "Iteration 7, loss = 0.94915383\n",
      "Iteration 8, loss = 0.94145347\n",
      "Iteration 9, loss = 0.98106064\n",
      "Iteration 10, loss = 0.96857799\n",
      "Iteration 11, loss = 0.91748340\n",
      "Iteration 12, loss = 1.01757264\n",
      "Iteration 13, loss = 1.04186488\n",
      "Iteration 14, loss = 0.95798598\n",
      "Iteration 15, loss = 0.97429903\n",
      "Iteration 16, loss = 0.91366803\n",
      "Iteration 17, loss = 0.91632067\n",
      "Iteration 18, loss = 0.98461576\n",
      "Iteration 19, loss = 0.91829881\n",
      "Iteration 20, loss = 0.96357988\n",
      "Iteration 21, loss = 0.89432925\n",
      "Iteration 22, loss = 0.94447849\n",
      "Iteration 23, loss = 0.94167538\n",
      "Iteration 24, loss = 0.92405998\n",
      "Iteration 25, loss = 0.91975354\n",
      "Iteration 26, loss = 0.91744335\n",
      "Iteration 11, loss = 0.91748340\n",
      "Iteration 12, loss = 1.01757264\n",
      "Iteration 13, loss = 1.04186488\n",
      "Iteration 14, loss = 0.95798598\n",
      "Iteration 15, loss = 0.97429903\n",
      "Iteration 16, loss = 0.91366803\n",
      "Iteration 17, loss = 0.91632067\n",
      "Iteration 18, loss = 0.98461576\n",
      "Iteration 19, loss = 0.91829881\n",
      "Iteration 20, loss = 0.96357988\n",
      "Iteration 21, loss = 0.89432925\n",
      "Iteration 22, loss = 0.94447849\n",
      "Iteration 23, loss = 0.94167538\n",
      "Iteration 24, loss = 0.92405998\n",
      "Iteration 25, loss = 0.91975354\n",
      "Iteration 26, loss = 0.91744335\n",
      "Iteration 27, loss = 0.88714270\n",
      "Iteration 28, loss = 0.89791774\n",
      "Iteration 29, loss = 0.91668362\n",
      "Iteration 30, loss = 0.93046508\n",
      "Iteration 31, loss = 0.88067163\n",
      "Iteration 32, loss = 0.86261079\n",
      "Iteration 33, loss = 0.85973830\n",
      "Iteration 34, loss = 0.95748705\n",
      "Iteration 35, loss = 1.02842874\n",
      "Iteration 36, loss = 0.98995617\n",
      "Iteration 37, loss = 0.96339522\n",
      "Iteration 38, loss = 0.93033580\n",
      "Iteration 39, loss = 0.93295445\n",
      "Iteration 40, loss = 0.89884861\n",
      "Iteration 41, loss = 1.01355794\n",
      "Iteration 42, loss = 0.91789553\n",
      "Iteration 27, loss = 0.88714270\n",
      "Iteration 28, loss = 0.89791774\n",
      "Iteration 29, loss = 0.91668362\n",
      "Iteration 30, loss = 0.93046508\n",
      "Iteration 31, loss = 0.88067163\n",
      "Iteration 32, loss = 0.86261079\n",
      "Iteration 33, loss = 0.85973830\n",
      "Iteration 34, loss = 0.95748705\n",
      "Iteration 35, loss = 1.02842874\n",
      "Iteration 36, loss = 0.98995617\n",
      "Iteration 37, loss = 0.96339522\n",
      "Iteration 38, loss = 0.93033580\n",
      "Iteration 39, loss = 0.93295445\n",
      "Iteration 40, loss = 0.89884861\n",
      "Iteration 41, loss = 1.01355794\n",
      "Iteration 42, loss = 0.91789553\n",
      "Iteration 43, loss = 0.97796399\n",
      "Iteration 44, loss = 0.90752986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20972300\n",
      "Iteration 2, loss = 1.02267284\n",
      "Iteration 3, loss = 1.00984867\n",
      "Iteration 4, loss = 0.98481300\n",
      "Iteration 5, loss = 0.99002921\n",
      "Iteration 6, loss = 0.98481513\n",
      "Iteration 7, loss = 0.95469721\n",
      "Iteration 8, loss = 0.92813315\n",
      "Iteration 9, loss = 0.98510596\n",
      "Iteration 10, loss = 0.95638291\n",
      "Iteration 11, loss = 0.95179256\n",
      "Iteration 43, loss = 0.97796399\n",
      "Iteration 44, loss = 0.90752986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20972300\n",
      "Iteration 2, loss = 1.02267284\n",
      "Iteration 3, loss = 1.00984867\n",
      "Iteration 4, loss = 0.98481300\n",
      "Iteration 5, loss = 0.99002921\n",
      "Iteration 6, loss = 0.98481513\n",
      "Iteration 7, loss = 0.95469721\n",
      "Iteration 8, loss = 0.92813315\n",
      "Iteration 9, loss = 0.98510596\n",
      "Iteration 10, loss = 0.95638291\n",
      "Iteration 11, loss = 0.95179256\n",
      "Iteration 12, loss = 0.97399284\n",
      "Iteration 13, loss = 0.93178213\n",
      "Iteration 14, loss = 0.92130294\n",
      "Iteration 15, loss = 0.93482259\n",
      "Iteration 16, loss = 0.93059286\n",
      "Iteration 17, loss = 0.95039596\n",
      "Iteration 18, loss = 0.94415941\n",
      "Iteration 19, loss = 0.92207328\n",
      "Iteration 20, loss = 0.91619774\n",
      "Iteration 21, loss = 0.92450803\n",
      "Iteration 22, loss = 0.94230061\n",
      "Iteration 23, loss = 1.05186848\n",
      "Iteration 24, loss = 0.96600304\n",
      "Iteration 25, loss = 0.90788913\n",
      "Iteration 26, loss = 0.92451047\n",
      "Iteration 12, loss = 0.97399284\n",
      "Iteration 13, loss = 0.93178213\n",
      "Iteration 14, loss = 0.92130294\n",
      "Iteration 15, loss = 0.93482259\n",
      "Iteration 16, loss = 0.93059286\n",
      "Iteration 17, loss = 0.95039596\n",
      "Iteration 18, loss = 0.94415941\n",
      "Iteration 19, loss = 0.92207328\n",
      "Iteration 20, loss = 0.91619774\n",
      "Iteration 21, loss = 0.92450803\n",
      "Iteration 22, loss = 0.94230061\n",
      "Iteration 23, loss = 1.05186848\n",
      "Iteration 24, loss = 0.96600304\n",
      "Iteration 25, loss = 0.90788913\n",
      "Iteration 26, loss = 0.92451047\n",
      "Iteration 27, loss = 0.90820736\n",
      "Iteration 28, loss = 0.96890120\n",
      "Iteration 29, loss = 0.95850700\n",
      "Iteration 30, loss = 0.93635338\n",
      "Iteration 31, loss = 0.91876787\n",
      "Iteration 32, loss = 0.91855582\n",
      "Iteration 33, loss = 0.90468401\n",
      "Iteration 34, loss = 0.93774054\n",
      "Iteration 35, loss = 1.00450448\n",
      "Iteration 36, loss = 0.94077613\n",
      "Iteration 37, loss = 0.92160255\n",
      "Iteration 38, loss = 0.91694502\n",
      "Iteration 39, loss = 0.89980994\n",
      "Iteration 40, loss = 0.92341234\n",
      "Iteration 41, loss = 0.91379592\n",
      "Iteration 42, loss = 0.90365719\n",
      "Iteration 27, loss = 0.90820736\n",
      "Iteration 28, loss = 0.96890120\n",
      "Iteration 29, loss = 0.95850700\n",
      "Iteration 30, loss = 0.93635338\n",
      "Iteration 31, loss = 0.91876787\n",
      "Iteration 32, loss = 0.91855582\n",
      "Iteration 33, loss = 0.90468401\n",
      "Iteration 34, loss = 0.93774054\n",
      "Iteration 35, loss = 1.00450448\n",
      "Iteration 36, loss = 0.94077613\n",
      "Iteration 37, loss = 0.92160255\n",
      "Iteration 38, loss = 0.91694502\n",
      "Iteration 39, loss = 0.89980994\n",
      "Iteration 40, loss = 0.92341234\n",
      "Iteration 41, loss = 0.91379592\n",
      "Iteration 42, loss = 0.90365719\n",
      "Iteration 43, loss = 0.93406528\n",
      "Iteration 44, loss = 0.91010591\n",
      "Iteration 45, loss = 0.90121368\n",
      "Iteration 46, loss = 0.89942151\n",
      "Iteration 47, loss = 0.87940830\n",
      "Iteration 48, loss = 0.88295680\n",
      "Iteration 49, loss = 0.89432846\n",
      "Iteration 50, loss = 0.88914668\n",
      "Iteration 51, loss = 0.86452212\n",
      "Iteration 52, loss = 0.87825045\n",
      "Iteration 53, loss = 0.88278358\n",
      "Iteration 54, loss = 0.84858983\n",
      "Iteration 55, loss = 0.92193183\n",
      "Iteration 56, loss = 0.89233986\n",
      "Iteration 57, loss = 0.89394101\n",
      "Iteration 58, loss = 0.86102999\n",
      "Iteration 43, loss = 0.93406528\n",
      "Iteration 44, loss = 0.91010591\n",
      "Iteration 45, loss = 0.90121368\n",
      "Iteration 46, loss = 0.89942151\n",
      "Iteration 47, loss = 0.87940830\n",
      "Iteration 48, loss = 0.88295680\n",
      "Iteration 49, loss = 0.89432846\n",
      "Iteration 50, loss = 0.88914668\n",
      "Iteration 51, loss = 0.86452212\n",
      "Iteration 52, loss = 0.87825045\n",
      "Iteration 53, loss = 0.88278358\n",
      "Iteration 54, loss = 0.84858983\n",
      "Iteration 55, loss = 0.92193183\n",
      "Iteration 56, loss = 0.89233986\n",
      "Iteration 57, loss = 0.89394101\n",
      "Iteration 58, loss = 0.86102999\n",
      "Iteration 59, loss = 0.87911926\n",
      "Iteration 60, loss = 0.88537086\n",
      "Iteration 61, loss = 0.87792906\n",
      "Iteration 62, loss = 0.91027854\n",
      "Iteration 63, loss = 0.89611175\n",
      "Iteration 64, loss = 0.87779459\n",
      "Iteration 65, loss = 0.89106205\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19272814\n",
      "Iteration 2, loss = 1.07730502\n",
      "Iteration 3, loss = 1.11254056\n",
      "Iteration 4, loss = 1.07092308\n",
      "Iteration 5, loss = 1.00716636\n",
      "Iteration 6, loss = 1.06642339\n",
      "Iteration 7, loss = 1.09918969\n",
      "Iteration 59, loss = 0.87911926\n",
      "Iteration 60, loss = 0.88537086\n",
      "Iteration 61, loss = 0.87792906\n",
      "Iteration 62, loss = 0.91027854\n",
      "Iteration 63, loss = 0.89611175\n",
      "Iteration 64, loss = 0.87779459\n",
      "Iteration 65, loss = 0.89106205\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19272814\n",
      "Iteration 2, loss = 1.07730502\n",
      "Iteration 3, loss = 1.11254056\n",
      "Iteration 4, loss = 1.07092308\n",
      "Iteration 5, loss = 1.00716636\n",
      "Iteration 6, loss = 1.06642339\n",
      "Iteration 7, loss = 1.09918969\n",
      "Iteration 8, loss = 1.00167986\n",
      "Iteration 9, loss = 1.04608944\n",
      "Iteration 10, loss = 1.03729875\n",
      "Iteration 11, loss = 1.07332647\n",
      "Iteration 12, loss = 1.08398838\n",
      "Iteration 13, loss = 1.01555384\n",
      "Iteration 14, loss = 1.06378246\n",
      "Iteration 15, loss = 1.01078002\n",
      "Iteration 16, loss = 0.96570868\n",
      "Iteration 17, loss = 1.00302524\n",
      "Iteration 18, loss = 0.95499174\n",
      "Iteration 19, loss = 0.97639292\n",
      "Iteration 20, loss = 0.98423565\n",
      "Iteration 21, loss = 0.97041864\n",
      "Iteration 8, loss = 1.00167986\n",
      "Iteration 9, loss = 1.04608944\n",
      "Iteration 10, loss = 1.03729875\n",
      "Iteration 11, loss = 1.07332647\n",
      "Iteration 12, loss = 1.08398838\n",
      "Iteration 13, loss = 1.01555384\n",
      "Iteration 14, loss = 1.06378246\n",
      "Iteration 15, loss = 1.01078002\n",
      "Iteration 16, loss = 0.96570868\n",
      "Iteration 17, loss = 1.00302524\n",
      "Iteration 18, loss = 0.95499174\n",
      "Iteration 19, loss = 0.97639292\n",
      "Iteration 20, loss = 0.98423565\n",
      "Iteration 21, loss = 0.97041864\n",
      "Iteration 22, loss = 1.00613276\n",
      "Iteration 23, loss = 0.99535593\n",
      "Iteration 24, loss = 0.96374874\n",
      "Iteration 25, loss = 0.94190980\n",
      "Iteration 26, loss = 0.97906921\n",
      "Iteration 27, loss = 0.97763161\n",
      "Iteration 28, loss = 0.96745634\n",
      "Iteration 29, loss = 1.05035827\n",
      "Iteration 30, loss = 0.99658316\n",
      "Iteration 31, loss = 0.99396707\n",
      "Iteration 32, loss = 1.06387996\n",
      "Iteration 33, loss = 1.06681610\n",
      "Iteration 34, loss = 1.08143785\n",
      "Iteration 35, loss = 1.09498499\n",
      "Iteration 36, loss = 1.02864072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 1.00613276\n",
      "Iteration 23, loss = 0.99535593\n",
      "Iteration 24, loss = 0.96374874\n",
      "Iteration 25, loss = 0.94190980\n",
      "Iteration 26, loss = 0.97906921\n",
      "Iteration 27, loss = 0.97763161\n",
      "Iteration 28, loss = 0.96745634\n",
      "Iteration 29, loss = 1.05035827\n",
      "Iteration 30, loss = 0.99658316\n",
      "Iteration 31, loss = 0.99396707\n",
      "Iteration 32, loss = 1.06387996\n",
      "Iteration 33, loss = 1.06681610\n",
      "Iteration 34, loss = 1.08143785\n",
      "Iteration 35, loss = 1.09498499\n",
      "Iteration 36, loss = 1.02864072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19553029\n",
      "Iteration 2, loss = 1.08118323\n",
      "Iteration 3, loss = 1.05345879\n",
      "Iteration 4, loss = 1.01186419\n",
      "Iteration 5, loss = 0.99044154\n",
      "Iteration 6, loss = 1.01650339\n",
      "Iteration 7, loss = 0.98025535\n",
      "Iteration 8, loss = 1.03239250\n",
      "Iteration 9, loss = 0.97320302\n",
      "Iteration 10, loss = 0.98484489\n",
      "Iteration 11, loss = 1.01869785\n",
      "Iteration 12, loss = 0.96598489\n",
      "Iteration 13, loss = 1.00453505\n",
      "Iteration 1, loss = 1.19553029\n",
      "Iteration 2, loss = 1.08118323\n",
      "Iteration 3, loss = 1.05345879\n",
      "Iteration 4, loss = 1.01186419\n",
      "Iteration 5, loss = 0.99044154\n",
      "Iteration 6, loss = 1.01650339\n",
      "Iteration 7, loss = 0.98025535\n",
      "Iteration 8, loss = 1.03239250\n",
      "Iteration 9, loss = 0.97320302\n",
      "Iteration 10, loss = 0.98484489\n",
      "Iteration 11, loss = 1.01869785\n",
      "Iteration 12, loss = 0.96598489\n",
      "Iteration 13, loss = 1.00453505\n",
      "Iteration 14, loss = 0.96056033\n",
      "Iteration 15, loss = 1.00017452\n",
      "Iteration 16, loss = 0.93112343\n",
      "Iteration 17, loss = 0.95230737\n",
      "Iteration 18, loss = 0.98963479\n",
      "Iteration 19, loss = 1.03209011\n",
      "Iteration 20, loss = 1.02074508\n",
      "Iteration 21, loss = 1.00730848\n",
      "Iteration 22, loss = 1.03223103\n",
      "Iteration 23, loss = 1.04984976\n",
      "Iteration 24, loss = 1.04110100\n",
      "Iteration 25, loss = 0.98693413\n",
      "Iteration 26, loss = 0.99296001\n",
      "Iteration 27, loss = 0.99107757\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20142221\n",
      "Iteration 14, loss = 0.96056033\n",
      "Iteration 15, loss = 1.00017452\n",
      "Iteration 16, loss = 0.93112343\n",
      "Iteration 17, loss = 0.95230737\n",
      "Iteration 18, loss = 0.98963479\n",
      "Iteration 19, loss = 1.03209011\n",
      "Iteration 20, loss = 1.02074508\n",
      "Iteration 21, loss = 1.00730848\n",
      "Iteration 22, loss = 1.03223103\n",
      "Iteration 23, loss = 1.04984976\n",
      "Iteration 24, loss = 1.04110100\n",
      "Iteration 25, loss = 0.98693413\n",
      "Iteration 26, loss = 0.99296001\n",
      "Iteration 27, loss = 0.99107757\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20142221\n",
      "Iteration 2, loss = 1.08005844\n",
      "Iteration 3, loss = 1.11319159\n",
      "Iteration 4, loss = 1.03586449\n",
      "Iteration 5, loss = 1.07050720\n",
      "Iteration 6, loss = 1.09686563\n",
      "Iteration 7, loss = 1.08717271\n",
      "Iteration 8, loss = 1.09075397\n",
      "Iteration 9, loss = 0.99914535\n",
      "Iteration 10, loss = 0.99202230\n",
      "Iteration 1, loss = 1.20678400\n",
      "Iteration 2, loss = 1.08005844\n",
      "Iteration 3, loss = 1.11319159\n",
      "Iteration 4, loss = 1.03586449\n",
      "Iteration 5, loss = 1.07050720\n",
      "Iteration 6, loss = 1.09686563\n",
      "Iteration 7, loss = 1.08717271\n",
      "Iteration 8, loss = 1.09075397\n",
      "Iteration 9, loss = 0.99914535\n",
      "Iteration 10, loss = 0.99202230\n",
      "Iteration 1, loss = 1.20678400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.98172192\n",
      "Iteration 3, loss = 0.98494001\n",
      "Iteration 4, loss = 0.95141651\n",
      "Iteration 5, loss = 1.01610086\n",
      "Iteration 6, loss = 1.03908852\n",
      "Iteration 7, loss = 1.07571116\n",
      "Iteration 8, loss = 1.01843699\n",
      "Iteration 9, loss = 0.97823360\n",
      "Iteration 10, loss = 0.95490293\n",
      "Iteration 1, loss = 1.23953703\n",
      "Iteration 2, loss = 1.03563442\n",
      "Iteration 3, loss = 1.16281591\n",
      "Iteration 4, loss = 1.25566806\n",
      "Iteration 2, loss = 0.98172192\n",
      "Iteration 3, loss = 0.98494001\n",
      "Iteration 4, loss = 0.95141651\n",
      "Iteration 5, loss = 1.01610086\n",
      "Iteration 6, loss = 1.03908852\n",
      "Iteration 7, loss = 1.07571116\n",
      "Iteration 8, loss = 1.01843699\n",
      "Iteration 9, loss = 0.97823360\n",
      "Iteration 10, loss = 0.95490293\n",
      "Iteration 1, loss = 1.23953703\n",
      "Iteration 2, loss = 1.03563442\n",
      "Iteration 3, loss = 1.16281591\n",
      "Iteration 4, loss = 1.25566806\n",
      "Iteration 5, loss = 1.26893118\n",
      "Iteration 6, loss = 1.26114202\n",
      "Iteration 7, loss = 1.27359665\n",
      "Iteration 8, loss = 1.24859494\n",
      "Iteration 9, loss = 1.28903531\n",
      "Iteration 10, loss = 1.26379777\n",
      "Iteration 1, loss = 1.20499309\n",
      "Iteration 2, loss = 1.12832782\n",
      "Iteration 3, loss = 1.07182540\n",
      "Iteration 4, loss = 1.04350859\n",
      "Iteration 5, loss = 1.00929755\n",
      "Iteration 6, loss = 1.09791510\n",
      "Iteration 7, loss = 1.02620632\n",
      "Iteration 8, loss = 1.07437209\n",
      "Iteration 5, loss = 1.26893118\n",
      "Iteration 6, loss = 1.26114202\n",
      "Iteration 7, loss = 1.27359665\n",
      "Iteration 8, loss = 1.24859494\n",
      "Iteration 9, loss = 1.28903531\n",
      "Iteration 10, loss = 1.26379777\n",
      "Iteration 1, loss = 1.20499309\n",
      "Iteration 2, loss = 1.12832782\n",
      "Iteration 3, loss = 1.07182540\n",
      "Iteration 4, loss = 1.04350859\n",
      "Iteration 5, loss = 1.00929755\n",
      "Iteration 6, loss = 1.09791510\n",
      "Iteration 7, loss = 1.02620632\n",
      "Iteration 8, loss = 1.07437209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.03047891\n",
      "Iteration 10, loss = 1.07586059\n",
      "Iteration 1, loss = 1.24477097\n",
      "Iteration 2, loss = 1.05487787\n",
      "Iteration 3, loss = 1.09799019\n",
      "Iteration 4, loss = 1.06052341\n",
      "Iteration 5, loss = 1.01337212\n",
      "Iteration 6, loss = 0.95271549\n",
      "Iteration 7, loss = 1.04938326\n",
      "Iteration 8, loss = 1.01538743\n",
      "Iteration 9, loss = 1.00694932\n",
      "Iteration 10, loss = 1.07728201\n",
      "Iteration 1, loss = 1.20142221\n",
      "Iteration 9, loss = 1.03047891\n",
      "Iteration 10, loss = 1.07586059\n",
      "Iteration 1, loss = 1.24477097\n",
      "Iteration 2, loss = 1.05487787\n",
      "Iteration 3, loss = 1.09799019\n",
      "Iteration 4, loss = 1.06052341\n",
      "Iteration 5, loss = 1.01337212\n",
      "Iteration 6, loss = 0.95271549\n",
      "Iteration 7, loss = 1.04938326\n",
      "Iteration 8, loss = 1.01538743\n",
      "Iteration 9, loss = 1.00694932\n",
      "Iteration 10, loss = 1.07728201\n",
      "Iteration 1, loss = 1.20142221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.08005844\n",
      "Iteration 3, loss = 1.11319159\n",
      "Iteration 4, loss = 1.03586449\n",
      "Iteration 5, loss = 1.07050720\n",
      "Iteration 6, loss = 1.09686563\n",
      "Iteration 7, loss = 1.08717271\n",
      "Iteration 8, loss = 1.09075397\n",
      "Iteration 9, loss = 0.99914535\n",
      "Iteration 10, loss = 0.99202230\n",
      "Iteration 11, loss = 1.00239613\n",
      "Iteration 12, loss = 0.99838803\n",
      "Iteration 13, loss = 0.99157191\n",
      "Iteration 14, loss = 0.98782483\n",
      "Iteration 15, loss = 0.99501711\n",
      "Iteration 2, loss = 1.08005844\n",
      "Iteration 3, loss = 1.11319159\n",
      "Iteration 4, loss = 1.03586449\n",
      "Iteration 5, loss = 1.07050720\n",
      "Iteration 6, loss = 1.09686563\n",
      "Iteration 7, loss = 1.08717271\n",
      "Iteration 8, loss = 1.09075397\n",
      "Iteration 9, loss = 0.99914535\n",
      "Iteration 10, loss = 0.99202230\n",
      "Iteration 11, loss = 1.00239613\n",
      "Iteration 12, loss = 0.99838803\n",
      "Iteration 13, loss = 0.99157191\n",
      "Iteration 14, loss = 0.98782483\n",
      "Iteration 15, loss = 0.99501711\n",
      "Iteration 16, loss = 0.98436494\n",
      "Iteration 17, loss = 0.99059351\n",
      "Iteration 18, loss = 0.98336514\n",
      "Iteration 19, loss = 0.97616611\n",
      "Iteration 20, loss = 0.98591765\n",
      "Iteration 21, loss = 0.98012618\n",
      "Iteration 22, loss = 0.99094056\n",
      "Iteration 23, loss = 0.98910094\n",
      "Iteration 24, loss = 0.98691070\n",
      "Iteration 25, loss = 0.99996927\n",
      "Iteration 26, loss = 0.98699075\n",
      "Iteration 27, loss = 0.98124657\n",
      "Iteration 28, loss = 1.00213235\n",
      "Iteration 29, loss = 0.98426122\n",
      "Iteration 16, loss = 0.98436494\n",
      "Iteration 17, loss = 0.99059351\n",
      "Iteration 18, loss = 0.98336514\n",
      "Iteration 19, loss = 0.97616611\n",
      "Iteration 20, loss = 0.98591765\n",
      "Iteration 21, loss = 0.98012618\n",
      "Iteration 22, loss = 0.99094056\n",
      "Iteration 23, loss = 0.98910094\n",
      "Iteration 24, loss = 0.98691070\n",
      "Iteration 25, loss = 0.99996927\n",
      "Iteration 26, loss = 0.98699075\n",
      "Iteration 27, loss = 0.98124657\n",
      "Iteration 28, loss = 1.00213235\n",
      "Iteration 29, loss = 0.98426122\n",
      "Iteration 30, loss = 0.96525609\n",
      "Iteration 31, loss = 0.99152298\n",
      "Iteration 32, loss = 0.98014305\n",
      "Iteration 33, loss = 0.98475624\n",
      "Iteration 34, loss = 0.98739005\n",
      "Iteration 35, loss = 0.98939906\n",
      "Iteration 36, loss = 1.00216872\n",
      "Iteration 37, loss = 0.98864324\n",
      "Iteration 38, loss = 1.00208019\n",
      "Iteration 39, loss = 0.98819379\n",
      "Iteration 40, loss = 0.97525955\n",
      "Iteration 41, loss = 1.01235455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20678400\n",
      "Iteration 2, loss = 0.98172192\n",
      "Iteration 3, loss = 0.98494001\n",
      "Iteration 30, loss = 0.96525609\n",
      "Iteration 31, loss = 0.99152298\n",
      "Iteration 32, loss = 0.98014305\n",
      "Iteration 33, loss = 0.98475624\n",
      "Iteration 34, loss = 0.98739005\n",
      "Iteration 35, loss = 0.98939906\n",
      "Iteration 36, loss = 1.00216872\n",
      "Iteration 37, loss = 0.98864324\n",
      "Iteration 38, loss = 1.00208019\n",
      "Iteration 39, loss = 0.98819379\n",
      "Iteration 40, loss = 0.97525955\n",
      "Iteration 41, loss = 1.01235455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20678400\n",
      "Iteration 2, loss = 0.98172192\n",
      "Iteration 3, loss = 0.98494001\n",
      "Iteration 4, loss = 0.95141651\n",
      "Iteration 5, loss = 1.01610086\n",
      "Iteration 6, loss = 1.03908852\n",
      "Iteration 7, loss = 1.07571116\n",
      "Iteration 8, loss = 1.01843699\n",
      "Iteration 9, loss = 0.97823360\n",
      "Iteration 10, loss = 0.95490293\n",
      "Iteration 11, loss = 0.95365463\n",
      "Iteration 12, loss = 0.98384601\n",
      "Iteration 13, loss = 0.96578230\n",
      "Iteration 14, loss = 0.93784110\n",
      "Iteration 15, loss = 0.95424867\n",
      "Iteration 16, loss = 0.92572458\n",
      "Iteration 17, loss = 0.95146730\n",
      "Iteration 18, loss = 0.95630281\n",
      "Iteration 19, loss = 0.93039666\n",
      "Iteration 4, loss = 0.95141651\n",
      "Iteration 5, loss = 1.01610086\n",
      "Iteration 6, loss = 1.03908852\n",
      "Iteration 7, loss = 1.07571116\n",
      "Iteration 8, loss = 1.01843699\n",
      "Iteration 9, loss = 0.97823360\n",
      "Iteration 10, loss = 0.95490293\n",
      "Iteration 11, loss = 0.95365463\n",
      "Iteration 12, loss = 0.98384601\n",
      "Iteration 13, loss = 0.96578230\n",
      "Iteration 14, loss = 0.93784110\n",
      "Iteration 15, loss = 0.95424867\n",
      "Iteration 16, loss = 0.92572458\n",
      "Iteration 17, loss = 0.95146730\n",
      "Iteration 18, loss = 0.95630281\n",
      "Iteration 19, loss = 0.93039666\n",
      "Iteration 20, loss = 0.94193574\n",
      "Iteration 21, loss = 0.91953441\n",
      "Iteration 22, loss = 0.93725139\n",
      "Iteration 23, loss = 0.94344562\n",
      "Iteration 24, loss = 0.91671920\n",
      "Iteration 25, loss = 0.93923208\n",
      "Iteration 26, loss = 0.94975430\n",
      "Iteration 27, loss = 0.93121986\n",
      "Iteration 28, loss = 0.92740587\n",
      "Iteration 29, loss = 0.91690336\n",
      "Iteration 30, loss = 0.91023487\n",
      "Iteration 31, loss = 0.93549638\n",
      "Iteration 32, loss = 0.92531702\n",
      "Iteration 33, loss = 0.93379549\n",
      "Iteration 34, loss = 0.92296600\n",
      "Iteration 35, loss = 0.92903882\n",
      "Iteration 20, loss = 0.94193574\n",
      "Iteration 21, loss = 0.91953441\n",
      "Iteration 22, loss = 0.93725139\n",
      "Iteration 23, loss = 0.94344562\n",
      "Iteration 24, loss = 0.91671920\n",
      "Iteration 25, loss = 0.93923208\n",
      "Iteration 26, loss = 0.94975430\n",
      "Iteration 27, loss = 0.93121986\n",
      "Iteration 28, loss = 0.92740587\n",
      "Iteration 29, loss = 0.91690336\n",
      "Iteration 30, loss = 0.91023487\n",
      "Iteration 31, loss = 0.93549638\n",
      "Iteration 32, loss = 0.92531702\n",
      "Iteration 33, loss = 0.93379549\n",
      "Iteration 34, loss = 0.92296600\n",
      "Iteration 35, loss = 0.92903882\n",
      "Iteration 36, loss = 0.94272136\n",
      "Iteration 37, loss = 0.92010203\n",
      "Iteration 38, loss = 0.93110173\n",
      "Iteration 39, loss = 0.92583589\n",
      "Iteration 40, loss = 0.92755348\n",
      "Iteration 41, loss = 0.93820007\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23953703\n",
      "Iteration 2, loss = 1.03563442\n",
      "Iteration 3, loss = 1.16281591\n",
      "Iteration 4, loss = 1.25566806\n",
      "Iteration 5, loss = 1.26893118\n",
      "Iteration 6, loss = 1.26114202\n",
      "Iteration 36, loss = 0.94272136\n",
      "Iteration 37, loss = 0.92010203\n",
      "Iteration 38, loss = 0.93110173\n",
      "Iteration 39, loss = 0.92583589\n",
      "Iteration 40, loss = 0.92755348\n",
      "Iteration 41, loss = 0.93820007\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23953703\n",
      "Iteration 2, loss = 1.03563442\n",
      "Iteration 3, loss = 1.16281591\n",
      "Iteration 4, loss = 1.25566806\n",
      "Iteration 5, loss = 1.26893118\n",
      "Iteration 6, loss = 1.26114202\n",
      "Iteration 7, loss = 1.27359665\n",
      "Iteration 8, loss = 1.24859494\n",
      "Iteration 9, loss = 1.28903531\n",
      "Iteration 10, loss = 1.26379777\n",
      "Iteration 11, loss = 1.26480022\n",
      "Iteration 12, loss = 1.25591067\n",
      "Iteration 13, loss = 1.26081528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20499309\n",
      "Iteration 2, loss = 1.12832782\n",
      "Iteration 3, loss = 1.07182540\n",
      "Iteration 4, loss = 1.04350859\n",
      "Iteration 5, loss = 1.00929755\n",
      "Iteration 6, loss = 1.09791510\n",
      "Iteration 7, loss = 1.27359665\n",
      "Iteration 8, loss = 1.24859494\n",
      "Iteration 9, loss = 1.28903531\n",
      "Iteration 10, loss = 1.26379777\n",
      "Iteration 11, loss = 1.26480022\n",
      "Iteration 12, loss = 1.25591067\n",
      "Iteration 13, loss = 1.26081528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20499309\n",
      "Iteration 2, loss = 1.12832782\n",
      "Iteration 3, loss = 1.07182540\n",
      "Iteration 4, loss = 1.04350859\n",
      "Iteration 5, loss = 1.00929755\n",
      "Iteration 6, loss = 1.09791510\n",
      "Iteration 7, loss = 1.02620632\n",
      "Iteration 8, loss = 1.07437209\n",
      "Iteration 9, loss = 1.03047891\n",
      "Iteration 10, loss = 1.07586059\n",
      "Iteration 11, loss = 1.05094425\n",
      "Iteration 12, loss = 1.08286261\n",
      "Iteration 13, loss = 1.08180604\n",
      "Iteration 14, loss = 1.10068602\n",
      "Iteration 15, loss = 1.11307141\n",
      "Iteration 16, loss = 1.04415194\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24477097\n",
      "Iteration 2, loss = 1.05487787\n",
      "Iteration 7, loss = 1.02620632\n",
      "Iteration 8, loss = 1.07437209\n",
      "Iteration 9, loss = 1.03047891\n",
      "Iteration 10, loss = 1.07586059\n",
      "Iteration 11, loss = 1.05094425\n",
      "Iteration 12, loss = 1.08286261\n",
      "Iteration 13, loss = 1.08180604\n",
      "Iteration 14, loss = 1.10068602\n",
      "Iteration 15, loss = 1.11307141\n",
      "Iteration 16, loss = 1.04415194\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24477097\n",
      "Iteration 2, loss = 1.05487787\n",
      "Iteration 3, loss = 1.09799019\n",
      "Iteration 4, loss = 1.06052341\n",
      "Iteration 5, loss = 1.01337212\n",
      "Iteration 6, loss = 0.95271549\n",
      "Iteration 7, loss = 1.04938326\n",
      "Iteration 8, loss = 1.01538743\n",
      "Iteration 9, loss = 1.00694932\n",
      "Iteration 10, loss = 1.07728201\n",
      "Iteration 11, loss = 1.00964270\n",
      "Iteration 12, loss = 1.04869672\n",
      "Iteration 13, loss = 1.00455099\n",
      "Iteration 14, loss = 0.97354560\n",
      "Iteration 15, loss = 0.98219614\n",
      "Iteration 16, loss = 0.98002311\n",
      "Iteration 3, loss = 1.09799019\n",
      "Iteration 4, loss = 1.06052341\n",
      "Iteration 5, loss = 1.01337212\n",
      "Iteration 6, loss = 0.95271549\n",
      "Iteration 7, loss = 1.04938326\n",
      "Iteration 8, loss = 1.01538743\n",
      "Iteration 9, loss = 1.00694932\n",
      "Iteration 10, loss = 1.07728201\n",
      "Iteration 11, loss = 1.00964270\n",
      "Iteration 12, loss = 1.04869672\n",
      "Iteration 13, loss = 1.00455099\n",
      "Iteration 14, loss = 0.97354560\n",
      "Iteration 15, loss = 0.98219614\n",
      "Iteration 16, loss = 0.98002311\n",
      "Iteration 17, loss = 0.98378148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20142221\n",
      "Iteration 2, loss = 1.08005844\n",
      "Iteration 3, loss = 1.11319159\n",
      "Iteration 4, loss = 1.03586449\n",
      "Iteration 5, loss = 1.07050720\n",
      "Iteration 6, loss = 1.09686563\n",
      "Iteration 7, loss = 1.08717271\n",
      "Iteration 8, loss = 1.09075397\n",
      "Iteration 9, loss = 0.99914535\n",
      "Iteration 10, loss = 0.99202230\n",
      "Iteration 17, loss = 0.98378148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20142221\n",
      "Iteration 2, loss = 1.08005844\n",
      "Iteration 3, loss = 1.11319159\n",
      "Iteration 4, loss = 1.03586449\n",
      "Iteration 5, loss = 1.07050720\n",
      "Iteration 6, loss = 1.09686563\n",
      "Iteration 7, loss = 1.08717271\n",
      "Iteration 8, loss = 1.09075397\n",
      "Iteration 9, loss = 0.99914535\n",
      "Iteration 10, loss = 0.99202230\n",
      "Iteration 11, loss = 1.00239613\n",
      "Iteration 12, loss = 0.99838803\n",
      "Iteration 13, loss = 0.99157191\n",
      "Iteration 14, loss = 0.98782483\n",
      "Iteration 15, loss = 0.99501711\n",
      "Iteration 16, loss = 0.98436494\n",
      "Iteration 17, loss = 0.99059351\n",
      "Iteration 18, loss = 0.98336514\n",
      "Iteration 19, loss = 0.97616611\n",
      "Iteration 20, loss = 0.98591765\n",
      "Iteration 21, loss = 0.98012618\n",
      "Iteration 22, loss = 0.99094056\n",
      "Iteration 23, loss = 0.98910094\n",
      "Iteration 24, loss = 0.98691070\n",
      "Iteration 25, loss = 0.99996927\n",
      "Iteration 11, loss = 1.00239613\n",
      "Iteration 12, loss = 0.99838803\n",
      "Iteration 13, loss = 0.99157191\n",
      "Iteration 14, loss = 0.98782483\n",
      "Iteration 15, loss = 0.99501711\n",
      "Iteration 16, loss = 0.98436494\n",
      "Iteration 17, loss = 0.99059351\n",
      "Iteration 18, loss = 0.98336514\n",
      "Iteration 19, loss = 0.97616611\n",
      "Iteration 20, loss = 0.98591765\n",
      "Iteration 21, loss = 0.98012618\n",
      "Iteration 22, loss = 0.99094056\n",
      "Iteration 23, loss = 0.98910094\n",
      "Iteration 24, loss = 0.98691070\n",
      "Iteration 25, loss = 0.99996927\n",
      "Iteration 26, loss = 0.98699075\n",
      "Iteration 27, loss = 0.98124657\n",
      "Iteration 28, loss = 1.00213235\n",
      "Iteration 29, loss = 0.98426122\n",
      "Iteration 30, loss = 0.96525609\n",
      "Iteration 31, loss = 0.99152298\n",
      "Iteration 32, loss = 0.98014305\n",
      "Iteration 33, loss = 0.98475624\n",
      "Iteration 34, loss = 0.98739005\n",
      "Iteration 35, loss = 0.98939906\n",
      "Iteration 36, loss = 1.00216872\n",
      "Iteration 37, loss = 0.98864324\n",
      "Iteration 38, loss = 1.00208019\n",
      "Iteration 39, loss = 0.98819379\n",
      "Iteration 40, loss = 0.97525955\n",
      "Iteration 41, loss = 1.01235455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20678400\n",
      "Iteration 26, loss = 0.98699075\n",
      "Iteration 27, loss = 0.98124657\n",
      "Iteration 28, loss = 1.00213235\n",
      "Iteration 29, loss = 0.98426122\n",
      "Iteration 30, loss = 0.96525609\n",
      "Iteration 31, loss = 0.99152298\n",
      "Iteration 32, loss = 0.98014305\n",
      "Iteration 33, loss = 0.98475624\n",
      "Iteration 34, loss = 0.98739005\n",
      "Iteration 35, loss = 0.98939906\n",
      "Iteration 36, loss = 1.00216872\n",
      "Iteration 37, loss = 0.98864324\n",
      "Iteration 38, loss = 1.00208019\n",
      "Iteration 39, loss = 0.98819379\n",
      "Iteration 40, loss = 0.97525955\n",
      "Iteration 41, loss = 1.01235455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20678400\n",
      "Iteration 2, loss = 0.98172192\n",
      "Iteration 3, loss = 0.98494001\n",
      "Iteration 4, loss = 0.95141651\n",
      "Iteration 5, loss = 1.01610086\n",
      "Iteration 6, loss = 1.03908852\n",
      "Iteration 7, loss = 1.07571116\n",
      "Iteration 8, loss = 1.01843699\n",
      "Iteration 9, loss = 0.97823360\n",
      "Iteration 10, loss = 0.95490293\n",
      "Iteration 11, loss = 0.95365463\n",
      "Iteration 12, loss = 0.98384601\n",
      "Iteration 13, loss = 0.96578230\n",
      "Iteration 14, loss = 0.93784110\n",
      "Iteration 2, loss = 0.98172192\n",
      "Iteration 3, loss = 0.98494001\n",
      "Iteration 4, loss = 0.95141651\n",
      "Iteration 5, loss = 1.01610086\n",
      "Iteration 6, loss = 1.03908852\n",
      "Iteration 7, loss = 1.07571116\n",
      "Iteration 8, loss = 1.01843699\n",
      "Iteration 9, loss = 0.97823360\n",
      "Iteration 10, loss = 0.95490293\n",
      "Iteration 11, loss = 0.95365463\n",
      "Iteration 12, loss = 0.98384601\n",
      "Iteration 13, loss = 0.96578230\n",
      "Iteration 14, loss = 0.93784110\n",
      "Iteration 15, loss = 0.95424867\n",
      "Iteration 16, loss = 0.92572458\n",
      "Iteration 17, loss = 0.95146730\n",
      "Iteration 18, loss = 0.95630281\n",
      "Iteration 19, loss = 0.93039666\n",
      "Iteration 20, loss = 0.94193574\n",
      "Iteration 21, loss = 0.91953441\n",
      "Iteration 22, loss = 0.93725139\n",
      "Iteration 23, loss = 0.94344562\n",
      "Iteration 24, loss = 0.91671920\n",
      "Iteration 25, loss = 0.93923208\n",
      "Iteration 26, loss = 0.94975430\n",
      "Iteration 27, loss = 0.93121986\n",
      "Iteration 28, loss = 0.92740587\n",
      "Iteration 29, loss = 0.91690336\n",
      "Iteration 30, loss = 0.91023487\n",
      "Iteration 15, loss = 0.95424867\n",
      "Iteration 16, loss = 0.92572458\n",
      "Iteration 17, loss = 0.95146730\n",
      "Iteration 18, loss = 0.95630281\n",
      "Iteration 19, loss = 0.93039666\n",
      "Iteration 20, loss = 0.94193574\n",
      "Iteration 21, loss = 0.91953441\n",
      "Iteration 22, loss = 0.93725139\n",
      "Iteration 23, loss = 0.94344562\n",
      "Iteration 24, loss = 0.91671920\n",
      "Iteration 25, loss = 0.93923208\n",
      "Iteration 26, loss = 0.94975430\n",
      "Iteration 27, loss = 0.93121986\n",
      "Iteration 28, loss = 0.92740587\n",
      "Iteration 29, loss = 0.91690336\n",
      "Iteration 30, loss = 0.91023487\n",
      "Iteration 31, loss = 0.93549638\n",
      "Iteration 32, loss = 0.92531702\n",
      "Iteration 33, loss = 0.93379549\n",
      "Iteration 34, loss = 0.92296600\n",
      "Iteration 35, loss = 0.92903882\n",
      "Iteration 36, loss = 0.94272136\n",
      "Iteration 37, loss = 0.92010203\n",
      "Iteration 38, loss = 0.93110173\n",
      "Iteration 39, loss = 0.92583589\n",
      "Iteration 40, loss = 0.92755348\n",
      "Iteration 41, loss = 0.93820007\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23953703\n",
      "Iteration 2, loss = 1.03563442\n",
      "Iteration 31, loss = 0.93549638\n",
      "Iteration 32, loss = 0.92531702\n",
      "Iteration 33, loss = 0.93379549\n",
      "Iteration 34, loss = 0.92296600\n",
      "Iteration 35, loss = 0.92903882\n",
      "Iteration 36, loss = 0.94272136\n",
      "Iteration 37, loss = 0.92010203\n",
      "Iteration 38, loss = 0.93110173\n",
      "Iteration 39, loss = 0.92583589\n",
      "Iteration 40, loss = 0.92755348\n",
      "Iteration 41, loss = 0.93820007\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23953703\n",
      "Iteration 2, loss = 1.03563442\n",
      "Iteration 3, loss = 1.16281591\n",
      "Iteration 4, loss = 1.25566806\n",
      "Iteration 5, loss = 1.26893118\n",
      "Iteration 6, loss = 1.26114202\n",
      "Iteration 7, loss = 1.27359665\n",
      "Iteration 8, loss = 1.24859494\n",
      "Iteration 9, loss = 1.28903531\n",
      "Iteration 10, loss = 1.26379777\n",
      "Iteration 11, loss = 1.26480022\n",
      "Iteration 12, loss = 1.25591067\n",
      "Iteration 13, loss = 1.26081528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20499309\n",
      "Iteration 2, loss = 1.12832782\n",
      "Iteration 3, loss = 1.07182540\n",
      "Iteration 3, loss = 1.16281591\n",
      "Iteration 4, loss = 1.25566806\n",
      "Iteration 5, loss = 1.26893118\n",
      "Iteration 6, loss = 1.26114202\n",
      "Iteration 7, loss = 1.27359665\n",
      "Iteration 8, loss = 1.24859494\n",
      "Iteration 9, loss = 1.28903531\n",
      "Iteration 10, loss = 1.26379777\n",
      "Iteration 11, loss = 1.26480022\n",
      "Iteration 12, loss = 1.25591067\n",
      "Iteration 13, loss = 1.26081528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20499309\n",
      "Iteration 2, loss = 1.12832782\n",
      "Iteration 3, loss = 1.07182540\n",
      "Iteration 4, loss = 1.04350859\n",
      "Iteration 5, loss = 1.00929755\n",
      "Iteration 6, loss = 1.09791510\n",
      "Iteration 7, loss = 1.02620632\n",
      "Iteration 8, loss = 1.07437209\n",
      "Iteration 9, loss = 1.03047891\n",
      "Iteration 10, loss = 1.07586059\n",
      "Iteration 11, loss = 1.05094425\n",
      "Iteration 12, loss = 1.08286261\n",
      "Iteration 13, loss = 1.08180604\n",
      "Iteration 14, loss = 1.10068602\n",
      "Iteration 15, loss = 1.11307141\n",
      "Iteration 16, loss = 1.04415194\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24477097\n",
      "Iteration 4, loss = 1.04350859\n",
      "Iteration 5, loss = 1.00929755\n",
      "Iteration 6, loss = 1.09791510\n",
      "Iteration 7, loss = 1.02620632\n",
      "Iteration 8, loss = 1.07437209\n",
      "Iteration 9, loss = 1.03047891\n",
      "Iteration 10, loss = 1.07586059\n",
      "Iteration 11, loss = 1.05094425\n",
      "Iteration 12, loss = 1.08286261\n",
      "Iteration 13, loss = 1.08180604\n",
      "Iteration 14, loss = 1.10068602\n",
      "Iteration 15, loss = 1.11307141\n",
      "Iteration 16, loss = 1.04415194\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24477097\n",
      "Iteration 2, loss = 1.05487787\n",
      "Iteration 3, loss = 1.09799019\n",
      "Iteration 4, loss = 1.06052341\n",
      "Iteration 5, loss = 1.01337212\n",
      "Iteration 6, loss = 0.95271549\n",
      "Iteration 7, loss = 1.04938326\n",
      "Iteration 8, loss = 1.01538743\n",
      "Iteration 9, loss = 1.00694932\n",
      "Iteration 10, loss = 1.07728201\n",
      "Iteration 11, loss = 1.00964270\n",
      "Iteration 12, loss = 1.04869672\n",
      "Iteration 13, loss = 1.00455099\n",
      "Iteration 14, loss = 0.97354560\n",
      "Iteration 15, loss = 0.98219614\n",
      "Iteration 16, loss = 0.98002311\n",
      "Iteration 2, loss = 1.05487787\n",
      "Iteration 3, loss = 1.09799019\n",
      "Iteration 4, loss = 1.06052341\n",
      "Iteration 5, loss = 1.01337212\n",
      "Iteration 6, loss = 0.95271549\n",
      "Iteration 7, loss = 1.04938326\n",
      "Iteration 8, loss = 1.01538743\n",
      "Iteration 9, loss = 1.00694932\n",
      "Iteration 10, loss = 1.07728201\n",
      "Iteration 11, loss = 1.00964270\n",
      "Iteration 12, loss = 1.04869672\n",
      "Iteration 13, loss = 1.00455099\n",
      "Iteration 14, loss = 0.97354560\n",
      "Iteration 15, loss = 0.98219614\n",
      "Iteration 16, loss = 0.98002311\n",
      "Iteration 17, loss = 0.98378148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21275079\n",
      "Iteration 2, loss = 1.13283181\n",
      "Iteration 3, loss = 1.27649817\n",
      "Iteration 4, loss = 1.25700518\n",
      "Iteration 5, loss = 1.24829007\n",
      "Iteration 6, loss = 1.24307488\n",
      "Iteration 7, loss = 1.24138661\n",
      "Iteration 8, loss = 1.25931325\n",
      "Iteration 9, loss = 1.25085085\n",
      "Iteration 10, loss = 1.24839508\n",
      "Iteration 1, loss = 1.20478574\n",
      "Iteration 2, loss = 1.03018369\n",
      "Iteration 17, loss = 0.98378148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21275079\n",
      "Iteration 2, loss = 1.13283181\n",
      "Iteration 3, loss = 1.27649817\n",
      "Iteration 4, loss = 1.25700518\n",
      "Iteration 5, loss = 1.24829007\n",
      "Iteration 6, loss = 1.24307488\n",
      "Iteration 7, loss = 1.24138661\n",
      "Iteration 8, loss = 1.25931325\n",
      "Iteration 9, loss = 1.25085085\n",
      "Iteration 10, loss = 1.24839508\n",
      "Iteration 1, loss = 1.20478574\n",
      "Iteration 2, loss = 1.03018369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.01548306\n",
      "Iteration 4, loss = 1.02120292\n",
      "Iteration 5, loss = 0.99515731\n",
      "Iteration 6, loss = 1.05824216\n",
      "Iteration 7, loss = 1.17583963\n",
      "Iteration 8, loss = 1.00775400\n",
      "Iteration 9, loss = 1.10249117\n",
      "Iteration 10, loss = 1.07672182\n",
      "Iteration 1, loss = 1.24099536\n",
      "Iteration 2, loss = 1.03897651\n",
      "Iteration 3, loss = 1.27074058\n",
      "Iteration 3, loss = 1.01548306\n",
      "Iteration 4, loss = 1.02120292\n",
      "Iteration 5, loss = 0.99515731\n",
      "Iteration 6, loss = 1.05824216\n",
      "Iteration 7, loss = 1.17583963\n",
      "Iteration 8, loss = 1.00775400\n",
      "Iteration 9, loss = 1.10249117\n",
      "Iteration 10, loss = 1.07672182\n",
      "Iteration 1, loss = 1.24099536\n",
      "Iteration 2, loss = 1.03897651\n",
      "Iteration 3, loss = 1.27074058\n",
      "Iteration 4, loss = 1.27299658\n",
      "Iteration 5, loss = 1.28176590\n",
      "Iteration 6, loss = 1.27793341\n",
      "Iteration 7, loss = 1.29130883\n",
      "Iteration 8, loss = 1.25074441\n",
      "Iteration 9, loss = 1.32427144\n",
      "Iteration 10, loss = 1.28039844\n",
      "Iteration 1, loss = 1.23830909\n",
      "Iteration 2, loss = 1.17524752\n",
      "Iteration 3, loss = 1.10705000\n",
      "Iteration 4, loss = 1.27299658\n",
      "Iteration 5, loss = 1.28176590\n",
      "Iteration 6, loss = 1.27793341\n",
      "Iteration 7, loss = 1.29130883\n",
      "Iteration 8, loss = 1.25074441\n",
      "Iteration 9, loss = 1.32427144\n",
      "Iteration 10, loss = 1.28039844\n",
      "Iteration 1, loss = 1.23830909\n",
      "Iteration 2, loss = 1.17524752\n",
      "Iteration 3, loss = 1.10705000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.12549988\n",
      "Iteration 5, loss = 1.08822070\n",
      "Iteration 6, loss = 1.13364504\n",
      "Iteration 7, loss = 1.04461131\n",
      "Iteration 8, loss = 1.05869160\n",
      "Iteration 9, loss = 1.01786121\n",
      "Iteration 10, loss = 1.00936539\n",
      "Iteration 1, loss = 1.27522375\n",
      "Iteration 2, loss = 1.21885405\n",
      "Iteration 3, loss = 1.27097675\n",
      "Iteration 4, loss = 1.10489067\n",
      "Iteration 4, loss = 1.12549988\n",
      "Iteration 5, loss = 1.08822070\n",
      "Iteration 6, loss = 1.13364504\n",
      "Iteration 7, loss = 1.04461131\n",
      "Iteration 8, loss = 1.05869160\n",
      "Iteration 9, loss = 1.01786121\n",
      "Iteration 10, loss = 1.00936539\n",
      "Iteration 1, loss = 1.27522375\n",
      "Iteration 2, loss = 1.21885405\n",
      "Iteration 3, loss = 1.27097675\n",
      "Iteration 4, loss = 1.10489067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.18536731\n",
      "Iteration 6, loss = 1.31359647\n",
      "Iteration 7, loss = 1.29844787\n",
      "Iteration 8, loss = 1.28597168\n",
      "Iteration 9, loss = 1.28561883\n",
      "Iteration 10, loss = 1.24061159\n",
      "Iteration 1, loss = 1.21275079\n",
      "Iteration 2, loss = 1.13283181\n",
      "Iteration 3, loss = 1.27649817\n",
      "Iteration 4, loss = 1.25700518\n",
      "Iteration 5, loss = 1.24829007\n",
      "Iteration 5, loss = 1.18536731\n",
      "Iteration 6, loss = 1.31359647\n",
      "Iteration 7, loss = 1.29844787\n",
      "Iteration 8, loss = 1.28597168\n",
      "Iteration 9, loss = 1.28561883\n",
      "Iteration 10, loss = 1.24061159\n",
      "Iteration 1, loss = 1.21275079\n",
      "Iteration 2, loss = 1.13283181\n",
      "Iteration 3, loss = 1.27649817\n",
      "Iteration 4, loss = 1.25700518\n",
      "Iteration 5, loss = 1.24829007\n",
      "Iteration 6, loss = 1.24307488\n",
      "Iteration 7, loss = 1.24138661\n",
      "Iteration 8, loss = 1.25931325\n",
      "Iteration 9, loss = 1.25085085\n",
      "Iteration 10, loss = 1.24839508\n",
      "Iteration 11, loss = 1.25539928\n",
      "Iteration 12, loss = 1.25752731\n",
      "Iteration 13, loss = 1.23911850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20478574\n",
      "Iteration 2, loss = 1.03018369\n",
      "Iteration 3, loss = 1.01548306\n",
      "Iteration 4, loss = 1.02120292\n",
      "Iteration 5, loss = 0.99515731\n",
      "Iteration 6, loss = 1.05824216\n",
      "Iteration 6, loss = 1.24307488\n",
      "Iteration 7, loss = 1.24138661\n",
      "Iteration 8, loss = 1.25931325\n",
      "Iteration 9, loss = 1.25085085\n",
      "Iteration 10, loss = 1.24839508\n",
      "Iteration 11, loss = 1.25539928\n",
      "Iteration 12, loss = 1.25752731\n",
      "Iteration 13, loss = 1.23911850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20478574\n",
      "Iteration 2, loss = 1.03018369\n",
      "Iteration 3, loss = 1.01548306\n",
      "Iteration 4, loss = 1.02120292\n",
      "Iteration 5, loss = 0.99515731\n",
      "Iteration 6, loss = 1.05824216\n",
      "Iteration 7, loss = 1.17583963\n",
      "Iteration 8, loss = 1.00775400\n",
      "Iteration 9, loss = 1.10249117\n",
      "Iteration 10, loss = 1.07672182\n",
      "Iteration 11, loss = 1.02789283\n",
      "Iteration 12, loss = 1.11469666\n",
      "Iteration 13, loss = 1.07726093\n",
      "Iteration 14, loss = 1.04499316\n",
      "Iteration 15, loss = 1.13281941\n",
      "Iteration 16, loss = 1.05910161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24099536\n",
      "Iteration 2, loss = 1.03897651\n",
      "Iteration 3, loss = 1.27074058\n",
      "Iteration 4, loss = 1.27299658\n",
      "Iteration 7, loss = 1.17583963\n",
      "Iteration 8, loss = 1.00775400\n",
      "Iteration 9, loss = 1.10249117\n",
      "Iteration 10, loss = 1.07672182\n",
      "Iteration 11, loss = 1.02789283\n",
      "Iteration 12, loss = 1.11469666\n",
      "Iteration 13, loss = 1.07726093\n",
      "Iteration 14, loss = 1.04499316\n",
      "Iteration 15, loss = 1.13281941\n",
      "Iteration 16, loss = 1.05910161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24099536\n",
      "Iteration 2, loss = 1.03897651\n",
      "Iteration 3, loss = 1.27074058\n",
      "Iteration 4, loss = 1.27299658\n",
      "Iteration 5, loss = 1.28176590\n",
      "Iteration 6, loss = 1.27793341\n",
      "Iteration 7, loss = 1.29130883\n",
      "Iteration 8, loss = 1.25074441\n",
      "Iteration 9, loss = 1.32427144\n",
      "Iteration 10, loss = 1.28039844\n",
      "Iteration 11, loss = 1.27850080\n",
      "Iteration 12, loss = 1.27207105\n",
      "Iteration 13, loss = 1.27247890\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23830909\n",
      "Iteration 2, loss = 1.17524752\n",
      "Iteration 3, loss = 1.10705000\n",
      "Iteration 4, loss = 1.12549988\n",
      "Iteration 5, loss = 1.08822070\n",
      "Iteration 6, loss = 1.13364504\n",
      "Iteration 7, loss = 1.04461131\n",
      "Iteration 5, loss = 1.28176590\n",
      "Iteration 6, loss = 1.27793341\n",
      "Iteration 7, loss = 1.29130883\n",
      "Iteration 8, loss = 1.25074441\n",
      "Iteration 9, loss = 1.32427144\n",
      "Iteration 10, loss = 1.28039844\n",
      "Iteration 11, loss = 1.27850080\n",
      "Iteration 12, loss = 1.27207105\n",
      "Iteration 13, loss = 1.27247890\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23830909\n",
      "Iteration 2, loss = 1.17524752\n",
      "Iteration 3, loss = 1.10705000\n",
      "Iteration 4, loss = 1.12549988\n",
      "Iteration 5, loss = 1.08822070\n",
      "Iteration 6, loss = 1.13364504\n",
      "Iteration 7, loss = 1.04461131\n",
      "Iteration 8, loss = 1.05869160\n",
      "Iteration 9, loss = 1.01786121\n",
      "Iteration 10, loss = 1.00936539\n",
      "Iteration 11, loss = 1.01221118\n",
      "Iteration 12, loss = 1.04152685\n",
      "Iteration 13, loss = 1.01568227\n",
      "Iteration 14, loss = 1.01656987\n",
      "Iteration 15, loss = 1.03140491\n",
      "Iteration 16, loss = 1.00827469\n",
      "Iteration 17, loss = 1.02750863\n",
      "Iteration 18, loss = 1.00815526\n",
      "Iteration 19, loss = 1.00623453\n",
      "Iteration 20, loss = 1.01740711\n",
      "Iteration 21, loss = 1.00079208\n",
      "Iteration 8, loss = 1.05869160\n",
      "Iteration 9, loss = 1.01786121\n",
      "Iteration 10, loss = 1.00936539\n",
      "Iteration 11, loss = 1.01221118\n",
      "Iteration 12, loss = 1.04152685\n",
      "Iteration 13, loss = 1.01568227\n",
      "Iteration 14, loss = 1.01656987\n",
      "Iteration 15, loss = 1.03140491\n",
      "Iteration 16, loss = 1.00827469\n",
      "Iteration 17, loss = 1.02750863\n",
      "Iteration 18, loss = 1.00815526\n",
      "Iteration 19, loss = 1.00623453\n",
      "Iteration 20, loss = 1.01740711\n",
      "Iteration 21, loss = 1.00079208\n",
      "Iteration 22, loss = 1.00224327\n",
      "Iteration 23, loss = 1.05663093\n",
      "Iteration 24, loss = 1.03134264\n",
      "Iteration 25, loss = 0.99591143\n",
      "Iteration 26, loss = 0.99142962\n",
      "Iteration 27, loss = 1.02573671\n",
      "Iteration 28, loss = 1.01361285\n",
      "Iteration 29, loss = 1.02794618\n",
      "Iteration 30, loss = 1.02106613\n",
      "Iteration 31, loss = 1.01216722\n",
      "Iteration 32, loss = 1.00396699\n",
      "Iteration 33, loss = 1.01378806\n",
      "Iteration 34, loss = 1.20576166\n",
      "Iteration 35, loss = 1.27196151\n",
      "Iteration 36, loss = 1.25870949\n",
      "Iteration 22, loss = 1.00224327\n",
      "Iteration 23, loss = 1.05663093\n",
      "Iteration 24, loss = 1.03134264\n",
      "Iteration 25, loss = 0.99591143\n",
      "Iteration 26, loss = 0.99142962\n",
      "Iteration 27, loss = 1.02573671\n",
      "Iteration 28, loss = 1.01361285\n",
      "Iteration 29, loss = 1.02794618\n",
      "Iteration 30, loss = 1.02106613\n",
      "Iteration 31, loss = 1.01216722\n",
      "Iteration 32, loss = 1.00396699\n",
      "Iteration 33, loss = 1.01378806\n",
      "Iteration 34, loss = 1.20576166\n",
      "Iteration 35, loss = 1.27196151\n",
      "Iteration 36, loss = 1.25870949\n",
      "Iteration 37, loss = 1.26310148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27522375\n",
      "Iteration 2, loss = 1.21885405\n",
      "Iteration 3, loss = 1.27097675\n",
      "Iteration 4, loss = 1.10489067\n",
      "Iteration 5, loss = 1.18536731\n",
      "Iteration 6, loss = 1.31359647\n",
      "Iteration 7, loss = 1.29844787\n",
      "Iteration 8, loss = 1.28597168\n",
      "Iteration 9, loss = 1.28561883\n",
      "Iteration 10, loss = 1.24061159\n",
      "Iteration 11, loss = 1.12507445\n",
      "Iteration 12, loss = 1.18061602\n",
      "Iteration 13, loss = 1.30433972\n",
      "Iteration 37, loss = 1.26310148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27522375\n",
      "Iteration 2, loss = 1.21885405\n",
      "Iteration 3, loss = 1.27097675\n",
      "Iteration 4, loss = 1.10489067\n",
      "Iteration 5, loss = 1.18536731\n",
      "Iteration 6, loss = 1.31359647\n",
      "Iteration 7, loss = 1.29844787\n",
      "Iteration 8, loss = 1.28597168\n",
      "Iteration 9, loss = 1.28561883\n",
      "Iteration 10, loss = 1.24061159\n",
      "Iteration 11, loss = 1.12507445\n",
      "Iteration 12, loss = 1.18061602\n",
      "Iteration 13, loss = 1.30433972\n",
      "Iteration 14, loss = 1.29645373\n",
      "Iteration 15, loss = 1.31348799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21275079\n",
      "Iteration 2, loss = 1.13283181\n",
      "Iteration 3, loss = 1.27649817\n",
      "Iteration 4, loss = 1.25700518\n",
      "Iteration 5, loss = 1.24829007\n",
      "Iteration 6, loss = 1.24307488\n",
      "Iteration 7, loss = 1.24138661\n",
      "Iteration 8, loss = 1.25931325\n",
      "Iteration 9, loss = 1.25085085\n",
      "Iteration 10, loss = 1.24839508\n",
      "Iteration 11, loss = 1.25539928\n",
      "Iteration 12, loss = 1.25752731\n",
      "Iteration 14, loss = 1.29645373\n",
      "Iteration 15, loss = 1.31348799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21275079\n",
      "Iteration 2, loss = 1.13283181\n",
      "Iteration 3, loss = 1.27649817\n",
      "Iteration 4, loss = 1.25700518\n",
      "Iteration 5, loss = 1.24829007\n",
      "Iteration 6, loss = 1.24307488\n",
      "Iteration 7, loss = 1.24138661\n",
      "Iteration 8, loss = 1.25931325\n",
      "Iteration 9, loss = 1.25085085\n",
      "Iteration 10, loss = 1.24839508\n",
      "Iteration 11, loss = 1.25539928\n",
      "Iteration 12, loss = 1.25752731\n",
      "Iteration 13, loss = 1.23911850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20478574\n",
      "Iteration 2, loss = 1.03018369\n",
      "Iteration 3, loss = 1.01548306\n",
      "Iteration 4, loss = 1.02120292\n",
      "Iteration 5, loss = 0.99515731\n",
      "Iteration 6, loss = 1.05824216\n",
      "Iteration 7, loss = 1.17583963\n",
      "Iteration 8, loss = 1.00775400\n",
      "Iteration 9, loss = 1.10249117\n",
      "Iteration 10, loss = 1.07672182\n",
      "Iteration 11, loss = 1.02789283\n",
      "Iteration 12, loss = 1.11469666\n",
      "Iteration 13, loss = 1.23911850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20478574\n",
      "Iteration 2, loss = 1.03018369\n",
      "Iteration 3, loss = 1.01548306\n",
      "Iteration 4, loss = 1.02120292\n",
      "Iteration 5, loss = 0.99515731\n",
      "Iteration 6, loss = 1.05824216\n",
      "Iteration 7, loss = 1.17583963\n",
      "Iteration 8, loss = 1.00775400\n",
      "Iteration 9, loss = 1.10249117\n",
      "Iteration 10, loss = 1.07672182\n",
      "Iteration 11, loss = 1.02789283\n",
      "Iteration 12, loss = 1.11469666\n",
      "Iteration 13, loss = 1.07726093\n",
      "Iteration 14, loss = 1.04499316\n",
      "Iteration 15, loss = 1.13281941\n",
      "Iteration 16, loss = 1.05910161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24099536\n",
      "Iteration 2, loss = 1.03897651\n",
      "Iteration 3, loss = 1.27074058\n",
      "Iteration 4, loss = 1.27299658\n",
      "Iteration 5, loss = 1.28176590\n",
      "Iteration 6, loss = 1.27793341\n",
      "Iteration 7, loss = 1.29130883\n",
      "Iteration 8, loss = 1.25074441\n",
      "Iteration 9, loss = 1.32427144\n",
      "Iteration 10, loss = 1.28039844\n",
      "Iteration 13, loss = 1.07726093\n",
      "Iteration 14, loss = 1.04499316\n",
      "Iteration 15, loss = 1.13281941\n",
      "Iteration 16, loss = 1.05910161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24099536\n",
      "Iteration 2, loss = 1.03897651\n",
      "Iteration 3, loss = 1.27074058\n",
      "Iteration 4, loss = 1.27299658\n",
      "Iteration 5, loss = 1.28176590\n",
      "Iteration 6, loss = 1.27793341\n",
      "Iteration 7, loss = 1.29130883\n",
      "Iteration 8, loss = 1.25074441\n",
      "Iteration 9, loss = 1.32427144\n",
      "Iteration 10, loss = 1.28039844\n",
      "Iteration 11, loss = 1.27850080\n",
      "Iteration 12, loss = 1.27207105\n",
      "Iteration 13, loss = 1.27247890\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23830909\n",
      "Iteration 2, loss = 1.17524752\n",
      "Iteration 3, loss = 1.10705000\n",
      "Iteration 4, loss = 1.12549988\n",
      "Iteration 5, loss = 1.08822070\n",
      "Iteration 6, loss = 1.13364504\n",
      "Iteration 7, loss = 1.04461131\n",
      "Iteration 8, loss = 1.05869160\n",
      "Iteration 9, loss = 1.01786121\n",
      "Iteration 10, loss = 1.00936539Iteration 11, loss = 1.27850080\n",
      "Iteration 12, loss = 1.27207105\n",
      "Iteration 13, loss = 1.27247890\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23830909\n",
      "Iteration 2, loss = 1.17524752\n",
      "Iteration 3, loss = 1.10705000\n",
      "Iteration 4, loss = 1.12549988\n",
      "Iteration 5, loss = 1.08822070\n",
      "Iteration 6, loss = 1.13364504\n",
      "Iteration 7, loss = 1.04461131\n",
      "Iteration 8, loss = 1.05869160\n",
      "Iteration 9, loss = 1.01786121\n",
      "Iteration 10, loss = 1.00936539\n",
      "Iteration 11, loss = 1.01221118\n",
      "Iteration 12, loss = 1.04152685\n",
      "Iteration 13, loss = 1.01568227\n",
      "Iteration 14, loss = 1.01656987\n",
      "Iteration 15, loss = 1.03140491\n",
      "Iteration 16, loss = 1.00827469\n",
      "Iteration 17, loss = 1.02750863\n",
      "Iteration 18, loss = 1.00815526\n",
      "Iteration 19, loss = 1.00623453\n",
      "Iteration 20, loss = 1.01740711\n",
      "Iteration 21, loss = 1.00079208\n",
      "Iteration 22, loss = 1.00224327\n",
      "Iteration 23, loss = 1.05663093\n",
      "Iteration 24, loss = 1.03134264\n",
      "Iteration 25, loss = 0.99591143\n",
      "\n",
      "Iteration 11, loss = 1.01221118\n",
      "Iteration 12, loss = 1.04152685\n",
      "Iteration 13, loss = 1.01568227\n",
      "Iteration 14, loss = 1.01656987\n",
      "Iteration 15, loss = 1.03140491\n",
      "Iteration 16, loss = 1.00827469\n",
      "Iteration 17, loss = 1.02750863\n",
      "Iteration 18, loss = 1.00815526\n",
      "Iteration 19, loss = 1.00623453\n",
      "Iteration 20, loss = 1.01740711\n",
      "Iteration 21, loss = 1.00079208\n",
      "Iteration 22, loss = 1.00224327\n",
      "Iteration 23, loss = 1.05663093\n",
      "Iteration 24, loss = 1.03134264\n",
      "Iteration 25, loss = 0.99591143\n",
      "Iteration 26, loss = 0.99142962\n",
      "Iteration 27, loss = 1.02573671\n",
      "Iteration 28, loss = 1.01361285\n",
      "Iteration 29, loss = 1.02794618\n",
      "Iteration 30, loss = 1.02106613\n",
      "Iteration 31, loss = 1.01216722\n",
      "Iteration 32, loss = 1.00396699\n",
      "Iteration 33, loss = 1.01378806\n",
      "Iteration 34, loss = 1.20576166\n",
      "Iteration 35, loss = 1.27196151\n",
      "Iteration 36, loss = 1.25870949\n",
      "Iteration 37, loss = 1.26310148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27522375\n",
      "Iteration 2, loss = 1.21885405\n",
      "Iteration 3, loss = 1.27097675\n",
      "Iteration 26, loss = 0.99142962\n",
      "Iteration 27, loss = 1.02573671\n",
      "Iteration 28, loss = 1.01361285\n",
      "Iteration 29, loss = 1.02794618\n",
      "Iteration 30, loss = 1.02106613\n",
      "Iteration 31, loss = 1.01216722\n",
      "Iteration 32, loss = 1.00396699\n",
      "Iteration 33, loss = 1.01378806\n",
      "Iteration 34, loss = 1.20576166\n",
      "Iteration 35, loss = 1.27196151\n",
      "Iteration 36, loss = 1.25870949\n",
      "Iteration 37, loss = 1.26310148\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27522375\n",
      "Iteration 2, loss = 1.21885405\n",
      "Iteration 3, loss = 1.27097675\n",
      "Iteration 4, loss = 1.10489067\n",
      "Iteration 5, loss = 1.18536731\n",
      "Iteration 6, loss = 1.31359647\n",
      "Iteration 7, loss = 1.29844787\n",
      "Iteration 8, loss = 1.28597168\n",
      "Iteration 9, loss = 1.28561883\n",
      "Iteration 10, loss = 1.24061159\n",
      "Iteration 11, loss = 1.12507445\n",
      "Iteration 12, loss = 1.18061602\n",
      "Iteration 13, loss = 1.30433972\n",
      "Iteration 14, loss = 1.29645373\n",
      "Iteration 15, loss = 1.31348799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21821372\n",
      "Iteration 2, loss = 1.08204339\n",
      "Iteration 4, loss = 1.10489067\n",
      "Iteration 5, loss = 1.18536731\n",
      "Iteration 6, loss = 1.31359647\n",
      "Iteration 7, loss = 1.29844787\n",
      "Iteration 8, loss = 1.28597168\n",
      "Iteration 9, loss = 1.28561883\n",
      "Iteration 10, loss = 1.24061159\n",
      "Iteration 11, loss = 1.12507445\n",
      "Iteration 12, loss = 1.18061602\n",
      "Iteration 13, loss = 1.30433972\n",
      "Iteration 14, loss = 1.29645373\n",
      "Iteration 15, loss = 1.31348799\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21821372\n",
      "Iteration 2, loss = 1.08204339\n",
      "Iteration 3, loss = 1.05027868\n",
      "Iteration 4, loss = 1.02015932\n",
      "Iteration 5, loss = 1.01927329\n",
      "Iteration 6, loss = 1.01159561\n",
      "Iteration 7, loss = 0.99223572\n",
      "Iteration 8, loss = 0.94815696\n",
      "Iteration 9, loss = 0.98382527\n",
      "Iteration 10, loss = 0.93154952\n",
      "Iteration 1, loss = 1.18811615\n",
      "Iteration 2, loss = 1.08312675\n",
      "Iteration 3, loss = 1.00366239\n",
      "Iteration 4, loss = 0.95444093\n",
      "Iteration 5, loss = 0.95986478\n",
      "Iteration 6, loss = 1.01326591\n",
      "Iteration 3, loss = 1.05027868\n",
      "Iteration 4, loss = 1.02015932\n",
      "Iteration 5, loss = 1.01927329\n",
      "Iteration 6, loss = 1.01159561\n",
      "Iteration 7, loss = 0.99223572\n",
      "Iteration 8, loss = 0.94815696\n",
      "Iteration 9, loss = 0.98382527\n",
      "Iteration 10, loss = 0.93154952\n",
      "Iteration 1, loss = 1.18811615\n",
      "Iteration 2, loss = 1.08312675\n",
      "Iteration 3, loss = 1.00366239\n",
      "Iteration 4, loss = 0.95444093\n",
      "Iteration 5, loss = 0.95986478\n",
      "Iteration 6, loss = 1.01326591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.96541161\n",
      "Iteration 8, loss = 0.93845878\n",
      "Iteration 9, loss = 0.90819268\n",
      "Iteration 10, loss = 0.89434031\n",
      "Iteration 1, loss = 1.20443075\n",
      "Iteration 2, loss = 1.16437285\n",
      "Iteration 3, loss = 1.08253860\n",
      "Iteration 4, loss = 1.02001078\n",
      "Iteration 5, loss = 1.01325213\n",
      "Iteration 6, loss = 1.02019306\n",
      "Iteration 7, loss = 1.04073497\n",
      "Iteration 8, loss = 0.96573079\n",
      "Iteration 9, loss = 0.97252281\n",
      "Iteration 10, loss = 0.93432026\n",
      "Iteration 7, loss = 0.96541161\n",
      "Iteration 8, loss = 0.93845878\n",
      "Iteration 9, loss = 0.90819268\n",
      "Iteration 10, loss = 0.89434031\n",
      "Iteration 1, loss = 1.20443075\n",
      "Iteration 2, loss = 1.16437285\n",
      "Iteration 3, loss = 1.08253860\n",
      "Iteration 4, loss = 1.02001078\n",
      "Iteration 5, loss = 1.01325213\n",
      "Iteration 6, loss = 1.02019306\n",
      "Iteration 7, loss = 1.04073497\n",
      "Iteration 8, loss = 0.96573079\n",
      "Iteration 9, loss = 0.97252281\n",
      "Iteration 10, loss = 0.93432026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22817852\n",
      "Iteration 2, loss = 1.12560353\n",
      "Iteration 3, loss = 1.06717596\n",
      "Iteration 4, loss = 1.03436477\n",
      "Iteration 5, loss = 1.05101431\n",
      "Iteration 6, loss = 1.00972157\n",
      "Iteration 7, loss = 1.03667692\n",
      "Iteration 8, loss = 0.97122350\n",
      "Iteration 9, loss = 0.95344317\n",
      "Iteration 10, loss = 0.94329692\n",
      "Iteration 1, loss = 1.20896780\n",
      "Iteration 2, loss = 1.06099751\n",
      "Iteration 3, loss = 1.02633667\n",
      "Iteration 4, loss = 1.01053076\n",
      "Iteration 1, loss = 1.22817852\n",
      "Iteration 2, loss = 1.12560353\n",
      "Iteration 3, loss = 1.06717596\n",
      "Iteration 4, loss = 1.03436477\n",
      "Iteration 5, loss = 1.05101431\n",
      "Iteration 6, loss = 1.00972157\n",
      "Iteration 7, loss = 1.03667692\n",
      "Iteration 8, loss = 0.97122350\n",
      "Iteration 9, loss = 0.95344317\n",
      "Iteration 10, loss = 0.94329692\n",
      "Iteration 1, loss = 1.20896780\n",
      "Iteration 2, loss = 1.06099751\n",
      "Iteration 3, loss = 1.02633667\n",
      "Iteration 4, loss = 1.01053076\n",
      "Iteration 5, loss = 1.08271765\n",
      "Iteration 6, loss = 1.02074288\n",
      "Iteration 7, loss = 0.99805294\n",
      "Iteration 8, loss = 1.00744308\n",
      "Iteration 9, loss = 0.97315729\n",
      "Iteration 10, loss = 0.92438895\n",
      "Iteration 1, loss = 1.21821372\n",
      "Iteration 2, loss = 1.08204339\n",
      "Iteration 3, loss = 1.05027868\n",
      "Iteration 4, loss = 1.02015932\n",
      "Iteration 5, loss = 1.01927329\n",
      "Iteration 6, loss = 1.01159561\n",
      "Iteration 7, loss = 0.99223572\n",
      "Iteration 8, loss = 0.94815696\n",
      "Iteration 9, loss = 0.98382527\n",
      "Iteration 5, loss = 1.08271765\n",
      "Iteration 6, loss = 1.02074288\n",
      "Iteration 7, loss = 0.99805294\n",
      "Iteration 8, loss = 1.00744308\n",
      "Iteration 9, loss = 0.97315729\n",
      "Iteration 10, loss = 0.92438895\n",
      "Iteration 1, loss = 1.21821372\n",
      "Iteration 2, loss = 1.08204339\n",
      "Iteration 3, loss = 1.05027868\n",
      "Iteration 4, loss = 1.02015932\n",
      "Iteration 5, loss = 1.01927329\n",
      "Iteration 6, loss = 1.01159561\n",
      "Iteration 7, loss = 0.99223572\n",
      "Iteration 8, loss = 0.94815696\n",
      "Iteration 9, loss = 0.98382527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.93154952\n",
      "Iteration 11, loss = 0.92243263\n",
      "Iteration 12, loss = 0.95128525\n",
      "Iteration 13, loss = 0.95400079\n",
      "Iteration 14, loss = 0.92436438\n",
      "Iteration 15, loss = 0.92469398\n",
      "Iteration 16, loss = 0.93572156\n",
      "Iteration 17, loss = 0.90891152\n",
      "Iteration 18, loss = 0.95329009\n",
      "Iteration 19, loss = 0.94450659\n",
      "Iteration 20, loss = 0.93857179\n",
      "Iteration 21, loss = 0.86347742\n",
      "Iteration 22, loss = 0.88165457\n",
      "Iteration 23, loss = 0.94966100\n",
      "Iteration 24, loss = 0.88737128\n",
      "Iteration 10, loss = 0.93154952\n",
      "Iteration 11, loss = 0.92243263\n",
      "Iteration 12, loss = 0.95128525\n",
      "Iteration 13, loss = 0.95400079\n",
      "Iteration 14, loss = 0.92436438\n",
      "Iteration 15, loss = 0.92469398\n",
      "Iteration 16, loss = 0.93572156\n",
      "Iteration 17, loss = 0.90891152\n",
      "Iteration 18, loss = 0.95329009\n",
      "Iteration 19, loss = 0.94450659\n",
      "Iteration 20, loss = 0.93857179\n",
      "Iteration 21, loss = 0.86347742\n",
      "Iteration 22, loss = 0.88165457\n",
      "Iteration 23, loss = 0.94966100\n",
      "Iteration 24, loss = 0.88737128\n",
      "Iteration 25, loss = 0.87781124\n",
      "Iteration 26, loss = 0.88526314\n",
      "Iteration 27, loss = 0.88919087\n",
      "Iteration 28, loss = 0.87912992\n",
      "Iteration 29, loss = 0.84511583\n",
      "Iteration 30, loss = 0.84586069\n",
      "Iteration 31, loss = 0.83819788\n",
      "Iteration 32, loss = 0.87406164\n",
      "Iteration 33, loss = 0.85032698\n",
      "Iteration 34, loss = 0.83992811\n",
      "Iteration 35, loss = 0.81205324\n",
      "Iteration 36, loss = 0.84589696\n",
      "Iteration 37, loss = 0.84163616\n",
      "Iteration 38, loss = 0.82382103\n",
      "Iteration 39, loss = 0.85209901\n",
      "Iteration 25, loss = 0.87781124\n",
      "Iteration 26, loss = 0.88526314\n",
      "Iteration 27, loss = 0.88919087\n",
      "Iteration 28, loss = 0.87912992\n",
      "Iteration 29, loss = 0.84511583\n",
      "Iteration 30, loss = 0.84586069\n",
      "Iteration 31, loss = 0.83819788\n",
      "Iteration 32, loss = 0.87406164\n",
      "Iteration 33, loss = 0.85032698\n",
      "Iteration 34, loss = 0.83992811\n",
      "Iteration 35, loss = 0.81205324\n",
      "Iteration 36, loss = 0.84589696\n",
      "Iteration 37, loss = 0.84163616\n",
      "Iteration 38, loss = 0.82382103\n",
      "Iteration 39, loss = 0.85209901\n",
      "Iteration 40, loss = 0.81832958\n",
      "Iteration 41, loss = 0.81276992\n",
      "Iteration 42, loss = 0.81729207\n",
      "Iteration 43, loss = 0.83706287\n",
      "Iteration 44, loss = 0.81209841\n",
      "Iteration 45, loss = 0.82917762\n",
      "Iteration 46, loss = 0.82801057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18811615\n",
      "Iteration 2, loss = 1.08312675\n",
      "Iteration 3, loss = 1.00366239\n",
      "Iteration 4, loss = 0.95444093\n",
      "Iteration 5, loss = 0.95986478\n",
      "Iteration 6, loss = 1.01326591\n",
      "Iteration 7, loss = 0.96541161\n",
      "Iteration 40, loss = 0.81832958\n",
      "Iteration 41, loss = 0.81276992\n",
      "Iteration 42, loss = 0.81729207\n",
      "Iteration 43, loss = 0.83706287\n",
      "Iteration 44, loss = 0.81209841\n",
      "Iteration 45, loss = 0.82917762\n",
      "Iteration 46, loss = 0.82801057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18811615\n",
      "Iteration 2, loss = 1.08312675\n",
      "Iteration 3, loss = 1.00366239\n",
      "Iteration 4, loss = 0.95444093\n",
      "Iteration 5, loss = 0.95986478\n",
      "Iteration 6, loss = 1.01326591\n",
      "Iteration 7, loss = 0.96541161\n",
      "Iteration 8, loss = 0.93845878\n",
      "Iteration 9, loss = 0.90819268\n",
      "Iteration 10, loss = 0.89434031\n",
      "Iteration 11, loss = 0.90622387\n",
      "Iteration 12, loss = 0.93498273\n",
      "Iteration 13, loss = 0.90186514\n",
      "Iteration 14, loss = 0.90139123\n",
      "Iteration 15, loss = 0.87822221\n",
      "Iteration 16, loss = 0.90120050\n",
      "Iteration 17, loss = 0.87802125\n",
      "Iteration 18, loss = 0.87053890\n",
      "Iteration 19, loss = 0.89440889\n",
      "Iteration 20, loss = 0.84507388\n",
      "Iteration 21, loss = 0.85085581\n",
      "Iteration 22, loss = 0.86246529\n",
      "Iteration 8, loss = 0.93845878\n",
      "Iteration 9, loss = 0.90819268\n",
      "Iteration 10, loss = 0.89434031\n",
      "Iteration 11, loss = 0.90622387\n",
      "Iteration 12, loss = 0.93498273\n",
      "Iteration 13, loss = 0.90186514\n",
      "Iteration 14, loss = 0.90139123\n",
      "Iteration 15, loss = 0.87822221\n",
      "Iteration 16, loss = 0.90120050\n",
      "Iteration 17, loss = 0.87802125\n",
      "Iteration 18, loss = 0.87053890\n",
      "Iteration 19, loss = 0.89440889\n",
      "Iteration 20, loss = 0.84507388\n",
      "Iteration 21, loss = 0.85085581\n",
      "Iteration 22, loss = 0.86246529\n",
      "Iteration 23, loss = 0.86843696\n",
      "Iteration 24, loss = 0.84823476\n",
      "Iteration 25, loss = 0.82110172\n",
      "Iteration 26, loss = 0.81869499\n",
      "Iteration 27, loss = 0.84095774\n",
      "Iteration 28, loss = 0.83298718\n",
      "Iteration 29, loss = 0.86368251\n",
      "Iteration 30, loss = 0.82656504\n",
      "Iteration 31, loss = 0.82389690\n",
      "Iteration 32, loss = 0.82630891\n",
      "Iteration 33, loss = 0.81666324\n",
      "Iteration 34, loss = 0.79801402\n",
      "Iteration 35, loss = 0.79144785\n",
      "Iteration 36, loss = 0.79659617\n",
      "Iteration 37, loss = 0.77151959\n",
      "Iteration 38, loss = 0.81088735\n",
      "Iteration 23, loss = 0.86843696\n",
      "Iteration 24, loss = 0.84823476\n",
      "Iteration 25, loss = 0.82110172\n",
      "Iteration 26, loss = 0.81869499\n",
      "Iteration 27, loss = 0.84095774\n",
      "Iteration 28, loss = 0.83298718\n",
      "Iteration 29, loss = 0.86368251\n",
      "Iteration 30, loss = 0.82656504\n",
      "Iteration 31, loss = 0.82389690\n",
      "Iteration 32, loss = 0.82630891\n",
      "Iteration 33, loss = 0.81666324\n",
      "Iteration 34, loss = 0.79801402\n",
      "Iteration 35, loss = 0.79144785\n",
      "Iteration 36, loss = 0.79659617\n",
      "Iteration 37, loss = 0.77151959\n",
      "Iteration 38, loss = 0.81088735\n",
      "Iteration 39, loss = 0.78299272\n",
      "Iteration 40, loss = 0.79059072\n",
      "Iteration 41, loss = 0.76537698\n",
      "Iteration 42, loss = 0.77292202\n",
      "Iteration 43, loss = 0.77885320\n",
      "Iteration 44, loss = 0.80530159\n",
      "Iteration 45, loss = 0.78010819\n",
      "Iteration 46, loss = 0.77625691\n",
      "Iteration 47, loss = 0.82661486\n",
      "Iteration 48, loss = 0.76873960\n",
      "Iteration 49, loss = 0.74959700\n",
      "Iteration 50, loss = 0.75313406\n",
      "Iteration 1, loss = 1.20443075\n",
      "Iteration 2, loss = 1.16437285\n",
      "Iteration 3, loss = 1.08253860\n",
      "Iteration 39, loss = 0.78299272\n",
      "Iteration 40, loss = 0.79059072\n",
      "Iteration 41, loss = 0.76537698\n",
      "Iteration 42, loss = 0.77292202\n",
      "Iteration 43, loss = 0.77885320\n",
      "Iteration 44, loss = 0.80530159\n",
      "Iteration 45, loss = 0.78010819\n",
      "Iteration 46, loss = 0.77625691\n",
      "Iteration 47, loss = 0.82661486\n",
      "Iteration 48, loss = 0.76873960\n",
      "Iteration 49, loss = 0.74959700\n",
      "Iteration 50, loss = 0.75313406\n",
      "Iteration 1, loss = 1.20443075\n",
      "Iteration 2, loss = 1.16437285\n",
      "Iteration 3, loss = 1.08253860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.02001078\n",
      "Iteration 5, loss = 1.01325213\n",
      "Iteration 6, loss = 1.02019306\n",
      "Iteration 7, loss = 1.04073497\n",
      "Iteration 8, loss = 0.96573079\n",
      "Iteration 9, loss = 0.97252281\n",
      "Iteration 10, loss = 0.93432026\n",
      "Iteration 11, loss = 1.04027355\n",
      "Iteration 12, loss = 0.92962312\n",
      "Iteration 13, loss = 0.94753287\n",
      "Iteration 14, loss = 0.94961420\n",
      "Iteration 15, loss = 0.94329830\n",
      "Iteration 16, loss = 0.91735501\n",
      "Iteration 17, loss = 0.92722701\n",
      "Iteration 4, loss = 1.02001078\n",
      "Iteration 5, loss = 1.01325213\n",
      "Iteration 6, loss = 1.02019306\n",
      "Iteration 7, loss = 1.04073497\n",
      "Iteration 8, loss = 0.96573079\n",
      "Iteration 9, loss = 0.97252281\n",
      "Iteration 10, loss = 0.93432026\n",
      "Iteration 11, loss = 1.04027355\n",
      "Iteration 12, loss = 0.92962312\n",
      "Iteration 13, loss = 0.94753287\n",
      "Iteration 14, loss = 0.94961420\n",
      "Iteration 15, loss = 0.94329830\n",
      "Iteration 16, loss = 0.91735501\n",
      "Iteration 17, loss = 0.92722701\n",
      "Iteration 18, loss = 0.92514454\n",
      "Iteration 19, loss = 0.94894692\n",
      "Iteration 20, loss = 0.92477130\n",
      "Iteration 21, loss = 0.89132348\n",
      "Iteration 22, loss = 0.89103288\n",
      "Iteration 23, loss = 0.87942962\n",
      "Iteration 24, loss = 0.90724681\n",
      "Iteration 25, loss = 0.89716554\n",
      "Iteration 26, loss = 0.86844946\n",
      "Iteration 27, loss = 0.90470751\n",
      "Iteration 28, loss = 0.89691008\n",
      "Iteration 29, loss = 0.83792391\n",
      "Iteration 30, loss = 0.88949189\n",
      "Iteration 31, loss = 0.86836227\n",
      "Iteration 32, loss = 0.87962052\n",
      "Iteration 18, loss = 0.92514454\n",
      "Iteration 19, loss = 0.94894692\n",
      "Iteration 20, loss = 0.92477130\n",
      "Iteration 21, loss = 0.89132348\n",
      "Iteration 22, loss = 0.89103288\n",
      "Iteration 23, loss = 0.87942962\n",
      "Iteration 24, loss = 0.90724681\n",
      "Iteration 25, loss = 0.89716554\n",
      "Iteration 26, loss = 0.86844946\n",
      "Iteration 27, loss = 0.90470751\n",
      "Iteration 28, loss = 0.89691008\n",
      "Iteration 29, loss = 0.83792391\n",
      "Iteration 30, loss = 0.88949189\n",
      "Iteration 31, loss = 0.86836227\n",
      "Iteration 32, loss = 0.87962052\n",
      "Iteration 33, loss = 0.86288314\n",
      "Iteration 34, loss = 0.85434321\n",
      "Iteration 35, loss = 0.85247439\n",
      "Iteration 36, loss = 0.86921182\n",
      "Iteration 37, loss = 0.86954251\n",
      "Iteration 38, loss = 0.82440201\n",
      "Iteration 39, loss = 0.85107414\n",
      "Iteration 40, loss = 0.87384748\n",
      "Iteration 41, loss = 0.79657542\n",
      "Iteration 42, loss = 0.88627871\n",
      "Iteration 43, loss = 0.83610075\n",
      "Iteration 44, loss = 0.81838252\n",
      "Iteration 45, loss = 0.79716128\n",
      "Iteration 46, loss = 0.82424810\n",
      "Iteration 47, loss = 0.81159944\n",
      "Iteration 48, loss = 0.79176198\n",
      "Iteration 33, loss = 0.86288314\n",
      "Iteration 34, loss = 0.85434321\n",
      "Iteration 35, loss = 0.85247439\n",
      "Iteration 36, loss = 0.86921182\n",
      "Iteration 37, loss = 0.86954251\n",
      "Iteration 38, loss = 0.82440201\n",
      "Iteration 39, loss = 0.85107414\n",
      "Iteration 40, loss = 0.87384748\n",
      "Iteration 41, loss = 0.79657542\n",
      "Iteration 42, loss = 0.88627871\n",
      "Iteration 43, loss = 0.83610075\n",
      "Iteration 44, loss = 0.81838252\n",
      "Iteration 45, loss = 0.79716128\n",
      "Iteration 46, loss = 0.82424810\n",
      "Iteration 47, loss = 0.81159944\n",
      "Iteration 48, loss = 0.79176198\n",
      "Iteration 49, loss = 0.80796009\n",
      "Iteration 50, loss = 0.78126520\n",
      "Iteration 1, loss = 1.22817852\n",
      "Iteration 2, loss = 1.12560353\n",
      "Iteration 3, loss = 1.06717596\n",
      "Iteration 4, loss = 1.03436477\n",
      "Iteration 5, loss = 1.05101431\n",
      "Iteration 6, loss = 1.00972157\n",
      "Iteration 7, loss = 1.03667692\n",
      "Iteration 8, loss = 0.97122350\n",
      "Iteration 9, loss = 0.95344317\n",
      "Iteration 10, loss = 0.94329692\n",
      "Iteration 11, loss = 0.97878175\n",
      "Iteration 12, loss = 0.97600712\n",
      "Iteration 49, loss = 0.80796009\n",
      "Iteration 50, loss = 0.78126520\n",
      "Iteration 1, loss = 1.22817852\n",
      "Iteration 2, loss = 1.12560353\n",
      "Iteration 3, loss = 1.06717596\n",
      "Iteration 4, loss = 1.03436477\n",
      "Iteration 5, loss = 1.05101431\n",
      "Iteration 6, loss = 1.00972157\n",
      "Iteration 7, loss = 1.03667692\n",
      "Iteration 8, loss = 0.97122350\n",
      "Iteration 9, loss = 0.95344317\n",
      "Iteration 10, loss = 0.94329692\n",
      "Iteration 11, loss = 0.97878175\n",
      "Iteration 12, loss = 0.97600712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.93187600\n",
      "Iteration 14, loss = 0.93316796\n",
      "Iteration 15, loss = 0.92560443\n",
      "Iteration 16, loss = 0.93905021\n",
      "Iteration 17, loss = 0.92114151\n",
      "Iteration 18, loss = 0.92769343\n",
      "Iteration 19, loss = 0.92683937\n",
      "Iteration 20, loss = 0.89433670\n",
      "Iteration 21, loss = 0.91890098\n",
      "Iteration 22, loss = 0.93406159\n",
      "Iteration 23, loss = 0.90579185\n",
      "Iteration 24, loss = 0.88106317\n",
      "Iteration 25, loss = 0.86542972\n",
      "Iteration 26, loss = 0.89278055\n",
      "Iteration 27, loss = 0.87491315\n",
      "Iteration 28, loss = 0.88133049\n",
      "Iteration 13, loss = 0.93187600\n",
      "Iteration 14, loss = 0.93316796\n",
      "Iteration 15, loss = 0.92560443\n",
      "Iteration 16, loss = 0.93905021\n",
      "Iteration 17, loss = 0.92114151\n",
      "Iteration 18, loss = 0.92769343\n",
      "Iteration 19, loss = 0.92683937\n",
      "Iteration 20, loss = 0.89433670\n",
      "Iteration 21, loss = 0.91890098\n",
      "Iteration 22, loss = 0.93406159\n",
      "Iteration 23, loss = 0.90579185\n",
      "Iteration 24, loss = 0.88106317\n",
      "Iteration 25, loss = 0.86542972\n",
      "Iteration 26, loss = 0.89278055\n",
      "Iteration 27, loss = 0.87491315\n",
      "Iteration 28, loss = 0.88133049\n",
      "Iteration 29, loss = 0.86585105\n",
      "Iteration 30, loss = 0.83259626\n",
      "Iteration 31, loss = 0.86053949\n",
      "Iteration 32, loss = 0.85108207\n",
      "Iteration 33, loss = 0.86046713\n",
      "Iteration 34, loss = 0.82503522\n",
      "Iteration 35, loss = 0.89027531\n",
      "Iteration 36, loss = 0.84280826\n",
      "Iteration 37, loss = 0.83459800\n",
      "Iteration 38, loss = 0.84788195\n",
      "Iteration 39, loss = 0.83375909\n",
      "Iteration 40, loss = 0.84313326\n",
      "Iteration 41, loss = 0.78550834\n",
      "Iteration 42, loss = 0.81533533\n",
      "Iteration 43, loss = 0.83283885\n",
      "Iteration 44, loss = 0.79166349\n",
      "Iteration 29, loss = 0.86585105\n",
      "Iteration 30, loss = 0.83259626\n",
      "Iteration 31, loss = 0.86053949\n",
      "Iteration 32, loss = 0.85108207\n",
      "Iteration 33, loss = 0.86046713\n",
      "Iteration 34, loss = 0.82503522\n",
      "Iteration 35, loss = 0.89027531\n",
      "Iteration 36, loss = 0.84280826\n",
      "Iteration 37, loss = 0.83459800\n",
      "Iteration 38, loss = 0.84788195\n",
      "Iteration 39, loss = 0.83375909\n",
      "Iteration 40, loss = 0.84313326\n",
      "Iteration 41, loss = 0.78550834\n",
      "Iteration 42, loss = 0.81533533\n",
      "Iteration 43, loss = 0.83283885\n",
      "Iteration 44, loss = 0.79166349\n",
      "Iteration 45, loss = 0.80456202\n",
      "Iteration 46, loss = 0.77269594\n",
      "Iteration 47, loss = 0.79760621\n",
      "Iteration 48, loss = 0.77927381\n",
      "Iteration 49, loss = 0.78674073\n",
      "Iteration 50, loss = 0.79914665\n",
      "Iteration 1, loss = 1.20896780\n",
      "Iteration 2, loss = 1.06099751\n",
      "Iteration 3, loss = 1.02633667\n",
      "Iteration 4, loss = 1.01053076\n",
      "Iteration 5, loss = 1.08271765\n",
      "Iteration 6, loss = 1.02074288\n",
      "Iteration 7, loss = 0.99805294\n",
      "Iteration 8, loss = 1.00744308\n",
      "Iteration 9, loss = 0.97315729\n",
      "Iteration 45, loss = 0.80456202\n",
      "Iteration 46, loss = 0.77269594\n",
      "Iteration 47, loss = 0.79760621\n",
      "Iteration 48, loss = 0.77927381\n",
      "Iteration 49, loss = 0.78674073\n",
      "Iteration 50, loss = 0.79914665\n",
      "Iteration 1, loss = 1.20896780\n",
      "Iteration 2, loss = 1.06099751\n",
      "Iteration 3, loss = 1.02633667\n",
      "Iteration 4, loss = 1.01053076\n",
      "Iteration 5, loss = 1.08271765\n",
      "Iteration 6, loss = 1.02074288\n",
      "Iteration 7, loss = 0.99805294\n",
      "Iteration 8, loss = 1.00744308\n",
      "Iteration 9, loss = 0.97315729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.92438895\n",
      "Iteration 11, loss = 0.97106979\n",
      "Iteration 12, loss = 0.92105530\n",
      "Iteration 13, loss = 0.92374832\n",
      "Iteration 14, loss = 0.93177876\n",
      "Iteration 15, loss = 0.94852433\n",
      "Iteration 16, loss = 0.93600329\n",
      "Iteration 17, loss = 0.93705012\n",
      "Iteration 18, loss = 0.95504618\n",
      "Iteration 19, loss = 0.92666407\n",
      "Iteration 20, loss = 0.88466392\n",
      "Iteration 21, loss = 0.90027494\n",
      "Iteration 22, loss = 0.90414324\n",
      "Iteration 23, loss = 0.92013593\n",
      "Iteration 24, loss = 0.87657160\n",
      "Iteration 10, loss = 0.92438895\n",
      "Iteration 11, loss = 0.97106979\n",
      "Iteration 12, loss = 0.92105530\n",
      "Iteration 13, loss = 0.92374832\n",
      "Iteration 14, loss = 0.93177876\n",
      "Iteration 15, loss = 0.94852433\n",
      "Iteration 16, loss = 0.93600329\n",
      "Iteration 17, loss = 0.93705012\n",
      "Iteration 18, loss = 0.95504618\n",
      "Iteration 19, loss = 0.92666407\n",
      "Iteration 20, loss = 0.88466392\n",
      "Iteration 21, loss = 0.90027494\n",
      "Iteration 22, loss = 0.90414324\n",
      "Iteration 23, loss = 0.92013593\n",
      "Iteration 24, loss = 0.87657160\n",
      "Iteration 25, loss = 0.88529940\n",
      "Iteration 26, loss = 0.86539812\n",
      "Iteration 27, loss = 0.85150674\n",
      "Iteration 28, loss = 0.87472510\n",
      "Iteration 29, loss = 0.85501536\n",
      "Iteration 30, loss = 0.84480004\n",
      "Iteration 31, loss = 0.87496127\n",
      "Iteration 32, loss = 0.87601946\n",
      "Iteration 33, loss = 0.82921625\n",
      "Iteration 34, loss = 0.84684353\n",
      "Iteration 35, loss = 0.86659695\n",
      "Iteration 36, loss = 0.82828996\n",
      "Iteration 37, loss = 0.88179719\n",
      "Iteration 38, loss = 0.84326787\n",
      "Iteration 39, loss = 0.80615870\n",
      "Iteration 40, loss = 0.82825403\n",
      "Iteration 25, loss = 0.88529940\n",
      "Iteration 26, loss = 0.86539812\n",
      "Iteration 27, loss = 0.85150674\n",
      "Iteration 28, loss = 0.87472510\n",
      "Iteration 29, loss = 0.85501536\n",
      "Iteration 30, loss = 0.84480004\n",
      "Iteration 31, loss = 0.87496127\n",
      "Iteration 32, loss = 0.87601946\n",
      "Iteration 33, loss = 0.82921625\n",
      "Iteration 34, loss = 0.84684353\n",
      "Iteration 35, loss = 0.86659695\n",
      "Iteration 36, loss = 0.82828996\n",
      "Iteration 37, loss = 0.88179719\n",
      "Iteration 38, loss = 0.84326787\n",
      "Iteration 39, loss = 0.80615870\n",
      "Iteration 40, loss = 0.82825403\n",
      "Iteration 41, loss = 0.82487628\n",
      "Iteration 42, loss = 0.85401039\n",
      "Iteration 43, loss = 0.84451956\n",
      "Iteration 44, loss = 0.82022948\n",
      "Iteration 45, loss = 0.82853638\n",
      "Iteration 46, loss = 0.78997397\n",
      "Iteration 47, loss = 0.80974701\n",
      "Iteration 48, loss = 0.81353657\n",
      "Iteration 49, loss = 0.85265232\n",
      "Iteration 50, loss = 0.82516849\n",
      "Iteration 1, loss = 1.21821372\n",
      "Iteration 2, loss = 1.08204339\n",
      "Iteration 3, loss = 1.05027868\n",
      "Iteration 41, loss = 0.82487628\n",
      "Iteration 42, loss = 0.85401039\n",
      "Iteration 43, loss = 0.84451956\n",
      "Iteration 44, loss = 0.82022948\n",
      "Iteration 45, loss = 0.82853638\n",
      "Iteration 46, loss = 0.78997397\n",
      "Iteration 47, loss = 0.80974701\n",
      "Iteration 48, loss = 0.81353657\n",
      "Iteration 49, loss = 0.85265232\n",
      "Iteration 50, loss = 0.82516849\n",
      "Iteration 1, loss = 1.21821372\n",
      "Iteration 2, loss = 1.08204339\n",
      "Iteration 3, loss = 1.05027868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.02015932\n",
      "Iteration 5, loss = 1.01927329\n",
      "Iteration 6, loss = 1.01159561\n",
      "Iteration 7, loss = 0.99223572\n",
      "Iteration 8, loss = 0.94815696\n",
      "Iteration 9, loss = 0.98382527\n",
      "Iteration 10, loss = 0.93154952\n",
      "Iteration 11, loss = 0.92243263\n",
      "Iteration 12, loss = 0.95128525\n",
      "Iteration 13, loss = 0.95400079\n",
      "Iteration 14, loss = 0.92436438\n",
      "Iteration 15, loss = 0.92469398\n",
      "Iteration 16, loss = 0.93572156\n",
      "Iteration 17, loss = 0.90891152\n",
      "Iteration 4, loss = 1.02015932\n",
      "Iteration 5, loss = 1.01927329\n",
      "Iteration 6, loss = 1.01159561\n",
      "Iteration 7, loss = 0.99223572\n",
      "Iteration 8, loss = 0.94815696\n",
      "Iteration 9, loss = 0.98382527\n",
      "Iteration 10, loss = 0.93154952\n",
      "Iteration 11, loss = 0.92243263\n",
      "Iteration 12, loss = 0.95128525\n",
      "Iteration 13, loss = 0.95400079\n",
      "Iteration 14, loss = 0.92436438\n",
      "Iteration 15, loss = 0.92469398\n",
      "Iteration 16, loss = 0.93572156\n",
      "Iteration 17, loss = 0.90891152\n",
      "Iteration 18, loss = 0.95329009\n",
      "Iteration 19, loss = 0.94450659\n",
      "Iteration 20, loss = 0.93857179\n",
      "Iteration 21, loss = 0.86347742\n",
      "Iteration 22, loss = 0.88165457\n",
      "Iteration 23, loss = 0.94966100\n",
      "Iteration 24, loss = 0.88737128\n",
      "Iteration 25, loss = 0.87781124\n",
      "Iteration 26, loss = 0.88526314\n",
      "Iteration 27, loss = 0.88919087\n",
      "Iteration 28, loss = 0.87912992\n",
      "Iteration 29, loss = 0.84511583\n",
      "Iteration 30, loss = 0.84586069\n",
      "Iteration 31, loss = 0.83819788\n",
      "Iteration 32, loss = 0.87406164\n",
      "Iteration 18, loss = 0.95329009\n",
      "Iteration 19, loss = 0.94450659\n",
      "Iteration 20, loss = 0.93857179\n",
      "Iteration 21, loss = 0.86347742\n",
      "Iteration 22, loss = 0.88165457\n",
      "Iteration 23, loss = 0.94966100\n",
      "Iteration 24, loss = 0.88737128\n",
      "Iteration 25, loss = 0.87781124\n",
      "Iteration 26, loss = 0.88526314\n",
      "Iteration 27, loss = 0.88919087\n",
      "Iteration 28, loss = 0.87912992\n",
      "Iteration 29, loss = 0.84511583\n",
      "Iteration 30, loss = 0.84586069\n",
      "Iteration 31, loss = 0.83819788\n",
      "Iteration 32, loss = 0.87406164\n",
      "Iteration 33, loss = 0.85032698\n",
      "Iteration 34, loss = 0.83992811\n",
      "Iteration 35, loss = 0.81205324\n",
      "Iteration 36, loss = 0.84589696\n",
      "Iteration 37, loss = 0.84163616\n",
      "Iteration 38, loss = 0.82382103\n",
      "Iteration 39, loss = 0.85209901\n",
      "Iteration 40, loss = 0.81832958\n",
      "Iteration 41, loss = 0.81276992\n",
      "Iteration 42, loss = 0.81729207\n",
      "Iteration 43, loss = 0.83706287\n",
      "Iteration 44, loss = 0.81209841\n",
      "Iteration 45, loss = 0.82917762\n",
      "Iteration 46, loss = 0.82801057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18811615\n",
      "Iteration 33, loss = 0.85032698\n",
      "Iteration 34, loss = 0.83992811\n",
      "Iteration 35, loss = 0.81205324\n",
      "Iteration 36, loss = 0.84589696\n",
      "Iteration 37, loss = 0.84163616\n",
      "Iteration 38, loss = 0.82382103\n",
      "Iteration 39, loss = 0.85209901\n",
      "Iteration 40, loss = 0.81832958\n",
      "Iteration 41, loss = 0.81276992\n",
      "Iteration 42, loss = 0.81729207\n",
      "Iteration 43, loss = 0.83706287\n",
      "Iteration 44, loss = 0.81209841\n",
      "Iteration 45, loss = 0.82917762\n",
      "Iteration 46, loss = 0.82801057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18811615\n",
      "Iteration 2, loss = 1.08312675\n",
      "Iteration 3, loss = 1.00366239\n",
      "Iteration 4, loss = 0.95444093\n",
      "Iteration 5, loss = 0.95986478\n",
      "Iteration 6, loss = 1.01326591\n",
      "Iteration 7, loss = 0.96541161\n",
      "Iteration 8, loss = 0.93845878\n",
      "Iteration 9, loss = 0.90819268\n",
      "Iteration 10, loss = 0.89434031\n",
      "Iteration 11, loss = 0.90622387\n",
      "Iteration 12, loss = 0.93498273\n",
      "Iteration 13, loss = 0.90186514\n",
      "Iteration 14, loss = 0.90139123\n",
      "Iteration 15, loss = 0.87822221\n",
      "Iteration 16, loss = 0.90120050\n",
      "Iteration 2, loss = 1.08312675\n",
      "Iteration 3, loss = 1.00366239\n",
      "Iteration 4, loss = 0.95444093\n",
      "Iteration 5, loss = 0.95986478\n",
      "Iteration 6, loss = 1.01326591\n",
      "Iteration 7, loss = 0.96541161\n",
      "Iteration 8, loss = 0.93845878\n",
      "Iteration 9, loss = 0.90819268\n",
      "Iteration 10, loss = 0.89434031\n",
      "Iteration 11, loss = 0.90622387\n",
      "Iteration 12, loss = 0.93498273\n",
      "Iteration 13, loss = 0.90186514\n",
      "Iteration 14, loss = 0.90139123\n",
      "Iteration 15, loss = 0.87822221\n",
      "Iteration 16, loss = 0.90120050\n",
      "Iteration 17, loss = 0.87802125\n",
      "Iteration 18, loss = 0.87053890\n",
      "Iteration 19, loss = 0.89440889\n",
      "Iteration 20, loss = 0.84507388\n",
      "Iteration 21, loss = 0.85085581\n",
      "Iteration 22, loss = 0.86246529\n",
      "Iteration 23, loss = 0.86843696\n",
      "Iteration 24, loss = 0.84823476\n",
      "Iteration 25, loss = 0.82110172\n",
      "Iteration 26, loss = 0.81869499\n",
      "Iteration 27, loss = 0.84095774\n",
      "Iteration 28, loss = 0.83298718\n",
      "Iteration 29, loss = 0.86368251\n",
      "Iteration 30, loss = 0.82656504\n",
      "Iteration 31, loss = 0.82389690\n",
      "Iteration 32, loss = 0.82630891\n",
      "Iteration 17, loss = 0.87802125\n",
      "Iteration 18, loss = 0.87053890\n",
      "Iteration 19, loss = 0.89440889\n",
      "Iteration 20, loss = 0.84507388\n",
      "Iteration 21, loss = 0.85085581\n",
      "Iteration 22, loss = 0.86246529\n",
      "Iteration 23, loss = 0.86843696\n",
      "Iteration 24, loss = 0.84823476\n",
      "Iteration 25, loss = 0.82110172\n",
      "Iteration 26, loss = 0.81869499\n",
      "Iteration 27, loss = 0.84095774\n",
      "Iteration 28, loss = 0.83298718\n",
      "Iteration 29, loss = 0.86368251\n",
      "Iteration 30, loss = 0.82656504\n",
      "Iteration 31, loss = 0.82389690\n",
      "Iteration 32, loss = 0.82630891\n",
      "Iteration 33, loss = 0.81666324\n",
      "Iteration 34, loss = 0.79801402\n",
      "Iteration 35, loss = 0.79144785\n",
      "Iteration 36, loss = 0.79659617\n",
      "Iteration 37, loss = 0.77151959\n",
      "Iteration 38, loss = 0.81088735\n",
      "Iteration 39, loss = 0.78299272\n",
      "Iteration 40, loss = 0.79059072\n",
      "Iteration 41, loss = 0.76537698\n",
      "Iteration 42, loss = 0.77292202\n",
      "Iteration 43, loss = 0.77885320\n",
      "Iteration 44, loss = 0.80530159\n",
      "Iteration 45, loss = 0.78010819\n",
      "Iteration 46, loss = 0.77625691\n",
      "Iteration 47, loss = 0.82661486\n",
      "Iteration 48, loss = 0.76873960\n",
      "Iteration 33, loss = 0.81666324\n",
      "Iteration 34, loss = 0.79801402\n",
      "Iteration 35, loss = 0.79144785\n",
      "Iteration 36, loss = 0.79659617\n",
      "Iteration 37, loss = 0.77151959\n",
      "Iteration 38, loss = 0.81088735\n",
      "Iteration 39, loss = 0.78299272\n",
      "Iteration 40, loss = 0.79059072\n",
      "Iteration 41, loss = 0.76537698\n",
      "Iteration 42, loss = 0.77292202\n",
      "Iteration 43, loss = 0.77885320\n",
      "Iteration 44, loss = 0.80530159\n",
      "Iteration 45, loss = 0.78010819\n",
      "Iteration 46, loss = 0.77625691\n",
      "Iteration 47, loss = 0.82661486\n",
      "Iteration 48, loss = 0.76873960\n",
      "Iteration 49, loss = 0.74959700\n",
      "Iteration 50, loss = 0.75313406\n",
      "Iteration 51, loss = 0.77333297\n",
      "Iteration 52, loss = 0.80170557\n",
      "Iteration 53, loss = 0.77152125\n",
      "Iteration 54, loss = 0.75754027\n",
      "Iteration 55, loss = 0.76629598\n",
      "Iteration 56, loss = 0.75257531\n",
      "Iteration 57, loss = 0.75425193\n",
      "Iteration 58, loss = 0.73610207\n",
      "Iteration 59, loss = 0.74672888\n",
      "Iteration 60, loss = 0.76775371\n",
      "Iteration 61, loss = 0.78317664\n",
      "Iteration 62, loss = 0.80331470\n",
      "Iteration 63, loss = 0.73265870\n",
      "Iteration 49, loss = 0.74959700\n",
      "Iteration 50, loss = 0.75313406\n",
      "Iteration 51, loss = 0.77333297\n",
      "Iteration 52, loss = 0.80170557\n",
      "Iteration 53, loss = 0.77152125\n",
      "Iteration 54, loss = 0.75754027\n",
      "Iteration 55, loss = 0.76629598\n",
      "Iteration 56, loss = 0.75257531\n",
      "Iteration 57, loss = 0.75425193\n",
      "Iteration 58, loss = 0.73610207\n",
      "Iteration 59, loss = 0.74672888\n",
      "Iteration 60, loss = 0.76775371\n",
      "Iteration 61, loss = 0.78317664\n",
      "Iteration 62, loss = 0.80331470\n",
      "Iteration 63, loss = 0.73265870\n",
      "Iteration 64, loss = 0.74641183\n",
      "Iteration 65, loss = 0.72823321\n",
      "Iteration 66, loss = 0.76788460\n",
      "Iteration 67, loss = 0.74691479\n",
      "Iteration 68, loss = 0.69511827\n",
      "Iteration 69, loss = 0.73531584\n",
      "Iteration 70, loss = 0.72637057\n",
      "Iteration 71, loss = 0.71669779\n",
      "Iteration 72, loss = 0.71586884\n",
      "Iteration 73, loss = 0.71006579\n",
      "Iteration 74, loss = 0.76096115\n",
      "Iteration 75, loss = 0.73868650\n",
      "Iteration 76, loss = 0.68567733\n",
      "Iteration 77, loss = 0.75372181\n",
      "Iteration 78, loss = 0.73864406\n",
      "Iteration 64, loss = 0.74641183\n",
      "Iteration 65, loss = 0.72823321\n",
      "Iteration 66, loss = 0.76788460\n",
      "Iteration 67, loss = 0.74691479\n",
      "Iteration 68, loss = 0.69511827\n",
      "Iteration 69, loss = 0.73531584\n",
      "Iteration 70, loss = 0.72637057\n",
      "Iteration 71, loss = 0.71669779\n",
      "Iteration 72, loss = 0.71586884\n",
      "Iteration 73, loss = 0.71006579\n",
      "Iteration 74, loss = 0.76096115\n",
      "Iteration 75, loss = 0.73868650\n",
      "Iteration 76, loss = 0.68567733\n",
      "Iteration 77, loss = 0.75372181\n",
      "Iteration 78, loss = 0.73864406\n",
      "Iteration 79, loss = 0.72276623\n",
      "Iteration 80, loss = 0.67996336\n",
      "Iteration 81, loss = 0.73145907\n",
      "Iteration 82, loss = 0.73422839\n",
      "Iteration 83, loss = 0.69403291\n",
      "Iteration 84, loss = 0.71252291\n",
      "Iteration 85, loss = 0.72950191\n",
      "Iteration 86, loss = 0.75247967\n",
      "Iteration 87, loss = 0.70390917\n",
      "Iteration 88, loss = 0.74101117\n",
      "Iteration 89, loss = 0.70480858\n",
      "Iteration 90, loss = 0.67006012\n",
      "Iteration 91, loss = 0.69340929\n",
      "Iteration 92, loss = 0.74942882\n",
      "Iteration 93, loss = 0.72640781\n",
      "Iteration 94, loss = 0.73832233\n",
      "Iteration 79, loss = 0.72276623\n",
      "Iteration 80, loss = 0.67996336\n",
      "Iteration 81, loss = 0.73145907\n",
      "Iteration 82, loss = 0.73422839\n",
      "Iteration 83, loss = 0.69403291\n",
      "Iteration 84, loss = 0.71252291\n",
      "Iteration 85, loss = 0.72950191\n",
      "Iteration 86, loss = 0.75247967\n",
      "Iteration 87, loss = 0.70390917\n",
      "Iteration 88, loss = 0.74101117\n",
      "Iteration 89, loss = 0.70480858\n",
      "Iteration 90, loss = 0.67006012\n",
      "Iteration 91, loss = 0.69340929\n",
      "Iteration 92, loss = 0.74942882\n",
      "Iteration 93, loss = 0.72640781\n",
      "Iteration 94, loss = 0.73832233\n",
      "Iteration 95, loss = 0.69728846\n",
      "Iteration 96, loss = 0.68869084\n",
      "Iteration 97, loss = 0.69201344\n",
      "Iteration 98, loss = 0.68515667\n",
      "Iteration 99, loss = 0.70254330\n",
      "Iteration 100, loss = 0.68450502\n",
      "Iteration 1, loss = 1.20443075\n",
      "Iteration 2, loss = 1.16437285\n",
      "Iteration 3, loss = 1.08253860\n",
      "Iteration 4, loss = 1.02001078\n",
      "Iteration 5, loss = 1.01325213\n",
      "Iteration 6, loss = 1.02019306\n",
      "Iteration 7, loss = 1.04073497\n",
      "Iteration 8, loss = 0.96573079\n",
      "Iteration 95, loss = 0.69728846\n",
      "Iteration 96, loss = 0.68869084\n",
      "Iteration 97, loss = 0.69201344\n",
      "Iteration 98, loss = 0.68515667\n",
      "Iteration 99, loss = 0.70254330\n",
      "Iteration 100, loss = 0.68450502\n",
      "Iteration 1, loss = 1.20443075\n",
      "Iteration 2, loss = 1.16437285\n",
      "Iteration 3, loss = 1.08253860\n",
      "Iteration 4, loss = 1.02001078\n",
      "Iteration 5, loss = 1.01325213\n",
      "Iteration 6, loss = 1.02019306\n",
      "Iteration 7, loss = 1.04073497\n",
      "Iteration 8, loss = 0.96573079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.97252281\n",
      "Iteration 10, loss = 0.93432026\n",
      "Iteration 11, loss = 1.04027355\n",
      "Iteration 12, loss = 0.92962312\n",
      "Iteration 13, loss = 0.94753287\n",
      "Iteration 14, loss = 0.94961420\n",
      "Iteration 15, loss = 0.94329830\n",
      "Iteration 16, loss = 0.91735501\n",
      "Iteration 17, loss = 0.92722701\n",
      "Iteration 18, loss = 0.92514454\n",
      "Iteration 19, loss = 0.94894692\n",
      "Iteration 20, loss = 0.92477130\n",
      "Iteration 21, loss = 0.89132348\n",
      "Iteration 22, loss = 0.89103288\n",
      "Iteration 23, loss = 0.87942962\n",
      "Iteration 9, loss = 0.97252281\n",
      "Iteration 10, loss = 0.93432026\n",
      "Iteration 11, loss = 1.04027355\n",
      "Iteration 12, loss = 0.92962312\n",
      "Iteration 13, loss = 0.94753287\n",
      "Iteration 14, loss = 0.94961420\n",
      "Iteration 15, loss = 0.94329830\n",
      "Iteration 16, loss = 0.91735501\n",
      "Iteration 17, loss = 0.92722701\n",
      "Iteration 18, loss = 0.92514454\n",
      "Iteration 19, loss = 0.94894692\n",
      "Iteration 20, loss = 0.92477130\n",
      "Iteration 21, loss = 0.89132348\n",
      "Iteration 22, loss = 0.89103288\n",
      "Iteration 23, loss = 0.87942962\n",
      "Iteration 24, loss = 0.90724681\n",
      "Iteration 25, loss = 0.89716554\n",
      "Iteration 26, loss = 0.86844946\n",
      "Iteration 27, loss = 0.90470751\n",
      "Iteration 28, loss = 0.89691008\n",
      "Iteration 29, loss = 0.83792391\n",
      "Iteration 30, loss = 0.88949189\n",
      "Iteration 31, loss = 0.86836227\n",
      "Iteration 32, loss = 0.87962052\n",
      "Iteration 33, loss = 0.86288314\n",
      "Iteration 34, loss = 0.85434321\n",
      "Iteration 35, loss = 0.85247439\n",
      "Iteration 36, loss = 0.86921182\n",
      "Iteration 37, loss = 0.86954251\n",
      "Iteration 38, loss = 0.82440201\n",
      "Iteration 39, loss = 0.85107414\n",
      "Iteration 24, loss = 0.90724681\n",
      "Iteration 25, loss = 0.89716554\n",
      "Iteration 26, loss = 0.86844946\n",
      "Iteration 27, loss = 0.90470751\n",
      "Iteration 28, loss = 0.89691008\n",
      "Iteration 29, loss = 0.83792391\n",
      "Iteration 30, loss = 0.88949189\n",
      "Iteration 31, loss = 0.86836227\n",
      "Iteration 32, loss = 0.87962052\n",
      "Iteration 33, loss = 0.86288314\n",
      "Iteration 34, loss = 0.85434321\n",
      "Iteration 35, loss = 0.85247439\n",
      "Iteration 36, loss = 0.86921182\n",
      "Iteration 37, loss = 0.86954251\n",
      "Iteration 38, loss = 0.82440201\n",
      "Iteration 39, loss = 0.85107414\n",
      "Iteration 40, loss = 0.87384748\n",
      "Iteration 41, loss = 0.79657542\n",
      "Iteration 42, loss = 0.88627871\n",
      "Iteration 43, loss = 0.83610075\n",
      "Iteration 44, loss = 0.81838252\n",
      "Iteration 45, loss = 0.79716128\n",
      "Iteration 46, loss = 0.82424810\n",
      "Iteration 47, loss = 0.81159944\n",
      "Iteration 48, loss = 0.79176198\n",
      "Iteration 49, loss = 0.80796009\n",
      "Iteration 50, loss = 0.78126520\n",
      "Iteration 51, loss = 0.79443731\n",
      "Iteration 52, loss = 0.79350813\n",
      "Iteration 53, loss = 0.77572388\n",
      "Iteration 54, loss = 0.80763114\n",
      "Iteration 40, loss = 0.87384748\n",
      "Iteration 41, loss = 0.79657542\n",
      "Iteration 42, loss = 0.88627871\n",
      "Iteration 43, loss = 0.83610075\n",
      "Iteration 44, loss = 0.81838252\n",
      "Iteration 45, loss = 0.79716128\n",
      "Iteration 46, loss = 0.82424810\n",
      "Iteration 47, loss = 0.81159944\n",
      "Iteration 48, loss = 0.79176198\n",
      "Iteration 49, loss = 0.80796009\n",
      "Iteration 50, loss = 0.78126520\n",
      "Iteration 51, loss = 0.79443731\n",
      "Iteration 52, loss = 0.79350813\n",
      "Iteration 53, loss = 0.77572388\n",
      "Iteration 54, loss = 0.80763114\n",
      "Iteration 55, loss = 0.79326035\n",
      "Iteration 56, loss = 0.79801361\n",
      "Iteration 57, loss = 0.76429328\n",
      "Iteration 58, loss = 0.77366792\n",
      "Iteration 59, loss = 0.83697864\n",
      "Iteration 60, loss = 0.83507757\n",
      "Iteration 61, loss = 0.82656872\n",
      "Iteration 62, loss = 0.81591939\n",
      "Iteration 63, loss = 0.81738049\n",
      "Iteration 64, loss = 0.83025942\n",
      "Iteration 65, loss = 0.81649789\n",
      "Iteration 66, loss = 0.78741243\n",
      "Iteration 67, loss = 0.80256648\n",
      "Iteration 68, loss = 0.79442874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22817852\n",
      "Iteration 2, loss = 1.12560353\n",
      "Iteration 55, loss = 0.79326035\n",
      "Iteration 56, loss = 0.79801361\n",
      "Iteration 57, loss = 0.76429328\n",
      "Iteration 58, loss = 0.77366792\n",
      "Iteration 59, loss = 0.83697864\n",
      "Iteration 60, loss = 0.83507757\n",
      "Iteration 61, loss = 0.82656872\n",
      "Iteration 62, loss = 0.81591939\n",
      "Iteration 63, loss = 0.81738049\n",
      "Iteration 64, loss = 0.83025942\n",
      "Iteration 65, loss = 0.81649789\n",
      "Iteration 66, loss = 0.78741243\n",
      "Iteration 67, loss = 0.80256648\n",
      "Iteration 68, loss = 0.79442874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22817852\n",
      "Iteration 2, loss = 1.12560353\n",
      "Iteration 3, loss = 1.06717596\n",
      "Iteration 4, loss = 1.03436477\n",
      "Iteration 5, loss = 1.05101431\n",
      "Iteration 6, loss = 1.00972157\n",
      "Iteration 7, loss = 1.03667692\n",
      "Iteration 8, loss = 0.97122350\n",
      "Iteration 9, loss = 0.95344317\n",
      "Iteration 10, loss = 0.94329692\n",
      "Iteration 11, loss = 0.97878175\n",
      "Iteration 12, loss = 0.97600712\n",
      "Iteration 13, loss = 0.93187600\n",
      "Iteration 14, loss = 0.93316796\n",
      "Iteration 15, loss = 0.92560443\n",
      "Iteration 16, loss = 0.93905021\n",
      "Iteration 3, loss = 1.06717596\n",
      "Iteration 4, loss = 1.03436477\n",
      "Iteration 5, loss = 1.05101431\n",
      "Iteration 6, loss = 1.00972157\n",
      "Iteration 7, loss = 1.03667692\n",
      "Iteration 8, loss = 0.97122350\n",
      "Iteration 9, loss = 0.95344317\n",
      "Iteration 10, loss = 0.94329692\n",
      "Iteration 11, loss = 0.97878175\n",
      "Iteration 12, loss = 0.97600712\n",
      "Iteration 13, loss = 0.93187600\n",
      "Iteration 14, loss = 0.93316796\n",
      "Iteration 15, loss = 0.92560443\n",
      "Iteration 16, loss = 0.93905021\n",
      "Iteration 17, loss = 0.92114151\n",
      "Iteration 18, loss = 0.92769343\n",
      "Iteration 19, loss = 0.92683937\n",
      "Iteration 20, loss = 0.89433670\n",
      "Iteration 21, loss = 0.91890098\n",
      "Iteration 22, loss = 0.93406159\n",
      "Iteration 23, loss = 0.90579185\n",
      "Iteration 24, loss = 0.88106317\n",
      "Iteration 25, loss = 0.86542972\n",
      "Iteration 26, loss = 0.89278055\n",
      "Iteration 27, loss = 0.87491315\n",
      "Iteration 28, loss = 0.88133049\n",
      "Iteration 29, loss = 0.86585105\n",
      "Iteration 30, loss = 0.83259626\n",
      "Iteration 31, loss = 0.86053949\n",
      "Iteration 32, loss = 0.85108207\n",
      "Iteration 17, loss = 0.92114151\n",
      "Iteration 18, loss = 0.92769343\n",
      "Iteration 19, loss = 0.92683937\n",
      "Iteration 20, loss = 0.89433670\n",
      "Iteration 21, loss = 0.91890098\n",
      "Iteration 22, loss = 0.93406159\n",
      "Iteration 23, loss = 0.90579185\n",
      "Iteration 24, loss = 0.88106317\n",
      "Iteration 25, loss = 0.86542972\n",
      "Iteration 26, loss = 0.89278055\n",
      "Iteration 27, loss = 0.87491315\n",
      "Iteration 28, loss = 0.88133049\n",
      "Iteration 29, loss = 0.86585105\n",
      "Iteration 30, loss = 0.83259626\n",
      "Iteration 31, loss = 0.86053949\n",
      "Iteration 32, loss = 0.85108207\n",
      "Iteration 33, loss = 0.86046713\n",
      "Iteration 34, loss = 0.82503522\n",
      "Iteration 35, loss = 0.89027531\n",
      "Iteration 36, loss = 0.84280826\n",
      "Iteration 37, loss = 0.83459800\n",
      "Iteration 38, loss = 0.84788195\n",
      "Iteration 39, loss = 0.83375909\n",
      "Iteration 40, loss = 0.84313326\n",
      "Iteration 41, loss = 0.78550834\n",
      "Iteration 42, loss = 0.81533533\n",
      "Iteration 43, loss = 0.83283885\n",
      "Iteration 44, loss = 0.79166349\n",
      "Iteration 45, loss = 0.80456202\n",
      "Iteration 46, loss = 0.77269594\n",
      "Iteration 47, loss = 0.79760621\n",
      "Iteration 48, loss = 0.77927381\n",
      "Iteration 33, loss = 0.86046713\n",
      "Iteration 34, loss = 0.82503522\n",
      "Iteration 35, loss = 0.89027531\n",
      "Iteration 36, loss = 0.84280826\n",
      "Iteration 37, loss = 0.83459800\n",
      "Iteration 38, loss = 0.84788195\n",
      "Iteration 39, loss = 0.83375909\n",
      "Iteration 40, loss = 0.84313326\n",
      "Iteration 41, loss = 0.78550834\n",
      "Iteration 42, loss = 0.81533533\n",
      "Iteration 43, loss = 0.83283885\n",
      "Iteration 44, loss = 0.79166349\n",
      "Iteration 45, loss = 0.80456202\n",
      "Iteration 46, loss = 0.77269594\n",
      "Iteration 47, loss = 0.79760621\n",
      "Iteration 48, loss = 0.77927381\n",
      "Iteration 49, loss = 0.78674073\n",
      "Iteration 50, loss = 0.79914665\n",
      "Iteration 51, loss = 0.80469495\n",
      "Iteration 52, loss = 0.78073708\n",
      "Iteration 53, loss = 0.81703464\n",
      "Iteration 54, loss = 0.78506352\n",
      "Iteration 55, loss = 0.83384803\n",
      "Iteration 56, loss = 0.85938209\n",
      "Iteration 57, loss = 0.83516165\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20896780\n",
      "Iteration 2, loss = 1.06099751\n",
      "Iteration 3, loss = 1.02633667\n",
      "Iteration 4, loss = 1.01053076\n",
      "Iteration 5, loss = 1.08271765\n",
      "Iteration 6, loss = 1.02074288\n",
      "Iteration 49, loss = 0.78674073\n",
      "Iteration 50, loss = 0.79914665\n",
      "Iteration 51, loss = 0.80469495\n",
      "Iteration 52, loss = 0.78073708\n",
      "Iteration 53, loss = 0.81703464\n",
      "Iteration 54, loss = 0.78506352\n",
      "Iteration 55, loss = 0.83384803\n",
      "Iteration 56, loss = 0.85938209\n",
      "Iteration 57, loss = 0.83516165\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20896780\n",
      "Iteration 2, loss = 1.06099751\n",
      "Iteration 3, loss = 1.02633667\n",
      "Iteration 4, loss = 1.01053076\n",
      "Iteration 5, loss = 1.08271765\n",
      "Iteration 6, loss = 1.02074288\n",
      "Iteration 7, loss = 0.99805294\n",
      "Iteration 8, loss = 1.00744308\n",
      "Iteration 9, loss = 0.97315729\n",
      "Iteration 10, loss = 0.92438895\n",
      "Iteration 11, loss = 0.97106979\n",
      "Iteration 12, loss = 0.92105530\n",
      "Iteration 13, loss = 0.92374832\n",
      "Iteration 14, loss = 0.93177876\n",
      "Iteration 15, loss = 0.94852433\n",
      "Iteration 16, loss = 0.93600329\n",
      "Iteration 17, loss = 0.93705012\n",
      "Iteration 18, loss = 0.95504618\n",
      "Iteration 19, loss = 0.92666407\n",
      "Iteration 20, loss = 0.88466392\n",
      "Iteration 7, loss = 0.99805294\n",
      "Iteration 8, loss = 1.00744308\n",
      "Iteration 9, loss = 0.97315729\n",
      "Iteration 10, loss = 0.92438895\n",
      "Iteration 11, loss = 0.97106979\n",
      "Iteration 12, loss = 0.92105530\n",
      "Iteration 13, loss = 0.92374832\n",
      "Iteration 14, loss = 0.93177876\n",
      "Iteration 15, loss = 0.94852433\n",
      "Iteration 16, loss = 0.93600329\n",
      "Iteration 17, loss = 0.93705012\n",
      "Iteration 18, loss = 0.95504618\n",
      "Iteration 19, loss = 0.92666407\n",
      "Iteration 20, loss = 0.88466392\n",
      "Iteration 21, loss = 0.90027494\n",
      "Iteration 22, loss = 0.90414324\n",
      "Iteration 23, loss = 0.92013593\n",
      "Iteration 24, loss = 0.87657160\n",
      "Iteration 25, loss = 0.88529940\n",
      "Iteration 26, loss = 0.86539812\n",
      "Iteration 27, loss = 0.85150674\n",
      "Iteration 28, loss = 0.87472510\n",
      "Iteration 29, loss = 0.85501536\n",
      "Iteration 30, loss = 0.84480004\n",
      "Iteration 31, loss = 0.87496127\n",
      "Iteration 32, loss = 0.87601946\n",
      "Iteration 33, loss = 0.82921625\n",
      "Iteration 34, loss = 0.84684353\n",
      "Iteration 35, loss = 0.86659695\n",
      "Iteration 36, loss = 0.82828996\n",
      "Iteration 21, loss = 0.90027494\n",
      "Iteration 22, loss = 0.90414324\n",
      "Iteration 23, loss = 0.92013593\n",
      "Iteration 24, loss = 0.87657160\n",
      "Iteration 25, loss = 0.88529940\n",
      "Iteration 26, loss = 0.86539812\n",
      "Iteration 27, loss = 0.85150674\n",
      "Iteration 28, loss = 0.87472510\n",
      "Iteration 29, loss = 0.85501536\n",
      "Iteration 30, loss = 0.84480004\n",
      "Iteration 31, loss = 0.87496127\n",
      "Iteration 32, loss = 0.87601946\n",
      "Iteration 33, loss = 0.82921625\n",
      "Iteration 34, loss = 0.84684353\n",
      "Iteration 35, loss = 0.86659695\n",
      "Iteration 36, loss = 0.82828996\n",
      "Iteration 37, loss = 0.88179719\n",
      "Iteration 38, loss = 0.84326787\n",
      "Iteration 39, loss = 0.80615870\n",
      "Iteration 40, loss = 0.82825403\n",
      "Iteration 41, loss = 0.82487628\n",
      "Iteration 42, loss = 0.85401039\n",
      "Iteration 43, loss = 0.84451956\n",
      "Iteration 44, loss = 0.82022948\n",
      "Iteration 45, loss = 0.82853638\n",
      "Iteration 46, loss = 0.78997397\n",
      "Iteration 47, loss = 0.80974701\n",
      "Iteration 48, loss = 0.81353657\n",
      "Iteration 49, loss = 0.85265232\n",
      "Iteration 50, loss = 0.82516849\n",
      "Iteration 51, loss = 0.81996333\n",
      "Iteration 37, loss = 0.88179719\n",
      "Iteration 38, loss = 0.84326787\n",
      "Iteration 39, loss = 0.80615870\n",
      "Iteration 40, loss = 0.82825403\n",
      "Iteration 41, loss = 0.82487628\n",
      "Iteration 42, loss = 0.85401039\n",
      "Iteration 43, loss = 0.84451956\n",
      "Iteration 44, loss = 0.82022948\n",
      "Iteration 45, loss = 0.82853638\n",
      "Iteration 46, loss = 0.78997397\n",
      "Iteration 47, loss = 0.80974701\n",
      "Iteration 48, loss = 0.81353657\n",
      "Iteration 49, loss = 0.85265232\n",
      "Iteration 50, loss = 0.82516849\n",
      "Iteration 51, loss = 0.81996333\n",
      "Iteration 52, loss = 0.80976619\n",
      "Iteration 53, loss = 0.81250711\n",
      "Iteration 54, loss = 0.78288241\n",
      "Iteration 55, loss = 0.80136488\n",
      "Iteration 56, loss = 0.80491029\n",
      "Iteration 57, loss = 0.76625911\n",
      "Iteration 58, loss = 0.81656014\n",
      "Iteration 59, loss = 0.80987656\n",
      "Iteration 60, loss = 0.74018592\n",
      "Iteration 61, loss = 0.79007433\n",
      "Iteration 62, loss = 0.80514368\n",
      "Iteration 63, loss = 0.76546056\n",
      "Iteration 64, loss = 0.76999477\n",
      "Iteration 65, loss = 0.76848644\n",
      "Iteration 66, loss = 0.75404317\n",
      "Iteration 67, loss = 0.76426063\n",
      "Iteration 52, loss = 0.80976619\n",
      "Iteration 53, loss = 0.81250711\n",
      "Iteration 54, loss = 0.78288241\n",
      "Iteration 55, loss = 0.80136488\n",
      "Iteration 56, loss = 0.80491029\n",
      "Iteration 57, loss = 0.76625911\n",
      "Iteration 58, loss = 0.81656014\n",
      "Iteration 59, loss = 0.80987656\n",
      "Iteration 60, loss = 0.74018592\n",
      "Iteration 61, loss = 0.79007433\n",
      "Iteration 62, loss = 0.80514368\n",
      "Iteration 63, loss = 0.76546056\n",
      "Iteration 64, loss = 0.76999477\n",
      "Iteration 65, loss = 0.76848644\n",
      "Iteration 66, loss = 0.75404317\n",
      "Iteration 67, loss = 0.76426063\n",
      "Iteration 68, loss = 0.75148991\n",
      "Iteration 69, loss = 0.73352894\n",
      "Iteration 70, loss = 0.79213129\n",
      "Iteration 71, loss = 0.75570441\n",
      "Iteration 72, loss = 0.76056036\n",
      "Iteration 73, loss = 0.81062725\n",
      "Iteration 74, loss = 0.76012579\n",
      "Iteration 75, loss = 0.77251093\n",
      "Iteration 76, loss = 0.75641361\n",
      "Iteration 77, loss = 0.74110049\n",
      "Iteration 78, loss = 0.75772919\n",
      "Iteration 79, loss = 0.77078281\n",
      "Iteration 80, loss = 0.73618976\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23532840\n",
      "Iteration 2, loss = 1.21393107\n",
      "Iteration 68, loss = 0.75148991\n",
      "Iteration 69, loss = 0.73352894\n",
      "Iteration 70, loss = 0.79213129\n",
      "Iteration 71, loss = 0.75570441\n",
      "Iteration 72, loss = 0.76056036\n",
      "Iteration 73, loss = 0.81062725\n",
      "Iteration 74, loss = 0.76012579\n",
      "Iteration 75, loss = 0.77251093\n",
      "Iteration 76, loss = 0.75641361\n",
      "Iteration 77, loss = 0.74110049\n",
      "Iteration 78, loss = 0.75772919\n",
      "Iteration 79, loss = 0.77078281\n",
      "Iteration 80, loss = 0.73618976\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23532840\n",
      "Iteration 2, loss = 1.21393107\n",
      "Iteration 3, loss = 1.13015039\n",
      "Iteration 4, loss = 1.10951288\n",
      "Iteration 5, loss = 1.07603822\n",
      "Iteration 6, loss = 1.06519784\n",
      "Iteration 7, loss = 1.05993658\n",
      "Iteration 8, loss = 1.00472032\n",
      "Iteration 9, loss = 1.02630080\n",
      "Iteration 10, loss = 0.97117422\n",
      "Iteration 1, loss = 1.22005904\n",
      "Iteration 2, loss = 1.12050223\n",
      "Iteration 3, loss = 0.97314501\n",
      "Iteration 4, loss = 0.98620621\n",
      "Iteration 5, loss = 0.97052064\n",
      "Iteration 6, loss = 0.98581206\n",
      "Iteration 7, loss = 0.93795318\n",
      "Iteration 3, loss = 1.13015039\n",
      "Iteration 4, loss = 1.10951288\n",
      "Iteration 5, loss = 1.07603822\n",
      "Iteration 6, loss = 1.06519784\n",
      "Iteration 7, loss = 1.05993658\n",
      "Iteration 8, loss = 1.00472032\n",
      "Iteration 9, loss = 1.02630080\n",
      "Iteration 10, loss = 0.97117422\n",
      "Iteration 1, loss = 1.22005904\n",
      "Iteration 2, loss = 1.12050223\n",
      "Iteration 3, loss = 0.97314501\n",
      "Iteration 4, loss = 0.98620621\n",
      "Iteration 5, loss = 0.97052064\n",
      "Iteration 6, loss = 0.98581206\n",
      "Iteration 7, loss = 0.93795318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.97814335\n",
      "Iteration 9, loss = 0.94519323\n",
      "Iteration 10, loss = 0.94308577\n",
      "Iteration 1, loss = 1.18253125\n",
      "Iteration 2, loss = 1.20235709\n",
      "Iteration 3, loss = 1.05063763\n",
      "Iteration 4, loss = 1.11264553\n",
      "Iteration 5, loss = 0.98098999\n",
      "Iteration 6, loss = 0.98727939\n",
      "Iteration 7, loss = 0.95825845\n",
      "Iteration 8, loss = 1.07945652\n",
      "Iteration 9, loss = 0.98666445\n",
      "Iteration 8, loss = 0.97814335\n",
      "Iteration 9, loss = 0.94519323\n",
      "Iteration 10, loss = 0.94308577\n",
      "Iteration 1, loss = 1.18253125\n",
      "Iteration 2, loss = 1.20235709\n",
      "Iteration 3, loss = 1.05063763\n",
      "Iteration 4, loss = 1.11264553\n",
      "Iteration 5, loss = 0.98098999\n",
      "Iteration 6, loss = 0.98727939\n",
      "Iteration 7, loss = 0.95825845\n",
      "Iteration 8, loss = 1.07945652\n",
      "Iteration 9, loss = 0.98666445\n",
      "Iteration 10, loss = 0.97708936\n",
      "Iteration 1, loss = 1.28473848\n",
      "Iteration 2, loss = 1.22449622\n",
      "Iteration 3, loss = 1.04481062\n",
      "Iteration 4, loss = 1.07136084\n",
      "Iteration 5, loss = 1.05957546\n",
      "Iteration 6, loss = 1.14387117\n",
      "Iteration 7, loss = 1.03768076\n",
      "Iteration 8, loss = 1.02944725\n",
      "Iteration 9, loss = 1.01312871\n",
      "Iteration 10, loss = 1.03726992\n",
      "Iteration 1, loss = 1.28358600\n",
      "Iteration 2, loss = 1.14873312\n",
      "Iteration 3, loss = 1.04899247\n",
      "Iteration 10, loss = 0.97708936\n",
      "Iteration 1, loss = 1.28473848\n",
      "Iteration 2, loss = 1.22449622\n",
      "Iteration 3, loss = 1.04481062\n",
      "Iteration 4, loss = 1.07136084\n",
      "Iteration 5, loss = 1.05957546\n",
      "Iteration 6, loss = 1.14387117\n",
      "Iteration 7, loss = 1.03768076\n",
      "Iteration 8, loss = 1.02944725\n",
      "Iteration 9, loss = 1.01312871\n",
      "Iteration 10, loss = 1.03726992\n",
      "Iteration 1, loss = 1.28358600\n",
      "Iteration 2, loss = 1.14873312\n",
      "Iteration 3, loss = 1.04899247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.99789369\n",
      "Iteration 5, loss = 1.08484350\n",
      "Iteration 6, loss = 1.04162805\n",
      "Iteration 7, loss = 0.99503410\n",
      "Iteration 8, loss = 1.01923053\n",
      "Iteration 9, loss = 1.00549368\n",
      "Iteration 10, loss = 1.02143243\n",
      "Iteration 1, loss = 1.23532840\n",
      "Iteration 2, loss = 1.21393107\n",
      "Iteration 3, loss = 1.13015039\n",
      "Iteration 4, loss = 1.10951288\n",
      "Iteration 5, loss = 1.07603822\n",
      "Iteration 6, loss = 1.06519784\n",
      "Iteration 7, loss = 1.05993658\n",
      "Iteration 4, loss = 0.99789369\n",
      "Iteration 5, loss = 1.08484350\n",
      "Iteration 6, loss = 1.04162805\n",
      "Iteration 7, loss = 0.99503410\n",
      "Iteration 8, loss = 1.01923053\n",
      "Iteration 9, loss = 1.00549368\n",
      "Iteration 10, loss = 1.02143243\n",
      "Iteration 1, loss = 1.23532840\n",
      "Iteration 2, loss = 1.21393107\n",
      "Iteration 3, loss = 1.13015039\n",
      "Iteration 4, loss = 1.10951288\n",
      "Iteration 5, loss = 1.07603822\n",
      "Iteration 6, loss = 1.06519784\n",
      "Iteration 7, loss = 1.05993658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.00472032\n",
      "Iteration 9, loss = 1.02630080\n",
      "Iteration 10, loss = 0.97117422\n",
      "Iteration 11, loss = 0.95827715\n",
      "Iteration 12, loss = 0.98187511\n",
      "Iteration 13, loss = 1.00631363\n",
      "Iteration 14, loss = 0.97076671\n",
      "Iteration 15, loss = 0.94620608\n",
      "Iteration 16, loss = 0.97502835\n",
      "Iteration 17, loss = 0.97831099\n",
      "Iteration 18, loss = 0.94815188\n",
      "Iteration 19, loss = 0.99292138\n",
      "Iteration 20, loss = 1.03166497\n",
      "Iteration 21, loss = 0.97209043\n",
      "Iteration 22, loss = 0.99828218\n",
      "Iteration 23, loss = 0.98404739\n",
      "Iteration 8, loss = 1.00472032\n",
      "Iteration 9, loss = 1.02630080\n",
      "Iteration 10, loss = 0.97117422\n",
      "Iteration 11, loss = 0.95827715\n",
      "Iteration 12, loss = 0.98187511\n",
      "Iteration 13, loss = 1.00631363\n",
      "Iteration 14, loss = 0.97076671\n",
      "Iteration 15, loss = 0.94620608\n",
      "Iteration 16, loss = 0.97502835\n",
      "Iteration 17, loss = 0.97831099\n",
      "Iteration 18, loss = 0.94815188\n",
      "Iteration 19, loss = 0.99292138\n",
      "Iteration 20, loss = 1.03166497\n",
      "Iteration 21, loss = 0.97209043\n",
      "Iteration 22, loss = 0.99828218\n",
      "Iteration 23, loss = 0.98404739\n",
      "Iteration 24, loss = 0.99288073\n",
      "Iteration 25, loss = 0.99228123\n",
      "Iteration 26, loss = 0.93322373\n",
      "Iteration 27, loss = 0.99208167\n",
      "Iteration 28, loss = 0.98274932\n",
      "Iteration 29, loss = 0.96241117\n",
      "Iteration 30, loss = 0.99242055\n",
      "Iteration 31, loss = 0.97108437\n",
      "Iteration 32, loss = 0.94259332\n",
      "Iteration 33, loss = 0.93371293\n",
      "Iteration 34, loss = 0.93682088\n",
      "Iteration 35, loss = 0.93850403\n",
      "Iteration 36, loss = 0.94282911\n",
      "Iteration 37, loss = 0.96571482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22005904\n",
      "Iteration 24, loss = 0.99288073\n",
      "Iteration 25, loss = 0.99228123\n",
      "Iteration 26, loss = 0.93322373\n",
      "Iteration 27, loss = 0.99208167\n",
      "Iteration 28, loss = 0.98274932\n",
      "Iteration 29, loss = 0.96241117\n",
      "Iteration 30, loss = 0.99242055\n",
      "Iteration 31, loss = 0.97108437\n",
      "Iteration 32, loss = 0.94259332\n",
      "Iteration 33, loss = 0.93371293\n",
      "Iteration 34, loss = 0.93682088\n",
      "Iteration 35, loss = 0.93850403\n",
      "Iteration 36, loss = 0.94282911\n",
      "Iteration 37, loss = 0.96571482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22005904\n",
      "Iteration 2, loss = 1.12050223\n",
      "Iteration 3, loss = 0.97314501\n",
      "Iteration 4, loss = 0.98620621\n",
      "Iteration 5, loss = 0.97052064\n",
      "Iteration 6, loss = 0.98581206\n",
      "Iteration 7, loss = 0.93795318\n",
      "Iteration 8, loss = 0.97814335\n",
      "Iteration 9, loss = 0.94519323\n",
      "Iteration 10, loss = 0.94308577\n",
      "Iteration 11, loss = 0.92452775\n",
      "Iteration 12, loss = 0.94050946\n",
      "Iteration 13, loss = 0.93519450\n",
      "Iteration 14, loss = 0.92830307\n",
      "Iteration 15, loss = 0.91530457\n",
      "Iteration 16, loss = 0.93487255\n",
      "Iteration 2, loss = 1.12050223\n",
      "Iteration 3, loss = 0.97314501\n",
      "Iteration 4, loss = 0.98620621\n",
      "Iteration 5, loss = 0.97052064\n",
      "Iteration 6, loss = 0.98581206\n",
      "Iteration 7, loss = 0.93795318\n",
      "Iteration 8, loss = 0.97814335\n",
      "Iteration 9, loss = 0.94519323\n",
      "Iteration 10, loss = 0.94308577\n",
      "Iteration 11, loss = 0.92452775\n",
      "Iteration 12, loss = 0.94050946\n",
      "Iteration 13, loss = 0.93519450\n",
      "Iteration 14, loss = 0.92830307\n",
      "Iteration 15, loss = 0.91530457\n",
      "Iteration 16, loss = 0.93487255\n",
      "Iteration 17, loss = 0.95062646\n",
      "Iteration 18, loss = 0.93421782\n",
      "Iteration 19, loss = 0.92792029\n",
      "Iteration 20, loss = 0.91118915\n",
      "Iteration 21, loss = 0.90206570\n",
      "Iteration 22, loss = 0.90210433\n",
      "Iteration 23, loss = 0.90076744\n",
      "Iteration 24, loss = 0.89836009\n",
      "Iteration 25, loss = 0.89636797\n",
      "Iteration 26, loss = 0.88040131\n",
      "Iteration 27, loss = 0.92023133\n",
      "Iteration 28, loss = 0.89125153\n",
      "Iteration 29, loss = 0.91300793\n",
      "Iteration 30, loss = 0.89619128\n",
      "Iteration 31, loss = 0.90236278\n",
      "Iteration 32, loss = 0.90352646\n",
      "Iteration 17, loss = 0.95062646\n",
      "Iteration 18, loss = 0.93421782\n",
      "Iteration 19, loss = 0.92792029\n",
      "Iteration 20, loss = 0.91118915\n",
      "Iteration 21, loss = 0.90206570\n",
      "Iteration 22, loss = 0.90210433\n",
      "Iteration 23, loss = 0.90076744\n",
      "Iteration 24, loss = 0.89836009\n",
      "Iteration 25, loss = 0.89636797\n",
      "Iteration 26, loss = 0.88040131\n",
      "Iteration 27, loss = 0.92023133\n",
      "Iteration 28, loss = 0.89125153\n",
      "Iteration 29, loss = 0.91300793\n",
      "Iteration 30, loss = 0.89619128\n",
      "Iteration 31, loss = 0.90236278\n",
      "Iteration 32, loss = 0.90352646\n",
      "Iteration 33, loss = 0.89808138\n",
      "Iteration 34, loss = 0.90712778\n",
      "Iteration 35, loss = 0.88827858\n",
      "Iteration 36, loss = 0.89582126\n",
      "Iteration 37, loss = 0.90727965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18253125\n",
      "Iteration 2, loss = 1.20235709\n",
      "Iteration 3, loss = 1.05063763\n",
      "Iteration 4, loss = 1.11264553\n",
      "Iteration 5, loss = 0.98098999\n",
      "Iteration 6, loss = 0.98727939\n",
      "Iteration 7, loss = 0.95825845\n",
      "Iteration 8, loss = 1.07945652\n",
      "Iteration 9, loss = 0.98666445\n",
      "Iteration 10, loss = 0.97708936\n",
      "Iteration 11, loss = 1.01233817\n",
      "Iteration 33, loss = 0.89808138\n",
      "Iteration 34, loss = 0.90712778\n",
      "Iteration 35, loss = 0.88827858\n",
      "Iteration 36, loss = 0.89582126\n",
      "Iteration 37, loss = 0.90727965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18253125\n",
      "Iteration 2, loss = 1.20235709\n",
      "Iteration 3, loss = 1.05063763\n",
      "Iteration 4, loss = 1.11264553\n",
      "Iteration 5, loss = 0.98098999\n",
      "Iteration 6, loss = 0.98727939\n",
      "Iteration 7, loss = 0.95825845\n",
      "Iteration 8, loss = 1.07945652\n",
      "Iteration 9, loss = 0.98666445\n",
      "Iteration 10, loss = 0.97708936\n",
      "Iteration 11, loss = 1.01233817\n",
      "Iteration 12, loss = 0.97622136\n",
      "Iteration 13, loss = 1.01134016\n",
      "Iteration 14, loss = 1.25121979\n",
      "Iteration 15, loss = 1.04231769\n",
      "Iteration 16, loss = 0.97382772\n",
      "Iteration 17, loss = 0.96502740\n",
      "Iteration 18, loss = 0.95165621\n",
      "Iteration 19, loss = 0.98252016\n",
      "Iteration 20, loss = 1.06270292\n",
      "Iteration 21, loss = 0.98556426\n",
      "Iteration 22, loss = 0.95302798\n",
      "Iteration 23, loss = 0.92275566\n",
      "Iteration 24, loss = 0.93980824\n",
      "Iteration 25, loss = 0.93109428\n",
      "Iteration 26, loss = 0.94107632\n",
      "Iteration 27, loss = 0.92861620\n",
      "Iteration 12, loss = 0.97622136\n",
      "Iteration 13, loss = 1.01134016\n",
      "Iteration 14, loss = 1.25121979\n",
      "Iteration 15, loss = 1.04231769\n",
      "Iteration 16, loss = 0.97382772\n",
      "Iteration 17, loss = 0.96502740\n",
      "Iteration 18, loss = 0.95165621\n",
      "Iteration 19, loss = 0.98252016\n",
      "Iteration 20, loss = 1.06270292\n",
      "Iteration 21, loss = 0.98556426\n",
      "Iteration 22, loss = 0.95302798\n",
      "Iteration 23, loss = 0.92275566\n",
      "Iteration 24, loss = 0.93980824\n",
      "Iteration 25, loss = 0.93109428\n",
      "Iteration 26, loss = 0.94107632\n",
      "Iteration 27, loss = 0.92861620\n",
      "Iteration 28, loss = 0.97073688\n",
      "Iteration 29, loss = 0.95436058\n",
      "Iteration 30, loss = 0.93304538\n",
      "Iteration 31, loss = 0.90747845\n",
      "Iteration 32, loss = 0.92631592\n",
      "Iteration 33, loss = 0.99550890\n",
      "Iteration 34, loss = 0.97799567\n",
      "Iteration 35, loss = 1.30158240\n",
      "Iteration 36, loss = 1.25764911\n",
      "Iteration 37, loss = 1.26520228\n",
      "Iteration 38, loss = 1.26009453\n",
      "Iteration 39, loss = 1.26241045\n",
      "Iteration 40, loss = 1.26345126\n",
      "Iteration 41, loss = 1.26065389\n",
      "Iteration 42, loss = 1.26545846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28473848\n",
      "Iteration 28, loss = 0.97073688\n",
      "Iteration 29, loss = 0.95436058\n",
      "Iteration 30, loss = 0.93304538\n",
      "Iteration 31, loss = 0.90747845\n",
      "Iteration 32, loss = 0.92631592\n",
      "Iteration 33, loss = 0.99550890\n",
      "Iteration 34, loss = 0.97799567\n",
      "Iteration 35, loss = 1.30158240\n",
      "Iteration 36, loss = 1.25764911\n",
      "Iteration 37, loss = 1.26520228\n",
      "Iteration 38, loss = 1.26009453\n",
      "Iteration 39, loss = 1.26241045\n",
      "Iteration 40, loss = 1.26345126\n",
      "Iteration 41, loss = 1.26065389\n",
      "Iteration 42, loss = 1.26545846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28473848\n",
      "Iteration 2, loss = 1.22449622\n",
      "Iteration 3, loss = 1.04481062\n",
      "Iteration 4, loss = 1.07136084\n",
      "Iteration 5, loss = 1.05957546\n",
      "Iteration 6, loss = 1.14387117\n",
      "Iteration 7, loss = 1.03768076\n",
      "Iteration 8, loss = 1.02944725\n",
      "Iteration 9, loss = 1.01312871\n",
      "Iteration 10, loss = 1.03726992\n",
      "Iteration 11, loss = 1.02262332\n",
      "Iteration 12, loss = 1.09159252\n",
      "Iteration 13, loss = 1.03403789\n",
      "Iteration 14, loss = 1.02478761\n",
      "Iteration 15, loss = 1.02805228\n",
      "Iteration 2, loss = 1.22449622\n",
      "Iteration 3, loss = 1.04481062\n",
      "Iteration 4, loss = 1.07136084\n",
      "Iteration 5, loss = 1.05957546\n",
      "Iteration 6, loss = 1.14387117\n",
      "Iteration 7, loss = 1.03768076\n",
      "Iteration 8, loss = 1.02944725\n",
      "Iteration 9, loss = 1.01312871\n",
      "Iteration 10, loss = 1.03726992\n",
      "Iteration 11, loss = 1.02262332\n",
      "Iteration 12, loss = 1.09159252\n",
      "Iteration 13, loss = 1.03403789\n",
      "Iteration 14, loss = 1.02478761\n",
      "Iteration 15, loss = 1.02805228\n",
      "Iteration 16, loss = 0.96445074\n",
      "Iteration 17, loss = 0.98739812\n",
      "Iteration 18, loss = 0.96052414\n",
      "Iteration 19, loss = 0.96493915\n",
      "Iteration 20, loss = 0.97234984\n",
      "Iteration 21, loss = 0.98197620\n",
      "Iteration 22, loss = 1.06867449\n",
      "Iteration 23, loss = 0.97710122\n",
      "Iteration 24, loss = 0.98088351\n",
      "Iteration 25, loss = 0.99306631\n",
      "Iteration 26, loss = 0.99555025\n",
      "Iteration 27, loss = 1.02377546\n",
      "Iteration 28, loss = 1.02366427\n",
      "Iteration 29, loss = 1.00490478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28358600\n",
      "Iteration 16, loss = 0.96445074\n",
      "Iteration 17, loss = 0.98739812\n",
      "Iteration 18, loss = 0.96052414\n",
      "Iteration 19, loss = 0.96493915\n",
      "Iteration 20, loss = 0.97234984\n",
      "Iteration 21, loss = 0.98197620\n",
      "Iteration 22, loss = 1.06867449\n",
      "Iteration 23, loss = 0.97710122\n",
      "Iteration 24, loss = 0.98088351\n",
      "Iteration 25, loss = 0.99306631\n",
      "Iteration 26, loss = 0.99555025\n",
      "Iteration 27, loss = 1.02377546\n",
      "Iteration 28, loss = 1.02366427\n",
      "Iteration 29, loss = 1.00490478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28358600\n",
      "Iteration 2, loss = 1.14873312\n",
      "Iteration 3, loss = 1.04899247\n",
      "Iteration 4, loss = 0.99789369\n",
      "Iteration 5, loss = 1.08484350\n",
      "Iteration 6, loss = 1.04162805\n",
      "Iteration 7, loss = 0.99503410\n",
      "Iteration 8, loss = 1.01923053\n",
      "Iteration 9, loss = 1.00549368\n",
      "Iteration 10, loss = 1.02143243\n",
      "Iteration 11, loss = 1.02857603\n",
      "Iteration 12, loss = 1.05044551\n",
      "Iteration 13, loss = 0.99246786\n",
      "Iteration 14, loss = 1.04002894\n",
      "Iteration 15, loss = 1.03784942\n",
      "Iteration 16, loss = 0.98618588\n",
      "Iteration 17, loss = 0.98462743\n",
      "Iteration 2, loss = 1.14873312\n",
      "Iteration 3, loss = 1.04899247\n",
      "Iteration 4, loss = 0.99789369\n",
      "Iteration 5, loss = 1.08484350\n",
      "Iteration 6, loss = 1.04162805\n",
      "Iteration 7, loss = 0.99503410\n",
      "Iteration 8, loss = 1.01923053\n",
      "Iteration 9, loss = 1.00549368\n",
      "Iteration 10, loss = 1.02143243\n",
      "Iteration 11, loss = 1.02857603\n",
      "Iteration 12, loss = 1.05044551\n",
      "Iteration 13, loss = 0.99246786\n",
      "Iteration 14, loss = 1.04002894\n",
      "Iteration 15, loss = 1.03784942\n",
      "Iteration 16, loss = 0.98618588\n",
      "Iteration 17, loss = 0.98462743\n",
      "Iteration 18, loss = 0.99682079\n",
      "Iteration 19, loss = 0.99614087\n",
      "Iteration 20, loss = 0.99824094\n",
      "Iteration 21, loss = 0.99652909\n",
      "Iteration 22, loss = 0.97008089\n",
      "Iteration 23, loss = 0.95111884\n",
      "Iteration 24, loss = 0.98899778\n",
      "Iteration 25, loss = 0.95990520\n",
      "Iteration 26, loss = 0.99422797\n",
      "Iteration 27, loss = 0.95959101\n",
      "Iteration 28, loss = 0.96983999\n",
      "Iteration 29, loss = 0.99405446\n",
      "Iteration 30, loss = 0.97840362\n",
      "Iteration 31, loss = 0.99490917\n",
      "Iteration 32, loss = 0.97778104\n",
      "Iteration 33, loss = 0.97842664\n",
      "Iteration 18, loss = 0.99682079\n",
      "Iteration 19, loss = 0.99614087\n",
      "Iteration 20, loss = 0.99824094\n",
      "Iteration 21, loss = 0.99652909\n",
      "Iteration 22, loss = 0.97008089\n",
      "Iteration 23, loss = 0.95111884\n",
      "Iteration 24, loss = 0.98899778\n",
      "Iteration 25, loss = 0.95990520\n",
      "Iteration 26, loss = 0.99422797\n",
      "Iteration 27, loss = 0.95959101\n",
      "Iteration 28, loss = 0.96983999\n",
      "Iteration 29, loss = 0.99405446\n",
      "Iteration 30, loss = 0.97840362\n",
      "Iteration 31, loss = 0.99490917\n",
      "Iteration 32, loss = 0.97778104\n",
      "Iteration 33, loss = 0.97842664\n",
      "Iteration 34, loss = 0.99687189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23532840\n",
      "Iteration 2, loss = 1.21393107\n",
      "Iteration 3, loss = 1.13015039\n",
      "Iteration 4, loss = 1.10951288\n",
      "Iteration 5, loss = 1.07603822\n",
      "Iteration 6, loss = 1.06519784\n",
      "Iteration 7, loss = 1.05993658\n",
      "Iteration 8, loss = 1.00472032\n",
      "Iteration 9, loss = 1.02630080\n",
      "Iteration 10, loss = 0.97117422\n",
      "Iteration 11, loss = 0.95827715\n",
      "Iteration 12, loss = 0.98187511\n",
      "Iteration 13, loss = 1.00631363\n",
      "Iteration 34, loss = 0.99687189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23532840\n",
      "Iteration 2, loss = 1.21393107\n",
      "Iteration 3, loss = 1.13015039\n",
      "Iteration 4, loss = 1.10951288\n",
      "Iteration 5, loss = 1.07603822\n",
      "Iteration 6, loss = 1.06519784\n",
      "Iteration 7, loss = 1.05993658\n",
      "Iteration 8, loss = 1.00472032\n",
      "Iteration 9, loss = 1.02630080\n",
      "Iteration 10, loss = 0.97117422\n",
      "Iteration 11, loss = 0.95827715\n",
      "Iteration 12, loss = 0.98187511\n",
      "Iteration 13, loss = 1.00631363\n",
      "Iteration 14, loss = 0.97076671\n",
      "Iteration 15, loss = 0.94620608\n",
      "Iteration 16, loss = 0.97502835\n",
      "Iteration 17, loss = 0.97831099\n",
      "Iteration 18, loss = 0.94815188\n",
      "Iteration 19, loss = 0.99292138\n",
      "Iteration 20, loss = 1.03166497\n",
      "Iteration 21, loss = 0.97209043\n",
      "Iteration 22, loss = 0.99828218\n",
      "Iteration 23, loss = 0.98404739\n",
      "Iteration 24, loss = 0.99288073\n",
      "Iteration 25, loss = 0.99228123\n",
      "Iteration 26, loss = 0.93322373\n",
      "Iteration 27, loss = 0.99208167\n",
      "Iteration 28, loss = 0.98274932\n",
      "Iteration 29, loss = 0.96241117\n",
      "Iteration 14, loss = 0.97076671\n",
      "Iteration 15, loss = 0.94620608\n",
      "Iteration 16, loss = 0.97502835\n",
      "Iteration 17, loss = 0.97831099\n",
      "Iteration 18, loss = 0.94815188\n",
      "Iteration 19, loss = 0.99292138\n",
      "Iteration 20, loss = 1.03166497\n",
      "Iteration 21, loss = 0.97209043\n",
      "Iteration 22, loss = 0.99828218\n",
      "Iteration 23, loss = 0.98404739\n",
      "Iteration 24, loss = 0.99288073\n",
      "Iteration 25, loss = 0.99228123\n",
      "Iteration 26, loss = 0.93322373\n",
      "Iteration 27, loss = 0.99208167\n",
      "Iteration 28, loss = 0.98274932\n",
      "Iteration 29, loss = 0.96241117\n",
      "Iteration 30, loss = 0.99242055\n",
      "Iteration 31, loss = 0.97108437\n",
      "Iteration 32, loss = 0.94259332\n",
      "Iteration 33, loss = 0.93371293\n",
      "Iteration 34, loss = 0.93682088\n",
      "Iteration 35, loss = 0.93850403\n",
      "Iteration 36, loss = 0.94282911\n",
      "Iteration 37, loss = 0.96571482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22005904\n",
      "Iteration 2, loss = 1.12050223\n",
      "Iteration 3, loss = 0.97314501\n",
      "Iteration 4, loss = 0.98620621\n",
      "Iteration 5, loss = 0.97052064\n",
      "Iteration 6, loss = 0.98581206\n",
      "Iteration 7, loss = 0.93795318\n",
      "Iteration 30, loss = 0.99242055\n",
      "Iteration 31, loss = 0.97108437\n",
      "Iteration 32, loss = 0.94259332\n",
      "Iteration 33, loss = 0.93371293\n",
      "Iteration 34, loss = 0.93682088\n",
      "Iteration 35, loss = 0.93850403\n",
      "Iteration 36, loss = 0.94282911\n",
      "Iteration 37, loss = 0.96571482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22005904\n",
      "Iteration 2, loss = 1.12050223\n",
      "Iteration 3, loss = 0.97314501\n",
      "Iteration 4, loss = 0.98620621\n",
      "Iteration 5, loss = 0.97052064\n",
      "Iteration 6, loss = 0.98581206\n",
      "Iteration 7, loss = 0.93795318\n",
      "Iteration 8, loss = 0.97814335\n",
      "Iteration 9, loss = 0.94519323\n",
      "Iteration 10, loss = 0.94308577\n",
      "Iteration 11, loss = 0.92452775\n",
      "Iteration 12, loss = 0.94050946\n",
      "Iteration 13, loss = 0.93519450\n",
      "Iteration 14, loss = 0.92830307\n",
      "Iteration 15, loss = 0.91530457\n",
      "Iteration 16, loss = 0.93487255\n",
      "Iteration 17, loss = 0.95062646\n",
      "Iteration 18, loss = 0.93421782\n",
      "Iteration 19, loss = 0.92792029\n",
      "Iteration 20, loss = 0.91118915\n",
      "Iteration 21, loss = 0.90206570\n",
      "Iteration 22, loss = 0.90210433\n",
      "Iteration 8, loss = 0.97814335\n",
      "Iteration 9, loss = 0.94519323\n",
      "Iteration 10, loss = 0.94308577\n",
      "Iteration 11, loss = 0.92452775\n",
      "Iteration 12, loss = 0.94050946\n",
      "Iteration 13, loss = 0.93519450\n",
      "Iteration 14, loss = 0.92830307\n",
      "Iteration 15, loss = 0.91530457\n",
      "Iteration 16, loss = 0.93487255\n",
      "Iteration 17, loss = 0.95062646\n",
      "Iteration 18, loss = 0.93421782\n",
      "Iteration 19, loss = 0.92792029\n",
      "Iteration 20, loss = 0.91118915\n",
      "Iteration 21, loss = 0.90206570\n",
      "Iteration 22, loss = 0.90210433\n",
      "Iteration 23, loss = 0.90076744\n",
      "Iteration 24, loss = 0.89836009\n",
      "Iteration 25, loss = 0.89636797\n",
      "Iteration 26, loss = 0.88040131\n",
      "Iteration 27, loss = 0.92023133\n",
      "Iteration 28, loss = 0.89125153\n",
      "Iteration 29, loss = 0.91300793\n",
      "Iteration 30, loss = 0.89619128\n",
      "Iteration 31, loss = 0.90236278\n",
      "Iteration 32, loss = 0.90352646\n",
      "Iteration 33, loss = 0.89808138\n",
      "Iteration 34, loss = 0.90712778\n",
      "Iteration 35, loss = 0.88827858\n",
      "Iteration 36, loss = 0.89582126\n",
      "Iteration 37, loss = 0.90727965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18253125\n",
      "Iteration 23, loss = 0.90076744\n",
      "Iteration 24, loss = 0.89836009\n",
      "Iteration 25, loss = 0.89636797\n",
      "Iteration 26, loss = 0.88040131\n",
      "Iteration 27, loss = 0.92023133\n",
      "Iteration 28, loss = 0.89125153\n",
      "Iteration 29, loss = 0.91300793\n",
      "Iteration 30, loss = 0.89619128\n",
      "Iteration 31, loss = 0.90236278\n",
      "Iteration 32, loss = 0.90352646\n",
      "Iteration 33, loss = 0.89808138\n",
      "Iteration 34, loss = 0.90712778\n",
      "Iteration 35, loss = 0.88827858\n",
      "Iteration 36, loss = 0.89582126\n",
      "Iteration 37, loss = 0.90727965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18253125\n",
      "Iteration 2, loss = 1.20235709\n",
      "Iteration 3, loss = 1.05063763\n",
      "Iteration 4, loss = 1.11264553\n",
      "Iteration 5, loss = 0.98098999\n",
      "Iteration 6, loss = 0.98727939\n",
      "Iteration 7, loss = 0.95825845\n",
      "Iteration 8, loss = 1.07945652\n",
      "Iteration 9, loss = 0.98666445\n",
      "Iteration 10, loss = 0.97708936\n",
      "Iteration 11, loss = 1.01233817\n",
      "Iteration 12, loss = 0.97622136\n",
      "Iteration 13, loss = 1.01134016\n",
      "Iteration 14, loss = 1.25121979\n",
      "Iteration 15, loss = 1.04231769\n",
      "Iteration 16, loss = 0.97382772\n",
      "Iteration 2, loss = 1.20235709\n",
      "Iteration 3, loss = 1.05063763\n",
      "Iteration 4, loss = 1.11264553\n",
      "Iteration 5, loss = 0.98098999\n",
      "Iteration 6, loss = 0.98727939\n",
      "Iteration 7, loss = 0.95825845\n",
      "Iteration 8, loss = 1.07945652\n",
      "Iteration 9, loss = 0.98666445\n",
      "Iteration 10, loss = 0.97708936\n",
      "Iteration 11, loss = 1.01233817\n",
      "Iteration 12, loss = 0.97622136\n",
      "Iteration 13, loss = 1.01134016\n",
      "Iteration 14, loss = 1.25121979\n",
      "Iteration 15, loss = 1.04231769\n",
      "Iteration 16, loss = 0.97382772\n",
      "Iteration 17, loss = 0.96502740\n",
      "Iteration 18, loss = 0.95165621\n",
      "Iteration 19, loss = 0.98252016\n",
      "Iteration 20, loss = 1.06270292\n",
      "Iteration 21, loss = 0.98556426\n",
      "Iteration 22, loss = 0.95302798\n",
      "Iteration 23, loss = 0.92275566\n",
      "Iteration 24, loss = 0.93980824\n",
      "Iteration 25, loss = 0.93109428\n",
      "Iteration 26, loss = 0.94107632\n",
      "Iteration 27, loss = 0.92861620\n",
      "Iteration 28, loss = 0.97073688\n",
      "Iteration 29, loss = 0.95436058\n",
      "Iteration 30, loss = 0.93304538\n",
      "Iteration 31, loss = 0.90747845\n",
      "Iteration 32, loss = 0.92631592\n",
      "Iteration 17, loss = 0.96502740\n",
      "Iteration 18, loss = 0.95165621\n",
      "Iteration 19, loss = 0.98252016\n",
      "Iteration 20, loss = 1.06270292\n",
      "Iteration 21, loss = 0.98556426\n",
      "Iteration 22, loss = 0.95302798\n",
      "Iteration 23, loss = 0.92275566\n",
      "Iteration 24, loss = 0.93980824\n",
      "Iteration 25, loss = 0.93109428\n",
      "Iteration 26, loss = 0.94107632\n",
      "Iteration 27, loss = 0.92861620\n",
      "Iteration 28, loss = 0.97073688\n",
      "Iteration 29, loss = 0.95436058\n",
      "Iteration 30, loss = 0.93304538\n",
      "Iteration 31, loss = 0.90747845\n",
      "Iteration 32, loss = 0.92631592\n",
      "Iteration 33, loss = 0.99550890\n",
      "Iteration 34, loss = 0.97799567\n",
      "Iteration 35, loss = 1.30158240\n",
      "Iteration 36, loss = 1.25764911\n",
      "Iteration 37, loss = 1.26520228\n",
      "Iteration 38, loss = 1.26009453\n",
      "Iteration 39, loss = 1.26241045\n",
      "Iteration 40, loss = 1.26345126\n",
      "Iteration 41, loss = 1.26065389\n",
      "Iteration 42, loss = 1.26545846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28473848\n",
      "Iteration 2, loss = 1.22449622\n",
      "Iteration 3, loss = 1.04481062\n",
      "Iteration 4, loss = 1.07136084\n",
      "Iteration 5, loss = 1.05957546\n",
      "Iteration 6, loss = 1.14387117\n",
      "Iteration 33, loss = 0.99550890\n",
      "Iteration 34, loss = 0.97799567\n",
      "Iteration 35, loss = 1.30158240\n",
      "Iteration 36, loss = 1.25764911\n",
      "Iteration 37, loss = 1.26520228\n",
      "Iteration 38, loss = 1.26009453\n",
      "Iteration 39, loss = 1.26241045\n",
      "Iteration 40, loss = 1.26345126\n",
      "Iteration 41, loss = 1.26065389\n",
      "Iteration 42, loss = 1.26545846\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28473848\n",
      "Iteration 2, loss = 1.22449622\n",
      "Iteration 3, loss = 1.04481062\n",
      "Iteration 4, loss = 1.07136084\n",
      "Iteration 5, loss = 1.05957546\n",
      "Iteration 6, loss = 1.14387117\n",
      "Iteration 7, loss = 1.03768076\n",
      "Iteration 8, loss = 1.02944725\n",
      "Iteration 9, loss = 1.01312871\n",
      "Iteration 10, loss = 1.03726992\n",
      "Iteration 11, loss = 1.02262332\n",
      "Iteration 12, loss = 1.09159252\n",
      "Iteration 13, loss = 1.03403789\n",
      "Iteration 14, loss = 1.02478761\n",
      "Iteration 15, loss = 1.02805228\n",
      "Iteration 16, loss = 0.96445074\n",
      "Iteration 17, loss = 0.98739812\n",
      "Iteration 18, loss = 0.96052414\n",
      "Iteration 19, loss = 0.96493915\n",
      "Iteration 20, loss = 0.97234984\n",
      "Iteration 21, loss = 0.98197620\n",
      "Iteration 7, loss = 1.03768076\n",
      "Iteration 8, loss = 1.02944725\n",
      "Iteration 9, loss = 1.01312871\n",
      "Iteration 10, loss = 1.03726992\n",
      "Iteration 11, loss = 1.02262332\n",
      "Iteration 12, loss = 1.09159252\n",
      "Iteration 13, loss = 1.03403789\n",
      "Iteration 14, loss = 1.02478761\n",
      "Iteration 15, loss = 1.02805228\n",
      "Iteration 16, loss = 0.96445074\n",
      "Iteration 17, loss = 0.98739812\n",
      "Iteration 18, loss = 0.96052414\n",
      "Iteration 19, loss = 0.96493915\n",
      "Iteration 20, loss = 0.97234984\n",
      "Iteration 21, loss = 0.98197620\n",
      "Iteration 22, loss = 1.06867449\n",
      "Iteration 23, loss = 0.97710122\n",
      "Iteration 24, loss = 0.98088351\n",
      "Iteration 25, loss = 0.99306631\n",
      "Iteration 26, loss = 0.99555025\n",
      "Iteration 27, loss = 1.02377546\n",
      "Iteration 28, loss = 1.02366427\n",
      "Iteration 29, loss = 1.00490478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28358600\n",
      "Iteration 2, loss = 1.14873312\n",
      "Iteration 3, loss = 1.04899247\n",
      "Iteration 4, loss = 0.99789369\n",
      "Iteration 5, loss = 1.08484350\n",
      "Iteration 6, loss = 1.04162805\n",
      "Iteration 7, loss = 0.99503410\n",
      "Iteration 22, loss = 1.06867449\n",
      "Iteration 23, loss = 0.97710122\n",
      "Iteration 24, loss = 0.98088351\n",
      "Iteration 25, loss = 0.99306631\n",
      "Iteration 26, loss = 0.99555025\n",
      "Iteration 27, loss = 1.02377546\n",
      "Iteration 28, loss = 1.02366427\n",
      "Iteration 29, loss = 1.00490478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28358600\n",
      "Iteration 2, loss = 1.14873312\n",
      "Iteration 3, loss = 1.04899247\n",
      "Iteration 4, loss = 0.99789369\n",
      "Iteration 5, loss = 1.08484350\n",
      "Iteration 6, loss = 1.04162805\n",
      "Iteration 7, loss = 0.99503410\n",
      "Iteration 8, loss = 1.01923053\n",
      "Iteration 9, loss = 1.00549368\n",
      "Iteration 10, loss = 1.02143243\n",
      "Iteration 11, loss = 1.02857603\n",
      "Iteration 12, loss = 1.05044551\n",
      "Iteration 13, loss = 0.99246786\n",
      "Iteration 14, loss = 1.04002894\n",
      "Iteration 15, loss = 1.03784942\n",
      "Iteration 16, loss = 0.98618588\n",
      "Iteration 17, loss = 0.98462743\n",
      "Iteration 18, loss = 0.99682079\n",
      "Iteration 19, loss = 0.99614087\n",
      "Iteration 20, loss = 0.99824094\n",
      "Iteration 21, loss = 0.99652909\n",
      "Iteration 22, loss = 0.97008089\n",
      "Iteration 8, loss = 1.01923053\n",
      "Iteration 9, loss = 1.00549368\n",
      "Iteration 10, loss = 1.02143243\n",
      "Iteration 11, loss = 1.02857603\n",
      "Iteration 12, loss = 1.05044551\n",
      "Iteration 13, loss = 0.99246786\n",
      "Iteration 14, loss = 1.04002894\n",
      "Iteration 15, loss = 1.03784942\n",
      "Iteration 16, loss = 0.98618588\n",
      "Iteration 17, loss = 0.98462743\n",
      "Iteration 18, loss = 0.99682079\n",
      "Iteration 19, loss = 0.99614087\n",
      "Iteration 20, loss = 0.99824094\n",
      "Iteration 21, loss = 0.99652909\n",
      "Iteration 22, loss = 0.97008089\n",
      "Iteration 23, loss = 0.95111884\n",
      "Iteration 24, loss = 0.98899778\n",
      "Iteration 25, loss = 0.95990520\n",
      "Iteration 26, loss = 0.99422797\n",
      "Iteration 27, loss = 0.95959101\n",
      "Iteration 28, loss = 0.96983999\n",
      "Iteration 29, loss = 0.99405446\n",
      "Iteration 30, loss = 0.97840362\n",
      "Iteration 31, loss = 0.99490917\n",
      "Iteration 32, loss = 0.97778104\n",
      "Iteration 33, loss = 0.97842664\n",
      "Iteration 34, loss = 0.99687189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25314217\n",
      "Iteration 2, loss = 1.22720071\n",
      "Iteration 3, loss = 1.16189817\n",
      "Iteration 23, loss = 0.95111884\n",
      "Iteration 24, loss = 0.98899778\n",
      "Iteration 25, loss = 0.95990520\n",
      "Iteration 26, loss = 0.99422797\n",
      "Iteration 27, loss = 0.95959101\n",
      "Iteration 28, loss = 0.96983999\n",
      "Iteration 29, loss = 0.99405446\n",
      "Iteration 30, loss = 0.97840362\n",
      "Iteration 31, loss = 0.99490917\n",
      "Iteration 32, loss = 0.97778104\n",
      "Iteration 33, loss = 0.97842664\n",
      "Iteration 34, loss = 0.99687189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25314217\n",
      "Iteration 2, loss = 1.22720071\n",
      "Iteration 3, loss = 1.16189817\n",
      "Iteration 4, loss = 1.10632792\n",
      "Iteration 5, loss = 1.03475910\n",
      "Iteration 6, loss = 1.23459797\n",
      "Iteration 7, loss = 1.25130289\n",
      "Iteration 8, loss = 1.24412877\n",
      "Iteration 9, loss = 1.27075347\n",
      "Iteration 10, loss = 1.25885490\n",
      "Iteration 1, loss = 1.24120227\n",
      "Iteration 2, loss = 1.24205604\n",
      "Iteration 3, loss = 1.25796173\n",
      "Iteration 4, loss = 1.25108460\n",
      "Iteration 5, loss = 1.24050080\n",
      "Iteration 6, loss = 1.24288677\n",
      "Iteration 7, loss = 1.23757143\n",
      "Iteration 4, loss = 1.10632792\n",
      "Iteration 5, loss = 1.03475910\n",
      "Iteration 6, loss = 1.23459797\n",
      "Iteration 7, loss = 1.25130289\n",
      "Iteration 8, loss = 1.24412877\n",
      "Iteration 9, loss = 1.27075347\n",
      "Iteration 10, loss = 1.25885490\n",
      "Iteration 1, loss = 1.24120227\n",
      "Iteration 2, loss = 1.24205604\n",
      "Iteration 3, loss = 1.25796173\n",
      "Iteration 4, loss = 1.25108460\n",
      "Iteration 5, loss = 1.24050080\n",
      "Iteration 6, loss = 1.24288677\n",
      "Iteration 7, loss = 1.23757143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.24444724\n",
      "Iteration 9, loss = 1.26503663\n",
      "Iteration 10, loss = 1.25561935\n",
      "Iteration 1, loss = 1.27692611\n",
      "Iteration 2, loss = 1.22824472\n",
      "Iteration 3, loss = 1.26761708\n",
      "Iteration 4, loss = 1.26142279\n",
      "Iteration 5, loss = 1.24566363\n",
      "Iteration 6, loss = 1.27168872\n",
      "Iteration 7, loss = 1.25979450\n",
      "Iteration 8, loss = 1.27424378\n",
      "Iteration 9, loss = 1.28034109\n",
      "Iteration 10, loss = 1.27545775\n",
      "Iteration 1, loss = 1.31403408\n",
      "Iteration 8, loss = 1.24444724\n",
      "Iteration 9, loss = 1.26503663\n",
      "Iteration 10, loss = 1.25561935\n",
      "Iteration 1, loss = 1.27692611\n",
      "Iteration 2, loss = 1.22824472\n",
      "Iteration 3, loss = 1.26761708\n",
      "Iteration 4, loss = 1.26142279\n",
      "Iteration 5, loss = 1.24566363\n",
      "Iteration 6, loss = 1.27168872\n",
      "Iteration 7, loss = 1.25979450\n",
      "Iteration 8, loss = 1.27424378\n",
      "Iteration 9, loss = 1.28034109\n",
      "Iteration 10, loss = 1.27545775\n",
      "Iteration 1, loss = 1.31403408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.25159107\n",
      "Iteration 3, loss = 1.25364872\n",
      "Iteration 4, loss = 1.24534397\n",
      "Iteration 5, loss = 1.25274667\n",
      "Iteration 6, loss = 1.24839335\n",
      "Iteration 7, loss = 1.25205676\n",
      "Iteration 8, loss = 1.25164604\n",
      "Iteration 9, loss = 1.24416864\n",
      "Iteration 10, loss = 1.26685626\n",
      "Iteration 1, loss = 1.28397239\n",
      "Iteration 2, loss = 1.25639692\n",
      "Iteration 3, loss = 1.26746450\n",
      "Iteration 4, loss = 1.06894384\n",
      "Iteration 2, loss = 1.25159107\n",
      "Iteration 3, loss = 1.25364872\n",
      "Iteration 4, loss = 1.24534397\n",
      "Iteration 5, loss = 1.25274667\n",
      "Iteration 6, loss = 1.24839335\n",
      "Iteration 7, loss = 1.25205676\n",
      "Iteration 8, loss = 1.25164604\n",
      "Iteration 9, loss = 1.24416864\n",
      "Iteration 10, loss = 1.26685626\n",
      "Iteration 1, loss = 1.28397239\n",
      "Iteration 2, loss = 1.25639692\n",
      "Iteration 3, loss = 1.26746450\n",
      "Iteration 4, loss = 1.06894384\n",
      "Iteration 5, loss = 1.06824403\n",
      "Iteration 6, loss = 1.10121666\n",
      "Iteration 7, loss = 1.04259863\n",
      "Iteration 8, loss = 1.00979954\n",
      "Iteration 9, loss = 1.02810290\n",
      "Iteration 10, loss = 1.01084052\n",
      "Iteration 1, loss = 1.25314217\n",
      "Iteration 2, loss = 1.22720071\n",
      "Iteration 3, loss = 1.16189817\n",
      "Iteration 4, loss = 1.10632792\n",
      "Iteration 5, loss = 1.03475910\n",
      "Iteration 6, loss = 1.23459797\n",
      "Iteration 5, loss = 1.06824403\n",
      "Iteration 6, loss = 1.10121666\n",
      "Iteration 7, loss = 1.04259863\n",
      "Iteration 8, loss = 1.00979954\n",
      "Iteration 9, loss = 1.02810290\n",
      "Iteration 10, loss = 1.01084052\n",
      "Iteration 1, loss = 1.25314217\n",
      "Iteration 2, loss = 1.22720071\n",
      "Iteration 3, loss = 1.16189817\n",
      "Iteration 4, loss = 1.10632792\n",
      "Iteration 5, loss = 1.03475910\n",
      "Iteration 6, loss = 1.23459797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.25130289\n",
      "Iteration 8, loss = 1.24412877\n",
      "Iteration 9, loss = 1.27075347\n",
      "Iteration 10, loss = 1.25885490\n",
      "Iteration 11, loss = 1.26463057\n",
      "Iteration 12, loss = 1.25477730\n",
      "Iteration 13, loss = 1.24719358\n",
      "Iteration 14, loss = 1.24225804\n",
      "Iteration 15, loss = 1.24392495\n",
      "Iteration 16, loss = 1.23539717\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120227\n",
      "Iteration 2, loss = 1.24205604\n",
      "Iteration 7, loss = 1.25130289\n",
      "Iteration 8, loss = 1.24412877\n",
      "Iteration 9, loss = 1.27075347\n",
      "Iteration 10, loss = 1.25885490\n",
      "Iteration 11, loss = 1.26463057\n",
      "Iteration 12, loss = 1.25477730\n",
      "Iteration 13, loss = 1.24719358\n",
      "Iteration 14, loss = 1.24225804\n",
      "Iteration 15, loss = 1.24392495\n",
      "Iteration 16, loss = 1.23539717\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120227\n",
      "Iteration 2, loss = 1.24205604\n",
      "Iteration 3, loss = 1.25796173\n",
      "Iteration 4, loss = 1.25108460\n",
      "Iteration 5, loss = 1.24050080\n",
      "Iteration 6, loss = 1.24288677\n",
      "Iteration 7, loss = 1.23757143\n",
      "Iteration 8, loss = 1.24444724\n",
      "Iteration 9, loss = 1.26503663\n",
      "Iteration 10, loss = 1.25561935\n",
      "Iteration 11, loss = 1.24304091\n",
      "Iteration 12, loss = 1.23733955\n",
      "Iteration 13, loss = 1.23270392\n",
      "Iteration 14, loss = 1.23451786\n",
      "Iteration 15, loss = 1.23396941\n",
      "Iteration 16, loss = 1.24061326\n",
      "Iteration 3, loss = 1.25796173\n",
      "Iteration 4, loss = 1.25108460\n",
      "Iteration 5, loss = 1.24050080\n",
      "Iteration 6, loss = 1.24288677\n",
      "Iteration 7, loss = 1.23757143\n",
      "Iteration 8, loss = 1.24444724\n",
      "Iteration 9, loss = 1.26503663\n",
      "Iteration 10, loss = 1.25561935\n",
      "Iteration 11, loss = 1.24304091\n",
      "Iteration 12, loss = 1.23733955\n",
      "Iteration 13, loss = 1.23270392\n",
      "Iteration 14, loss = 1.23451786\n",
      "Iteration 15, loss = 1.23396941\n",
      "Iteration 16, loss = 1.24061326\n",
      "Iteration 17, loss = 1.24490223\n",
      "Iteration 18, loss = 1.23349386\n",
      "Iteration 19, loss = 1.25427961\n",
      "Iteration 20, loss = 1.23510308\n",
      "Iteration 21, loss = 1.23341292\n",
      "Iteration 22, loss = 1.23376615\n",
      "Iteration 23, loss = 1.24058230\n",
      "Iteration 24, loss = 1.23985169\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27692611\n",
      "Iteration 2, loss = 1.22824472\n",
      "Iteration 3, loss = 1.26761708\n",
      "Iteration 4, loss = 1.26142279\n",
      "Iteration 5, loss = 1.24566363\n",
      "Iteration 6, loss = 1.27168872\n",
      "Iteration 7, loss = 1.25979450\n",
      "Iteration 17, loss = 1.24490223\n",
      "Iteration 18, loss = 1.23349386\n",
      "Iteration 19, loss = 1.25427961\n",
      "Iteration 20, loss = 1.23510308\n",
      "Iteration 21, loss = 1.23341292\n",
      "Iteration 22, loss = 1.23376615\n",
      "Iteration 23, loss = 1.24058230\n",
      "Iteration 24, loss = 1.23985169\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27692611\n",
      "Iteration 2, loss = 1.22824472\n",
      "Iteration 3, loss = 1.26761708\n",
      "Iteration 4, loss = 1.26142279\n",
      "Iteration 5, loss = 1.24566363\n",
      "Iteration 6, loss = 1.27168872\n",
      "Iteration 7, loss = 1.25979450\n",
      "Iteration 8, loss = 1.27424378\n",
      "Iteration 9, loss = 1.28034109\n",
      "Iteration 10, loss = 1.27545775\n",
      "Iteration 11, loss = 1.27469982\n",
      "Iteration 12, loss = 1.25779017\n",
      "Iteration 13, loss = 1.25186097\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31403408\n",
      "Iteration 2, loss = 1.25159107\n",
      "Iteration 3, loss = 1.25364872\n",
      "Iteration 4, loss = 1.24534397\n",
      "Iteration 5, loss = 1.25274667\n",
      "Iteration 6, loss = 1.24839335\n",
      "Iteration 7, loss = 1.25205676\n",
      "Iteration 8, loss = 1.25164604\n",
      "Iteration 9, loss = 1.24416864\n",
      "Iteration 10, loss = 1.26685626\n",
      "Iteration 8, loss = 1.27424378\n",
      "Iteration 9, loss = 1.28034109\n",
      "Iteration 10, loss = 1.27545775\n",
      "Iteration 11, loss = 1.27469982\n",
      "Iteration 12, loss = 1.25779017\n",
      "Iteration 13, loss = 1.25186097\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31403408\n",
      "Iteration 2, loss = 1.25159107\n",
      "Iteration 3, loss = 1.25364872\n",
      "Iteration 4, loss = 1.24534397\n",
      "Iteration 5, loss = 1.25274667\n",
      "Iteration 6, loss = 1.24839335\n",
      "Iteration 7, loss = 1.25205676\n",
      "Iteration 8, loss = 1.25164604\n",
      "Iteration 9, loss = 1.24416864\n",
      "Iteration 10, loss = 1.26685626\n",
      "Iteration 11, loss = 1.27153858\n",
      "Iteration 12, loss = 1.24388597\n",
      "Iteration 13, loss = 1.25737692\n",
      "Iteration 14, loss = 1.25489369\n",
      "Iteration 15, loss = 1.24482578\n",
      "Iteration 16, loss = 1.24590577\n",
      "Iteration 17, loss = 1.24831559\n",
      "Iteration 18, loss = 1.24880130\n",
      "Iteration 19, loss = 1.26256476\n",
      "Iteration 20, loss = 1.25164410\n",
      "Iteration 21, loss = 1.24928701\n",
      "Iteration 22, loss = 1.24429504\n",
      "Iteration 23, loss = 1.24537351\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28397239\n",
      "Iteration 2, loss = 1.25639692\n",
      "Iteration 11, loss = 1.27153858\n",
      "Iteration 12, loss = 1.24388597\n",
      "Iteration 13, loss = 1.25737692\n",
      "Iteration 14, loss = 1.25489369\n",
      "Iteration 15, loss = 1.24482578\n",
      "Iteration 16, loss = 1.24590577\n",
      "Iteration 17, loss = 1.24831559\n",
      "Iteration 18, loss = 1.24880130\n",
      "Iteration 19, loss = 1.26256476\n",
      "Iteration 20, loss = 1.25164410\n",
      "Iteration 21, loss = 1.24928701\n",
      "Iteration 22, loss = 1.24429504\n",
      "Iteration 23, loss = 1.24537351\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28397239\n",
      "Iteration 2, loss = 1.25639692\n",
      "Iteration 3, loss = 1.26746450\n",
      "Iteration 4, loss = 1.06894384\n",
      "Iteration 5, loss = 1.06824403\n",
      "Iteration 6, loss = 1.10121666\n",
      "Iteration 7, loss = 1.04259863\n",
      "Iteration 8, loss = 1.00979954\n",
      "Iteration 9, loss = 1.02810290\n",
      "Iteration 10, loss = 1.01084052\n",
      "Iteration 11, loss = 1.06277339\n",
      "Iteration 12, loss = 1.03457059\n",
      "Iteration 13, loss = 0.99774991\n",
      "Iteration 14, loss = 1.00477283\n",
      "Iteration 15, loss = 0.99123232\n",
      "Iteration 16, loss = 0.98880962\n",
      "Iteration 17, loss = 0.99473759\n",
      "Iteration 3, loss = 1.26746450\n",
      "Iteration 4, loss = 1.06894384\n",
      "Iteration 5, loss = 1.06824403\n",
      "Iteration 6, loss = 1.10121666\n",
      "Iteration 7, loss = 1.04259863\n",
      "Iteration 8, loss = 1.00979954\n",
      "Iteration 9, loss = 1.02810290\n",
      "Iteration 10, loss = 1.01084052\n",
      "Iteration 11, loss = 1.06277339\n",
      "Iteration 12, loss = 1.03457059\n",
      "Iteration 13, loss = 0.99774991\n",
      "Iteration 14, loss = 1.00477283\n",
      "Iteration 15, loss = 0.99123232\n",
      "Iteration 16, loss = 0.98880962\n",
      "Iteration 17, loss = 0.99473759\n",
      "Iteration 18, loss = 0.99531141\n",
      "Iteration 19, loss = 0.99516557\n",
      "Iteration 20, loss = 0.99347708\n",
      "Iteration 21, loss = 1.00194423\n",
      "Iteration 22, loss = 1.00122606\n",
      "Iteration 23, loss = 0.99842091\n",
      "Iteration 24, loss = 1.24342474\n",
      "Iteration 25, loss = 1.26666999\n",
      "Iteration 26, loss = 1.23409027\n",
      "Iteration 27, loss = 1.23881927\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25314217\n",
      "Iteration 2, loss = 1.22720071\n",
      "Iteration 3, loss = 1.16189817\n",
      "Iteration 4, loss = 1.10632792\n",
      "Iteration 18, loss = 0.99531141\n",
      "Iteration 19, loss = 0.99516557\n",
      "Iteration 20, loss = 0.99347708\n",
      "Iteration 21, loss = 1.00194423\n",
      "Iteration 22, loss = 1.00122606\n",
      "Iteration 23, loss = 0.99842091\n",
      "Iteration 24, loss = 1.24342474\n",
      "Iteration 25, loss = 1.26666999\n",
      "Iteration 26, loss = 1.23409027\n",
      "Iteration 27, loss = 1.23881927\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25314217\n",
      "Iteration 2, loss = 1.22720071\n",
      "Iteration 3, loss = 1.16189817\n",
      "Iteration 4, loss = 1.10632792\n",
      "Iteration 5, loss = 1.03475910\n",
      "Iteration 6, loss = 1.23459797\n",
      "Iteration 7, loss = 1.25130289\n",
      "Iteration 8, loss = 1.24412877\n",
      "Iteration 9, loss = 1.27075347\n",
      "Iteration 10, loss = 1.25885490\n",
      "Iteration 11, loss = 1.26463057\n",
      "Iteration 12, loss = 1.25477730\n",
      "Iteration 13, loss = 1.24719358\n",
      "Iteration 14, loss = 1.24225804\n",
      "Iteration 15, loss = 1.24392495\n",
      "Iteration 16, loss = 1.23539717\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120227\n",
      "Iteration 2, loss = 1.24205604\n",
      "Iteration 5, loss = 1.03475910\n",
      "Iteration 6, loss = 1.23459797\n",
      "Iteration 7, loss = 1.25130289\n",
      "Iteration 8, loss = 1.24412877\n",
      "Iteration 9, loss = 1.27075347\n",
      "Iteration 10, loss = 1.25885490\n",
      "Iteration 11, loss = 1.26463057\n",
      "Iteration 12, loss = 1.25477730\n",
      "Iteration 13, loss = 1.24719358\n",
      "Iteration 14, loss = 1.24225804\n",
      "Iteration 15, loss = 1.24392495\n",
      "Iteration 16, loss = 1.23539717\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120227\n",
      "Iteration 2, loss = 1.24205604\n",
      "Iteration 3, loss = 1.25796173\n",
      "Iteration 4, loss = 1.25108460\n",
      "Iteration 5, loss = 1.24050080\n",
      "Iteration 6, loss = 1.24288677\n",
      "Iteration 7, loss = 1.23757143\n",
      "Iteration 8, loss = 1.24444724\n",
      "Iteration 9, loss = 1.26503663\n",
      "Iteration 10, loss = 1.25561935\n",
      "Iteration 11, loss = 1.24304091\n",
      "Iteration 12, loss = 1.23733955\n",
      "Iteration 13, loss = 1.23270392\n",
      "Iteration 14, loss = 1.23451786\n",
      "Iteration 15, loss = 1.23396941\n",
      "Iteration 16, loss = 1.24061326\n",
      "Iteration 17, loss = 1.24490223\n",
      "Iteration 3, loss = 1.25796173\n",
      "Iteration 4, loss = 1.25108460\n",
      "Iteration 5, loss = 1.24050080\n",
      "Iteration 6, loss = 1.24288677\n",
      "Iteration 7, loss = 1.23757143\n",
      "Iteration 8, loss = 1.24444724\n",
      "Iteration 9, loss = 1.26503663\n",
      "Iteration 10, loss = 1.25561935\n",
      "Iteration 11, loss = 1.24304091\n",
      "Iteration 12, loss = 1.23733955\n",
      "Iteration 13, loss = 1.23270392\n",
      "Iteration 14, loss = 1.23451786\n",
      "Iteration 15, loss = 1.23396941\n",
      "Iteration 16, loss = 1.24061326\n",
      "Iteration 17, loss = 1.24490223\n",
      "Iteration 18, loss = 1.23349386\n",
      "Iteration 19, loss = 1.25427961\n",
      "Iteration 20, loss = 1.23510308\n",
      "Iteration 21, loss = 1.23341292\n",
      "Iteration 22, loss = 1.23376615\n",
      "Iteration 23, loss = 1.24058230\n",
      "Iteration 24, loss = 1.23985169\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27692611\n",
      "Iteration 2, loss = 1.22824472\n",
      "Iteration 3, loss = 1.26761708\n",
      "Iteration 4, loss = 1.26142279\n",
      "Iteration 5, loss = 1.24566363\n",
      "Iteration 6, loss = 1.27168872\n",
      "Iteration 7, loss = 1.25979450\n",
      "Iteration 8, loss = 1.27424378\n",
      "Iteration 9, loss = 1.28034109\n",
      "Iteration 18, loss = 1.23349386\n",
      "Iteration 19, loss = 1.25427961\n",
      "Iteration 20, loss = 1.23510308\n",
      "Iteration 21, loss = 1.23341292\n",
      "Iteration 22, loss = 1.23376615\n",
      "Iteration 23, loss = 1.24058230\n",
      "Iteration 24, loss = 1.23985169\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27692611\n",
      "Iteration 2, loss = 1.22824472\n",
      "Iteration 3, loss = 1.26761708\n",
      "Iteration 4, loss = 1.26142279\n",
      "Iteration 5, loss = 1.24566363\n",
      "Iteration 6, loss = 1.27168872\n",
      "Iteration 7, loss = 1.25979450\n",
      "Iteration 8, loss = 1.27424378\n",
      "Iteration 9, loss = 1.28034109\n",
      "Iteration 10, loss = 1.27545775\n",
      "Iteration 11, loss = 1.27469982\n",
      "Iteration 12, loss = 1.25779017\n",
      "Iteration 13, loss = 1.25186097\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31403408\n",
      "Iteration 2, loss = 1.25159107\n",
      "Iteration 3, loss = 1.25364872\n",
      "Iteration 4, loss = 1.24534397\n",
      "Iteration 5, loss = 1.25274667\n",
      "Iteration 6, loss = 1.24839335\n",
      "Iteration 7, loss = 1.25205676\n",
      "Iteration 8, loss = 1.25164604\n",
      "Iteration 9, loss = 1.24416864\n",
      "Iteration 10, loss = 1.26685626\n",
      "Iteration 10, loss = 1.27545775\n",
      "Iteration 11, loss = 1.27469982\n",
      "Iteration 12, loss = 1.25779017\n",
      "Iteration 13, loss = 1.25186097\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31403408\n",
      "Iteration 2, loss = 1.25159107\n",
      "Iteration 3, loss = 1.25364872\n",
      "Iteration 4, loss = 1.24534397\n",
      "Iteration 5, loss = 1.25274667\n",
      "Iteration 6, loss = 1.24839335\n",
      "Iteration 7, loss = 1.25205676\n",
      "Iteration 8, loss = 1.25164604\n",
      "Iteration 9, loss = 1.24416864\n",
      "Iteration 10, loss = 1.26685626\n",
      "Iteration 11, loss = 1.27153858\n",
      "Iteration 12, loss = 1.24388597\n",
      "Iteration 13, loss = 1.25737692\n",
      "Iteration 14, loss = 1.25489369\n",
      "Iteration 15, loss = 1.24482578\n",
      "Iteration 16, loss = 1.24590577\n",
      "Iteration 17, loss = 1.24831559\n",
      "Iteration 18, loss = 1.24880130\n",
      "Iteration 19, loss = 1.26256476\n",
      "Iteration 20, loss = 1.25164410\n",
      "Iteration 21, loss = 1.24928701\n",
      "Iteration 22, loss = 1.24429504\n",
      "Iteration 23, loss = 1.24537351\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28397239\n",
      "Iteration 11, loss = 1.27153858\n",
      "Iteration 12, loss = 1.24388597\n",
      "Iteration 13, loss = 1.25737692\n",
      "Iteration 14, loss = 1.25489369\n",
      "Iteration 15, loss = 1.24482578\n",
      "Iteration 16, loss = 1.24590577\n",
      "Iteration 17, loss = 1.24831559\n",
      "Iteration 18, loss = 1.24880130\n",
      "Iteration 19, loss = 1.26256476\n",
      "Iteration 20, loss = 1.25164410\n",
      "Iteration 21, loss = 1.24928701\n",
      "Iteration 22, loss = 1.24429504\n",
      "Iteration 23, loss = 1.24537351\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28397239\n",
      "Iteration 2, loss = 1.25639692\n",
      "Iteration 3, loss = 1.26746450\n",
      "Iteration 4, loss = 1.06894384\n",
      "Iteration 5, loss = 1.06824403\n",
      "Iteration 6, loss = 1.10121666\n",
      "Iteration 7, loss = 1.04259863\n",
      "Iteration 8, loss = 1.00979954\n",
      "Iteration 9, loss = 1.02810290\n",
      "Iteration 10, loss = 1.01084052\n",
      "Iteration 11, loss = 1.06277339\n",
      "Iteration 12, loss = 1.03457059\n",
      "Iteration 13, loss = 0.99774991\n",
      "Iteration 14, loss = 1.00477283\n",
      "Iteration 2, loss = 1.25639692\n",
      "Iteration 3, loss = 1.26746450\n",
      "Iteration 4, loss = 1.06894384\n",
      "Iteration 5, loss = 1.06824403\n",
      "Iteration 6, loss = 1.10121666\n",
      "Iteration 7, loss = 1.04259863\n",
      "Iteration 8, loss = 1.00979954\n",
      "Iteration 9, loss = 1.02810290\n",
      "Iteration 10, loss = 1.01084052\n",
      "Iteration 11, loss = 1.06277339\n",
      "Iteration 12, loss = 1.03457059\n",
      "Iteration 13, loss = 0.99774991\n",
      "Iteration 14, loss = 1.00477283\n",
      "Iteration 15, loss = 0.99123232\n",
      "Iteration 16, loss = 0.98880962\n",
      "Iteration 17, loss = 0.99473759\n",
      "Iteration 18, loss = 0.99531141\n",
      "Iteration 19, loss = 0.99516557\n",
      "Iteration 20, loss = 0.99347708\n",
      "Iteration 21, loss = 1.00194423\n",
      "Iteration 22, loss = 1.00122606\n",
      "Iteration 23, loss = 0.99842091\n",
      "Iteration 24, loss = 1.24342474\n",
      "Iteration 25, loss = 1.26666999\n",
      "Iteration 26, loss = 1.23409027\n",
      "Iteration 27, loss = 1.23881927\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24592404\n",
      "Iteration 2, loss = 1.23892927\n",
      "Iteration 15, loss = 0.99123232\n",
      "Iteration 16, loss = 0.98880962\n",
      "Iteration 17, loss = 0.99473759\n",
      "Iteration 18, loss = 0.99531141\n",
      "Iteration 19, loss = 0.99516557\n",
      "Iteration 20, loss = 0.99347708\n",
      "Iteration 21, loss = 1.00194423\n",
      "Iteration 22, loss = 1.00122606\n",
      "Iteration 23, loss = 0.99842091\n",
      "Iteration 24, loss = 1.24342474\n",
      "Iteration 25, loss = 1.26666999\n",
      "Iteration 26, loss = 1.23409027\n",
      "Iteration 27, loss = 1.23881927\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24592404\n",
      "Iteration 2, loss = 1.23892927\n",
      "Iteration 3, loss = 1.25045855\n",
      "Iteration 4, loss = 1.25160756\n",
      "Iteration 5, loss = 1.23961497\n",
      "Iteration 6, loss = 1.24600846\n",
      "Iteration 7, loss = 1.24519821\n",
      "Iteration 8, loss = 1.24232394\n",
      "Iteration 9, loss = 1.26992042\n",
      "Iteration 10, loss = 1.25148308\n",
      "Iteration 1, loss = 1.24653588\n",
      "Iteration 2, loss = 1.21114820\n",
      "Iteration 3, loss = 1.26176545\n",
      "Iteration 4, loss = 1.25805660\n",
      "Iteration 5, loss = 1.24720676\n",
      "Iteration 3, loss = 1.25045855\n",
      "Iteration 4, loss = 1.25160756\n",
      "Iteration 5, loss = 1.23961497\n",
      "Iteration 6, loss = 1.24600846\n",
      "Iteration 7, loss = 1.24519821\n",
      "Iteration 8, loss = 1.24232394\n",
      "Iteration 9, loss = 1.26992042\n",
      "Iteration 10, loss = 1.25148308\n",
      "Iteration 1, loss = 1.24653588\n",
      "Iteration 2, loss = 1.21114820\n",
      "Iteration 3, loss = 1.26176545\n",
      "Iteration 4, loss = 1.25805660\n",
      "Iteration 5, loss = 1.24720676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.24900861\n",
      "Iteration 7, loss = 1.24141592\n",
      "Iteration 8, loss = 1.24798500\n",
      "Iteration 9, loss = 1.26267505\n",
      "Iteration 10, loss = 1.25090505\n",
      "Iteration 1, loss = 1.32989528\n",
      "Iteration 2, loss = 1.29396961\n",
      "Iteration 3, loss = 1.25705648\n",
      "Iteration 4, loss = 1.26197900\n",
      "Iteration 5, loss = 1.24817896\n",
      "Iteration 6, loss = 1.27661680\n",
      "Iteration 7, loss = 1.26144627\n",
      "Iteration 6, loss = 1.24900861\n",
      "Iteration 7, loss = 1.24141592\n",
      "Iteration 8, loss = 1.24798500\n",
      "Iteration 9, loss = 1.26267505\n",
      "Iteration 10, loss = 1.25090505\n",
      "Iteration 1, loss = 1.32989528\n",
      "Iteration 2, loss = 1.29396961\n",
      "Iteration 3, loss = 1.25705648\n",
      "Iteration 4, loss = 1.26197900\n",
      "Iteration 5, loss = 1.24817896\n",
      "Iteration 6, loss = 1.27661680\n",
      "Iteration 7, loss = 1.26144627\n",
      "Iteration 8, loss = 1.27341719\n",
      "Iteration 9, loss = 1.28559666\n",
      "Iteration 10, loss = 1.26889014\n",
      "Iteration 1, loss = 1.30212843\n",
      "Iteration 2, loss = 1.25951597\n",
      "Iteration 3, loss = 1.25757076\n",
      "Iteration 4, loss = 1.24868186\n",
      "Iteration 5, loss = 1.25758230\n",
      "Iteration 6, loss = 1.25389209\n",
      "Iteration 7, loss = 1.25828253\n",
      "Iteration 8, loss = 1.25617632\n",
      "Iteration 9, loss = 1.24598941\n",
      "Iteration 10, loss = 1.25960919\n",
      "Iteration 8, loss = 1.27341719\n",
      "Iteration 9, loss = 1.28559666\n",
      "Iteration 10, loss = 1.26889014\n",
      "Iteration 1, loss = 1.30212843\n",
      "Iteration 2, loss = 1.25951597\n",
      "Iteration 3, loss = 1.25757076\n",
      "Iteration 4, loss = 1.24868186\n",
      "Iteration 5, loss = 1.25758230\n",
      "Iteration 6, loss = 1.25389209\n",
      "Iteration 7, loss = 1.25828253\n",
      "Iteration 8, loss = 1.25617632\n",
      "Iteration 9, loss = 1.24598941\n",
      "Iteration 10, loss = 1.25960919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.28723363\n",
      "Iteration 2, loss = 1.26599486\n",
      "Iteration 3, loss = 1.27294872\n",
      "Iteration 4, loss = 1.25707698\n",
      "Iteration 5, loss = 1.26806240\n",
      "Iteration 6, loss = 1.26904979\n",
      "Iteration 7, loss = 1.26355283\n",
      "Iteration 8, loss = 1.26914315\n",
      "Iteration 9, loss = 1.25455892\n",
      "Iteration 10, loss = 1.26288018\n",
      "Iteration 1, loss = 1.24592404\n",
      "Iteration 2, loss = 1.23892927\n",
      "Iteration 1, loss = 1.28723363\n",
      "Iteration 2, loss = 1.26599486\n",
      "Iteration 3, loss = 1.27294872\n",
      "Iteration 4, loss = 1.25707698\n",
      "Iteration 5, loss = 1.26806240\n",
      "Iteration 6, loss = 1.26904979\n",
      "Iteration 7, loss = 1.26355283\n",
      "Iteration 8, loss = 1.26914315\n",
      "Iteration 9, loss = 1.25455892\n",
      "Iteration 10, loss = 1.26288018\n",
      "Iteration 1, loss = 1.24592404\n",
      "Iteration 2, loss = 1.23892927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.25045855\n",
      "Iteration 4, loss = 1.25160756\n",
      "Iteration 5, loss = 1.23961497\n",
      "Iteration 6, loss = 1.24600846\n",
      "Iteration 7, loss = 1.24519821\n",
      "Iteration 8, loss = 1.24232394\n",
      "Iteration 9, loss = 1.26992042\n",
      "Iteration 10, loss = 1.25148308\n",
      "Iteration 11, loss = 1.25955185\n",
      "Iteration 12, loss = 1.25718687\n",
      "Iteration 13, loss = 1.25174107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24653588\n",
      "Iteration 3, loss = 1.25045855\n",
      "Iteration 4, loss = 1.25160756\n",
      "Iteration 5, loss = 1.23961497\n",
      "Iteration 6, loss = 1.24600846\n",
      "Iteration 7, loss = 1.24519821\n",
      "Iteration 8, loss = 1.24232394\n",
      "Iteration 9, loss = 1.26992042\n",
      "Iteration 10, loss = 1.25148308\n",
      "Iteration 11, loss = 1.25955185\n",
      "Iteration 12, loss = 1.25718687\n",
      "Iteration 13, loss = 1.25174107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24653588\n",
      "Iteration 2, loss = 1.21114820\n",
      "Iteration 3, loss = 1.26176545\n",
      "Iteration 4, loss = 1.25805660\n",
      "Iteration 5, loss = 1.24720676\n",
      "Iteration 6, loss = 1.24900861\n",
      "Iteration 7, loss = 1.24141592\n",
      "Iteration 8, loss = 1.24798500\n",
      "Iteration 9, loss = 1.26267505\n",
      "Iteration 10, loss = 1.25090505\n",
      "Iteration 11, loss = 1.24511053\n",
      "Iteration 12, loss = 1.24129809\n",
      "Iteration 13, loss = 1.23403817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.32989528\n",
      "Iteration 2, loss = 1.21114820\n",
      "Iteration 3, loss = 1.26176545\n",
      "Iteration 4, loss = 1.25805660\n",
      "Iteration 5, loss = 1.24720676\n",
      "Iteration 6, loss = 1.24900861\n",
      "Iteration 7, loss = 1.24141592\n",
      "Iteration 8, loss = 1.24798500\n",
      "Iteration 9, loss = 1.26267505\n",
      "Iteration 10, loss = 1.25090505\n",
      "Iteration 11, loss = 1.24511053\n",
      "Iteration 12, loss = 1.24129809\n",
      "Iteration 13, loss = 1.23403817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.32989528\n",
      "Iteration 2, loss = 1.29396961\n",
      "Iteration 3, loss = 1.25705648\n",
      "Iteration 4, loss = 1.26197900\n",
      "Iteration 5, loss = 1.24817896\n",
      "Iteration 6, loss = 1.27661680\n",
      "Iteration 7, loss = 1.26144627\n",
      "Iteration 8, loss = 1.27341719\n",
      "Iteration 9, loss = 1.28559666\n",
      "Iteration 10, loss = 1.26889014\n",
      "Iteration 11, loss = 1.28279235\n",
      "Iteration 12, loss = 1.26049325\n",
      "Iteration 13, loss = 1.24554604\n",
      "Iteration 14, loss = 1.29085121\n",
      "Iteration 15, loss = 1.24728361\n",
      "Iteration 16, loss = 1.26784794\n",
      "Iteration 17, loss = 1.25948697\n",
      "Iteration 2, loss = 1.29396961\n",
      "Iteration 3, loss = 1.25705648\n",
      "Iteration 4, loss = 1.26197900\n",
      "Iteration 5, loss = 1.24817896\n",
      "Iteration 6, loss = 1.27661680\n",
      "Iteration 7, loss = 1.26144627\n",
      "Iteration 8, loss = 1.27341719\n",
      "Iteration 9, loss = 1.28559666\n",
      "Iteration 10, loss = 1.26889014\n",
      "Iteration 11, loss = 1.28279235\n",
      "Iteration 12, loss = 1.26049325\n",
      "Iteration 13, loss = 1.24554604\n",
      "Iteration 14, loss = 1.29085121\n",
      "Iteration 15, loss = 1.24728361\n",
      "Iteration 16, loss = 1.26784794\n",
      "Iteration 17, loss = 1.25948697\n",
      "Iteration 18, loss = 1.25553378\n",
      "Iteration 19, loss = 1.29126227\n",
      "Iteration 20, loss = 1.26933272\n",
      "Iteration 21, loss = 1.25071707\n",
      "Iteration 22, loss = 1.26009792\n",
      "Iteration 23, loss = 1.25335219\n",
      "Iteration 24, loss = 1.25798196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30212843\n",
      "Iteration 2, loss = 1.25951597\n",
      "Iteration 3, loss = 1.25757076\n",
      "Iteration 4, loss = 1.24868186\n",
      "Iteration 5, loss = 1.25758230\n",
      "Iteration 6, loss = 1.25389209\n",
      "Iteration 7, loss = 1.25828253\n",
      "Iteration 18, loss = 1.25553378\n",
      "Iteration 19, loss = 1.29126227\n",
      "Iteration 20, loss = 1.26933272\n",
      "Iteration 21, loss = 1.25071707\n",
      "Iteration 22, loss = 1.26009792\n",
      "Iteration 23, loss = 1.25335219\n",
      "Iteration 24, loss = 1.25798196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30212843\n",
      "Iteration 2, loss = 1.25951597\n",
      "Iteration 3, loss = 1.25757076\n",
      "Iteration 4, loss = 1.24868186\n",
      "Iteration 5, loss = 1.25758230\n",
      "Iteration 6, loss = 1.25389209\n",
      "Iteration 7, loss = 1.25828253\n",
      "Iteration 8, loss = 1.25617632\n",
      "Iteration 9, loss = 1.24598941\n",
      "Iteration 10, loss = 1.25960919\n",
      "Iteration 11, loss = 1.28724063\n",
      "Iteration 12, loss = 1.24806530\n",
      "Iteration 13, loss = 1.24941211\n",
      "Iteration 14, loss = 1.26075189\n",
      "Iteration 15, loss = 1.24801242\n",
      "Iteration 16, loss = 1.24990722\n",
      "Iteration 17, loss = 1.25236869\n",
      "Iteration 18, loss = 1.25412060\n",
      "Iteration 19, loss = 1.26773543\n",
      "Iteration 20, loss = 1.25719065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28723363\n",
      "Iteration 8, loss = 1.25617632\n",
      "Iteration 9, loss = 1.24598941\n",
      "Iteration 10, loss = 1.25960919\n",
      "Iteration 11, loss = 1.28724063\n",
      "Iteration 12, loss = 1.24806530\n",
      "Iteration 13, loss = 1.24941211\n",
      "Iteration 14, loss = 1.26075189\n",
      "Iteration 15, loss = 1.24801242\n",
      "Iteration 16, loss = 1.24990722\n",
      "Iteration 17, loss = 1.25236869\n",
      "Iteration 18, loss = 1.25412060\n",
      "Iteration 19, loss = 1.26773543\n",
      "Iteration 20, loss = 1.25719065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28723363\n",
      "Iteration 2, loss = 1.26599486\n",
      "Iteration 3, loss = 1.27294872\n",
      "Iteration 4, loss = 1.25707698\n",
      "Iteration 5, loss = 1.26806240\n",
      "Iteration 6, loss = 1.26904979\n",
      "Iteration 7, loss = 1.26355283\n",
      "Iteration 8, loss = 1.26914315\n",
      "Iteration 9, loss = 1.25455892\n",
      "Iteration 10, loss = 1.26288018\n",
      "Iteration 11, loss = 1.31971431\n",
      "Iteration 12, loss = 1.26586442\n",
      "Iteration 13, loss = 1.26599918\n",
      "Iteration 14, loss = 1.26217003\n",
      "Iteration 2, loss = 1.26599486\n",
      "Iteration 3, loss = 1.27294872\n",
      "Iteration 4, loss = 1.25707698\n",
      "Iteration 5, loss = 1.26806240\n",
      "Iteration 6, loss = 1.26904979\n",
      "Iteration 7, loss = 1.26355283\n",
      "Iteration 8, loss = 1.26914315\n",
      "Iteration 9, loss = 1.25455892\n",
      "Iteration 10, loss = 1.26288018\n",
      "Iteration 11, loss = 1.31971431\n",
      "Iteration 12, loss = 1.26586442\n",
      "Iteration 13, loss = 1.26599918\n",
      "Iteration 14, loss = 1.26217003\n",
      "Iteration 15, loss = 1.26564371\n",
      "Iteration 16, loss = 1.25859318\n",
      "Iteration 17, loss = 1.25849857\n",
      "Iteration 18, loss = 1.27498483\n",
      "Iteration 19, loss = 1.26739858\n",
      "Iteration 20, loss = 1.26886547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24592404\n",
      "Iteration 2, loss = 1.23892927\n",
      "Iteration 3, loss = 1.25045855\n",
      "Iteration 4, loss = 1.25160756\n",
      "Iteration 5, loss = 1.23961497\n",
      "Iteration 6, loss = 1.24600846\n",
      "Iteration 7, loss = 1.24519821\n",
      "Iteration 8, loss = 1.24232394\n",
      "Iteration 15, loss = 1.26564371\n",
      "Iteration 16, loss = 1.25859318\n",
      "Iteration 17, loss = 1.25849857\n",
      "Iteration 18, loss = 1.27498483\n",
      "Iteration 19, loss = 1.26739858\n",
      "Iteration 20, loss = 1.26886547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24592404\n",
      "Iteration 2, loss = 1.23892927\n",
      "Iteration 3, loss = 1.25045855\n",
      "Iteration 4, loss = 1.25160756\n",
      "Iteration 5, loss = 1.23961497\n",
      "Iteration 6, loss = 1.24600846\n",
      "Iteration 7, loss = 1.24519821\n",
      "Iteration 8, loss = 1.24232394\n",
      "Iteration 9, loss = 1.26992042\n",
      "Iteration 10, loss = 1.25148308\n",
      "Iteration 11, loss = 1.25955185\n",
      "Iteration 12, loss = 1.25718687\n",
      "Iteration 13, loss = 1.25174107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24653588\n",
      "Iteration 2, loss = 1.21114820\n",
      "Iteration 3, loss = 1.26176545\n",
      "Iteration 4, loss = 1.25805660\n",
      "Iteration 5, loss = 1.24720676\n",
      "Iteration 6, loss = 1.24900861\n",
      "Iteration 7, loss = 1.24141592\n",
      "Iteration 8, loss = 1.24798500\n",
      "Iteration 9, loss = 1.26992042\n",
      "Iteration 10, loss = 1.25148308\n",
      "Iteration 11, loss = 1.25955185\n",
      "Iteration 12, loss = 1.25718687\n",
      "Iteration 13, loss = 1.25174107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24653588\n",
      "Iteration 2, loss = 1.21114820\n",
      "Iteration 3, loss = 1.26176545\n",
      "Iteration 4, loss = 1.25805660\n",
      "Iteration 5, loss = 1.24720676\n",
      "Iteration 6, loss = 1.24900861\n",
      "Iteration 7, loss = 1.24141592\n",
      "Iteration 8, loss = 1.24798500\n",
      "Iteration 9, loss = 1.26267505\n",
      "Iteration 10, loss = 1.25090505\n",
      "Iteration 11, loss = 1.24511053\n",
      "Iteration 12, loss = 1.24129809\n",
      "Iteration 13, loss = 1.23403817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.32989528\n",
      "Iteration 2, loss = 1.29396961\n",
      "Iteration 3, loss = 1.25705648\n",
      "Iteration 4, loss = 1.26197900\n",
      "Iteration 5, loss = 1.24817896\n",
      "Iteration 6, loss = 1.27661680\n",
      "Iteration 7, loss = 1.26144627\n",
      "Iteration 9, loss = 1.26267505\n",
      "Iteration 10, loss = 1.25090505\n",
      "Iteration 11, loss = 1.24511053\n",
      "Iteration 12, loss = 1.24129809\n",
      "Iteration 13, loss = 1.23403817\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.32989528\n",
      "Iteration 2, loss = 1.29396961\n",
      "Iteration 3, loss = 1.25705648\n",
      "Iteration 4, loss = 1.26197900\n",
      "Iteration 5, loss = 1.24817896\n",
      "Iteration 6, loss = 1.27661680\n",
      "Iteration 7, loss = 1.26144627\n",
      "Iteration 8, loss = 1.27341719\n",
      "Iteration 9, loss = 1.28559666\n",
      "Iteration 10, loss = 1.26889014\n",
      "Iteration 11, loss = 1.28279235\n",
      "Iteration 12, loss = 1.26049325\n",
      "Iteration 13, loss = 1.24554604\n",
      "Iteration 14, loss = 1.29085121\n",
      "Iteration 15, loss = 1.24728361\n",
      "Iteration 16, loss = 1.26784794\n",
      "Iteration 17, loss = 1.25948697\n",
      "Iteration 18, loss = 1.25553378\n",
      "Iteration 19, loss = 1.29126227\n",
      "Iteration 20, loss = 1.26933272\n",
      "Iteration 21, loss = 1.25071707\n",
      "Iteration 22, loss = 1.26009792\n",
      "Iteration 23, loss = 1.25335219\n",
      "Iteration 8, loss = 1.27341719\n",
      "Iteration 9, loss = 1.28559666\n",
      "Iteration 10, loss = 1.26889014\n",
      "Iteration 11, loss = 1.28279235\n",
      "Iteration 12, loss = 1.26049325\n",
      "Iteration 13, loss = 1.24554604\n",
      "Iteration 14, loss = 1.29085121\n",
      "Iteration 15, loss = 1.24728361\n",
      "Iteration 16, loss = 1.26784794\n",
      "Iteration 17, loss = 1.25948697\n",
      "Iteration 18, loss = 1.25553378\n",
      "Iteration 19, loss = 1.29126227\n",
      "Iteration 20, loss = 1.26933272\n",
      "Iteration 21, loss = 1.25071707\n",
      "Iteration 22, loss = 1.26009792\n",
      "Iteration 23, loss = 1.25335219\n",
      "Iteration 24, loss = 1.25798196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30212843\n",
      "Iteration 2, loss = 1.25951597\n",
      "Iteration 3, loss = 1.25757076\n",
      "Iteration 4, loss = 1.24868186\n",
      "Iteration 5, loss = 1.25758230\n",
      "Iteration 6, loss = 1.25389209\n",
      "Iteration 7, loss = 1.25828253\n",
      "Iteration 8, loss = 1.25617632\n",
      "Iteration 9, loss = 1.24598941\n",
      "Iteration 10, loss = 1.25960919\n",
      "Iteration 11, loss = 1.28724063\n",
      "Iteration 12, loss = 1.24806530\n",
      "Iteration 13, loss = 1.24941211\n",
      "Iteration 24, loss = 1.25798196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30212843\n",
      "Iteration 2, loss = 1.25951597\n",
      "Iteration 3, loss = 1.25757076\n",
      "Iteration 4, loss = 1.24868186\n",
      "Iteration 5, loss = 1.25758230\n",
      "Iteration 6, loss = 1.25389209\n",
      "Iteration 7, loss = 1.25828253\n",
      "Iteration 8, loss = 1.25617632\n",
      "Iteration 9, loss = 1.24598941\n",
      "Iteration 10, loss = 1.25960919\n",
      "Iteration 11, loss = 1.28724063\n",
      "Iteration 12, loss = 1.24806530\n",
      "Iteration 13, loss = 1.24941211\n",
      "Iteration 14, loss = 1.26075189\n",
      "Iteration 15, loss = 1.24801242\n",
      "Iteration 16, loss = 1.24990722\n",
      "Iteration 17, loss = 1.25236869\n",
      "Iteration 18, loss = 1.25412060\n",
      "Iteration 19, loss = 1.26773543\n",
      "Iteration 20, loss = 1.25719065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28723363\n",
      "Iteration 2, loss = 1.26599486\n",
      "Iteration 3, loss = 1.27294872\n",
      "Iteration 4, loss = 1.25707698\n",
      "Iteration 5, loss = 1.26806240\n",
      "Iteration 6, loss = 1.26904979\n",
      "Iteration 7, loss = 1.26355283\n",
      "Iteration 14, loss = 1.26075189\n",
      "Iteration 15, loss = 1.24801242\n",
      "Iteration 16, loss = 1.24990722\n",
      "Iteration 17, loss = 1.25236869\n",
      "Iteration 18, loss = 1.25412060\n",
      "Iteration 19, loss = 1.26773543\n",
      "Iteration 20, loss = 1.25719065\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28723363\n",
      "Iteration 2, loss = 1.26599486\n",
      "Iteration 3, loss = 1.27294872\n",
      "Iteration 4, loss = 1.25707698\n",
      "Iteration 5, loss = 1.26806240\n",
      "Iteration 6, loss = 1.26904979\n",
      "Iteration 7, loss = 1.26355283\n",
      "Iteration 8, loss = 1.26914315\n",
      "Iteration 9, loss = 1.25455892\n",
      "Iteration 10, loss = 1.26288018\n",
      "Iteration 11, loss = 1.31971431\n",
      "Iteration 12, loss = 1.26586442\n",
      "Iteration 13, loss = 1.26599918\n",
      "Iteration 14, loss = 1.26217003\n",
      "Iteration 15, loss = 1.26564371\n",
      "Iteration 16, loss = 1.25859318\n",
      "Iteration 17, loss = 1.25849857\n",
      "Iteration 18, loss = 1.27498483\n",
      "Iteration 19, loss = 1.26739858\n",
      "Iteration 20, loss = 1.26886547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16410388\n",
      "Iteration 8, loss = 1.26914315\n",
      "Iteration 9, loss = 1.25455892\n",
      "Iteration 10, loss = 1.26288018\n",
      "Iteration 11, loss = 1.31971431\n",
      "Iteration 12, loss = 1.26586442\n",
      "Iteration 13, loss = 1.26599918\n",
      "Iteration 14, loss = 1.26217003\n",
      "Iteration 15, loss = 1.26564371\n",
      "Iteration 16, loss = 1.25859318\n",
      "Iteration 17, loss = 1.25849857\n",
      "Iteration 18, loss = 1.27498483\n",
      "Iteration 19, loss = 1.26739858\n",
      "Iteration 20, loss = 1.26886547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16410388\n",
      "Iteration 2, loss = 1.06114253\n",
      "Iteration 3, loss = 1.01061821\n",
      "Iteration 4, loss = 1.02601635\n",
      "Iteration 5, loss = 1.04910300\n",
      "Iteration 6, loss = 0.97278432\n",
      "Iteration 7, loss = 0.97380595\n",
      "Iteration 8, loss = 0.96100571\n",
      "Iteration 9, loss = 0.94673542\n",
      "Iteration 10, loss = 0.94236016\n",
      "Iteration 1, loss = 1.11852002\n",
      "Iteration 2, loss = 0.98596141\n",
      "Iteration 3, loss = 0.95955027\n",
      "Iteration 4, loss = 0.96344175\n",
      "Iteration 2, loss = 1.06114253\n",
      "Iteration 3, loss = 1.01061821\n",
      "Iteration 4, loss = 1.02601635\n",
      "Iteration 5, loss = 1.04910300\n",
      "Iteration 6, loss = 0.97278432\n",
      "Iteration 7, loss = 0.97380595\n",
      "Iteration 8, loss = 0.96100571\n",
      "Iteration 9, loss = 0.94673542\n",
      "Iteration 10, loss = 0.94236016\n",
      "Iteration 1, loss = 1.11852002\n",
      "Iteration 2, loss = 0.98596141\n",
      "Iteration 3, loss = 0.95955027\n",
      "Iteration 4, loss = 0.96344175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.92190924\n",
      "Iteration 6, loss = 0.90022669\n",
      "Iteration 7, loss = 0.93739151\n",
      "Iteration 8, loss = 0.92227794\n",
      "Iteration 9, loss = 0.91761736\n",
      "Iteration 10, loss = 0.92621622\n",
      "Iteration 1, loss = 1.15282747\n",
      "Iteration 2, loss = 1.05116399\n",
      "Iteration 3, loss = 0.95739551\n",
      "Iteration 4, loss = 0.97904131\n",
      "Iteration 5, loss = 0.96320164\n",
      "Iteration 5, loss = 0.92190924\n",
      "Iteration 6, loss = 0.90022669\n",
      "Iteration 7, loss = 0.93739151\n",
      "Iteration 8, loss = 0.92227794\n",
      "Iteration 9, loss = 0.91761736\n",
      "Iteration 10, loss = 0.92621622\n",
      "Iteration 1, loss = 1.15282747\n",
      "Iteration 2, loss = 1.05116399\n",
      "Iteration 3, loss = 0.95739551\n",
      "Iteration 4, loss = 0.97904131\n",
      "Iteration 5, loss = 0.96320164\n",
      "Iteration 6, loss = 0.94506776\n",
      "Iteration 7, loss = 0.93990902\n",
      "Iteration 8, loss = 0.95559461\n",
      "Iteration 9, loss = 0.94622936\n",
      "Iteration 10, loss = 0.93620885\n",
      "Iteration 1, loss = 1.17817981\n",
      "Iteration 2, loss = 1.07361478\n",
      "Iteration 3, loss = 0.97620908\n",
      "Iteration 4, loss = 1.02464114\n",
      "Iteration 5, loss = 0.98961322\n",
      "Iteration 6, loss = 0.96400761\n",
      "Iteration 7, loss = 0.94333784\n",
      "Iteration 8, loss = 0.96951576\n",
      "Iteration 6, loss = 0.94506776\n",
      "Iteration 7, loss = 0.93990902\n",
      "Iteration 8, loss = 0.95559461\n",
      "Iteration 9, loss = 0.94622936\n",
      "Iteration 10, loss = 0.93620885\n",
      "Iteration 1, loss = 1.17817981\n",
      "Iteration 2, loss = 1.07361478\n",
      "Iteration 3, loss = 0.97620908\n",
      "Iteration 4, loss = 1.02464114\n",
      "Iteration 5, loss = 0.98961322\n",
      "Iteration 6, loss = 0.96400761\n",
      "Iteration 7, loss = 0.94333784\n",
      "Iteration 8, loss = 0.96951576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.96575045\n",
      "Iteration 10, loss = 0.95635195\n",
      "Iteration 1, loss = 1.13436399\n",
      "Iteration 2, loss = 1.05391098\n",
      "Iteration 3, loss = 0.98806997\n",
      "Iteration 4, loss = 0.98340783\n",
      "Iteration 5, loss = 0.98651092\n",
      "Iteration 6, loss = 0.96685058\n",
      "Iteration 7, loss = 0.93336296\n",
      "Iteration 8, loss = 0.92310846\n",
      "Iteration 9, loss = 0.94977203\n",
      "Iteration 9, loss = 0.96575045\n",
      "Iteration 10, loss = 0.95635195\n",
      "Iteration 1, loss = 1.13436399\n",
      "Iteration 2, loss = 1.05391098\n",
      "Iteration 3, loss = 0.98806997\n",
      "Iteration 4, loss = 0.98340783\n",
      "Iteration 5, loss = 0.98651092\n",
      "Iteration 6, loss = 0.96685058\n",
      "Iteration 7, loss = 0.93336296\n",
      "Iteration 8, loss = 0.92310846\n",
      "Iteration 9, loss = 0.94977203\n",
      "Iteration 10, loss = 0.93022094\n",
      "Iteration 1, loss = 1.16410388\n",
      "Iteration 2, loss = 1.06114253\n",
      "Iteration 3, loss = 1.01061821\n",
      "Iteration 4, loss = 1.02601635\n",
      "Iteration 5, loss = 1.04910300\n",
      "Iteration 6, loss = 0.97278432\n",
      "Iteration 7, loss = 0.97380595\n",
      "Iteration 8, loss = 0.96100571\n",
      "Iteration 9, loss = 0.94673542\n",
      "Iteration 10, loss = 0.94236016\n",
      "Iteration 11, loss = 0.94222250\n",
      "Iteration 12, loss = 0.93229529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.93022094\n",
      "Iteration 1, loss = 1.16410388\n",
      "Iteration 2, loss = 1.06114253\n",
      "Iteration 3, loss = 1.01061821\n",
      "Iteration 4, loss = 1.02601635\n",
      "Iteration 5, loss = 1.04910300\n",
      "Iteration 6, loss = 0.97278432\n",
      "Iteration 7, loss = 0.97380595\n",
      "Iteration 8, loss = 0.96100571\n",
      "Iteration 9, loss = 0.94673542\n",
      "Iteration 10, loss = 0.94236016\n",
      "Iteration 11, loss = 0.94222250\n",
      "Iteration 12, loss = 0.93229529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.93077541\n",
      "Iteration 14, loss = 0.92286447\n",
      "Iteration 15, loss = 0.95489516\n",
      "Iteration 16, loss = 0.92448655\n",
      "Iteration 17, loss = 0.94946780\n",
      "Iteration 18, loss = 0.93563753\n",
      "Iteration 19, loss = 0.91134569\n",
      "Iteration 20, loss = 0.92192969\n",
      "Iteration 21, loss = 0.91699956\n",
      "Iteration 22, loss = 0.91465815\n",
      "Iteration 23, loss = 0.92312625\n",
      "Iteration 24, loss = 0.89700223\n",
      "Iteration 25, loss = 0.89169353\n",
      "Iteration 26, loss = 0.85963902\n",
      "Iteration 27, loss = 0.86134580\n",
      "Iteration 28, loss = 0.85766478\n",
      "Iteration 13, loss = 0.93077541\n",
      "Iteration 14, loss = 0.92286447\n",
      "Iteration 15, loss = 0.95489516\n",
      "Iteration 16, loss = 0.92448655\n",
      "Iteration 17, loss = 0.94946780\n",
      "Iteration 18, loss = 0.93563753\n",
      "Iteration 19, loss = 0.91134569\n",
      "Iteration 20, loss = 0.92192969\n",
      "Iteration 21, loss = 0.91699956\n",
      "Iteration 22, loss = 0.91465815\n",
      "Iteration 23, loss = 0.92312625\n",
      "Iteration 24, loss = 0.89700223\n",
      "Iteration 25, loss = 0.89169353\n",
      "Iteration 26, loss = 0.85963902\n",
      "Iteration 27, loss = 0.86134580\n",
      "Iteration 28, loss = 0.85766478\n",
      "Iteration 29, loss = 0.89748491\n",
      "Iteration 30, loss = 0.92599505\n",
      "Iteration 31, loss = 0.88380923\n",
      "Iteration 32, loss = 0.88111137\n",
      "Iteration 33, loss = 0.88089058\n",
      "Iteration 34, loss = 0.85019896\n",
      "Iteration 35, loss = 0.87532924\n",
      "Iteration 36, loss = 0.86862611\n",
      "Iteration 37, loss = 0.84883465\n",
      "Iteration 38, loss = 0.86422922\n",
      "Iteration 39, loss = 0.82089319\n",
      "Iteration 40, loss = 0.81620826\n",
      "Iteration 41, loss = 0.86119579\n",
      "Iteration 42, loss = 0.82668287\n",
      "Iteration 43, loss = 0.82325855\n",
      "Iteration 44, loss = 0.82893595\n",
      "Iteration 29, loss = 0.89748491\n",
      "Iteration 30, loss = 0.92599505\n",
      "Iteration 31, loss = 0.88380923\n",
      "Iteration 32, loss = 0.88111137\n",
      "Iteration 33, loss = 0.88089058\n",
      "Iteration 34, loss = 0.85019896\n",
      "Iteration 35, loss = 0.87532924\n",
      "Iteration 36, loss = 0.86862611\n",
      "Iteration 37, loss = 0.84883465\n",
      "Iteration 38, loss = 0.86422922\n",
      "Iteration 39, loss = 0.82089319\n",
      "Iteration 40, loss = 0.81620826\n",
      "Iteration 41, loss = 0.86119579\n",
      "Iteration 42, loss = 0.82668287\n",
      "Iteration 43, loss = 0.82325855\n",
      "Iteration 44, loss = 0.82893595\n",
      "Iteration 45, loss = 0.85322309\n",
      "Iteration 46, loss = 0.80849816\n",
      "Iteration 47, loss = 0.81763773\n",
      "Iteration 48, loss = 0.84217291\n",
      "Iteration 49, loss = 0.79727964\n",
      "Iteration 50, loss = 0.78436016\n",
      "Iteration 1, loss = 1.11852002\n",
      "Iteration 2, loss = 0.98596141\n",
      "Iteration 3, loss = 0.95955027\n",
      "Iteration 4, loss = 0.96344175\n",
      "Iteration 5, loss = 0.92190924\n",
      "Iteration 6, loss = 0.90022669\n",
      "Iteration 7, loss = 0.93739151\n",
      "Iteration 8, loss = 0.92227794\n",
      "Iteration 45, loss = 0.85322309\n",
      "Iteration 46, loss = 0.80849816\n",
      "Iteration 47, loss = 0.81763773\n",
      "Iteration 48, loss = 0.84217291\n",
      "Iteration 49, loss = 0.79727964\n",
      "Iteration 50, loss = 0.78436016\n",
      "Iteration 1, loss = 1.11852002\n",
      "Iteration 2, loss = 0.98596141\n",
      "Iteration 3, loss = 0.95955027\n",
      "Iteration 4, loss = 0.96344175\n",
      "Iteration 5, loss = 0.92190924\n",
      "Iteration 6, loss = 0.90022669\n",
      "Iteration 7, loss = 0.93739151\n",
      "Iteration 8, loss = 0.92227794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.91761736\n",
      "Iteration 10, loss = 0.92621622\n",
      "Iteration 11, loss = 0.88992243\n",
      "Iteration 12, loss = 0.88400040\n",
      "Iteration 13, loss = 0.89525258\n",
      "Iteration 14, loss = 0.88867076\n",
      "Iteration 15, loss = 0.86885409\n",
      "Iteration 16, loss = 0.87830541\n",
      "Iteration 17, loss = 0.86183337\n",
      "Iteration 18, loss = 0.86483089\n",
      "Iteration 19, loss = 0.88216069\n",
      "Iteration 20, loss = 0.84795519\n",
      "Iteration 21, loss = 0.86328018\n",
      "Iteration 22, loss = 0.86978759\n",
      "Iteration 9, loss = 0.91761736\n",
      "Iteration 10, loss = 0.92621622\n",
      "Iteration 11, loss = 0.88992243\n",
      "Iteration 12, loss = 0.88400040\n",
      "Iteration 13, loss = 0.89525258\n",
      "Iteration 14, loss = 0.88867076\n",
      "Iteration 15, loss = 0.86885409\n",
      "Iteration 16, loss = 0.87830541\n",
      "Iteration 17, loss = 0.86183337\n",
      "Iteration 18, loss = 0.86483089\n",
      "Iteration 19, loss = 0.88216069\n",
      "Iteration 20, loss = 0.84795519\n",
      "Iteration 21, loss = 0.86328018\n",
      "Iteration 22, loss = 0.86978759\n",
      "Iteration 23, loss = 0.87222890\n",
      "Iteration 24, loss = 0.84329702\n",
      "Iteration 25, loss = 0.81342835\n",
      "Iteration 26, loss = 0.80934165\n",
      "Iteration 27, loss = 0.80203141\n",
      "Iteration 28, loss = 0.79633928\n",
      "Iteration 29, loss = 0.84388916\n",
      "Iteration 30, loss = 0.80737998\n",
      "Iteration 31, loss = 0.78234657\n",
      "Iteration 32, loss = 0.80695889\n",
      "Iteration 33, loss = 0.81985477\n",
      "Iteration 34, loss = 0.75837975\n",
      "Iteration 35, loss = 0.80105094\n",
      "Iteration 36, loss = 0.78620175\n",
      "Iteration 37, loss = 0.78974450\n",
      "Iteration 23, loss = 0.87222890\n",
      "Iteration 24, loss = 0.84329702\n",
      "Iteration 25, loss = 0.81342835\n",
      "Iteration 26, loss = 0.80934165\n",
      "Iteration 27, loss = 0.80203141\n",
      "Iteration 28, loss = 0.79633928\n",
      "Iteration 29, loss = 0.84388916\n",
      "Iteration 30, loss = 0.80737998\n",
      "Iteration 31, loss = 0.78234657\n",
      "Iteration 32, loss = 0.80695889\n",
      "Iteration 33, loss = 0.81985477\n",
      "Iteration 34, loss = 0.75837975\n",
      "Iteration 35, loss = 0.80105094\n",
      "Iteration 36, loss = 0.78620175\n",
      "Iteration 37, loss = 0.78974450\n",
      "Iteration 38, loss = 0.77457732\n",
      "Iteration 39, loss = 0.77635957\n",
      "Iteration 40, loss = 0.78111787\n",
      "Iteration 41, loss = 0.76613834\n",
      "Iteration 42, loss = 0.75359444\n",
      "Iteration 43, loss = 0.76211508\n",
      "Iteration 44, loss = 0.75346839\n",
      "Iteration 45, loss = 0.76734827\n",
      "Iteration 46, loss = 0.70927197\n",
      "Iteration 47, loss = 0.72335636\n",
      "Iteration 48, loss = 0.75028555\n",
      "Iteration 49, loss = 0.74504244\n",
      "Iteration 50, loss = 0.76293598\n",
      "Iteration 1, loss = 1.15282747\n",
      "Iteration 2, loss = 1.05116399\n",
      "Iteration 38, loss = 0.77457732\n",
      "Iteration 39, loss = 0.77635957\n",
      "Iteration 40, loss = 0.78111787\n",
      "Iteration 41, loss = 0.76613834\n",
      "Iteration 42, loss = 0.75359444\n",
      "Iteration 43, loss = 0.76211508\n",
      "Iteration 44, loss = 0.75346839\n",
      "Iteration 45, loss = 0.76734827\n",
      "Iteration 46, loss = 0.70927197\n",
      "Iteration 47, loss = 0.72335636\n",
      "Iteration 48, loss = 0.75028555\n",
      "Iteration 49, loss = 0.74504244\n",
      "Iteration 50, loss = 0.76293598\n",
      "Iteration 1, loss = 1.15282747\n",
      "Iteration 2, loss = 1.05116399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.95739551\n",
      "Iteration 4, loss = 0.97904131\n",
      "Iteration 5, loss = 0.96320164\n",
      "Iteration 6, loss = 0.94506776\n",
      "Iteration 7, loss = 0.93990902\n",
      "Iteration 8, loss = 0.95559461\n",
      "Iteration 9, loss = 0.94622936\n",
      "Iteration 10, loss = 0.93620885\n",
      "Iteration 11, loss = 0.91285747\n",
      "Iteration 12, loss = 0.91853185\n",
      "Iteration 13, loss = 0.92865132\n",
      "Iteration 14, loss = 0.90332673\n",
      "Iteration 15, loss = 0.90622590\n",
      "Iteration 3, loss = 0.95739551\n",
      "Iteration 4, loss = 0.97904131\n",
      "Iteration 5, loss = 0.96320164\n",
      "Iteration 6, loss = 0.94506776\n",
      "Iteration 7, loss = 0.93990902\n",
      "Iteration 8, loss = 0.95559461\n",
      "Iteration 9, loss = 0.94622936\n",
      "Iteration 10, loss = 0.93620885\n",
      "Iteration 11, loss = 0.91285747\n",
      "Iteration 12, loss = 0.91853185\n",
      "Iteration 13, loss = 0.92865132\n",
      "Iteration 14, loss = 0.90332673\n",
      "Iteration 15, loss = 0.90622590\n",
      "Iteration 16, loss = 0.90096007\n",
      "Iteration 17, loss = 0.90909097\n",
      "Iteration 18, loss = 0.90740694\n",
      "Iteration 19, loss = 0.92381015\n",
      "Iteration 20, loss = 0.89483089\n",
      "Iteration 21, loss = 0.90622651\n",
      "Iteration 22, loss = 0.88792344\n",
      "Iteration 23, loss = 0.90129836\n",
      "Iteration 24, loss = 0.90662706\n",
      "Iteration 25, loss = 0.88416970\n",
      "Iteration 26, loss = 0.87226938\n",
      "Iteration 27, loss = 0.87406850\n",
      "Iteration 28, loss = 0.85219204\n",
      "Iteration 29, loss = 0.86470089\n",
      "Iteration 30, loss = 0.85099344\n",
      "Iteration 31, loss = 0.87894463\n",
      "Iteration 16, loss = 0.90096007\n",
      "Iteration 17, loss = 0.90909097\n",
      "Iteration 18, loss = 0.90740694\n",
      "Iteration 19, loss = 0.92381015\n",
      "Iteration 20, loss = 0.89483089\n",
      "Iteration 21, loss = 0.90622651\n",
      "Iteration 22, loss = 0.88792344\n",
      "Iteration 23, loss = 0.90129836\n",
      "Iteration 24, loss = 0.90662706\n",
      "Iteration 25, loss = 0.88416970\n",
      "Iteration 26, loss = 0.87226938\n",
      "Iteration 27, loss = 0.87406850\n",
      "Iteration 28, loss = 0.85219204\n",
      "Iteration 29, loss = 0.86470089\n",
      "Iteration 30, loss = 0.85099344\n",
      "Iteration 31, loss = 0.87894463\n",
      "Iteration 32, loss = 0.84163211\n",
      "Iteration 33, loss = 0.86893095\n",
      "Iteration 34, loss = 0.86483071\n",
      "Iteration 35, loss = 0.85019640\n",
      "Iteration 36, loss = 0.81134248\n",
      "Iteration 37, loss = 0.86392677\n",
      "Iteration 38, loss = 0.83442340\n",
      "Iteration 39, loss = 0.84508168\n",
      "Iteration 40, loss = 0.85710120\n",
      "Iteration 41, loss = 0.86503971\n",
      "Iteration 42, loss = 0.82753666\n",
      "Iteration 43, loss = 0.81938740\n",
      "Iteration 44, loss = 0.82419386\n",
      "Iteration 45, loss = 0.78078114\n",
      "Iteration 46, loss = 0.83893966\n",
      "Iteration 47, loss = 0.81869941\n",
      "Iteration 32, loss = 0.84163211\n",
      "Iteration 33, loss = 0.86893095\n",
      "Iteration 34, loss = 0.86483071\n",
      "Iteration 35, loss = 0.85019640\n",
      "Iteration 36, loss = 0.81134248\n",
      "Iteration 37, loss = 0.86392677\n",
      "Iteration 38, loss = 0.83442340\n",
      "Iteration 39, loss = 0.84508168\n",
      "Iteration 40, loss = 0.85710120\n",
      "Iteration 41, loss = 0.86503971\n",
      "Iteration 42, loss = 0.82753666\n",
      "Iteration 43, loss = 0.81938740\n",
      "Iteration 44, loss = 0.82419386\n",
      "Iteration 45, loss = 0.78078114\n",
      "Iteration 46, loss = 0.83893966\n",
      "Iteration 47, loss = 0.81869941\n",
      "Iteration 48, loss = 0.79995135\n",
      "Iteration 49, loss = 0.78877359\n",
      "Iteration 50, loss = 0.79577437\n",
      "Iteration 1, loss = 1.17817981\n",
      "Iteration 2, loss = 1.07361478\n",
      "Iteration 3, loss = 0.97620908\n",
      "Iteration 4, loss = 1.02464114\n",
      "Iteration 5, loss = 0.98961322\n",
      "Iteration 6, loss = 0.96400761\n",
      "Iteration 7, loss = 0.94333784\n",
      "Iteration 8, loss = 0.96951576\n",
      "Iteration 9, loss = 0.96575045\n",
      "Iteration 10, loss = 0.95635195\n",
      "Iteration 11, loss = 0.94715871\n",
      "Iteration 12, loss = 0.94435906\n",
      "Iteration 48, loss = 0.79995135\n",
      "Iteration 49, loss = 0.78877359\n",
      "Iteration 50, loss = 0.79577437\n",
      "Iteration 1, loss = 1.17817981\n",
      "Iteration 2, loss = 1.07361478\n",
      "Iteration 3, loss = 0.97620908\n",
      "Iteration 4, loss = 1.02464114\n",
      "Iteration 5, loss = 0.98961322\n",
      "Iteration 6, loss = 0.96400761\n",
      "Iteration 7, loss = 0.94333784\n",
      "Iteration 8, loss = 0.96951576\n",
      "Iteration 9, loss = 0.96575045\n",
      "Iteration 10, loss = 0.95635195\n",
      "Iteration 11, loss = 0.94715871\n",
      "Iteration 12, loss = 0.94435906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.92742417\n",
      "Iteration 14, loss = 0.93558488\n",
      "Iteration 15, loss = 0.93126299\n",
      "Iteration 16, loss = 0.93238038\n",
      "Iteration 17, loss = 0.92275417\n",
      "Iteration 18, loss = 0.91849910\n",
      "Iteration 19, loss = 0.97252541\n",
      "Iteration 20, loss = 0.94851304\n",
      "Iteration 21, loss = 0.93442318\n",
      "Iteration 22, loss = 0.93378483\n",
      "Iteration 23, loss = 0.92200415\n",
      "Iteration 24, loss = 0.96982198\n",
      "Iteration 25, loss = 0.91355055\n",
      "Iteration 26, loss = 0.90166838\n",
      "Iteration 27, loss = 0.90996469\n",
      "Iteration 13, loss = 0.92742417\n",
      "Iteration 14, loss = 0.93558488\n",
      "Iteration 15, loss = 0.93126299\n",
      "Iteration 16, loss = 0.93238038\n",
      "Iteration 17, loss = 0.92275417\n",
      "Iteration 18, loss = 0.91849910\n",
      "Iteration 19, loss = 0.97252541\n",
      "Iteration 20, loss = 0.94851304\n",
      "Iteration 21, loss = 0.93442318\n",
      "Iteration 22, loss = 0.93378483\n",
      "Iteration 23, loss = 0.92200415\n",
      "Iteration 24, loss = 0.96982198\n",
      "Iteration 25, loss = 0.91355055\n",
      "Iteration 26, loss = 0.90166838\n",
      "Iteration 27, loss = 0.90996469\n",
      "Iteration 28, loss = 0.84462931\n",
      "Iteration 29, loss = 0.90432815\n",
      "Iteration 30, loss = 0.87222858\n",
      "Iteration 31, loss = 0.88268592\n",
      "Iteration 32, loss = 0.87013403\n",
      "Iteration 33, loss = 0.87872106\n",
      "Iteration 34, loss = 0.86393112\n",
      "Iteration 35, loss = 0.86654346\n",
      "Iteration 36, loss = 0.84025510\n",
      "Iteration 37, loss = 0.88075108\n",
      "Iteration 38, loss = 0.82374628\n",
      "Iteration 39, loss = 0.84721339\n",
      "Iteration 40, loss = 0.87909214\n",
      "Iteration 41, loss = 0.84137163\n",
      "Iteration 42, loss = 0.83053209\n",
      "Iteration 43, loss = 0.82126012\n",
      "Iteration 28, loss = 0.84462931\n",
      "Iteration 29, loss = 0.90432815\n",
      "Iteration 30, loss = 0.87222858\n",
      "Iteration 31, loss = 0.88268592\n",
      "Iteration 32, loss = 0.87013403\n",
      "Iteration 33, loss = 0.87872106\n",
      "Iteration 34, loss = 0.86393112\n",
      "Iteration 35, loss = 0.86654346\n",
      "Iteration 36, loss = 0.84025510\n",
      "Iteration 37, loss = 0.88075108\n",
      "Iteration 38, loss = 0.82374628\n",
      "Iteration 39, loss = 0.84721339\n",
      "Iteration 40, loss = 0.87909214\n",
      "Iteration 41, loss = 0.84137163\n",
      "Iteration 42, loss = 0.83053209\n",
      "Iteration 43, loss = 0.82126012\n",
      "Iteration 44, loss = 0.85904158\n",
      "Iteration 45, loss = 0.90435742\n",
      "Iteration 46, loss = 0.80033083\n",
      "Iteration 47, loss = 0.79606631\n",
      "Iteration 48, loss = 0.83434517\n",
      "Iteration 49, loss = 0.81648526\n",
      "Iteration 50, loss = 0.80917611\n",
      "Iteration 1, loss = 1.13436399\n",
      "Iteration 2, loss = 1.05391098\n",
      "Iteration 3, loss = 0.98806997\n",
      "Iteration 4, loss = 0.98340783\n",
      "Iteration 5, loss = 0.98651092\n",
      "Iteration 6, loss = 0.96685058\n",
      "Iteration 7, loss = 0.93336296\n",
      "Iteration 44, loss = 0.85904158\n",
      "Iteration 45, loss = 0.90435742\n",
      "Iteration 46, loss = 0.80033083\n",
      "Iteration 47, loss = 0.79606631\n",
      "Iteration 48, loss = 0.83434517\n",
      "Iteration 49, loss = 0.81648526\n",
      "Iteration 50, loss = 0.80917611\n",
      "Iteration 1, loss = 1.13436399\n",
      "Iteration 2, loss = 1.05391098\n",
      "Iteration 3, loss = 0.98806997\n",
      "Iteration 4, loss = 0.98340783\n",
      "Iteration 5, loss = 0.98651092\n",
      "Iteration 6, loss = 0.96685058\n",
      "Iteration 7, loss = 0.93336296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.92310846\n",
      "Iteration 9, loss = 0.94977203\n",
      "Iteration 10, loss = 0.93022094\n",
      "Iteration 11, loss = 0.91310338\n",
      "Iteration 12, loss = 0.91510304\n",
      "Iteration 13, loss = 0.90971946\n",
      "Iteration 14, loss = 0.93049847\n",
      "Iteration 15, loss = 0.89836925\n",
      "Iteration 16, loss = 0.93589264\n",
      "Iteration 17, loss = 0.89051990\n",
      "Iteration 18, loss = 0.92459436\n",
      "Iteration 19, loss = 0.92486624\n",
      "Iteration 20, loss = 0.88568354\n",
      "Iteration 21, loss = 0.85843979\n",
      "Iteration 22, loss = 0.84050241\n",
      "Iteration 8, loss = 0.92310846\n",
      "Iteration 9, loss = 0.94977203\n",
      "Iteration 10, loss = 0.93022094\n",
      "Iteration 11, loss = 0.91310338\n",
      "Iteration 12, loss = 0.91510304\n",
      "Iteration 13, loss = 0.90971946\n",
      "Iteration 14, loss = 0.93049847\n",
      "Iteration 15, loss = 0.89836925\n",
      "Iteration 16, loss = 0.93589264\n",
      "Iteration 17, loss = 0.89051990\n",
      "Iteration 18, loss = 0.92459436\n",
      "Iteration 19, loss = 0.92486624\n",
      "Iteration 20, loss = 0.88568354\n",
      "Iteration 21, loss = 0.85843979\n",
      "Iteration 22, loss = 0.84050241\n",
      "Iteration 23, loss = 0.86776316\n",
      "Iteration 24, loss = 0.86183773\n",
      "Iteration 25, loss = 0.85653507\n",
      "Iteration 26, loss = 0.86306677\n",
      "Iteration 27, loss = 0.84258112\n",
      "Iteration 28, loss = 0.81711920\n",
      "Iteration 29, loss = 0.84700220\n",
      "Iteration 30, loss = 0.85424588\n",
      "Iteration 31, loss = 0.84208396\n",
      "Iteration 32, loss = 0.85104951\n",
      "Iteration 33, loss = 0.79992088\n",
      "Iteration 34, loss = 0.82701021\n",
      "Iteration 35, loss = 0.83397426\n",
      "Iteration 36, loss = 0.80816810\n",
      "Iteration 37, loss = 0.81696771\n",
      "Iteration 38, loss = 0.81423441\n",
      "Iteration 23, loss = 0.86776316\n",
      "Iteration 24, loss = 0.86183773\n",
      "Iteration 25, loss = 0.85653507\n",
      "Iteration 26, loss = 0.86306677\n",
      "Iteration 27, loss = 0.84258112\n",
      "Iteration 28, loss = 0.81711920\n",
      "Iteration 29, loss = 0.84700220\n",
      "Iteration 30, loss = 0.85424588\n",
      "Iteration 31, loss = 0.84208396\n",
      "Iteration 32, loss = 0.85104951\n",
      "Iteration 33, loss = 0.79992088\n",
      "Iteration 34, loss = 0.82701021\n",
      "Iteration 35, loss = 0.83397426\n",
      "Iteration 36, loss = 0.80816810\n",
      "Iteration 37, loss = 0.81696771\n",
      "Iteration 38, loss = 0.81423441\n",
      "Iteration 39, loss = 0.79858502\n",
      "Iteration 40, loss = 0.81094055\n",
      "Iteration 41, loss = 0.82110858\n",
      "Iteration 42, loss = 0.81612409\n",
      "Iteration 43, loss = 0.81199023\n",
      "Iteration 44, loss = 0.78602589\n",
      "Iteration 45, loss = 0.79870906\n",
      "Iteration 46, loss = 0.80328889\n",
      "Iteration 47, loss = 0.81208543\n",
      "Iteration 48, loss = 0.80435298\n",
      "Iteration 49, loss = 0.77419209\n",
      "Iteration 50, loss = 0.78992141\n",
      "Iteration 1, loss = 1.16410388\n",
      "Iteration 2, loss = 1.06114253\n",
      "Iteration 3, loss = 1.01061821\n",
      "Iteration 39, loss = 0.79858502\n",
      "Iteration 40, loss = 0.81094055\n",
      "Iteration 41, loss = 0.82110858\n",
      "Iteration 42, loss = 0.81612409\n",
      "Iteration 43, loss = 0.81199023\n",
      "Iteration 44, loss = 0.78602589\n",
      "Iteration 45, loss = 0.79870906\n",
      "Iteration 46, loss = 0.80328889\n",
      "Iteration 47, loss = 0.81208543\n",
      "Iteration 48, loss = 0.80435298\n",
      "Iteration 49, loss = 0.77419209\n",
      "Iteration 50, loss = 0.78992141\n",
      "Iteration 1, loss = 1.16410388\n",
      "Iteration 2, loss = 1.06114253\n",
      "Iteration 3, loss = 1.01061821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.02601635\n",
      "Iteration 5, loss = 1.04910300\n",
      "Iteration 6, loss = 0.97278432\n",
      "Iteration 7, loss = 0.97380595\n",
      "Iteration 8, loss = 0.96100571\n",
      "Iteration 9, loss = 0.94673542\n",
      "Iteration 10, loss = 0.94236016\n",
      "Iteration 11, loss = 0.94222250\n",
      "Iteration 12, loss = 0.93229529\n",
      "Iteration 13, loss = 0.93077541\n",
      "Iteration 14, loss = 0.92286447\n",
      "Iteration 15, loss = 0.95489516\n",
      "Iteration 16, loss = 0.92448655\n",
      "Iteration 4, loss = 1.02601635\n",
      "Iteration 5, loss = 1.04910300\n",
      "Iteration 6, loss = 0.97278432\n",
      "Iteration 7, loss = 0.97380595\n",
      "Iteration 8, loss = 0.96100571\n",
      "Iteration 9, loss = 0.94673542\n",
      "Iteration 10, loss = 0.94236016\n",
      "Iteration 11, loss = 0.94222250\n",
      "Iteration 12, loss = 0.93229529\n",
      "Iteration 13, loss = 0.93077541\n",
      "Iteration 14, loss = 0.92286447\n",
      "Iteration 15, loss = 0.95489516\n",
      "Iteration 16, loss = 0.92448655\n",
      "Iteration 17, loss = 0.94946780\n",
      "Iteration 18, loss = 0.93563753\n",
      "Iteration 19, loss = 0.91134569\n",
      "Iteration 20, loss = 0.92192969\n",
      "Iteration 21, loss = 0.91699956\n",
      "Iteration 22, loss = 0.91465815\n",
      "Iteration 23, loss = 0.92312625\n",
      "Iteration 24, loss = 0.89700223\n",
      "Iteration 25, loss = 0.89169353\n",
      "Iteration 26, loss = 0.85963902\n",
      "Iteration 27, loss = 0.86134580\n",
      "Iteration 28, loss = 0.85766478\n",
      "Iteration 29, loss = 0.89748491\n",
      "Iteration 30, loss = 0.92599505\n",
      "Iteration 31, loss = 0.88380923\n",
      "Iteration 17, loss = 0.94946780\n",
      "Iteration 18, loss = 0.93563753\n",
      "Iteration 19, loss = 0.91134569\n",
      "Iteration 20, loss = 0.92192969\n",
      "Iteration 21, loss = 0.91699956\n",
      "Iteration 22, loss = 0.91465815\n",
      "Iteration 23, loss = 0.92312625\n",
      "Iteration 24, loss = 0.89700223\n",
      "Iteration 25, loss = 0.89169353\n",
      "Iteration 26, loss = 0.85963902\n",
      "Iteration 27, loss = 0.86134580\n",
      "Iteration 28, loss = 0.85766478\n",
      "Iteration 29, loss = 0.89748491\n",
      "Iteration 30, loss = 0.92599505\n",
      "Iteration 31, loss = 0.88380923\n",
      "Iteration 32, loss = 0.88111137\n",
      "Iteration 33, loss = 0.88089058\n",
      "Iteration 34, loss = 0.85019896\n",
      "Iteration 35, loss = 0.87532924\n",
      "Iteration 36, loss = 0.86862611\n",
      "Iteration 37, loss = 0.84883465\n",
      "Iteration 38, loss = 0.86422922\n",
      "Iteration 39, loss = 0.82089319\n",
      "Iteration 40, loss = 0.81620826\n",
      "Iteration 41, loss = 0.86119579\n",
      "Iteration 42, loss = 0.82668287\n",
      "Iteration 43, loss = 0.82325855\n",
      "Iteration 32, loss = 0.88111137\n",
      "Iteration 33, loss = 0.88089058\n",
      "Iteration 34, loss = 0.85019896\n",
      "Iteration 35, loss = 0.87532924\n",
      "Iteration 36, loss = 0.86862611\n",
      "Iteration 37, loss = 0.84883465\n",
      "Iteration 38, loss = 0.86422922\n",
      "Iteration 39, loss = 0.82089319\n",
      "Iteration 40, loss = 0.81620826\n",
      "Iteration 41, loss = 0.86119579\n",
      "Iteration 42, loss = 0.82668287\n",
      "Iteration 43, loss = 0.82325855\n",
      "Iteration 44, loss = 0.82893595\n",
      "Iteration 45, loss = 0.85322309\n",
      "Iteration 46, loss = 0.80849816\n",
      "Iteration 47, loss = 0.81763773\n",
      "Iteration 48, loss = 0.84217291\n",
      "Iteration 49, loss = 0.79727964\n",
      "Iteration 50, loss = 0.78436016\n",
      "Iteration 51, loss = 0.86067645\n",
      "Iteration 52, loss = 0.80297574\n",
      "Iteration 53, loss = 0.78587136\n",
      "Iteration 54, loss = 0.76609035\n",
      "Iteration 55, loss = 0.76485823\n",
      "Iteration 56, loss = 0.78149427\n",
      "Iteration 57, loss = 0.77468693\n",
      "Iteration 58, loss = 0.78014407\n",
      "Iteration 44, loss = 0.82893595\n",
      "Iteration 45, loss = 0.85322309\n",
      "Iteration 46, loss = 0.80849816\n",
      "Iteration 47, loss = 0.81763773\n",
      "Iteration 48, loss = 0.84217291\n",
      "Iteration 49, loss = 0.79727964\n",
      "Iteration 50, loss = 0.78436016\n",
      "Iteration 51, loss = 0.86067645\n",
      "Iteration 52, loss = 0.80297574\n",
      "Iteration 53, loss = 0.78587136\n",
      "Iteration 54, loss = 0.76609035\n",
      "Iteration 55, loss = 0.76485823\n",
      "Iteration 56, loss = 0.78149427\n",
      "Iteration 57, loss = 0.77468693\n",
      "Iteration 58, loss = 0.78014407\n",
      "Iteration 59, loss = 0.77816139\n",
      "Iteration 60, loss = 0.75038206\n",
      "Iteration 61, loss = 0.76307916\n",
      "Iteration 62, loss = 0.82266588\n",
      "Iteration 63, loss = 0.72909047\n",
      "Iteration 64, loss = 0.77651414\n",
      "Iteration 65, loss = 0.77218573\n",
      "Iteration 66, loss = 0.72739938\n",
      "Iteration 67, loss = 0.77235972\n",
      "Iteration 68, loss = 0.74121556\n",
      "Iteration 69, loss = 0.70283470\n",
      "Iteration 70, loss = 0.71604464\n",
      "Iteration 71, loss = 0.70646919\n",
      "Iteration 72, loss = 0.68848162\n",
      "Iteration 73, loss = 0.69198501\n",
      "Iteration 59, loss = 0.77816139\n",
      "Iteration 60, loss = 0.75038206\n",
      "Iteration 61, loss = 0.76307916\n",
      "Iteration 62, loss = 0.82266588\n",
      "Iteration 63, loss = 0.72909047\n",
      "Iteration 64, loss = 0.77651414\n",
      "Iteration 65, loss = 0.77218573\n",
      "Iteration 66, loss = 0.72739938\n",
      "Iteration 67, loss = 0.77235972\n",
      "Iteration 68, loss = 0.74121556\n",
      "Iteration 69, loss = 0.70283470\n",
      "Iteration 70, loss = 0.71604464\n",
      "Iteration 71, loss = 0.70646919\n",
      "Iteration 72, loss = 0.68848162\n",
      "Iteration 73, loss = 0.69198501\n",
      "Iteration 74, loss = 0.68439361\n",
      "Iteration 75, loss = 0.70173707\n",
      "Iteration 76, loss = 0.71274352\n",
      "Iteration 77, loss = 0.74963746\n",
      "Iteration 78, loss = 0.71241195\n",
      "Iteration 79, loss = 0.75328499\n",
      "Iteration 80, loss = 0.78258573\n",
      "Iteration 81, loss = 0.85005577\n",
      "Iteration 82, loss = 0.76931426\n",
      "Iteration 83, loss = 0.79532677\n",
      "Iteration 84, loss = 0.69271569\n",
      "Iteration 85, loss = 0.66914182\n",
      "Iteration 86, loss = 0.69103889\n",
      "Iteration 87, loss = 0.70374008\n",
      "Iteration 88, loss = 0.69440889\n",
      "Iteration 89, loss = 0.70882539\n",
      "Iteration 74, loss = 0.68439361\n",
      "Iteration 75, loss = 0.70173707\n",
      "Iteration 76, loss = 0.71274352\n",
      "Iteration 77, loss = 0.74963746\n",
      "Iteration 78, loss = 0.71241195\n",
      "Iteration 79, loss = 0.75328499\n",
      "Iteration 80, loss = 0.78258573\n",
      "Iteration 81, loss = 0.85005577\n",
      "Iteration 82, loss = 0.76931426\n",
      "Iteration 83, loss = 0.79532677\n",
      "Iteration 84, loss = 0.69271569\n",
      "Iteration 85, loss = 0.66914182\n",
      "Iteration 86, loss = 0.69103889\n",
      "Iteration 87, loss = 0.70374008\n",
      "Iteration 88, loss = 0.69440889\n",
      "Iteration 89, loss = 0.70882539\n",
      "Iteration 90, loss = 0.72487018\n",
      "Iteration 91, loss = 0.67871947\n",
      "Iteration 92, loss = 0.72501497\n",
      "Iteration 93, loss = 0.66835452\n",
      "Iteration 94, loss = 0.65840133\n",
      "Iteration 95, loss = 0.66927670\n",
      "Iteration 96, loss = 0.67073869\n",
      "Iteration 97, loss = 0.64975079\n",
      "Iteration 98, loss = 0.69882133\n",
      "Iteration 99, loss = 0.66722999\n",
      "Iteration 100, loss = 0.67593148\n",
      "Iteration 1, loss = 1.11852002\n",
      "Iteration 2, loss = 0.98596141\n",
      "Iteration 3, loss = 0.95955027\n",
      "Iteration 4, loss = 0.96344175\n",
      "Iteration 90, loss = 0.72487018\n",
      "Iteration 91, loss = 0.67871947\n",
      "Iteration 92, loss = 0.72501497\n",
      "Iteration 93, loss = 0.66835452\n",
      "Iteration 94, loss = 0.65840133\n",
      "Iteration 95, loss = 0.66927670\n",
      "Iteration 96, loss = 0.67073869\n",
      "Iteration 97, loss = 0.64975079\n",
      "Iteration 98, loss = 0.69882133\n",
      "Iteration 99, loss = 0.66722999\n",
      "Iteration 100, loss = 0.67593148\n",
      "Iteration 1, loss = 1.11852002\n",
      "Iteration 2, loss = 0.98596141\n",
      "Iteration 3, loss = 0.95955027\n",
      "Iteration 4, loss = 0.96344175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.92190924\n",
      "Iteration 6, loss = 0.90022669\n",
      "Iteration 7, loss = 0.93739151\n",
      "Iteration 8, loss = 0.92227794\n",
      "Iteration 9, loss = 0.91761736\n",
      "Iteration 10, loss = 0.92621622\n",
      "Iteration 11, loss = 0.88992243\n",
      "Iteration 12, loss = 0.88400040\n",
      "Iteration 13, loss = 0.89525258\n",
      "Iteration 14, loss = 0.88867076\n",
      "Iteration 15, loss = 0.86885409\n",
      "Iteration 16, loss = 0.87830541\n",
      "Iteration 17, loss = 0.86183337\n",
      "Iteration 18, loss = 0.86483089\n",
      "Iteration 5, loss = 0.92190924\n",
      "Iteration 6, loss = 0.90022669\n",
      "Iteration 7, loss = 0.93739151\n",
      "Iteration 8, loss = 0.92227794\n",
      "Iteration 9, loss = 0.91761736\n",
      "Iteration 10, loss = 0.92621622\n",
      "Iteration 11, loss = 0.88992243\n",
      "Iteration 12, loss = 0.88400040\n",
      "Iteration 13, loss = 0.89525258\n",
      "Iteration 14, loss = 0.88867076\n",
      "Iteration 15, loss = 0.86885409\n",
      "Iteration 16, loss = 0.87830541\n",
      "Iteration 17, loss = 0.86183337\n",
      "Iteration 18, loss = 0.86483089\n",
      "Iteration 19, loss = 0.88216069\n",
      "Iteration 20, loss = 0.84795519\n",
      "Iteration 21, loss = 0.86328018\n",
      "Iteration 22, loss = 0.86978759\n",
      "Iteration 23, loss = 0.87222890\n",
      "Iteration 24, loss = 0.84329702\n",
      "Iteration 25, loss = 0.81342835\n",
      "Iteration 26, loss = 0.80934165\n",
      "Iteration 27, loss = 0.80203141\n",
      "Iteration 28, loss = 0.79633928\n",
      "Iteration 29, loss = 0.84388916\n",
      "Iteration 30, loss = 0.80737998\n",
      "Iteration 31, loss = 0.78234657\n",
      "Iteration 32, loss = 0.80695889\n",
      "Iteration 33, loss = 0.81985477\n",
      "Iteration 19, loss = 0.88216069\n",
      "Iteration 20, loss = 0.84795519\n",
      "Iteration 21, loss = 0.86328018\n",
      "Iteration 22, loss = 0.86978759\n",
      "Iteration 23, loss = 0.87222890\n",
      "Iteration 24, loss = 0.84329702\n",
      "Iteration 25, loss = 0.81342835\n",
      "Iteration 26, loss = 0.80934165\n",
      "Iteration 27, loss = 0.80203141\n",
      "Iteration 28, loss = 0.79633928\n",
      "Iteration 29, loss = 0.84388916\n",
      "Iteration 30, loss = 0.80737998\n",
      "Iteration 31, loss = 0.78234657\n",
      "Iteration 32, loss = 0.80695889\n",
      "Iteration 33, loss = 0.81985477\n",
      "Iteration 34, loss = 0.75837975\n",
      "Iteration 35, loss = 0.80105094\n",
      "Iteration 36, loss = 0.78620175\n",
      "Iteration 37, loss = 0.78974450\n",
      "Iteration 38, loss = 0.77457732\n",
      "Iteration 39, loss = 0.77635957\n",
      "Iteration 40, loss = 0.78111787\n",
      "Iteration 41, loss = 0.76613834\n",
      "Iteration 42, loss = 0.75359444\n",
      "Iteration 43, loss = 0.76211508\n",
      "Iteration 44, loss = 0.75346839\n",
      "Iteration 45, loss = 0.76734827\n",
      "Iteration 46, loss = 0.70927197\n",
      "Iteration 47, loss = 0.72335636\n",
      "Iteration 48, loss = 0.75028555\n",
      "Iteration 49, loss = 0.74504244\n",
      "Iteration 34, loss = 0.75837975\n",
      "Iteration 35, loss = 0.80105094\n",
      "Iteration 36, loss = 0.78620175\n",
      "Iteration 37, loss = 0.78974450\n",
      "Iteration 38, loss = 0.77457732\n",
      "Iteration 39, loss = 0.77635957\n",
      "Iteration 40, loss = 0.78111787\n",
      "Iteration 41, loss = 0.76613834\n",
      "Iteration 42, loss = 0.75359444\n",
      "Iteration 43, loss = 0.76211508\n",
      "Iteration 44, loss = 0.75346839\n",
      "Iteration 45, loss = 0.76734827\n",
      "Iteration 46, loss = 0.70927197\n",
      "Iteration 47, loss = 0.72335636\n",
      "Iteration 48, loss = 0.75028555\n",
      "Iteration 49, loss = 0.74504244\n",
      "Iteration 50, loss = 0.76293598\n",
      "Iteration 51, loss = 0.72871712\n",
      "Iteration 52, loss = 0.75739794\n",
      "Iteration 53, loss = 0.71509969\n",
      "Iteration 54, loss = 0.74810969\n",
      "Iteration 55, loss = 0.69860097\n",
      "Iteration 56, loss = 0.73127877\n",
      "Iteration 57, loss = 0.67683133\n",
      "Iteration 58, loss = 0.69849542\n",
      "Iteration 59, loss = 0.73741831\n",
      "Iteration 60, loss = 0.73272826\n",
      "Iteration 61, loss = 0.73381022\n",
      "Iteration 62, loss = 0.73701750\n",
      "Iteration 63, loss = 0.70416602\n",
      "Iteration 64, loss = 0.72726090\n",
      "Iteration 65, loss = 0.75124833\n",
      "Iteration 50, loss = 0.76293598\n",
      "Iteration 51, loss = 0.72871712\n",
      "Iteration 52, loss = 0.75739794\n",
      "Iteration 53, loss = 0.71509969\n",
      "Iteration 54, loss = 0.74810969\n",
      "Iteration 55, loss = 0.69860097\n",
      "Iteration 56, loss = 0.73127877\n",
      "Iteration 57, loss = 0.67683133\n",
      "Iteration 58, loss = 0.69849542\n",
      "Iteration 59, loss = 0.73741831\n",
      "Iteration 60, loss = 0.73272826\n",
      "Iteration 61, loss = 0.73381022\n",
      "Iteration 62, loss = 0.73701750\n",
      "Iteration 63, loss = 0.70416602\n",
      "Iteration 64, loss = 0.72726090\n",
      "Iteration 65, loss = 0.75124833\n",
      "Iteration 66, loss = 0.73015121\n",
      "Iteration 67, loss = 0.72041188\n",
      "Iteration 68, loss = 0.70759391\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15282747\n",
      "Iteration 2, loss = 1.05116399\n",
      "Iteration 3, loss = 0.95739551\n",
      "Iteration 4, loss = 0.97904131\n",
      "Iteration 5, loss = 0.96320164\n",
      "Iteration 6, loss = 0.94506776\n",
      "Iteration 7, loss = 0.93990902\n",
      "Iteration 8, loss = 0.95559461\n",
      "Iteration 9, loss = 0.94622936\n",
      "Iteration 10, loss = 0.93620885\n",
      "Iteration 66, loss = 0.73015121\n",
      "Iteration 67, loss = 0.72041188\n",
      "Iteration 68, loss = 0.70759391\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15282747\n",
      "Iteration 2, loss = 1.05116399\n",
      "Iteration 3, loss = 0.95739551\n",
      "Iteration 4, loss = 0.97904131\n",
      "Iteration 5, loss = 0.96320164\n",
      "Iteration 6, loss = 0.94506776\n",
      "Iteration 7, loss = 0.93990902\n",
      "Iteration 8, loss = 0.95559461\n",
      "Iteration 9, loss = 0.94622936\n",
      "Iteration 10, loss = 0.93620885\n",
      "Iteration 11, loss = 0.91285747\n",
      "Iteration 12, loss = 0.91853185\n",
      "Iteration 13, loss = 0.92865132\n",
      "Iteration 14, loss = 0.90332673\n",
      "Iteration 15, loss = 0.90622590\n",
      "Iteration 16, loss = 0.90096007\n",
      "Iteration 17, loss = 0.90909097\n",
      "Iteration 18, loss = 0.90740694\n",
      "Iteration 19, loss = 0.92381015\n",
      "Iteration 20, loss = 0.89483089\n",
      "Iteration 21, loss = 0.90622651\n",
      "Iteration 22, loss = 0.88792344\n",
      "Iteration 23, loss = 0.90129836\n",
      "Iteration 24, loss = 0.90662706\n",
      "Iteration 25, loss = 0.88416970\n",
      "Iteration 11, loss = 0.91285747\n",
      "Iteration 12, loss = 0.91853185\n",
      "Iteration 13, loss = 0.92865132\n",
      "Iteration 14, loss = 0.90332673\n",
      "Iteration 15, loss = 0.90622590\n",
      "Iteration 16, loss = 0.90096007\n",
      "Iteration 17, loss = 0.90909097\n",
      "Iteration 18, loss = 0.90740694\n",
      "Iteration 19, loss = 0.92381015\n",
      "Iteration 20, loss = 0.89483089\n",
      "Iteration 21, loss = 0.90622651\n",
      "Iteration 22, loss = 0.88792344\n",
      "Iteration 23, loss = 0.90129836\n",
      "Iteration 24, loss = 0.90662706\n",
      "Iteration 25, loss = 0.88416970\n",
      "Iteration 26, loss = 0.87226938\n",
      "Iteration 27, loss = 0.87406850\n",
      "Iteration 28, loss = 0.85219204\n",
      "Iteration 29, loss = 0.86470089\n",
      "Iteration 30, loss = 0.85099344\n",
      "Iteration 31, loss = 0.87894463\n",
      "Iteration 32, loss = 0.84163211\n",
      "Iteration 33, loss = 0.86893095\n",
      "Iteration 34, loss = 0.86483071\n",
      "Iteration 35, loss = 0.85019640\n",
      "Iteration 36, loss = 0.81134248\n",
      "Iteration 37, loss = 0.86392677\n",
      "Iteration 38, loss = 0.83442340\n",
      "Iteration 39, loss = 0.84508168\n",
      "Iteration 40, loss = 0.85710120\n",
      "Iteration 41, loss = 0.86503971\n",
      "Iteration 26, loss = 0.87226938\n",
      "Iteration 27, loss = 0.87406850\n",
      "Iteration 28, loss = 0.85219204\n",
      "Iteration 29, loss = 0.86470089\n",
      "Iteration 30, loss = 0.85099344\n",
      "Iteration 31, loss = 0.87894463\n",
      "Iteration 32, loss = 0.84163211\n",
      "Iteration 33, loss = 0.86893095\n",
      "Iteration 34, loss = 0.86483071\n",
      "Iteration 35, loss = 0.85019640\n",
      "Iteration 36, loss = 0.81134248\n",
      "Iteration 37, loss = 0.86392677\n",
      "Iteration 38, loss = 0.83442340\n",
      "Iteration 39, loss = 0.84508168\n",
      "Iteration 40, loss = 0.85710120\n",
      "Iteration 41, loss = 0.86503971\n",
      "Iteration 42, loss = 0.82753666\n",
      "Iteration 43, loss = 0.81938740\n",
      "Iteration 44, loss = 0.82419386\n",
      "Iteration 45, loss = 0.78078114\n",
      "Iteration 46, loss = 0.83893966\n",
      "Iteration 47, loss = 0.81869941\n",
      "Iteration 48, loss = 0.79995135\n",
      "Iteration 49, loss = 0.78877359\n",
      "Iteration 50, loss = 0.79577437\n",
      "Iteration 51, loss = 0.77279764\n",
      "Iteration 52, loss = 0.80572937\n",
      "Iteration 53, loss = 0.81063464\n",
      "Iteration 54, loss = 0.77415210\n",
      "Iteration 55, loss = 0.78027947\n",
      "Iteration 56, loss = 0.74165206\n",
      "Iteration 42, loss = 0.82753666\n",
      "Iteration 43, loss = 0.81938740\n",
      "Iteration 44, loss = 0.82419386\n",
      "Iteration 45, loss = 0.78078114\n",
      "Iteration 46, loss = 0.83893966\n",
      "Iteration 47, loss = 0.81869941\n",
      "Iteration 48, loss = 0.79995135\n",
      "Iteration 49, loss = 0.78877359\n",
      "Iteration 50, loss = 0.79577437\n",
      "Iteration 51, loss = 0.77279764\n",
      "Iteration 52, loss = 0.80572937\n",
      "Iteration 53, loss = 0.81063464\n",
      "Iteration 54, loss = 0.77415210\n",
      "Iteration 55, loss = 0.78027947\n",
      "Iteration 56, loss = 0.74165206\n",
      "Iteration 57, loss = 0.81629980\n",
      "Iteration 58, loss = 0.76887902\n",
      "Iteration 59, loss = 0.76067064\n",
      "Iteration 60, loss = 0.78917783\n",
      "Iteration 61, loss = 0.84860761\n",
      "Iteration 62, loss = 0.82492470\n",
      "Iteration 63, loss = 0.79360943\n",
      "Iteration 64, loss = 0.78639760\n",
      "Iteration 65, loss = 0.78159792\n",
      "Iteration 66, loss = 0.77605955\n",
      "Iteration 67, loss = 0.81450815\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17817981\n",
      "Iteration 2, loss = 1.07361478\n",
      "Iteration 3, loss = 0.97620908\n",
      "Iteration 57, loss = 0.81629980\n",
      "Iteration 58, loss = 0.76887902\n",
      "Iteration 59, loss = 0.76067064\n",
      "Iteration 60, loss = 0.78917783\n",
      "Iteration 61, loss = 0.84860761\n",
      "Iteration 62, loss = 0.82492470\n",
      "Iteration 63, loss = 0.79360943\n",
      "Iteration 64, loss = 0.78639760\n",
      "Iteration 65, loss = 0.78159792\n",
      "Iteration 66, loss = 0.77605955\n",
      "Iteration 67, loss = 0.81450815\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17817981\n",
      "Iteration 2, loss = 1.07361478\n",
      "Iteration 3, loss = 0.97620908\n",
      "Iteration 4, loss = 1.02464114\n",
      "Iteration 5, loss = 0.98961322\n",
      "Iteration 6, loss = 0.96400761\n",
      "Iteration 7, loss = 0.94333784\n",
      "Iteration 8, loss = 0.96951576\n",
      "Iteration 9, loss = 0.96575045\n",
      "Iteration 10, loss = 0.95635195\n",
      "Iteration 11, loss = 0.94715871\n",
      "Iteration 12, loss = 0.94435906\n",
      "Iteration 13, loss = 0.92742417\n",
      "Iteration 14, loss = 0.93558488\n",
      "Iteration 15, loss = 0.93126299\n",
      "Iteration 16, loss = 0.93238038\n",
      "Iteration 17, loss = 0.92275417\n",
      "Iteration 4, loss = 1.02464114\n",
      "Iteration 5, loss = 0.98961322\n",
      "Iteration 6, loss = 0.96400761\n",
      "Iteration 7, loss = 0.94333784\n",
      "Iteration 8, loss = 0.96951576\n",
      "Iteration 9, loss = 0.96575045\n",
      "Iteration 10, loss = 0.95635195\n",
      "Iteration 11, loss = 0.94715871\n",
      "Iteration 12, loss = 0.94435906\n",
      "Iteration 13, loss = 0.92742417\n",
      "Iteration 14, loss = 0.93558488\n",
      "Iteration 15, loss = 0.93126299\n",
      "Iteration 16, loss = 0.93238038\n",
      "Iteration 17, loss = 0.92275417\n",
      "Iteration 18, loss = 0.91849910\n",
      "Iteration 19, loss = 0.97252541\n",
      "Iteration 20, loss = 0.94851304\n",
      "Iteration 21, loss = 0.93442318\n",
      "Iteration 22, loss = 0.93378483\n",
      "Iteration 23, loss = 0.92200415\n",
      "Iteration 24, loss = 0.96982198\n",
      "Iteration 25, loss = 0.91355055\n",
      "Iteration 26, loss = 0.90166838\n",
      "Iteration 27, loss = 0.90996469\n",
      "Iteration 28, loss = 0.84462931\n",
      "Iteration 29, loss = 0.90432815\n",
      "Iteration 30, loss = 0.87222858\n",
      "Iteration 31, loss = 0.88268592\n",
      "Iteration 32, loss = 0.87013403\n",
      "Iteration 33, loss = 0.87872106\n",
      "Iteration 18, loss = 0.91849910\n",
      "Iteration 19, loss = 0.97252541\n",
      "Iteration 20, loss = 0.94851304\n",
      "Iteration 21, loss = 0.93442318\n",
      "Iteration 22, loss = 0.93378483\n",
      "Iteration 23, loss = 0.92200415\n",
      "Iteration 24, loss = 0.96982198\n",
      "Iteration 25, loss = 0.91355055\n",
      "Iteration 26, loss = 0.90166838\n",
      "Iteration 27, loss = 0.90996469\n",
      "Iteration 28, loss = 0.84462931\n",
      "Iteration 29, loss = 0.90432815\n",
      "Iteration 30, loss = 0.87222858\n",
      "Iteration 31, loss = 0.88268592\n",
      "Iteration 32, loss = 0.87013403\n",
      "Iteration 33, loss = 0.87872106\n",
      "Iteration 34, loss = 0.86393112\n",
      "Iteration 35, loss = 0.86654346\n",
      "Iteration 36, loss = 0.84025510\n",
      "Iteration 37, loss = 0.88075108\n",
      "Iteration 38, loss = 0.82374628\n",
      "Iteration 39, loss = 0.84721339\n",
      "Iteration 40, loss = 0.87909214\n",
      "Iteration 41, loss = 0.84137163\n",
      "Iteration 42, loss = 0.83053209\n",
      "Iteration 43, loss = 0.82126012\n",
      "Iteration 44, loss = 0.85904158\n",
      "Iteration 45, loss = 0.90435742\n",
      "Iteration 46, loss = 0.80033083\n",
      "Iteration 47, loss = 0.79606631\n",
      "Iteration 48, loss = 0.83434517\n",
      "Iteration 49, loss = 0.81648526\n",
      "Iteration 34, loss = 0.86393112\n",
      "Iteration 35, loss = 0.86654346\n",
      "Iteration 36, loss = 0.84025510\n",
      "Iteration 37, loss = 0.88075108\n",
      "Iteration 38, loss = 0.82374628\n",
      "Iteration 39, loss = 0.84721339\n",
      "Iteration 40, loss = 0.87909214\n",
      "Iteration 41, loss = 0.84137163\n",
      "Iteration 42, loss = 0.83053209\n",
      "Iteration 43, loss = 0.82126012\n",
      "Iteration 44, loss = 0.85904158\n",
      "Iteration 45, loss = 0.90435742\n",
      "Iteration 46, loss = 0.80033083\n",
      "Iteration 47, loss = 0.79606631\n",
      "Iteration 48, loss = 0.83434517\n",
      "Iteration 49, loss = 0.81648526\n",
      "Iteration 50, loss = 0.80917611\n",
      "Iteration 51, loss = 0.80069034\n",
      "Iteration 52, loss = 0.84040553\n",
      "Iteration 53, loss = 0.82384710\n",
      "Iteration 54, loss = 0.81257655\n",
      "Iteration 55, loss = 0.77606486\n",
      "Iteration 56, loss = 0.84033823\n",
      "Iteration 57, loss = 0.81536479\n",
      "Iteration 58, loss = 0.80746656\n",
      "Iteration 59, loss = 0.79681702\n",
      "Iteration 60, loss = 0.79629237\n",
      "Iteration 61, loss = 0.78211953\n",
      "Iteration 62, loss = 0.78764209\n",
      "Iteration 63, loss = 0.78911986\n",
      "Iteration 64, loss = 0.77012763\n",
      "Iteration 65, loss = 0.78962933\n",
      "Iteration 50, loss = 0.80917611\n",
      "Iteration 51, loss = 0.80069034\n",
      "Iteration 52, loss = 0.84040553\n",
      "Iteration 53, loss = 0.82384710\n",
      "Iteration 54, loss = 0.81257655\n",
      "Iteration 55, loss = 0.77606486\n",
      "Iteration 56, loss = 0.84033823\n",
      "Iteration 57, loss = 0.81536479\n",
      "Iteration 58, loss = 0.80746656\n",
      "Iteration 59, loss = 0.79681702\n",
      "Iteration 60, loss = 0.79629237\n",
      "Iteration 61, loss = 0.78211953\n",
      "Iteration 62, loss = 0.78764209\n",
      "Iteration 63, loss = 0.78911986\n",
      "Iteration 64, loss = 0.77012763\n",
      "Iteration 65, loss = 0.78962933\n",
      "Iteration 66, loss = 0.78813601\n",
      "Iteration 67, loss = 0.82610718\n",
      "Iteration 68, loss = 0.82254119\n",
      "Iteration 69, loss = 0.75336509\n",
      "Iteration 70, loss = 0.80862133\n",
      "Iteration 71, loss = 0.79193513\n",
      "Iteration 72, loss = 0.80720626\n",
      "Iteration 73, loss = 0.78052329\n",
      "Iteration 74, loss = 0.79640408\n",
      "Iteration 75, loss = 0.81884921\n",
      "Iteration 76, loss = 0.76271990\n",
      "Iteration 77, loss = 0.75179037\n",
      "Iteration 78, loss = 0.72927987\n",
      "Iteration 79, loss = 0.72809692\n",
      "Iteration 80, loss = 0.73497484\n",
      "Iteration 81, loss = 0.78659313\n",
      "Iteration 66, loss = 0.78813601\n",
      "Iteration 67, loss = 0.82610718\n",
      "Iteration 68, loss = 0.82254119\n",
      "Iteration 69, loss = 0.75336509\n",
      "Iteration 70, loss = 0.80862133\n",
      "Iteration 71, loss = 0.79193513\n",
      "Iteration 72, loss = 0.80720626\n",
      "Iteration 73, loss = 0.78052329\n",
      "Iteration 74, loss = 0.79640408\n",
      "Iteration 75, loss = 0.81884921\n",
      "Iteration 76, loss = 0.76271990\n",
      "Iteration 77, loss = 0.75179037\n",
      "Iteration 78, loss = 0.72927987\n",
      "Iteration 79, loss = 0.72809692\n",
      "Iteration 80, loss = 0.73497484\n",
      "Iteration 81, loss = 0.78659313\n",
      "Iteration 82, loss = 0.77440364\n",
      "Iteration 83, loss = 0.81455245\n",
      "Iteration 84, loss = 0.74059969\n",
      "Iteration 85, loss = 0.74387739\n",
      "Iteration 86, loss = 0.73844179\n",
      "Iteration 87, loss = 0.75203510\n",
      "Iteration 88, loss = 0.74237936\n",
      "Iteration 89, loss = 0.74218513\n",
      "Iteration 90, loss = 0.79056572\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13436399\n",
      "Iteration 2, loss = 1.05391098\n",
      "Iteration 3, loss = 0.98806997\n",
      "Iteration 82, loss = 0.77440364\n",
      "Iteration 83, loss = 0.81455245\n",
      "Iteration 84, loss = 0.74059969\n",
      "Iteration 85, loss = 0.74387739\n",
      "Iteration 86, loss = 0.73844179\n",
      "Iteration 87, loss = 0.75203510\n",
      "Iteration 88, loss = 0.74237936\n",
      "Iteration 89, loss = 0.74218513\n",
      "Iteration 90, loss = 0.79056572\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13436399\n",
      "Iteration 2, loss = 1.05391098\n",
      "Iteration 3, loss = 0.98806997\n",
      "Iteration 4, loss = 0.98340783\n",
      "Iteration 5, loss = 0.98651092\n",
      "Iteration 6, loss = 0.96685058\n",
      "Iteration 7, loss = 0.93336296\n",
      "Iteration 8, loss = 0.92310846\n",
      "Iteration 9, loss = 0.94977203\n",
      "Iteration 10, loss = 0.93022094\n",
      "Iteration 11, loss = 0.91310338\n",
      "Iteration 12, loss = 0.91510304\n",
      "Iteration 13, loss = 0.90971946\n",
      "Iteration 14, loss = 0.93049847\n",
      "Iteration 15, loss = 0.89836925\n",
      "Iteration 16, loss = 0.93589264\n",
      "Iteration 17, loss = 0.89051990\n",
      "Iteration 4, loss = 0.98340783\n",
      "Iteration 5, loss = 0.98651092\n",
      "Iteration 6, loss = 0.96685058\n",
      "Iteration 7, loss = 0.93336296\n",
      "Iteration 8, loss = 0.92310846\n",
      "Iteration 9, loss = 0.94977203\n",
      "Iteration 10, loss = 0.93022094\n",
      "Iteration 11, loss = 0.91310338\n",
      "Iteration 12, loss = 0.91510304\n",
      "Iteration 13, loss = 0.90971946\n",
      "Iteration 14, loss = 0.93049847\n",
      "Iteration 15, loss = 0.89836925\n",
      "Iteration 16, loss = 0.93589264\n",
      "Iteration 17, loss = 0.89051990\n",
      "Iteration 18, loss = 0.92459436\n",
      "Iteration 19, loss = 0.92486624\n",
      "Iteration 20, loss = 0.88568354\n",
      "Iteration 21, loss = 0.85843979\n",
      "Iteration 22, loss = 0.84050241\n",
      "Iteration 23, loss = 0.86776316\n",
      "Iteration 24, loss = 0.86183773\n",
      "Iteration 25, loss = 0.85653507\n",
      "Iteration 26, loss = 0.86306677\n",
      "Iteration 27, loss = 0.84258112\n",
      "Iteration 28, loss = 0.81711920\n",
      "Iteration 29, loss = 0.84700220\n",
      "Iteration 30, loss = 0.85424588\n",
      "Iteration 31, loss = 0.84208396\n",
      "Iteration 32, loss = 0.85104951\n",
      "Iteration 18, loss = 0.92459436\n",
      "Iteration 19, loss = 0.92486624\n",
      "Iteration 20, loss = 0.88568354\n",
      "Iteration 21, loss = 0.85843979\n",
      "Iteration 22, loss = 0.84050241\n",
      "Iteration 23, loss = 0.86776316\n",
      "Iteration 24, loss = 0.86183773\n",
      "Iteration 25, loss = 0.85653507\n",
      "Iteration 26, loss = 0.86306677\n",
      "Iteration 27, loss = 0.84258112\n",
      "Iteration 28, loss = 0.81711920\n",
      "Iteration 29, loss = 0.84700220\n",
      "Iteration 30, loss = 0.85424588\n",
      "Iteration 31, loss = 0.84208396\n",
      "Iteration 32, loss = 0.85104951\n",
      "Iteration 33, loss = 0.79992088\n",
      "Iteration 34, loss = 0.82701021\n",
      "Iteration 35, loss = 0.83397426\n",
      "Iteration 36, loss = 0.80816810\n",
      "Iteration 37, loss = 0.81696771\n",
      "Iteration 38, loss = 0.81423441\n",
      "Iteration 39, loss = 0.79858502\n",
      "Iteration 40, loss = 0.81094055\n",
      "Iteration 41, loss = 0.82110858\n",
      "Iteration 42, loss = 0.81612409\n",
      "Iteration 43, loss = 0.81199023\n",
      "Iteration 44, loss = 0.78602589\n",
      "Iteration 45, loss = 0.79870906\n",
      "Iteration 46, loss = 0.80328889\n",
      "Iteration 47, loss = 0.81208543\n",
      "Iteration 33, loss = 0.79992088\n",
      "Iteration 34, loss = 0.82701021\n",
      "Iteration 35, loss = 0.83397426\n",
      "Iteration 36, loss = 0.80816810\n",
      "Iteration 37, loss = 0.81696771\n",
      "Iteration 38, loss = 0.81423441\n",
      "Iteration 39, loss = 0.79858502\n",
      "Iteration 40, loss = 0.81094055\n",
      "Iteration 41, loss = 0.82110858\n",
      "Iteration 42, loss = 0.81612409\n",
      "Iteration 43, loss = 0.81199023\n",
      "Iteration 44, loss = 0.78602589\n",
      "Iteration 45, loss = 0.79870906\n",
      "Iteration 46, loss = 0.80328889\n",
      "Iteration 47, loss = 0.81208543\n",
      "Iteration 48, loss = 0.80435298\n",
      "Iteration 49, loss = 0.77419209\n",
      "Iteration 50, loss = 0.78992141\n",
      "Iteration 51, loss = 0.73638951\n",
      "Iteration 52, loss = 0.81882231\n",
      "Iteration 53, loss = 0.74192291\n",
      "Iteration 54, loss = 0.78699571\n",
      "Iteration 55, loss = 0.76919420\n",
      "Iteration 56, loss = 0.80735252\n",
      "Iteration 57, loss = 0.76464490\n",
      "Iteration 58, loss = 0.75135354\n",
      "Iteration 59, loss = 0.77760312\n",
      "Iteration 60, loss = 0.75102652\n",
      "Iteration 61, loss = 0.77381330\n",
      "Iteration 62, loss = 0.73342674\n",
      "Iteration 48, loss = 0.80435298\n",
      "Iteration 49, loss = 0.77419209\n",
      "Iteration 50, loss = 0.78992141\n",
      "Iteration 51, loss = 0.73638951\n",
      "Iteration 52, loss = 0.81882231\n",
      "Iteration 53, loss = 0.74192291\n",
      "Iteration 54, loss = 0.78699571\n",
      "Iteration 55, loss = 0.76919420\n",
      "Iteration 56, loss = 0.80735252\n",
      "Iteration 57, loss = 0.76464490\n",
      "Iteration 58, loss = 0.75135354\n",
      "Iteration 59, loss = 0.77760312\n",
      "Iteration 60, loss = 0.75102652\n",
      "Iteration 61, loss = 0.77381330\n",
      "Iteration 62, loss = 0.73342674\n",
      "Iteration 63, loss = 0.75022154\n",
      "Iteration 64, loss = 0.74396356\n",
      "Iteration 65, loss = 0.83598545\n",
      "Iteration 66, loss = 0.76636767\n",
      "Iteration 67, loss = 0.77566247\n",
      "Iteration 68, loss = 0.75859591\n",
      "Iteration 69, loss = 0.75144721\n",
      "Iteration 70, loss = 0.73758558\n",
      "Iteration 71, loss = 0.72021970\n",
      "Iteration 72, loss = 0.73515284\n",
      "Iteration 73, loss = 0.72629858\n",
      "Iteration 74, loss = 0.80040999\n",
      "Iteration 75, loss = 0.73350801\n",
      "Iteration 76, loss = 0.76474987\n",
      "Iteration 77, loss = 0.76582538\n",
      "Iteration 78, loss = 0.73132973\n",
      "Iteration 63, loss = 0.75022154\n",
      "Iteration 64, loss = 0.74396356\n",
      "Iteration 65, loss = 0.83598545\n",
      "Iteration 66, loss = 0.76636767\n",
      "Iteration 67, loss = 0.77566247\n",
      "Iteration 68, loss = 0.75859591\n",
      "Iteration 69, loss = 0.75144721\n",
      "Iteration 70, loss = 0.73758558\n",
      "Iteration 71, loss = 0.72021970\n",
      "Iteration 72, loss = 0.73515284\n",
      "Iteration 73, loss = 0.72629858\n",
      "Iteration 74, loss = 0.80040999\n",
      "Iteration 75, loss = 0.73350801\n",
      "Iteration 76, loss = 0.76474987\n",
      "Iteration 77, loss = 0.76582538\n",
      "Iteration 78, loss = 0.73132973\n",
      "Iteration 79, loss = 0.71608198\n",
      "Iteration 80, loss = 0.70218705\n",
      "Iteration 81, loss = 0.71605585\n",
      "Iteration 82, loss = 0.71844618\n",
      "Iteration 83, loss = 0.70902770\n",
      "Iteration 84, loss = 0.70620279\n",
      "Iteration 85, loss = 0.74417400\n",
      "Iteration 86, loss = 0.80255973\n",
      "Iteration 87, loss = 0.74261355\n",
      "Iteration 88, loss = 0.69881646\n",
      "Iteration 89, loss = 0.73598814\n",
      "Iteration 90, loss = 0.75014010\n",
      "Iteration 91, loss = 0.73161212\n",
      "Iteration 92, loss = 0.72479099\n",
      "Iteration 93, loss = 0.76824194\n",
      "Iteration 94, loss = 0.71159414\n",
      "Iteration 79, loss = 0.71608198\n",
      "Iteration 80, loss = 0.70218705\n",
      "Iteration 81, loss = 0.71605585\n",
      "Iteration 82, loss = 0.71844618\n",
      "Iteration 83, loss = 0.70902770\n",
      "Iteration 84, loss = 0.70620279\n",
      "Iteration 85, loss = 0.74417400\n",
      "Iteration 86, loss = 0.80255973\n",
      "Iteration 87, loss = 0.74261355\n",
      "Iteration 88, loss = 0.69881646\n",
      "Iteration 89, loss = 0.73598814\n",
      "Iteration 90, loss = 0.75014010\n",
      "Iteration 91, loss = 0.73161212\n",
      "Iteration 92, loss = 0.72479099\n",
      "Iteration 93, loss = 0.76824194\n",
      "Iteration 94, loss = 0.71159414\n",
      "Iteration 95, loss = 0.72068517\n",
      "Iteration 96, loss = 0.72818427\n",
      "Iteration 97, loss = 0.77728055\n",
      "Iteration 98, loss = 0.81075703\n",
      "Iteration 99, loss = 0.72471691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18804998\n",
      "Iteration 2, loss = 1.06130742\n",
      "Iteration 3, loss = 1.02391653\n",
      "Iteration 4, loss = 1.04974692\n",
      "Iteration 5, loss = 1.04265506\n",
      "Iteration 6, loss = 0.97490598\n",
      "Iteration 7, loss = 1.00876221\n",
      "Iteration 8, loss = 0.97997582\n",
      "Iteration 95, loss = 0.72068517\n",
      "Iteration 96, loss = 0.72818427\n",
      "Iteration 97, loss = 0.77728055\n",
      "Iteration 98, loss = 0.81075703\n",
      "Iteration 99, loss = 0.72471691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18804998\n",
      "Iteration 2, loss = 1.06130742\n",
      "Iteration 3, loss = 1.02391653\n",
      "Iteration 4, loss = 1.04974692\n",
      "Iteration 5, loss = 1.04265506\n",
      "Iteration 6, loss = 0.97490598\n",
      "Iteration 7, loss = 1.00876221\n",
      "Iteration 8, loss = 0.97997582\n",
      "Iteration 9, loss = 1.00140803\n",
      "Iteration 10, loss = 0.96719030\n",
      "Iteration 1, loss = 1.13218596\n",
      "Iteration 2, loss = 0.96914932\n",
      "Iteration 3, loss = 0.95922253\n",
      "Iteration 4, loss = 0.99488700\n",
      "Iteration 5, loss = 0.94093082\n",
      "Iteration 6, loss = 0.95112604\n",
      "Iteration 7, loss = 0.96689519\n",
      "Iteration 8, loss = 0.97422902\n",
      "Iteration 9, loss = 0.96724850\n",
      "Iteration 10, loss = 0.96673346\n",
      "Iteration 9, loss = 1.00140803\n",
      "Iteration 10, loss = 0.96719030\n",
      "Iteration 1, loss = 1.13218596\n",
      "Iteration 2, loss = 0.96914932\n",
      "Iteration 3, loss = 0.95922253\n",
      "Iteration 4, loss = 0.99488700\n",
      "Iteration 5, loss = 0.94093082\n",
      "Iteration 6, loss = 0.95112604\n",
      "Iteration 7, loss = 0.96689519\n",
      "Iteration 8, loss = 0.97422902\n",
      "Iteration 9, loss = 0.96724850\n",
      "Iteration 10, loss = 0.96673346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.16657917\n",
      "Iteration 2, loss = 1.05937355\n",
      "Iteration 3, loss = 1.01671921\n",
      "Iteration 4, loss = 1.00984022\n",
      "Iteration 5, loss = 0.98747500\n",
      "Iteration 6, loss = 0.99313027\n",
      "Iteration 7, loss = 0.96203522\n",
      "Iteration 8, loss = 0.94470281\n",
      "Iteration 9, loss = 0.98049827\n",
      "Iteration 10, loss = 0.96723489\n",
      "Iteration 1, loss = 1.19276241\n",
      "Iteration 2, loss = 1.16685268\n",
      "Iteration 1, loss = 1.16657917\n",
      "Iteration 2, loss = 1.05937355\n",
      "Iteration 3, loss = 1.01671921\n",
      "Iteration 4, loss = 1.00984022\n",
      "Iteration 5, loss = 0.98747500\n",
      "Iteration 6, loss = 0.99313027\n",
      "Iteration 7, loss = 0.96203522\n",
      "Iteration 8, loss = 0.94470281\n",
      "Iteration 9, loss = 0.98049827\n",
      "Iteration 10, loss = 0.96723489\n",
      "Iteration 1, loss = 1.19276241\n",
      "Iteration 2, loss = 1.16685268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.01861489\n",
      "Iteration 4, loss = 1.02785931\n",
      "Iteration 5, loss = 1.01435465\n",
      "Iteration 6, loss = 1.00592225\n",
      "Iteration 7, loss = 1.00852151\n",
      "Iteration 8, loss = 1.02537972\n",
      "Iteration 9, loss = 1.00965365\n",
      "Iteration 10, loss = 1.03118501\n",
      "Iteration 1, loss = 1.17140437\n",
      "Iteration 2, loss = 1.05556634\n",
      "Iteration 3, loss = 1.05583969\n",
      "Iteration 4, loss = 1.00169824\n",
      "Iteration 5, loss = 0.97456622\n",
      "Iteration 3, loss = 1.01861489\n",
      "Iteration 4, loss = 1.02785931\n",
      "Iteration 5, loss = 1.01435465\n",
      "Iteration 6, loss = 1.00592225\n",
      "Iteration 7, loss = 1.00852151\n",
      "Iteration 8, loss = 1.02537972\n",
      "Iteration 9, loss = 1.00965365\n",
      "Iteration 10, loss = 1.03118501\n",
      "Iteration 1, loss = 1.17140437\n",
      "Iteration 2, loss = 1.05556634\n",
      "Iteration 3, loss = 1.05583969\n",
      "Iteration 4, loss = 1.00169824\n",
      "Iteration 5, loss = 0.97456622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.97621035\n",
      "Iteration 7, loss = 0.99147216\n",
      "Iteration 8, loss = 0.98610947\n",
      "Iteration 9, loss = 1.00918588\n",
      "Iteration 10, loss = 1.02237369\n",
      "Iteration 1, loss = 1.18804998\n",
      "Iteration 2, loss = 1.06130742\n",
      "Iteration 3, loss = 1.02391653\n",
      "Iteration 4, loss = 1.04974692\n",
      "Iteration 5, loss = 1.04265506\n",
      "Iteration 6, loss = 0.97490598\n",
      "Iteration 7, loss = 1.00876221\n",
      "Iteration 8, loss = 0.97997582\n",
      "Iteration 6, loss = 0.97621035\n",
      "Iteration 7, loss = 0.99147216\n",
      "Iteration 8, loss = 0.98610947\n",
      "Iteration 9, loss = 1.00918588\n",
      "Iteration 10, loss = 1.02237369\n",
      "Iteration 1, loss = 1.18804998\n",
      "Iteration 2, loss = 1.06130742\n",
      "Iteration 3, loss = 1.02391653\n",
      "Iteration 4, loss = 1.04974692\n",
      "Iteration 5, loss = 1.04265506\n",
      "Iteration 6, loss = 0.97490598\n",
      "Iteration 7, loss = 1.00876221\n",
      "Iteration 8, loss = 0.97997582\n",
      "Iteration 9, loss = 1.00140803\n",
      "Iteration 10, loss = 0.96719030\n",
      "Iteration 11, loss = 0.98841893\n",
      "Iteration 12, loss = 1.03601587\n",
      "Iteration 13, loss = 0.98447115\n",
      "Iteration 14, loss = 0.97792824\n",
      "Iteration 15, loss = 1.01194891\n",
      "Iteration 16, loss = 0.96253333\n",
      "Iteration 17, loss = 0.97989503\n",
      "Iteration 18, loss = 0.97195306\n",
      "Iteration 19, loss = 0.95890443\n",
      "Iteration 20, loss = 0.98651180\n",
      "Iteration 21, loss = 0.97673652\n",
      "Iteration 22, loss = 0.98289761\n",
      "Iteration 9, loss = 1.00140803\n",
      "Iteration 10, loss = 0.96719030\n",
      "Iteration 11, loss = 0.98841893\n",
      "Iteration 12, loss = 1.03601587\n",
      "Iteration 13, loss = 0.98447115\n",
      "Iteration 14, loss = 0.97792824\n",
      "Iteration 15, loss = 1.01194891\n",
      "Iteration 16, loss = 0.96253333\n",
      "Iteration 17, loss = 0.97989503\n",
      "Iteration 18, loss = 0.97195306\n",
      "Iteration 19, loss = 0.95890443\n",
      "Iteration 20, loss = 0.98651180\n",
      "Iteration 21, loss = 0.97673652\n",
      "Iteration 22, loss = 0.98289761\n",
      "Iteration 23, loss = 0.98574200\n",
      "Iteration 24, loss = 0.98483446\n",
      "Iteration 25, loss = 1.00736219\n",
      "Iteration 26, loss = 0.98597501\n",
      "Iteration 27, loss = 0.95198014\n",
      "Iteration 28, loss = 0.99449930\n",
      "Iteration 29, loss = 0.95713062\n",
      "Iteration 30, loss = 0.94273766\n",
      "Iteration 31, loss = 1.00365485\n",
      "Iteration 32, loss = 1.00617545\n",
      "Iteration 33, loss = 1.04246190\n",
      "Iteration 34, loss = 0.92314893\n",
      "Iteration 35, loss = 0.96532049\n",
      "Iteration 36, loss = 0.94957165\n",
      "Iteration 37, loss = 0.95076944\n",
      "Iteration 38, loss = 0.94503824\n",
      "Iteration 23, loss = 0.98574200\n",
      "Iteration 24, loss = 0.98483446\n",
      "Iteration 25, loss = 1.00736219\n",
      "Iteration 26, loss = 0.98597501\n",
      "Iteration 27, loss = 0.95198014\n",
      "Iteration 28, loss = 0.99449930\n",
      "Iteration 29, loss = 0.95713062\n",
      "Iteration 30, loss = 0.94273766\n",
      "Iteration 31, loss = 1.00365485\n",
      "Iteration 32, loss = 1.00617545\n",
      "Iteration 33, loss = 1.04246190\n",
      "Iteration 34, loss = 0.92314893\n",
      "Iteration 35, loss = 0.96532049\n",
      "Iteration 36, loss = 0.94957165\n",
      "Iteration 37, loss = 0.95076944\n",
      "Iteration 38, loss = 0.94503824\n",
      "Iteration 39, loss = 0.94179946\n",
      "Iteration 40, loss = 0.97691428\n",
      "Iteration 41, loss = 0.93426372\n",
      "Iteration 42, loss = 0.93253699\n",
      "Iteration 43, loss = 0.96098130\n",
      "Iteration 44, loss = 0.93331008\n",
      "Iteration 45, loss = 0.97144680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13218596\n",
      "Iteration 2, loss = 0.96914932\n",
      "Iteration 3, loss = 0.95922253\n",
      "Iteration 4, loss = 0.99488700\n",
      "Iteration 5, loss = 0.94093082\n",
      "Iteration 39, loss = 0.94179946\n",
      "Iteration 40, loss = 0.97691428\n",
      "Iteration 41, loss = 0.93426372\n",
      "Iteration 42, loss = 0.93253699\n",
      "Iteration 43, loss = 0.96098130\n",
      "Iteration 44, loss = 0.93331008\n",
      "Iteration 45, loss = 0.97144680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13218596\n",
      "Iteration 2, loss = 0.96914932\n",
      "Iteration 3, loss = 0.95922253\n",
      "Iteration 4, loss = 0.99488700\n",
      "Iteration 5, loss = 0.94093082\n",
      "Iteration 6, loss = 0.95112604\n",
      "Iteration 7, loss = 0.96689519\n",
      "Iteration 8, loss = 0.97422902\n",
      "Iteration 9, loss = 0.96724850\n",
      "Iteration 10, loss = 0.96673346\n",
      "Iteration 11, loss = 0.97007784\n",
      "Iteration 12, loss = 0.97896036\n",
      "Iteration 13, loss = 0.94133183\n",
      "Iteration 14, loss = 0.96016177\n",
      "Iteration 15, loss = 0.95377622\n",
      "Iteration 16, loss = 0.90811698\n",
      "Iteration 17, loss = 0.95576779\n",
      "Iteration 18, loss = 0.93206474\n",
      "Iteration 19, loss = 0.95368340\n",
      "Iteration 6, loss = 0.95112604\n",
      "Iteration 7, loss = 0.96689519\n",
      "Iteration 8, loss = 0.97422902\n",
      "Iteration 9, loss = 0.96724850\n",
      "Iteration 10, loss = 0.96673346\n",
      "Iteration 11, loss = 0.97007784\n",
      "Iteration 12, loss = 0.97896036\n",
      "Iteration 13, loss = 0.94133183\n",
      "Iteration 14, loss = 0.96016177\n",
      "Iteration 15, loss = 0.95377622\n",
      "Iteration 16, loss = 0.90811698\n",
      "Iteration 17, loss = 0.95576779\n",
      "Iteration 18, loss = 0.93206474\n",
      "Iteration 19, loss = 0.95368340\n",
      "Iteration 20, loss = 0.94833378\n",
      "Iteration 21, loss = 0.90746264\n",
      "Iteration 22, loss = 0.93392680\n",
      "Iteration 23, loss = 0.97214284\n",
      "Iteration 24, loss = 0.98065827\n",
      "Iteration 25, loss = 0.91339133\n",
      "Iteration 26, loss = 0.89662900\n",
      "Iteration 27, loss = 0.89615724\n",
      "Iteration 28, loss = 0.92723886\n",
      "Iteration 29, loss = 0.95028239\n",
      "Iteration 30, loss = 0.92881968\n",
      "Iteration 31, loss = 0.91534082\n",
      "Iteration 32, loss = 0.91516132\n",
      "Iteration 33, loss = 0.94858935\n",
      "Iteration 34, loss = 0.91467959\n",
      "Iteration 35, loss = 0.98749611\n",
      "Iteration 20, loss = 0.94833378\n",
      "Iteration 21, loss = 0.90746264\n",
      "Iteration 22, loss = 0.93392680\n",
      "Iteration 23, loss = 0.97214284\n",
      "Iteration 24, loss = 0.98065827\n",
      "Iteration 25, loss = 0.91339133\n",
      "Iteration 26, loss = 0.89662900\n",
      "Iteration 27, loss = 0.89615724\n",
      "Iteration 28, loss = 0.92723886\n",
      "Iteration 29, loss = 0.95028239\n",
      "Iteration 30, loss = 0.92881968\n",
      "Iteration 31, loss = 0.91534082\n",
      "Iteration 32, loss = 0.91516132\n",
      "Iteration 33, loss = 0.94858935\n",
      "Iteration 34, loss = 0.91467959\n",
      "Iteration 35, loss = 0.98749611\n",
      "Iteration 36, loss = 0.93689431\n",
      "Iteration 37, loss = 0.90874918\n",
      "Iteration 38, loss = 0.92767341\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16657917\n",
      "Iteration 2, loss = 1.05937355\n",
      "Iteration 3, loss = 1.01671921\n",
      "Iteration 4, loss = 1.00984022\n",
      "Iteration 5, loss = 0.98747500\n",
      "Iteration 6, loss = 0.99313027\n",
      "Iteration 7, loss = 0.96203522\n",
      "Iteration 8, loss = 0.94470281\n",
      "Iteration 9, loss = 0.98049827\n",
      "Iteration 10, loss = 0.96723489\n",
      "Iteration 11, loss = 0.97271429\n",
      "Iteration 36, loss = 0.93689431\n",
      "Iteration 37, loss = 0.90874918\n",
      "Iteration 38, loss = 0.92767341\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16657917\n",
      "Iteration 2, loss = 1.05937355\n",
      "Iteration 3, loss = 1.01671921\n",
      "Iteration 4, loss = 1.00984022\n",
      "Iteration 5, loss = 0.98747500\n",
      "Iteration 6, loss = 0.99313027\n",
      "Iteration 7, loss = 0.96203522\n",
      "Iteration 8, loss = 0.94470281\n",
      "Iteration 9, loss = 0.98049827\n",
      "Iteration 10, loss = 0.96723489\n",
      "Iteration 11, loss = 0.97271429\n",
      "Iteration 12, loss = 0.97849217\n",
      "Iteration 13, loss = 0.98817969\n",
      "Iteration 14, loss = 0.94340663\n",
      "Iteration 15, loss = 0.98139619\n",
      "Iteration 16, loss = 0.96652316\n",
      "Iteration 17, loss = 0.97305384\n",
      "Iteration 18, loss = 1.00108055\n",
      "Iteration 19, loss = 0.99381807\n",
      "Iteration 20, loss = 0.96034183\n",
      "Iteration 21, loss = 0.95255871\n",
      "Iteration 22, loss = 1.00767121\n",
      "Iteration 23, loss = 0.96705981\n",
      "Iteration 24, loss = 0.97777435\n",
      "Iteration 25, loss = 0.95127483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19276241\n",
      "Iteration 12, loss = 0.97849217\n",
      "Iteration 13, loss = 0.98817969\n",
      "Iteration 14, loss = 0.94340663\n",
      "Iteration 15, loss = 0.98139619\n",
      "Iteration 16, loss = 0.96652316\n",
      "Iteration 17, loss = 0.97305384\n",
      "Iteration 18, loss = 1.00108055\n",
      "Iteration 19, loss = 0.99381807\n",
      "Iteration 20, loss = 0.96034183\n",
      "Iteration 21, loss = 0.95255871\n",
      "Iteration 22, loss = 1.00767121\n",
      "Iteration 23, loss = 0.96705981\n",
      "Iteration 24, loss = 0.97777435\n",
      "Iteration 25, loss = 0.95127483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19276241\n",
      "Iteration 2, loss = 1.16685268\n",
      "Iteration 3, loss = 1.01861489\n",
      "Iteration 4, loss = 1.02785931\n",
      "Iteration 5, loss = 1.01435465\n",
      "Iteration 6, loss = 1.00592225\n",
      "Iteration 7, loss = 1.00852151\n",
      "Iteration 8, loss = 1.02537972\n",
      "Iteration 9, loss = 1.00965365\n",
      "Iteration 10, loss = 1.03118501\n",
      "Iteration 11, loss = 0.96686503\n",
      "Iteration 12, loss = 0.98951287\n",
      "Iteration 13, loss = 0.97148065\n",
      "Iteration 14, loss = 0.98536785\n",
      "Iteration 15, loss = 0.97277018\n",
      "Iteration 2, loss = 1.16685268\n",
      "Iteration 3, loss = 1.01861489\n",
      "Iteration 4, loss = 1.02785931\n",
      "Iteration 5, loss = 1.01435465\n",
      "Iteration 6, loss = 1.00592225\n",
      "Iteration 7, loss = 1.00852151\n",
      "Iteration 8, loss = 1.02537972\n",
      "Iteration 9, loss = 1.00965365\n",
      "Iteration 10, loss = 1.03118501\n",
      "Iteration 11, loss = 0.96686503\n",
      "Iteration 12, loss = 0.98951287\n",
      "Iteration 13, loss = 0.97148065\n",
      "Iteration 14, loss = 0.98536785\n",
      "Iteration 15, loss = 0.97277018\n",
      "Iteration 16, loss = 0.99757545\n",
      "Iteration 17, loss = 0.95099989\n",
      "Iteration 18, loss = 0.95712879\n",
      "Iteration 19, loss = 1.03014085\n",
      "Iteration 20, loss = 0.97358476\n",
      "Iteration 21, loss = 0.99995391\n",
      "Iteration 22, loss = 0.98823642\n",
      "Iteration 23, loss = 0.96314950\n",
      "Iteration 24, loss = 0.97831956\n",
      "Iteration 25, loss = 0.97716109\n",
      "Iteration 26, loss = 0.98537812\n",
      "Iteration 27, loss = 0.94830619\n",
      "Iteration 28, loss = 0.91407190\n",
      "Iteration 29, loss = 0.96293907\n",
      "Iteration 30, loss = 0.92645471\n",
      "Iteration 31, loss = 0.99149646\n",
      "Iteration 16, loss = 0.99757545\n",
      "Iteration 17, loss = 0.95099989\n",
      "Iteration 18, loss = 0.95712879\n",
      "Iteration 19, loss = 1.03014085\n",
      "Iteration 20, loss = 0.97358476\n",
      "Iteration 21, loss = 0.99995391\n",
      "Iteration 22, loss = 0.98823642\n",
      "Iteration 23, loss = 0.96314950\n",
      "Iteration 24, loss = 0.97831956\n",
      "Iteration 25, loss = 0.97716109\n",
      "Iteration 26, loss = 0.98537812\n",
      "Iteration 27, loss = 0.94830619\n",
      "Iteration 28, loss = 0.91407190\n",
      "Iteration 29, loss = 0.96293907\n",
      "Iteration 30, loss = 0.92645471\n",
      "Iteration 31, loss = 0.99149646\n",
      "Iteration 32, loss = 0.92857420\n",
      "Iteration 33, loss = 0.92598704\n",
      "Iteration 34, loss = 0.92239752\n",
      "Iteration 35, loss = 0.93496555\n",
      "Iteration 36, loss = 0.97909143\n",
      "Iteration 37, loss = 0.93711173\n",
      "Iteration 38, loss = 0.92699897\n",
      "Iteration 39, loss = 0.90639395\n",
      "Iteration 40, loss = 0.91541679\n",
      "Iteration 41, loss = 0.94370239\n",
      "Iteration 42, loss = 0.91188733\n",
      "Iteration 43, loss = 0.89333816\n",
      "Iteration 44, loss = 0.87746760\n",
      "Iteration 45, loss = 0.89865916\n",
      "Iteration 32, loss = 0.92857420\n",
      "Iteration 33, loss = 0.92598704\n",
      "Iteration 34, loss = 0.92239752\n",
      "Iteration 35, loss = 0.93496555\n",
      "Iteration 36, loss = 0.97909143\n",
      "Iteration 37, loss = 0.93711173\n",
      "Iteration 38, loss = 0.92699897\n",
      "Iteration 39, loss = 0.90639395\n",
      "Iteration 40, loss = 0.91541679\n",
      "Iteration 41, loss = 0.94370239\n",
      "Iteration 42, loss = 0.91188733\n",
      "Iteration 43, loss = 0.89333816\n",
      "Iteration 44, loss = 0.87746760\n",
      "Iteration 45, loss = 0.89865916\n",
      "Iteration 46, loss = 0.88735303\n",
      "Iteration 47, loss = 0.88266918\n",
      "Iteration 48, loss = 0.94034823\n",
      "Iteration 49, loss = 0.87850021\n",
      "Iteration 50, loss = 0.96066179\n",
      "Iteration 1, loss = 1.17140437\n",
      "Iteration 2, loss = 1.05556634\n",
      "Iteration 3, loss = 1.05583969\n",
      "Iteration 4, loss = 1.00169824\n",
      "Iteration 5, loss = 0.97456622\n",
      "Iteration 6, loss = 0.97621035\n",
      "Iteration 7, loss = 0.99147216\n",
      "Iteration 8, loss = 0.98610947\n",
      "Iteration 46, loss = 0.88735303\n",
      "Iteration 47, loss = 0.88266918\n",
      "Iteration 48, loss = 0.94034823\n",
      "Iteration 49, loss = 0.87850021\n",
      "Iteration 50, loss = 0.96066179\n",
      "Iteration 1, loss = 1.17140437\n",
      "Iteration 2, loss = 1.05556634\n",
      "Iteration 3, loss = 1.05583969\n",
      "Iteration 4, loss = 1.00169824\n",
      "Iteration 5, loss = 0.97456622\n",
      "Iteration 6, loss = 0.97621035\n",
      "Iteration 7, loss = 0.99147216\n",
      "Iteration 8, loss = 0.98610947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.00918588\n",
      "Iteration 10, loss = 1.02237369\n",
      "Iteration 11, loss = 1.00616250\n",
      "Iteration 12, loss = 0.98833999\n",
      "Iteration 13, loss = 0.95470351\n",
      "Iteration 14, loss = 0.99348312\n",
      "Iteration 15, loss = 0.96047770\n",
      "Iteration 16, loss = 0.98344287\n",
      "Iteration 17, loss = 0.95314178\n",
      "Iteration 18, loss = 0.95987246\n",
      "Iteration 19, loss = 1.08182055\n",
      "Iteration 20, loss = 1.05223662\n",
      "Iteration 21, loss = 0.96322215\n",
      "Iteration 22, loss = 0.96001273\n",
      "Iteration 9, loss = 1.00918588\n",
      "Iteration 10, loss = 1.02237369\n",
      "Iteration 11, loss = 1.00616250\n",
      "Iteration 12, loss = 0.98833999\n",
      "Iteration 13, loss = 0.95470351\n",
      "Iteration 14, loss = 0.99348312\n",
      "Iteration 15, loss = 0.96047770\n",
      "Iteration 16, loss = 0.98344287\n",
      "Iteration 17, loss = 0.95314178\n",
      "Iteration 18, loss = 0.95987246\n",
      "Iteration 19, loss = 1.08182055\n",
      "Iteration 20, loss = 1.05223662\n",
      "Iteration 21, loss = 0.96322215\n",
      "Iteration 22, loss = 0.96001273\n",
      "Iteration 23, loss = 0.96168471\n",
      "Iteration 24, loss = 0.91462133\n",
      "Iteration 25, loss = 0.92253859\n",
      "Iteration 26, loss = 0.99651726\n",
      "Iteration 27, loss = 0.94726945\n",
      "Iteration 28, loss = 0.90729552\n",
      "Iteration 29, loss = 0.95292504\n",
      "Iteration 30, loss = 0.90269847\n",
      "Iteration 31, loss = 0.92873435\n",
      "Iteration 32, loss = 0.97255632\n",
      "Iteration 33, loss = 0.90610508\n",
      "Iteration 34, loss = 0.90981125\n",
      "Iteration 35, loss = 0.92274031\n",
      "Iteration 36, loss = 0.93520676\n",
      "Iteration 23, loss = 0.96168471\n",
      "Iteration 24, loss = 0.91462133\n",
      "Iteration 25, loss = 0.92253859\n",
      "Iteration 26, loss = 0.99651726\n",
      "Iteration 27, loss = 0.94726945\n",
      "Iteration 28, loss = 0.90729552\n",
      "Iteration 29, loss = 0.95292504\n",
      "Iteration 30, loss = 0.90269847\n",
      "Iteration 31, loss = 0.92873435\n",
      "Iteration 32, loss = 0.97255632\n",
      "Iteration 33, loss = 0.90610508\n",
      "Iteration 34, loss = 0.90981125\n",
      "Iteration 35, loss = 0.92274031\n",
      "Iteration 36, loss = 0.93520676\n",
      "Iteration 37, loss = 0.92647115\n",
      "Iteration 38, loss = 0.93337570\n",
      "Iteration 39, loss = 0.94995767\n",
      "Iteration 40, loss = 0.90446267\n",
      "Iteration 41, loss = 0.94997189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18804998\n",
      "Iteration 2, loss = 1.06130742\n",
      "Iteration 3, loss = 1.02391653\n",
      "Iteration 4, loss = 1.04974692\n",
      "Iteration 5, loss = 1.04265506\n",
      "Iteration 6, loss = 0.97490598\n",
      "Iteration 7, loss = 1.00876221\n",
      "Iteration 8, loss = 0.97997582\n",
      "Iteration 9, loss = 1.00140803\n",
      "Iteration 10, loss = 0.96719030\n",
      "Iteration 37, loss = 0.92647115\n",
      "Iteration 38, loss = 0.93337570\n",
      "Iteration 39, loss = 0.94995767\n",
      "Iteration 40, loss = 0.90446267\n",
      "Iteration 41, loss = 0.94997189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18804998\n",
      "Iteration 2, loss = 1.06130742\n",
      "Iteration 3, loss = 1.02391653\n",
      "Iteration 4, loss = 1.04974692\n",
      "Iteration 5, loss = 1.04265506\n",
      "Iteration 6, loss = 0.97490598\n",
      "Iteration 7, loss = 1.00876221\n",
      "Iteration 8, loss = 0.97997582\n",
      "Iteration 9, loss = 1.00140803\n",
      "Iteration 10, loss = 0.96719030\n",
      "Iteration 11, loss = 0.98841893\n",
      "Iteration 12, loss = 1.03601587\n",
      "Iteration 13, loss = 0.98447115\n",
      "Iteration 14, loss = 0.97792824\n",
      "Iteration 15, loss = 1.01194891\n",
      "Iteration 16, loss = 0.96253333\n",
      "Iteration 17, loss = 0.97989503\n",
      "Iteration 18, loss = 0.97195306\n",
      "Iteration 19, loss = 0.95890443\n",
      "Iteration 20, loss = 0.98651180\n",
      "Iteration 21, loss = 0.97673652\n",
      "Iteration 22, loss = 0.98289761\n",
      "Iteration 23, loss = 0.98574200\n",
      "Iteration 11, loss = 0.98841893\n",
      "Iteration 12, loss = 1.03601587\n",
      "Iteration 13, loss = 0.98447115\n",
      "Iteration 14, loss = 0.97792824\n",
      "Iteration 15, loss = 1.01194891\n",
      "Iteration 16, loss = 0.96253333\n",
      "Iteration 17, loss = 0.97989503\n",
      "Iteration 18, loss = 0.97195306\n",
      "Iteration 19, loss = 0.95890443\n",
      "Iteration 20, loss = 0.98651180\n",
      "Iteration 21, loss = 0.97673652\n",
      "Iteration 22, loss = 0.98289761\n",
      "Iteration 23, loss = 0.98574200\n",
      "Iteration 24, loss = 0.98483446\n",
      "Iteration 25, loss = 1.00736219\n",
      "Iteration 26, loss = 0.98597501\n",
      "Iteration 27, loss = 0.95198014\n",
      "Iteration 28, loss = 0.99449930\n",
      "Iteration 29, loss = 0.95713062\n",
      "Iteration 30, loss = 0.94273766\n",
      "Iteration 31, loss = 1.00365485\n",
      "Iteration 32, loss = 1.00617545\n",
      "Iteration 33, loss = 1.04246190\n",
      "Iteration 34, loss = 0.92314893\n",
      "Iteration 35, loss = 0.96532049\n",
      "Iteration 36, loss = 0.94957165\n",
      "Iteration 37, loss = 0.95076944\n",
      "Iteration 38, loss = 0.94503824\n",
      "Iteration 24, loss = 0.98483446\n",
      "Iteration 25, loss = 1.00736219\n",
      "Iteration 26, loss = 0.98597501\n",
      "Iteration 27, loss = 0.95198014\n",
      "Iteration 28, loss = 0.99449930\n",
      "Iteration 29, loss = 0.95713062\n",
      "Iteration 30, loss = 0.94273766\n",
      "Iteration 31, loss = 1.00365485\n",
      "Iteration 32, loss = 1.00617545\n",
      "Iteration 33, loss = 1.04246190\n",
      "Iteration 34, loss = 0.92314893\n",
      "Iteration 35, loss = 0.96532049\n",
      "Iteration 36, loss = 0.94957165\n",
      "Iteration 37, loss = 0.95076944\n",
      "Iteration 38, loss = 0.94503824\n",
      "Iteration 39, loss = 0.94179946\n",
      "Iteration 40, loss = 0.97691428\n",
      "Iteration 41, loss = 0.93426372\n",
      "Iteration 42, loss = 0.93253699\n",
      "Iteration 43, loss = 0.96098130\n",
      "Iteration 44, loss = 0.93331008\n",
      "Iteration 45, loss = 0.97144680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13218596\n",
      "Iteration 2, loss = 0.96914932\n",
      "Iteration 3, loss = 0.95922253\n",
      "Iteration 4, loss = 0.99488700\n",
      "Iteration 5, loss = 0.94093082\n",
      "Iteration 6, loss = 0.95112604\n",
      "Iteration 7, loss = 0.96689519\n",
      "Iteration 8, loss = 0.97422902\n",
      "Iteration 39, loss = 0.94179946\n",
      "Iteration 40, loss = 0.97691428\n",
      "Iteration 41, loss = 0.93426372\n",
      "Iteration 42, loss = 0.93253699\n",
      "Iteration 43, loss = 0.96098130\n",
      "Iteration 44, loss = 0.93331008\n",
      "Iteration 45, loss = 0.97144680\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13218596\n",
      "Iteration 2, loss = 0.96914932\n",
      "Iteration 3, loss = 0.95922253\n",
      "Iteration 4, loss = 0.99488700\n",
      "Iteration 5, loss = 0.94093082\n",
      "Iteration 6, loss = 0.95112604\n",
      "Iteration 7, loss = 0.96689519\n",
      "Iteration 8, loss = 0.97422902\n",
      "Iteration 9, loss = 0.96724850\n",
      "Iteration 10, loss = 0.96673346\n",
      "Iteration 11, loss = 0.97007784\n",
      "Iteration 12, loss = 0.97896036\n",
      "Iteration 13, loss = 0.94133183\n",
      "Iteration 14, loss = 0.96016177\n",
      "Iteration 15, loss = 0.95377622\n",
      "Iteration 16, loss = 0.90811698\n",
      "Iteration 17, loss = 0.95576779\n",
      "Iteration 18, loss = 0.93206474\n",
      "Iteration 19, loss = 0.95368340\n",
      "Iteration 20, loss = 0.94833378\n",
      "Iteration 9, loss = 0.96724850\n",
      "Iteration 10, loss = 0.96673346\n",
      "Iteration 11, loss = 0.97007784\n",
      "Iteration 12, loss = 0.97896036\n",
      "Iteration 13, loss = 0.94133183\n",
      "Iteration 14, loss = 0.96016177\n",
      "Iteration 15, loss = 0.95377622\n",
      "Iteration 16, loss = 0.90811698\n",
      "Iteration 17, loss = 0.95576779\n",
      "Iteration 18, loss = 0.93206474\n",
      "Iteration 19, loss = 0.95368340\n",
      "Iteration 20, loss = 0.94833378\n",
      "Iteration 21, loss = 0.90746264\n",
      "Iteration 22, loss = 0.93392680\n",
      "Iteration 23, loss = 0.97214284\n",
      "Iteration 24, loss = 0.98065827\n",
      "Iteration 25, loss = 0.91339133\n",
      "Iteration 26, loss = 0.89662900\n",
      "Iteration 27, loss = 0.89615724\n",
      "Iteration 28, loss = 0.92723886\n",
      "Iteration 29, loss = 0.95028239\n",
      "Iteration 30, loss = 0.92881968\n",
      "Iteration 31, loss = 0.91534082\n",
      "Iteration 32, loss = 0.91516132\n",
      "Iteration 33, loss = 0.94858935\n",
      "Iteration 34, loss = 0.91467959\n",
      "Iteration 35, loss = 0.98749611\n",
      "Iteration 36, loss = 0.93689431\n",
      "Iteration 21, loss = 0.90746264\n",
      "Iteration 22, loss = 0.93392680\n",
      "Iteration 23, loss = 0.97214284\n",
      "Iteration 24, loss = 0.98065827\n",
      "Iteration 25, loss = 0.91339133\n",
      "Iteration 26, loss = 0.89662900\n",
      "Iteration 27, loss = 0.89615724\n",
      "Iteration 28, loss = 0.92723886\n",
      "Iteration 29, loss = 0.95028239\n",
      "Iteration 30, loss = 0.92881968\n",
      "Iteration 31, loss = 0.91534082\n",
      "Iteration 32, loss = 0.91516132\n",
      "Iteration 33, loss = 0.94858935\n",
      "Iteration 34, loss = 0.91467959\n",
      "Iteration 35, loss = 0.98749611\n",
      "Iteration 36, loss = 0.93689431\n",
      "Iteration 37, loss = 0.90874918\n",
      "Iteration 38, loss = 0.92767341\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16657917\n",
      "Iteration 2, loss = 1.05937355\n",
      "Iteration 3, loss = 1.01671921\n",
      "Iteration 4, loss = 1.00984022\n",
      "Iteration 5, loss = 0.98747500\n",
      "Iteration 6, loss = 0.99313027\n",
      "Iteration 7, loss = 0.96203522\n",
      "Iteration 8, loss = 0.94470281\n",
      "Iteration 9, loss = 0.98049827\n",
      "Iteration 10, loss = 0.96723489\n",
      "Iteration 11, loss = 0.97271429\n",
      "Iteration 12, loss = 0.97849217\n",
      "Iteration 37, loss = 0.90874918\n",
      "Iteration 38, loss = 0.92767341\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16657917\n",
      "Iteration 2, loss = 1.05937355\n",
      "Iteration 3, loss = 1.01671921\n",
      "Iteration 4, loss = 1.00984022\n",
      "Iteration 5, loss = 0.98747500\n",
      "Iteration 6, loss = 0.99313027\n",
      "Iteration 7, loss = 0.96203522\n",
      "Iteration 8, loss = 0.94470281\n",
      "Iteration 9, loss = 0.98049827\n",
      "Iteration 10, loss = 0.96723489\n",
      "Iteration 11, loss = 0.97271429\n",
      "Iteration 12, loss = 0.97849217\n",
      "Iteration 13, loss = 0.98817969\n",
      "Iteration 14, loss = 0.94340663\n",
      "Iteration 15, loss = 0.98139619\n",
      "Iteration 16, loss = 0.96652316\n",
      "Iteration 17, loss = 0.97305384\n",
      "Iteration 18, loss = 1.00108055\n",
      "Iteration 19, loss = 0.99381807\n",
      "Iteration 20, loss = 0.96034183\n",
      "Iteration 21, loss = 0.95255871\n",
      "Iteration 22, loss = 1.00767121\n",
      "Iteration 23, loss = 0.96705981\n",
      "Iteration 24, loss = 0.97777435\n",
      "Iteration 25, loss = 0.95127483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.98817969\n",
      "Iteration 14, loss = 0.94340663\n",
      "Iteration 15, loss = 0.98139619\n",
      "Iteration 16, loss = 0.96652316\n",
      "Iteration 17, loss = 0.97305384\n",
      "Iteration 18, loss = 1.00108055\n",
      "Iteration 19, loss = 0.99381807\n",
      "Iteration 20, loss = 0.96034183\n",
      "Iteration 21, loss = 0.95255871\n",
      "Iteration 22, loss = 1.00767121\n",
      "Iteration 23, loss = 0.96705981\n",
      "Iteration 24, loss = 0.97777435\n",
      "Iteration 25, loss = 0.95127483\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19276241\n",
      "Iteration 2, loss = 1.16685268\n",
      "Iteration 3, loss = 1.01861489\n",
      "Iteration 4, loss = 1.02785931\n",
      "Iteration 5, loss = 1.01435465\n",
      "Iteration 6, loss = 1.00592225\n",
      "Iteration 7, loss = 1.00852151\n",
      "Iteration 8, loss = 1.02537972\n",
      "Iteration 9, loss = 1.00965365\n",
      "Iteration 10, loss = 1.03118501\n",
      "Iteration 11, loss = 0.96686503\n",
      "Iteration 12, loss = 0.98951287\n",
      "Iteration 1, loss = 1.19276241\n",
      "Iteration 2, loss = 1.16685268\n",
      "Iteration 3, loss = 1.01861489\n",
      "Iteration 4, loss = 1.02785931\n",
      "Iteration 5, loss = 1.01435465\n",
      "Iteration 6, loss = 1.00592225\n",
      "Iteration 7, loss = 1.00852151\n",
      "Iteration 8, loss = 1.02537972\n",
      "Iteration 9, loss = 1.00965365\n",
      "Iteration 10, loss = 1.03118501\n",
      "Iteration 11, loss = 0.96686503\n",
      "Iteration 12, loss = 0.98951287\n",
      "Iteration 13, loss = 0.97148065\n",
      "Iteration 14, loss = 0.98536785\n",
      "Iteration 15, loss = 0.97277018\n",
      "Iteration 16, loss = 0.99757545\n",
      "Iteration 17, loss = 0.95099989\n",
      "Iteration 18, loss = 0.95712879\n",
      "Iteration 19, loss = 1.03014085\n",
      "Iteration 20, loss = 0.97358476\n",
      "Iteration 21, loss = 0.99995391\n",
      "Iteration 22, loss = 0.98823642\n",
      "Iteration 23, loss = 0.96314950\n",
      "Iteration 24, loss = 0.97831956\n",
      "Iteration 25, loss = 0.97716109\n",
      "Iteration 26, loss = 0.98537812\n",
      "Iteration 27, loss = 0.94830619\n",
      "Iteration 28, loss = 0.91407190\n",
      "Iteration 13, loss = 0.97148065\n",
      "Iteration 14, loss = 0.98536785\n",
      "Iteration 15, loss = 0.97277018\n",
      "Iteration 16, loss = 0.99757545\n",
      "Iteration 17, loss = 0.95099989\n",
      "Iteration 18, loss = 0.95712879\n",
      "Iteration 19, loss = 1.03014085\n",
      "Iteration 20, loss = 0.97358476\n",
      "Iteration 21, loss = 0.99995391\n",
      "Iteration 22, loss = 0.98823642\n",
      "Iteration 23, loss = 0.96314950\n",
      "Iteration 24, loss = 0.97831956\n",
      "Iteration 25, loss = 0.97716109\n",
      "Iteration 26, loss = 0.98537812\n",
      "Iteration 27, loss = 0.94830619\n",
      "Iteration 28, loss = 0.91407190\n",
      "Iteration 29, loss = 0.96293907\n",
      "Iteration 30, loss = 0.92645471\n",
      "Iteration 31, loss = 0.99149646\n",
      "Iteration 32, loss = 0.92857420\n",
      "Iteration 33, loss = 0.92598704\n",
      "Iteration 34, loss = 0.92239752\n",
      "Iteration 35, loss = 0.93496555\n",
      "Iteration 36, loss = 0.97909143\n",
      "Iteration 37, loss = 0.93711173\n",
      "Iteration 38, loss = 0.92699897\n",
      "Iteration 39, loss = 0.90639395\n",
      "Iteration 40, loss = 0.91541679\n",
      "Iteration 41, loss = 0.94370239\n",
      "Iteration 42, loss = 0.91188733\n",
      "Iteration 43, loss = 0.89333816\n",
      "Iteration 44, loss = 0.87746760\n",
      "Iteration 29, loss = 0.96293907\n",
      "Iteration 30, loss = 0.92645471\n",
      "Iteration 31, loss = 0.99149646\n",
      "Iteration 32, loss = 0.92857420\n",
      "Iteration 33, loss = 0.92598704\n",
      "Iteration 34, loss = 0.92239752\n",
      "Iteration 35, loss = 0.93496555\n",
      "Iteration 36, loss = 0.97909143\n",
      "Iteration 37, loss = 0.93711173\n",
      "Iteration 38, loss = 0.92699897\n",
      "Iteration 39, loss = 0.90639395\n",
      "Iteration 40, loss = 0.91541679\n",
      "Iteration 41, loss = 0.94370239\n",
      "Iteration 42, loss = 0.91188733\n",
      "Iteration 43, loss = 0.89333816\n",
      "Iteration 44, loss = 0.87746760\n",
      "Iteration 45, loss = 0.89865916\n",
      "Iteration 46, loss = 0.88735303\n",
      "Iteration 47, loss = 0.88266918\n",
      "Iteration 48, loss = 0.94034823\n",
      "Iteration 49, loss = 0.87850021\n",
      "Iteration 50, loss = 0.96066179\n",
      "Iteration 51, loss = 0.95132090\n",
      "Iteration 52, loss = 0.93914914\n",
      "Iteration 53, loss = 0.91500143\n",
      "Iteration 54, loss = 0.88736871\n",
      "Iteration 55, loss = 0.90670306\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17140437\n",
      "Iteration 2, loss = 1.05556634\n",
      "Iteration 45, loss = 0.89865916\n",
      "Iteration 46, loss = 0.88735303\n",
      "Iteration 47, loss = 0.88266918\n",
      "Iteration 48, loss = 0.94034823\n",
      "Iteration 49, loss = 0.87850021\n",
      "Iteration 50, loss = 0.96066179\n",
      "Iteration 51, loss = 0.95132090\n",
      "Iteration 52, loss = 0.93914914\n",
      "Iteration 53, loss = 0.91500143\n",
      "Iteration 54, loss = 0.88736871\n",
      "Iteration 55, loss = 0.90670306\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17140437\n",
      "Iteration 2, loss = 1.05556634\n",
      "Iteration 3, loss = 1.05583969\n",
      "Iteration 4, loss = 1.00169824\n",
      "Iteration 5, loss = 0.97456622\n",
      "Iteration 6, loss = 0.97621035\n",
      "Iteration 7, loss = 0.99147216\n",
      "Iteration 8, loss = 0.98610947\n",
      "Iteration 9, loss = 1.00918588\n",
      "Iteration 10, loss = 1.02237369\n",
      "Iteration 11, loss = 1.00616250\n",
      "Iteration 12, loss = 0.98833999\n",
      "Iteration 13, loss = 0.95470351\n",
      "Iteration 14, loss = 0.99348312\n",
      "Iteration 3, loss = 1.05583969\n",
      "Iteration 4, loss = 1.00169824\n",
      "Iteration 5, loss = 0.97456622\n",
      "Iteration 6, loss = 0.97621035\n",
      "Iteration 7, loss = 0.99147216\n",
      "Iteration 8, loss = 0.98610947\n",
      "Iteration 9, loss = 1.00918588\n",
      "Iteration 10, loss = 1.02237369\n",
      "Iteration 11, loss = 1.00616250\n",
      "Iteration 12, loss = 0.98833999\n",
      "Iteration 13, loss = 0.95470351\n",
      "Iteration 14, loss = 0.99348312\n",
      "Iteration 15, loss = 0.96047770\n",
      "Iteration 16, loss = 0.98344287\n",
      "Iteration 17, loss = 0.95314178\n",
      "Iteration 18, loss = 0.95987246\n",
      "Iteration 19, loss = 1.08182055\n",
      "Iteration 20, loss = 1.05223662\n",
      "Iteration 21, loss = 0.96322215\n",
      "Iteration 22, loss = 0.96001273\n",
      "Iteration 23, loss = 0.96168471\n",
      "Iteration 24, loss = 0.91462133\n",
      "Iteration 25, loss = 0.92253859\n",
      "Iteration 26, loss = 0.99651726\n",
      "Iteration 27, loss = 0.94726945\n",
      "Iteration 28, loss = 0.90729552\n",
      "Iteration 29, loss = 0.95292504\n",
      "Iteration 30, loss = 0.90269847\n",
      "Iteration 15, loss = 0.96047770\n",
      "Iteration 16, loss = 0.98344287\n",
      "Iteration 17, loss = 0.95314178\n",
      "Iteration 18, loss = 0.95987246\n",
      "Iteration 19, loss = 1.08182055\n",
      "Iteration 20, loss = 1.05223662\n",
      "Iteration 21, loss = 0.96322215\n",
      "Iteration 22, loss = 0.96001273\n",
      "Iteration 23, loss = 0.96168471\n",
      "Iteration 24, loss = 0.91462133\n",
      "Iteration 25, loss = 0.92253859\n",
      "Iteration 26, loss = 0.99651726\n",
      "Iteration 27, loss = 0.94726945\n",
      "Iteration 28, loss = 0.90729552\n",
      "Iteration 29, loss = 0.95292504\n",
      "Iteration 30, loss = 0.90269847\n",
      "Iteration 31, loss = 0.92873435\n",
      "Iteration 32, loss = 0.97255632\n",
      "Iteration 33, loss = 0.90610508\n",
      "Iteration 34, loss = 0.90981125\n",
      "Iteration 35, loss = 0.92274031\n",
      "Iteration 36, loss = 0.93520676\n",
      "Iteration 37, loss = 0.92647115\n",
      "Iteration 38, loss = 0.93337570\n",
      "Iteration 39, loss = 0.94995767\n",
      "Iteration 40, loss = 0.90446267\n",
      "Iteration 41, loss = 0.94997189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23255692\n",
      "Iteration 2, loss = 1.12912121\n",
      "Iteration 31, loss = 0.92873435\n",
      "Iteration 32, loss = 0.97255632\n",
      "Iteration 33, loss = 0.90610508\n",
      "Iteration 34, loss = 0.90981125\n",
      "Iteration 35, loss = 0.92274031\n",
      "Iteration 36, loss = 0.93520676\n",
      "Iteration 37, loss = 0.92647115\n",
      "Iteration 38, loss = 0.93337570\n",
      "Iteration 39, loss = 0.94995767\n",
      "Iteration 40, loss = 0.90446267\n",
      "Iteration 41, loss = 0.94997189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23255692\n",
      "Iteration 2, loss = 1.12912121\n",
      "Iteration 3, loss = 1.06562377\n",
      "Iteration 4, loss = 1.12101942\n",
      "Iteration 5, loss = 1.04330788\n",
      "Iteration 6, loss = 1.01044476\n",
      "Iteration 7, loss = 0.98143754\n",
      "Iteration 8, loss = 1.23585666\n",
      "Iteration 9, loss = 1.29593244\n",
      "Iteration 10, loss = 1.26066968\n",
      "Iteration 1, loss = 1.17772583\n",
      "Iteration 2, loss = 0.99402579\n",
      "Iteration 3, loss = 1.03735589\n",
      "Iteration 4, loss = 1.10174250\n",
      "Iteration 3, loss = 1.06562377\n",
      "Iteration 4, loss = 1.12101942\n",
      "Iteration 5, loss = 1.04330788\n",
      "Iteration 6, loss = 1.01044476\n",
      "Iteration 7, loss = 0.98143754\n",
      "Iteration 8, loss = 1.23585666\n",
      "Iteration 9, loss = 1.29593244\n",
      "Iteration 10, loss = 1.26066968\n",
      "Iteration 1, loss = 1.17772583\n",
      "Iteration 2, loss = 0.99402579\n",
      "Iteration 3, loss = 1.03735589\n",
      "Iteration 4, loss = 1.10174250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.96786515\n",
      "Iteration 6, loss = 0.98202218\n",
      "Iteration 7, loss = 1.01810564\n",
      "Iteration 8, loss = 1.03056244\n",
      "Iteration 9, loss = 1.02428038\n",
      "Iteration 10, loss = 0.96607119\n",
      "Iteration 1, loss = 1.22351819\n",
      "Iteration 2, loss = 1.04586765\n",
      "Iteration 3, loss = 1.03046392\n",
      "Iteration 5, loss = 0.96786515\n",
      "Iteration 6, loss = 0.98202218\n",
      "Iteration 7, loss = 1.01810564\n",
      "Iteration 8, loss = 1.03056244\n",
      "Iteration 9, loss = 1.02428038\n",
      "Iteration 10, loss = 0.96607119\n",
      "Iteration 1, loss = 1.22351819\n",
      "Iteration 2, loss = 1.04586765\n",
      "Iteration 3, loss = 1.03046392\n",
      "Iteration 4, loss = 1.04372017\n",
      "Iteration 5, loss = 0.96465049\n",
      "Iteration 6, loss = 1.02087450\n",
      "Iteration 7, loss = 0.99439077\n",
      "Iteration 8, loss = 0.99765774\n",
      "Iteration 9, loss = 1.05756025\n",
      "Iteration 10, loss = 1.01322662\n",
      "Iteration 1, loss = 1.23549427\n",
      "Iteration 2, loss = 1.14519139\n",
      "Iteration 3, loss = 1.06786415\n",
      "Iteration 4, loss = 1.11180947\n",
      "Iteration 5, loss = 1.07943883\n",
      "Iteration 4, loss = 1.04372017\n",
      "Iteration 5, loss = 0.96465049\n",
      "Iteration 6, loss = 1.02087450\n",
      "Iteration 7, loss = 0.99439077\n",
      "Iteration 8, loss = 0.99765774\n",
      "Iteration 9, loss = 1.05756025\n",
      "Iteration 10, loss = 1.01322662\n",
      "Iteration 1, loss = 1.23549427\n",
      "Iteration 2, loss = 1.14519139\n",
      "Iteration 3, loss = 1.06786415\n",
      "Iteration 4, loss = 1.11180947\n",
      "Iteration 5, loss = 1.07943883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.04938877\n",
      "Iteration 7, loss = 1.10351074\n",
      "Iteration 8, loss = 1.05305411\n",
      "Iteration 9, loss = 1.07781249\n",
      "Iteration 10, loss = 1.07551244\n",
      "Iteration 1, loss = 1.22002503\n",
      "Iteration 2, loss = 1.12099860\n",
      "Iteration 3, loss = 1.03878418\n",
      "Iteration 4, loss = 1.05907557\n",
      "Iteration 5, loss = 1.05158666\n",
      "Iteration 6, loss = 1.02903853\n",
      "Iteration 7, loss = 1.04447525\n",
      "Iteration 8, loss = 1.00721339\n",
      "Iteration 6, loss = 1.04938877\n",
      "Iteration 7, loss = 1.10351074\n",
      "Iteration 8, loss = 1.05305411\n",
      "Iteration 9, loss = 1.07781249\n",
      "Iteration 10, loss = 1.07551244\n",
      "Iteration 1, loss = 1.22002503\n",
      "Iteration 2, loss = 1.12099860\n",
      "Iteration 3, loss = 1.03878418\n",
      "Iteration 4, loss = 1.05907557\n",
      "Iteration 5, loss = 1.05158666\n",
      "Iteration 6, loss = 1.02903853\n",
      "Iteration 7, loss = 1.04447525\n",
      "Iteration 8, loss = 1.00721339\n",
      "Iteration 9, loss = 1.00663120\n",
      "Iteration 10, loss = 1.08588296\n",
      "Iteration 1, loss = 1.23255692\n",
      "Iteration 2, loss = 1.12912121\n",
      "Iteration 3, loss = 1.06562377\n",
      "Iteration 4, loss = 1.12101942\n",
      "Iteration 5, loss = 1.04330788\n",
      "Iteration 6, loss = 1.01044476\n",
      "Iteration 7, loss = 0.98143754\n",
      "Iteration 8, loss = 1.23585666\n",
      "Iteration 9, loss = 1.29593244\n",
      "Iteration 10, loss = 1.26066968\n",
      "Iteration 9, loss = 1.00663120\n",
      "Iteration 10, loss = 1.08588296\n",
      "Iteration 1, loss = 1.23255692\n",
      "Iteration 2, loss = 1.12912121\n",
      "Iteration 3, loss = 1.06562377\n",
      "Iteration 4, loss = 1.12101942\n",
      "Iteration 5, loss = 1.04330788\n",
      "Iteration 6, loss = 1.01044476\n",
      "Iteration 7, loss = 0.98143754\n",
      "Iteration 8, loss = 1.23585666\n",
      "Iteration 9, loss = 1.29593244\n",
      "Iteration 10, loss = 1.26066968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.27744042\n",
      "Iteration 12, loss = 1.25217039\n",
      "Iteration 13, loss = 1.27734370\n",
      "Iteration 14, loss = 1.26068935\n",
      "Iteration 15, loss = 1.25996024\n",
      "Iteration 16, loss = 1.27853804\n",
      "Iteration 17, loss = 1.27118267\n",
      "Iteration 18, loss = 1.25909493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17772583\n",
      "Iteration 2, loss = 0.99402579\n",
      "Iteration 3, loss = 1.03735589\n",
      "Iteration 4, loss = 1.10174250\n",
      "Iteration 5, loss = 0.96786515\n",
      "Iteration 6, loss = 0.98202218\n",
      "Iteration 11, loss = 1.27744042\n",
      "Iteration 12, loss = 1.25217039\n",
      "Iteration 13, loss = 1.27734370\n",
      "Iteration 14, loss = 1.26068935\n",
      "Iteration 15, loss = 1.25996024\n",
      "Iteration 16, loss = 1.27853804\n",
      "Iteration 17, loss = 1.27118267\n",
      "Iteration 18, loss = 1.25909493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17772583\n",
      "Iteration 2, loss = 0.99402579\n",
      "Iteration 3, loss = 1.03735589\n",
      "Iteration 4, loss = 1.10174250\n",
      "Iteration 5, loss = 0.96786515\n",
      "Iteration 6, loss = 0.98202218\n",
      "Iteration 7, loss = 1.01810564\n",
      "Iteration 8, loss = 1.03056244\n",
      "Iteration 9, loss = 1.02428038\n",
      "Iteration 10, loss = 0.96607119\n",
      "Iteration 11, loss = 1.03439652\n",
      "Iteration 12, loss = 1.01398393\n",
      "Iteration 13, loss = 0.97202503\n",
      "Iteration 14, loss = 0.97742991\n",
      "Iteration 15, loss = 0.96266958\n",
      "Iteration 16, loss = 0.93441946\n",
      "Iteration 17, loss = 0.98371685\n",
      "Iteration 18, loss = 0.95371509\n",
      "Iteration 19, loss = 0.98910248\n",
      "Iteration 20, loss = 1.01344121\n",
      "Iteration 7, loss = 1.01810564\n",
      "Iteration 8, loss = 1.03056244\n",
      "Iteration 9, loss = 1.02428038\n",
      "Iteration 10, loss = 0.96607119\n",
      "Iteration 11, loss = 1.03439652\n",
      "Iteration 12, loss = 1.01398393\n",
      "Iteration 13, loss = 0.97202503\n",
      "Iteration 14, loss = 0.97742991\n",
      "Iteration 15, loss = 0.96266958\n",
      "Iteration 16, loss = 0.93441946\n",
      "Iteration 17, loss = 0.98371685\n",
      "Iteration 18, loss = 0.95371509\n",
      "Iteration 19, loss = 0.98910248\n",
      "Iteration 20, loss = 1.01344121\n",
      "Iteration 21, loss = 1.00544578\n",
      "Iteration 22, loss = 0.99936583\n",
      "Iteration 23, loss = 0.97810055\n",
      "Iteration 24, loss = 1.04516310\n",
      "Iteration 25, loss = 0.98612921\n",
      "Iteration 26, loss = 0.95130692\n",
      "Iteration 27, loss = 0.93862792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22351819\n",
      "Iteration 2, loss = 1.04586765\n",
      "Iteration 3, loss = 1.03046392\n",
      "Iteration 4, loss = 1.04372017\n",
      "Iteration 5, loss = 0.96465049\n",
      "Iteration 6, loss = 1.02087450\n",
      "Iteration 7, loss = 0.99439077\n",
      "Iteration 21, loss = 1.00544578\n",
      "Iteration 22, loss = 0.99936583\n",
      "Iteration 23, loss = 0.97810055\n",
      "Iteration 24, loss = 1.04516310\n",
      "Iteration 25, loss = 0.98612921\n",
      "Iteration 26, loss = 0.95130692\n",
      "Iteration 27, loss = 0.93862792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22351819\n",
      "Iteration 2, loss = 1.04586765\n",
      "Iteration 3, loss = 1.03046392\n",
      "Iteration 4, loss = 1.04372017\n",
      "Iteration 5, loss = 0.96465049\n",
      "Iteration 6, loss = 1.02087450\n",
      "Iteration 7, loss = 0.99439077\n",
      "Iteration 8, loss = 0.99765774\n",
      "Iteration 9, loss = 1.05756025\n",
      "Iteration 10, loss = 1.01322662\n",
      "Iteration 11, loss = 1.00405899\n",
      "Iteration 12, loss = 1.02359940\n",
      "Iteration 13, loss = 0.99346449\n",
      "Iteration 14, loss = 0.95587791\n",
      "Iteration 15, loss = 1.02680914\n",
      "Iteration 16, loss = 1.03595591\n",
      "Iteration 17, loss = 1.01108838\n",
      "Iteration 18, loss = 1.06763785\n",
      "Iteration 19, loss = 1.07662702\n",
      "Iteration 20, loss = 1.09820830\n",
      "Iteration 21, loss = 1.07810583\n",
      "Iteration 8, loss = 0.99765774\n",
      "Iteration 9, loss = 1.05756025\n",
      "Iteration 10, loss = 1.01322662\n",
      "Iteration 11, loss = 1.00405899\n",
      "Iteration 12, loss = 1.02359940\n",
      "Iteration 13, loss = 0.99346449\n",
      "Iteration 14, loss = 0.95587791\n",
      "Iteration 15, loss = 1.02680914\n",
      "Iteration 16, loss = 1.03595591\n",
      "Iteration 17, loss = 1.01108838\n",
      "Iteration 18, loss = 1.06763785\n",
      "Iteration 19, loss = 1.07662702\n",
      "Iteration 20, loss = 1.09820830\n",
      "Iteration 21, loss = 1.07810583\n",
      "Iteration 22, loss = 1.12719082\n",
      "Iteration 23, loss = 0.98972598\n",
      "Iteration 24, loss = 1.00272946\n",
      "Iteration 25, loss = 1.00409835\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23549427\n",
      "Iteration 2, loss = 1.14519139\n",
      "Iteration 3, loss = 1.06786415\n",
      "Iteration 4, loss = 1.11180947\n",
      "Iteration 5, loss = 1.07943883\n",
      "Iteration 6, loss = 1.04938877\n",
      "Iteration 7, loss = 1.10351074\n",
      "Iteration 8, loss = 1.05305411\n",
      "Iteration 9, loss = 1.07781249\n",
      "Iteration 10, loss = 1.07551244\n",
      "Iteration 11, loss = 1.05740015\n",
      "Iteration 22, loss = 1.12719082\n",
      "Iteration 23, loss = 0.98972598\n",
      "Iteration 24, loss = 1.00272946\n",
      "Iteration 25, loss = 1.00409835\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23549427\n",
      "Iteration 2, loss = 1.14519139\n",
      "Iteration 3, loss = 1.06786415\n",
      "Iteration 4, loss = 1.11180947\n",
      "Iteration 5, loss = 1.07943883\n",
      "Iteration 6, loss = 1.04938877\n",
      "Iteration 7, loss = 1.10351074\n",
      "Iteration 8, loss = 1.05305411\n",
      "Iteration 9, loss = 1.07781249\n",
      "Iteration 10, loss = 1.07551244\n",
      "Iteration 11, loss = 1.05740015\n",
      "Iteration 12, loss = 1.03081820\n",
      "Iteration 13, loss = 1.00963062\n",
      "Iteration 14, loss = 1.08431675\n",
      "Iteration 15, loss = 1.07346984\n",
      "Iteration 16, loss = 1.04627513\n",
      "Iteration 17, loss = 1.03401381\n",
      "Iteration 18, loss = 1.06129397\n",
      "Iteration 19, loss = 1.21279335\n",
      "Iteration 20, loss = 1.25675128\n",
      "Iteration 21, loss = 1.15479854\n",
      "Iteration 22, loss = 1.06556048\n",
      "Iteration 23, loss = 1.03336763\n",
      "Iteration 24, loss = 1.14959087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22002503\n",
      "Iteration 12, loss = 1.03081820\n",
      "Iteration 13, loss = 1.00963062\n",
      "Iteration 14, loss = 1.08431675\n",
      "Iteration 15, loss = 1.07346984\n",
      "Iteration 16, loss = 1.04627513\n",
      "Iteration 17, loss = 1.03401381\n",
      "Iteration 18, loss = 1.06129397\n",
      "Iteration 19, loss = 1.21279335\n",
      "Iteration 20, loss = 1.25675128\n",
      "Iteration 21, loss = 1.15479854\n",
      "Iteration 22, loss = 1.06556048\n",
      "Iteration 23, loss = 1.03336763\n",
      "Iteration 24, loss = 1.14959087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22002503\n",
      "Iteration 2, loss = 1.12099860\n",
      "Iteration 3, loss = 1.03878418\n",
      "Iteration 4, loss = 1.05907557\n",
      "Iteration 5, loss = 1.05158666\n",
      "Iteration 6, loss = 1.02903853\n",
      "Iteration 7, loss = 1.04447525\n",
      "Iteration 8, loss = 1.00721339\n",
      "Iteration 9, loss = 1.00663120\n",
      "Iteration 10, loss = 1.08588296\n",
      "Iteration 11, loss = 1.04498302\n",
      "Iteration 12, loss = 1.00949941\n",
      "Iteration 13, loss = 0.99944621\n",
      "Iteration 14, loss = 1.04257499\n",
      "Iteration 15, loss = 1.06651573\n",
      "Iteration 2, loss = 1.12099860\n",
      "Iteration 3, loss = 1.03878418\n",
      "Iteration 4, loss = 1.05907557\n",
      "Iteration 5, loss = 1.05158666\n",
      "Iteration 6, loss = 1.02903853\n",
      "Iteration 7, loss = 1.04447525\n",
      "Iteration 8, loss = 1.00721339\n",
      "Iteration 9, loss = 1.00663120\n",
      "Iteration 10, loss = 1.08588296\n",
      "Iteration 11, loss = 1.04498302\n",
      "Iteration 12, loss = 1.00949941\n",
      "Iteration 13, loss = 0.99944621\n",
      "Iteration 14, loss = 1.04257499\n",
      "Iteration 15, loss = 1.06651573\n",
      "Iteration 16, loss = 1.05004752\n",
      "Iteration 17, loss = 1.09527251\n",
      "Iteration 18, loss = 1.06254514\n",
      "Iteration 19, loss = 1.19186046\n",
      "Iteration 20, loss = 1.27512022\n",
      "Iteration 21, loss = 1.27700261\n",
      "Iteration 22, loss = 1.26963117\n",
      "Iteration 23, loss = 1.27352034\n",
      "Iteration 24, loss = 1.28134662\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23255692\n",
      "Iteration 2, loss = 1.12912121\n",
      "Iteration 3, loss = 1.06562377\n",
      "Iteration 4, loss = 1.12101942\n",
      "Iteration 5, loss = 1.04330788\n",
      "Iteration 16, loss = 1.05004752\n",
      "Iteration 17, loss = 1.09527251\n",
      "Iteration 18, loss = 1.06254514\n",
      "Iteration 19, loss = 1.19186046\n",
      "Iteration 20, loss = 1.27512022\n",
      "Iteration 21, loss = 1.27700261\n",
      "Iteration 22, loss = 1.26963117\n",
      "Iteration 23, loss = 1.27352034\n",
      "Iteration 24, loss = 1.28134662\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23255692\n",
      "Iteration 2, loss = 1.12912121\n",
      "Iteration 3, loss = 1.06562377\n",
      "Iteration 4, loss = 1.12101942\n",
      "Iteration 5, loss = 1.04330788\n",
      "Iteration 6, loss = 1.01044476\n",
      "Iteration 7, loss = 0.98143754\n",
      "Iteration 8, loss = 1.23585666\n",
      "Iteration 9, loss = 1.29593244\n",
      "Iteration 10, loss = 1.26066968\n",
      "Iteration 11, loss = 1.27744042\n",
      "Iteration 12, loss = 1.25217039\n",
      "Iteration 13, loss = 1.27734370\n",
      "Iteration 14, loss = 1.26068935\n",
      "Iteration 15, loss = 1.25996024\n",
      "Iteration 16, loss = 1.27853804\n",
      "Iteration 17, loss = 1.27118267\n",
      "Iteration 18, loss = 1.25909493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17772583\n",
      "Iteration 6, loss = 1.01044476\n",
      "Iteration 7, loss = 0.98143754\n",
      "Iteration 8, loss = 1.23585666\n",
      "Iteration 9, loss = 1.29593244\n",
      "Iteration 10, loss = 1.26066968\n",
      "Iteration 11, loss = 1.27744042\n",
      "Iteration 12, loss = 1.25217039\n",
      "Iteration 13, loss = 1.27734370\n",
      "Iteration 14, loss = 1.26068935\n",
      "Iteration 15, loss = 1.25996024\n",
      "Iteration 16, loss = 1.27853804\n",
      "Iteration 17, loss = 1.27118267\n",
      "Iteration 18, loss = 1.25909493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17772583\n",
      "Iteration 2, loss = 0.99402579\n",
      "Iteration 3, loss = 1.03735589\n",
      "Iteration 4, loss = 1.10174250\n",
      "Iteration 5, loss = 0.96786515\n",
      "Iteration 6, loss = 0.98202218\n",
      "Iteration 7, loss = 1.01810564\n",
      "Iteration 8, loss = 1.03056244\n",
      "Iteration 9, loss = 1.02428038\n",
      "Iteration 10, loss = 0.96607119\n",
      "Iteration 11, loss = 1.03439652\n",
      "Iteration 12, loss = 1.01398393\n",
      "Iteration 13, loss = 0.97202503\n",
      "Iteration 14, loss = 0.97742991\n",
      "Iteration 15, loss = 0.96266958\n",
      "Iteration 16, loss = 0.93441946\n",
      "Iteration 2, loss = 0.99402579\n",
      "Iteration 3, loss = 1.03735589\n",
      "Iteration 4, loss = 1.10174250\n",
      "Iteration 5, loss = 0.96786515\n",
      "Iteration 6, loss = 0.98202218\n",
      "Iteration 7, loss = 1.01810564\n",
      "Iteration 8, loss = 1.03056244\n",
      "Iteration 9, loss = 1.02428038\n",
      "Iteration 10, loss = 0.96607119\n",
      "Iteration 11, loss = 1.03439652\n",
      "Iteration 12, loss = 1.01398393\n",
      "Iteration 13, loss = 0.97202503\n",
      "Iteration 14, loss = 0.97742991\n",
      "Iteration 15, loss = 0.96266958\n",
      "Iteration 16, loss = 0.93441946\n",
      "Iteration 17, loss = 0.98371685\n",
      "Iteration 18, loss = 0.95371509\n",
      "Iteration 19, loss = 0.98910248\n",
      "Iteration 20, loss = 1.01344121\n",
      "Iteration 21, loss = 1.00544578\n",
      "Iteration 22, loss = 0.99936583\n",
      "Iteration 23, loss = 0.97810055\n",
      "Iteration 24, loss = 1.04516310\n",
      "Iteration 25, loss = 0.98612921\n",
      "Iteration 26, loss = 0.95130692\n",
      "Iteration 27, loss = 0.93862792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22351819\n",
      "Iteration 2, loss = 1.04586765\n",
      "Iteration 3, loss = 1.03046392\n",
      "Iteration 4, loss = 1.04372017\n",
      "Iteration 5, loss = 0.96465049\n",
      "Iteration 17, loss = 0.98371685\n",
      "Iteration 18, loss = 0.95371509\n",
      "Iteration 19, loss = 0.98910248\n",
      "Iteration 20, loss = 1.01344121\n",
      "Iteration 21, loss = 1.00544578\n",
      "Iteration 22, loss = 0.99936583\n",
      "Iteration 23, loss = 0.97810055\n",
      "Iteration 24, loss = 1.04516310\n",
      "Iteration 25, loss = 0.98612921\n",
      "Iteration 26, loss = 0.95130692\n",
      "Iteration 27, loss = 0.93862792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22351819\n",
      "Iteration 2, loss = 1.04586765\n",
      "Iteration 3, loss = 1.03046392\n",
      "Iteration 4, loss = 1.04372017\n",
      "Iteration 5, loss = 0.96465049\n",
      "Iteration 6, loss = 1.02087450\n",
      "Iteration 7, loss = 0.99439077\n",
      "Iteration 8, loss = 0.99765774\n",
      "Iteration 9, loss = 1.05756025\n",
      "Iteration 10, loss = 1.01322662\n",
      "Iteration 11, loss = 1.00405899\n",
      "Iteration 12, loss = 1.02359940\n",
      "Iteration 13, loss = 0.99346449\n",
      "Iteration 14, loss = 0.95587791\n",
      "Iteration 15, loss = 1.02680914\n",
      "Iteration 16, loss = 1.03595591\n",
      "Iteration 17, loss = 1.01108838\n",
      "Iteration 18, loss = 1.06763785\n",
      "Iteration 19, loss = 1.07662702\n",
      "Iteration 20, loss = 1.09820830\n",
      "Iteration 6, loss = 1.02087450\n",
      "Iteration 7, loss = 0.99439077\n",
      "Iteration 8, loss = 0.99765774\n",
      "Iteration 9, loss = 1.05756025\n",
      "Iteration 10, loss = 1.01322662\n",
      "Iteration 11, loss = 1.00405899\n",
      "Iteration 12, loss = 1.02359940\n",
      "Iteration 13, loss = 0.99346449\n",
      "Iteration 14, loss = 0.95587791\n",
      "Iteration 15, loss = 1.02680914\n",
      "Iteration 16, loss = 1.03595591\n",
      "Iteration 17, loss = 1.01108838\n",
      "Iteration 18, loss = 1.06763785\n",
      "Iteration 19, loss = 1.07662702\n",
      "Iteration 20, loss = 1.09820830\n",
      "Iteration 21, loss = 1.07810583\n",
      "Iteration 22, loss = 1.12719082\n",
      "Iteration 23, loss = 0.98972598\n",
      "Iteration 24, loss = 1.00272946\n",
      "Iteration 25, loss = 1.00409835\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23549427\n",
      "Iteration 2, loss = 1.14519139\n",
      "Iteration 3, loss = 1.06786415\n",
      "Iteration 4, loss = 1.11180947\n",
      "Iteration 5, loss = 1.07943883\n",
      "Iteration 6, loss = 1.04938877\n",
      "Iteration 7, loss = 1.10351074\n",
      "Iteration 8, loss = 1.05305411\n",
      "Iteration 9, loss = 1.07781249\n",
      "Iteration 21, loss = 1.07810583\n",
      "Iteration 22, loss = 1.12719082\n",
      "Iteration 23, loss = 0.98972598\n",
      "Iteration 24, loss = 1.00272946\n",
      "Iteration 25, loss = 1.00409835\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23549427\n",
      "Iteration 2, loss = 1.14519139\n",
      "Iteration 3, loss = 1.06786415\n",
      "Iteration 4, loss = 1.11180947\n",
      "Iteration 5, loss = 1.07943883\n",
      "Iteration 6, loss = 1.04938877\n",
      "Iteration 7, loss = 1.10351074\n",
      "Iteration 8, loss = 1.05305411\n",
      "Iteration 9, loss = 1.07781249\n",
      "Iteration 10, loss = 1.07551244\n",
      "Iteration 11, loss = 1.05740015\n",
      "Iteration 12, loss = 1.03081820\n",
      "Iteration 13, loss = 1.00963062\n",
      "Iteration 14, loss = 1.08431675\n",
      "Iteration 15, loss = 1.07346984\n",
      "Iteration 16, loss = 1.04627513\n",
      "Iteration 17, loss = 1.03401381\n",
      "Iteration 18, loss = 1.06129397\n",
      "Iteration 19, loss = 1.21279335\n",
      "Iteration 20, loss = 1.25675128\n",
      "Iteration 21, loss = 1.15479854\n",
      "Iteration 22, loss = 1.06556048\n",
      "Iteration 23, loss = 1.03336763\n",
      "Iteration 24, loss = 1.14959087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22002503\n",
      "Iteration 10, loss = 1.07551244\n",
      "Iteration 11, loss = 1.05740015\n",
      "Iteration 12, loss = 1.03081820\n",
      "Iteration 13, loss = 1.00963062\n",
      "Iteration 14, loss = 1.08431675\n",
      "Iteration 15, loss = 1.07346984\n",
      "Iteration 16, loss = 1.04627513\n",
      "Iteration 17, loss = 1.03401381\n",
      "Iteration 18, loss = 1.06129397\n",
      "Iteration 19, loss = 1.21279335\n",
      "Iteration 20, loss = 1.25675128\n",
      "Iteration 21, loss = 1.15479854\n",
      "Iteration 22, loss = 1.06556048\n",
      "Iteration 23, loss = 1.03336763\n",
      "Iteration 24, loss = 1.14959087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22002503\n",
      "Iteration 2, loss = 1.12099860\n",
      "Iteration 3, loss = 1.03878418\n",
      "Iteration 4, loss = 1.05907557\n",
      "Iteration 5, loss = 1.05158666\n",
      "Iteration 6, loss = 1.02903853\n",
      "Iteration 7, loss = 1.04447525\n",
      "Iteration 8, loss = 1.00721339\n",
      "Iteration 9, loss = 1.00663120\n",
      "Iteration 10, loss = 1.08588296\n",
      "Iteration 11, loss = 1.04498302\n",
      "Iteration 12, loss = 1.00949941\n",
      "Iteration 13, loss = 0.99944621\n",
      "Iteration 14, loss = 1.04257499\n",
      "Iteration 15, loss = 1.06651573\n",
      "Iteration 2, loss = 1.12099860\n",
      "Iteration 3, loss = 1.03878418\n",
      "Iteration 4, loss = 1.05907557\n",
      "Iteration 5, loss = 1.05158666\n",
      "Iteration 6, loss = 1.02903853\n",
      "Iteration 7, loss = 1.04447525\n",
      "Iteration 8, loss = 1.00721339\n",
      "Iteration 9, loss = 1.00663120\n",
      "Iteration 10, loss = 1.08588296\n",
      "Iteration 11, loss = 1.04498302\n",
      "Iteration 12, loss = 1.00949941\n",
      "Iteration 13, loss = 0.99944621\n",
      "Iteration 14, loss = 1.04257499\n",
      "Iteration 15, loss = 1.06651573\n",
      "Iteration 16, loss = 1.05004752\n",
      "Iteration 17, loss = 1.09527251\n",
      "Iteration 18, loss = 1.06254514\n",
      "Iteration 19, loss = 1.19186046\n",
      "Iteration 20, loss = 1.27512022\n",
      "Iteration 21, loss = 1.27700261\n",
      "Iteration 22, loss = 1.26963117\n",
      "Iteration 23, loss = 1.27352034\n",
      "Iteration 24, loss = 1.28134662\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23859657\n",
      "Iteration 2, loss = 1.35238149\n",
      "Iteration 3, loss = 1.24124522\n",
      "Iteration 4, loss = 1.24554995\n",
      "Iteration 5, loss = 1.26090590\n",
      "Iteration 6, loss = 1.24519402\n",
      "Iteration 16, loss = 1.05004752\n",
      "Iteration 17, loss = 1.09527251\n",
      "Iteration 18, loss = 1.06254514\n",
      "Iteration 19, loss = 1.19186046\n",
      "Iteration 20, loss = 1.27512022\n",
      "Iteration 21, loss = 1.27700261\n",
      "Iteration 22, loss = 1.26963117\n",
      "Iteration 23, loss = 1.27352034\n",
      "Iteration 24, loss = 1.28134662\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23859657\n",
      "Iteration 2, loss = 1.35238149\n",
      "Iteration 3, loss = 1.24124522\n",
      "Iteration 4, loss = 1.24554995\n",
      "Iteration 5, loss = 1.26090590\n",
      "Iteration 6, loss = 1.24519402\n",
      "Iteration 7, loss = 1.24253138\n",
      "Iteration 8, loss = 1.25332905\n",
      "Iteration 9, loss = 1.25503239\n",
      "Iteration 10, loss = 1.25195722\n",
      "Iteration 1, loss = 1.22748249\n",
      "Iteration 2, loss = 1.23927594\n",
      "Iteration 3, loss = 1.27667471\n",
      "Iteration 4, loss = 1.26025004\n",
      "Iteration 5, loss = 1.26391119\n",
      "Iteration 6, loss = 1.24638292\n",
      "Iteration 7, loss = 1.25401392\n",
      "Iteration 8, loss = 1.27839157\n",
      "Iteration 9, loss = 1.27396711\n",
      "Iteration 10, loss = 1.24855456\n",
      "Iteration 7, loss = 1.24253138\n",
      "Iteration 8, loss = 1.25332905\n",
      "Iteration 9, loss = 1.25503239\n",
      "Iteration 10, loss = 1.25195722\n",
      "Iteration 1, loss = 1.22748249\n",
      "Iteration 2, loss = 1.23927594\n",
      "Iteration 3, loss = 1.27667471\n",
      "Iteration 4, loss = 1.26025004\n",
      "Iteration 5, loss = 1.26391119\n",
      "Iteration 6, loss = 1.24638292\n",
      "Iteration 7, loss = 1.25401392\n",
      "Iteration 8, loss = 1.27839157\n",
      "Iteration 9, loss = 1.27396711\n",
      "Iteration 10, loss = 1.24855456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.24770845\n",
      "Iteration 2, loss = 1.26122068\n",
      "Iteration 3, loss = 1.25483266\n",
      "Iteration 4, loss = 1.25549500\n",
      "Iteration 5, loss = 1.18539297\n",
      "Iteration 6, loss = 1.05048203\n",
      "Iteration 7, loss = 1.12037439\n",
      "Iteration 8, loss = 1.01193733\n",
      "Iteration 9, loss = 1.04679332\n",
      "Iteration 10, loss = 0.97360504\n",
      "Iteration 1, loss = 1.26442129\n",
      "Iteration 2, loss = 1.26268906\n",
      "Iteration 1, loss = 1.24770845\n",
      "Iteration 2, loss = 1.26122068\n",
      "Iteration 3, loss = 1.25483266\n",
      "Iteration 4, loss = 1.25549500\n",
      "Iteration 5, loss = 1.18539297\n",
      "Iteration 6, loss = 1.05048203\n",
      "Iteration 7, loss = 1.12037439\n",
      "Iteration 8, loss = 1.01193733\n",
      "Iteration 9, loss = 1.04679332\n",
      "Iteration 10, loss = 0.97360504\n",
      "Iteration 1, loss = 1.26442129\n",
      "Iteration 2, loss = 1.26268906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.25491041\n",
      "Iteration 4, loss = 1.25768410\n",
      "Iteration 5, loss = 1.26300560\n",
      "Iteration 6, loss = 1.25358851\n",
      "Iteration 7, loss = 1.25374631\n",
      "Iteration 8, loss = 1.25822373\n",
      "Iteration 9, loss = 1.24926304\n",
      "Iteration 10, loss = 1.25960843\n",
      "Iteration 1, loss = 1.27892518\n",
      "Iteration 2, loss = 1.26734066\n",
      "Iteration 3, loss = 1.26417841\n",
      "Iteration 4, loss = 1.26113238\n",
      "Iteration 5, loss = 1.27108591\n",
      "Iteration 3, loss = 1.25491041\n",
      "Iteration 4, loss = 1.25768410\n",
      "Iteration 5, loss = 1.26300560\n",
      "Iteration 6, loss = 1.25358851\n",
      "Iteration 7, loss = 1.25374631\n",
      "Iteration 8, loss = 1.25822373\n",
      "Iteration 9, loss = 1.24926304\n",
      "Iteration 10, loss = 1.25960843\n",
      "Iteration 1, loss = 1.27892518\n",
      "Iteration 2, loss = 1.26734066\n",
      "Iteration 3, loss = 1.26417841\n",
      "Iteration 4, loss = 1.26113238\n",
      "Iteration 5, loss = 1.27108591\n",
      "Iteration 6, loss = 1.25231030\n",
      "Iteration 7, loss = 1.25746534\n",
      "Iteration 8, loss = 1.27891551\n",
      "Iteration 9, loss = 1.26146052\n",
      "Iteration 10, loss = 1.27817128\n",
      "Iteration 1, loss = 1.23859657\n",
      "Iteration 2, loss = 1.35238149\n",
      "Iteration 3, loss = 1.24124522\n",
      "Iteration 4, loss = 1.24554995\n",
      "Iteration 5, loss = 1.26090590\n",
      "Iteration 6, loss = 1.24519402\n",
      "Iteration 7, loss = 1.24253138\n",
      "Iteration 8, loss = 1.25332905\n",
      "Iteration 9, loss = 1.25503239\n",
      "Iteration 6, loss = 1.25231030\n",
      "Iteration 7, loss = 1.25746534\n",
      "Iteration 8, loss = 1.27891551\n",
      "Iteration 9, loss = 1.26146052\n",
      "Iteration 10, loss = 1.27817128\n",
      "Iteration 1, loss = 1.23859657\n",
      "Iteration 2, loss = 1.35238149\n",
      "Iteration 3, loss = 1.24124522\n",
      "Iteration 4, loss = 1.24554995\n",
      "Iteration 5, loss = 1.26090590\n",
      "Iteration 6, loss = 1.24519402\n",
      "Iteration 7, loss = 1.24253138\n",
      "Iteration 8, loss = 1.25332905\n",
      "Iteration 9, loss = 1.25503239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25195722\n",
      "Iteration 11, loss = 1.26828302\n",
      "Iteration 12, loss = 1.24374862\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22748249\n",
      "Iteration 2, loss = 1.23927594\n",
      "Iteration 3, loss = 1.27667471\n",
      "Iteration 4, loss = 1.26025004\n",
      "Iteration 5, loss = 1.26391119\n",
      "Iteration 6, loss = 1.24638292\n",
      "Iteration 7, loss = 1.25401392\n",
      "Iteration 8, loss = 1.27839157\n",
      "Iteration 9, loss = 1.27396711\n",
      "Iteration 10, loss = 1.24855456\n",
      "Iteration 11, loss = 1.25163611\n",
      "Iteration 10, loss = 1.25195722\n",
      "Iteration 11, loss = 1.26828302\n",
      "Iteration 12, loss = 1.24374862\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22748249\n",
      "Iteration 2, loss = 1.23927594\n",
      "Iteration 3, loss = 1.27667471\n",
      "Iteration 4, loss = 1.26025004\n",
      "Iteration 5, loss = 1.26391119\n",
      "Iteration 6, loss = 1.24638292\n",
      "Iteration 7, loss = 1.25401392\n",
      "Iteration 8, loss = 1.27839157\n",
      "Iteration 9, loss = 1.27396711\n",
      "Iteration 10, loss = 1.24855456\n",
      "Iteration 11, loss = 1.25163611\n",
      "Iteration 12, loss = 1.25731150\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24770845\n",
      "Iteration 2, loss = 1.26122068\n",
      "Iteration 3, loss = 1.25483266\n",
      "Iteration 4, loss = 1.25549500\n",
      "Iteration 5, loss = 1.18539297\n",
      "Iteration 6, loss = 1.05048203\n",
      "Iteration 7, loss = 1.12037439\n",
      "Iteration 8, loss = 1.01193733\n",
      "Iteration 9, loss = 1.04679332\n",
      "Iteration 10, loss = 0.97360504\n",
      "Iteration 11, loss = 0.97627400\n",
      "Iteration 12, loss = 0.99160196\n",
      "Iteration 13, loss = 1.02623313\n",
      "Iteration 12, loss = 1.25731150\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24770845\n",
      "Iteration 2, loss = 1.26122068\n",
      "Iteration 3, loss = 1.25483266\n",
      "Iteration 4, loss = 1.25549500\n",
      "Iteration 5, loss = 1.18539297\n",
      "Iteration 6, loss = 1.05048203\n",
      "Iteration 7, loss = 1.12037439\n",
      "Iteration 8, loss = 1.01193733\n",
      "Iteration 9, loss = 1.04679332\n",
      "Iteration 10, loss = 0.97360504\n",
      "Iteration 11, loss = 0.97627400\n",
      "Iteration 12, loss = 0.99160196\n",
      "Iteration 13, loss = 1.02623313\n",
      "Iteration 14, loss = 0.99095241\n",
      "Iteration 15, loss = 1.00456101\n",
      "Iteration 16, loss = 0.98288619\n",
      "Iteration 17, loss = 0.97412102\n",
      "Iteration 18, loss = 1.05802645\n",
      "Iteration 19, loss = 1.27759423\n",
      "Iteration 20, loss = 1.28169216\n",
      "Iteration 21, loss = 1.27118582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26442129\n",
      "Iteration 2, loss = 1.26268906\n",
      "Iteration 3, loss = 1.25491041\n",
      "Iteration 4, loss = 1.25768410\n",
      "Iteration 5, loss = 1.26300560\n",
      "Iteration 6, loss = 1.25358851\n",
      "Iteration 14, loss = 0.99095241\n",
      "Iteration 15, loss = 1.00456101\n",
      "Iteration 16, loss = 0.98288619\n",
      "Iteration 17, loss = 0.97412102\n",
      "Iteration 18, loss = 1.05802645\n",
      "Iteration 19, loss = 1.27759423\n",
      "Iteration 20, loss = 1.28169216\n",
      "Iteration 21, loss = 1.27118582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26442129\n",
      "Iteration 2, loss = 1.26268906\n",
      "Iteration 3, loss = 1.25491041\n",
      "Iteration 4, loss = 1.25768410\n",
      "Iteration 5, loss = 1.26300560\n",
      "Iteration 6, loss = 1.25358851\n",
      "Iteration 7, loss = 1.25374631\n",
      "Iteration 8, loss = 1.25822373\n",
      "Iteration 9, loss = 1.24926304\n",
      "Iteration 10, loss = 1.25960843\n",
      "Iteration 11, loss = 1.25236694\n",
      "Iteration 12, loss = 1.25228261\n",
      "Iteration 13, loss = 1.25370150\n",
      "Iteration 14, loss = 1.25317589\n",
      "Iteration 15, loss = 1.25395812\n",
      "Iteration 16, loss = 1.26742275\n",
      "Iteration 17, loss = 1.24594408\n",
      "Iteration 18, loss = 1.25945152\n",
      "Iteration 19, loss = 1.25497102\n",
      "Iteration 20, loss = 1.24349462\n",
      "Iteration 21, loss = 1.26359414\n",
      "Iteration 7, loss = 1.25374631\n",
      "Iteration 8, loss = 1.25822373\n",
      "Iteration 9, loss = 1.24926304\n",
      "Iteration 10, loss = 1.25960843\n",
      "Iteration 11, loss = 1.25236694\n",
      "Iteration 12, loss = 1.25228261\n",
      "Iteration 13, loss = 1.25370150\n",
      "Iteration 14, loss = 1.25317589\n",
      "Iteration 15, loss = 1.25395812\n",
      "Iteration 16, loss = 1.26742275\n",
      "Iteration 17, loss = 1.24594408\n",
      "Iteration 18, loss = 1.25945152\n",
      "Iteration 19, loss = 1.25497102\n",
      "Iteration 20, loss = 1.24349462\n",
      "Iteration 21, loss = 1.26359414\n",
      "Iteration 22, loss = 1.25913257\n",
      "Iteration 23, loss = 1.27115019\n",
      "Iteration 24, loss = 1.26126121\n",
      "Iteration 25, loss = 1.30685924\n",
      "Iteration 26, loss = 1.24995437\n",
      "Iteration 27, loss = 1.26699286\n",
      "Iteration 28, loss = 1.23944280\n",
      "Iteration 29, loss = 1.24274474\n",
      "Iteration 30, loss = 1.25604768\n",
      "Iteration 31, loss = 1.25341888\n",
      "Iteration 32, loss = 1.25310036\n",
      "Iteration 33, loss = 1.26249920\n",
      "Iteration 34, loss = 1.25865398\n",
      "Iteration 35, loss = 1.24904826\n",
      "Iteration 36, loss = 1.25064800\n",
      "Iteration 37, loss = 1.24640378\n",
      "Iteration 22, loss = 1.25913257\n",
      "Iteration 23, loss = 1.27115019\n",
      "Iteration 24, loss = 1.26126121\n",
      "Iteration 25, loss = 1.30685924\n",
      "Iteration 26, loss = 1.24995437\n",
      "Iteration 27, loss = 1.26699286\n",
      "Iteration 28, loss = 1.23944280\n",
      "Iteration 29, loss = 1.24274474\n",
      "Iteration 30, loss = 1.25604768\n",
      "Iteration 31, loss = 1.25341888\n",
      "Iteration 32, loss = 1.25310036\n",
      "Iteration 33, loss = 1.26249920\n",
      "Iteration 34, loss = 1.25865398\n",
      "Iteration 35, loss = 1.24904826\n",
      "Iteration 36, loss = 1.25064800\n",
      "Iteration 37, loss = 1.24640378\n",
      "Iteration 38, loss = 1.25824244\n",
      "Iteration 39, loss = 1.25760207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27892518\n",
      "Iteration 2, loss = 1.26734066\n",
      "Iteration 3, loss = 1.26417841\n",
      "Iteration 4, loss = 1.26113238\n",
      "Iteration 5, loss = 1.27108591\n",
      "Iteration 6, loss = 1.25231030\n",
      "Iteration 7, loss = 1.25746534\n",
      "Iteration 8, loss = 1.27891551\n",
      "Iteration 9, loss = 1.26146052\n",
      "Iteration 10, loss = 1.27817128\n",
      "Iteration 11, loss = 1.26410780\n",
      "Iteration 38, loss = 1.25824244\n",
      "Iteration 39, loss = 1.25760207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27892518\n",
      "Iteration 2, loss = 1.26734066\n",
      "Iteration 3, loss = 1.26417841\n",
      "Iteration 4, loss = 1.26113238\n",
      "Iteration 5, loss = 1.27108591\n",
      "Iteration 6, loss = 1.25231030\n",
      "Iteration 7, loss = 1.25746534\n",
      "Iteration 8, loss = 1.27891551\n",
      "Iteration 9, loss = 1.26146052\n",
      "Iteration 10, loss = 1.27817128\n",
      "Iteration 11, loss = 1.26410780\n",
      "Iteration 12, loss = 1.26629095\n",
      "Iteration 13, loss = 1.27692890\n",
      "Iteration 14, loss = 1.26426534\n",
      "Iteration 15, loss = 1.25673522\n",
      "Iteration 16, loss = 1.29118952\n",
      "Iteration 17, loss = 1.26289030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23859657\n",
      "Iteration 2, loss = 1.35238149\n",
      "Iteration 3, loss = 1.24124522\n",
      "Iteration 4, loss = 1.24554995\n",
      "Iteration 5, loss = 1.26090590\n",
      "Iteration 6, loss = 1.24519402\n",
      "Iteration 7, loss = 1.24253138\n",
      "Iteration 8, loss = 1.25332905\n",
      "Iteration 9, loss = 1.25503239\n",
      "Iteration 12, loss = 1.26629095\n",
      "Iteration 13, loss = 1.27692890\n",
      "Iteration 14, loss = 1.26426534\n",
      "Iteration 15, loss = 1.25673522\n",
      "Iteration 16, loss = 1.29118952\n",
      "Iteration 17, loss = 1.26289030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23859657\n",
      "Iteration 2, loss = 1.35238149\n",
      "Iteration 3, loss = 1.24124522\n",
      "Iteration 4, loss = 1.24554995\n",
      "Iteration 5, loss = 1.26090590\n",
      "Iteration 6, loss = 1.24519402\n",
      "Iteration 7, loss = 1.24253138\n",
      "Iteration 8, loss = 1.25332905\n",
      "Iteration 9, loss = 1.25503239\n",
      "Iteration 10, loss = 1.25195722\n",
      "Iteration 11, loss = 1.26828302\n",
      "Iteration 12, loss = 1.24374862\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22748249\n",
      "Iteration 2, loss = 1.23927594\n",
      "Iteration 3, loss = 1.27667471\n",
      "Iteration 4, loss = 1.26025004\n",
      "Iteration 5, loss = 1.26391119\n",
      "Iteration 6, loss = 1.24638292\n",
      "Iteration 7, loss = 1.25401392\n",
      "Iteration 8, loss = 1.27839157\n",
      "Iteration 9, loss = 1.27396711\n",
      "Iteration 10, loss = 1.24855456\n",
      "Iteration 10, loss = 1.25195722\n",
      "Iteration 11, loss = 1.26828302\n",
      "Iteration 12, loss = 1.24374862\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22748249\n",
      "Iteration 2, loss = 1.23927594\n",
      "Iteration 3, loss = 1.27667471\n",
      "Iteration 4, loss = 1.26025004\n",
      "Iteration 5, loss = 1.26391119\n",
      "Iteration 6, loss = 1.24638292\n",
      "Iteration 7, loss = 1.25401392\n",
      "Iteration 8, loss = 1.27839157\n",
      "Iteration 9, loss = 1.27396711\n",
      "Iteration 10, loss = 1.24855456\n",
      "Iteration 11, loss = 1.25163611\n",
      "Iteration 12, loss = 1.25731150\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24770845\n",
      "Iteration 2, loss = 1.26122068\n",
      "Iteration 3, loss = 1.25483266\n",
      "Iteration 4, loss = 1.25549500\n",
      "Iteration 5, loss = 1.18539297\n",
      "Iteration 6, loss = 1.05048203\n",
      "Iteration 7, loss = 1.12037439\n",
      "Iteration 8, loss = 1.01193733\n",
      "Iteration 9, loss = 1.04679332\n",
      "Iteration 10, loss = 0.97360504\n",
      "Iteration 11, loss = 0.97627400\n",
      "Iteration 11, loss = 1.25163611\n",
      "Iteration 12, loss = 1.25731150\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24770845\n",
      "Iteration 2, loss = 1.26122068\n",
      "Iteration 3, loss = 1.25483266\n",
      "Iteration 4, loss = 1.25549500\n",
      "Iteration 5, loss = 1.18539297\n",
      "Iteration 6, loss = 1.05048203\n",
      "Iteration 7, loss = 1.12037439\n",
      "Iteration 8, loss = 1.01193733\n",
      "Iteration 9, loss = 1.04679332\n",
      "Iteration 10, loss = 0.97360504\n",
      "Iteration 11, loss = 0.97627400\n",
      "Iteration 12, loss = 0.99160196\n",
      "Iteration 13, loss = 1.02623313\n",
      "Iteration 14, loss = 0.99095241\n",
      "Iteration 15, loss = 1.00456101\n",
      "Iteration 16, loss = 0.98288619\n",
      "Iteration 17, loss = 0.97412102\n",
      "Iteration 18, loss = 1.05802645\n",
      "Iteration 19, loss = 1.27759423\n",
      "Iteration 20, loss = 1.28169216\n",
      "Iteration 21, loss = 1.27118582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26442129\n",
      "Iteration 2, loss = 1.26268906\n",
      "Iteration 3, loss = 1.25491041\n",
      "Iteration 4, loss = 1.25768410\n",
      "Iteration 12, loss = 0.99160196\n",
      "Iteration 13, loss = 1.02623313\n",
      "Iteration 14, loss = 0.99095241\n",
      "Iteration 15, loss = 1.00456101\n",
      "Iteration 16, loss = 0.98288619\n",
      "Iteration 17, loss = 0.97412102\n",
      "Iteration 18, loss = 1.05802645\n",
      "Iteration 19, loss = 1.27759423\n",
      "Iteration 20, loss = 1.28169216\n",
      "Iteration 21, loss = 1.27118582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26442129\n",
      "Iteration 2, loss = 1.26268906\n",
      "Iteration 3, loss = 1.25491041\n",
      "Iteration 4, loss = 1.25768410\n",
      "Iteration 5, loss = 1.26300560\n",
      "Iteration 6, loss = 1.25358851\n",
      "Iteration 7, loss = 1.25374631\n",
      "Iteration 8, loss = 1.25822373\n",
      "Iteration 9, loss = 1.24926304\n",
      "Iteration 10, loss = 1.25960843\n",
      "Iteration 11, loss = 1.25236694\n",
      "Iteration 12, loss = 1.25228261\n",
      "Iteration 13, loss = 1.25370150\n",
      "Iteration 14, loss = 1.25317589\n",
      "Iteration 15, loss = 1.25395812\n",
      "Iteration 16, loss = 1.26742275\n",
      "Iteration 17, loss = 1.24594408\n",
      "Iteration 18, loss = 1.25945152\n",
      "Iteration 5, loss = 1.26300560\n",
      "Iteration 6, loss = 1.25358851\n",
      "Iteration 7, loss = 1.25374631\n",
      "Iteration 8, loss = 1.25822373\n",
      "Iteration 9, loss = 1.24926304\n",
      "Iteration 10, loss = 1.25960843\n",
      "Iteration 11, loss = 1.25236694\n",
      "Iteration 12, loss = 1.25228261\n",
      "Iteration 13, loss = 1.25370150\n",
      "Iteration 14, loss = 1.25317589\n",
      "Iteration 15, loss = 1.25395812\n",
      "Iteration 16, loss = 1.26742275\n",
      "Iteration 17, loss = 1.24594408\n",
      "Iteration 18, loss = 1.25945152\n",
      "Iteration 19, loss = 1.25497102\n",
      "Iteration 20, loss = 1.24349462\n",
      "Iteration 21, loss = 1.26359414\n",
      "Iteration 22, loss = 1.25913257\n",
      "Iteration 23, loss = 1.27115019\n",
      "Iteration 24, loss = 1.26126121\n",
      "Iteration 25, loss = 1.30685924\n",
      "Iteration 26, loss = 1.24995437\n",
      "Iteration 27, loss = 1.26699286\n",
      "Iteration 28, loss = 1.23944280\n",
      "Iteration 29, loss = 1.24274474\n",
      "Iteration 30, loss = 1.25604768\n",
      "Iteration 31, loss = 1.25341888\n",
      "Iteration 32, loss = 1.25310036\n",
      "Iteration 33, loss = 1.26249920\n",
      "Iteration 19, loss = 1.25497102\n",
      "Iteration 20, loss = 1.24349462\n",
      "Iteration 21, loss = 1.26359414\n",
      "Iteration 22, loss = 1.25913257\n",
      "Iteration 23, loss = 1.27115019\n",
      "Iteration 24, loss = 1.26126121\n",
      "Iteration 25, loss = 1.30685924\n",
      "Iteration 26, loss = 1.24995437\n",
      "Iteration 27, loss = 1.26699286\n",
      "Iteration 28, loss = 1.23944280\n",
      "Iteration 29, loss = 1.24274474\n",
      "Iteration 30, loss = 1.25604768\n",
      "Iteration 31, loss = 1.25341888\n",
      "Iteration 32, loss = 1.25310036\n",
      "Iteration 33, loss = 1.26249920\n",
      "Iteration 34, loss = 1.25865398\n",
      "Iteration 35, loss = 1.24904826\n",
      "Iteration 36, loss = 1.25064800\n",
      "Iteration 37, loss = 1.24640378\n",
      "Iteration 38, loss = 1.25824244\n",
      "Iteration 39, loss = 1.25760207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27892518\n",
      "Iteration 2, loss = 1.26734066\n",
      "Iteration 3, loss = 1.26417841\n",
      "Iteration 4, loss = 1.26113238\n",
      "Iteration 5, loss = 1.27108591\n",
      "Iteration 6, loss = 1.25231030\n",
      "Iteration 7, loss = 1.25746534\n",
      "Iteration 34, loss = 1.25865398\n",
      "Iteration 35, loss = 1.24904826\n",
      "Iteration 36, loss = 1.25064800\n",
      "Iteration 37, loss = 1.24640378\n",
      "Iteration 38, loss = 1.25824244\n",
      "Iteration 39, loss = 1.25760207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27892518\n",
      "Iteration 2, loss = 1.26734066\n",
      "Iteration 3, loss = 1.26417841\n",
      "Iteration 4, loss = 1.26113238\n",
      "Iteration 5, loss = 1.27108591\n",
      "Iteration 6, loss = 1.25231030\n",
      "Iteration 7, loss = 1.25746534\n",
      "Iteration 8, loss = 1.27891551\n",
      "Iteration 9, loss = 1.26146052\n",
      "Iteration 10, loss = 1.27817128\n",
      "Iteration 11, loss = 1.26410780\n",
      "Iteration 12, loss = 1.26629095\n",
      "Iteration 13, loss = 1.27692890\n",
      "Iteration 14, loss = 1.26426534\n",
      "Iteration 15, loss = 1.25673522\n",
      "Iteration 16, loss = 1.29118952\n",
      "Iteration 17, loss = 1.26289030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18953148\n",
      "Iteration 2, loss = 1.09233516\n",
      "Iteration 3, loss = 1.02646607\n",
      "Iteration 4, loss = 1.04314350\n",
      "Iteration 8, loss = 1.27891551\n",
      "Iteration 9, loss = 1.26146052\n",
      "Iteration 10, loss = 1.27817128\n",
      "Iteration 11, loss = 1.26410780\n",
      "Iteration 12, loss = 1.26629095\n",
      "Iteration 13, loss = 1.27692890\n",
      "Iteration 14, loss = 1.26426534\n",
      "Iteration 15, loss = 1.25673522\n",
      "Iteration 16, loss = 1.29118952\n",
      "Iteration 17, loss = 1.26289030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18953148\n",
      "Iteration 2, loss = 1.09233516\n",
      "Iteration 3, loss = 1.02646607\n",
      "Iteration 4, loss = 1.04314350\n",
      "Iteration 5, loss = 0.97507855\n",
      "Iteration 6, loss = 0.98918908\n",
      "Iteration 7, loss = 0.98308687\n",
      "Iteration 8, loss = 0.96046551\n",
      "Iteration 9, loss = 0.93628703\n",
      "Iteration 10, loss = 0.93675703\n",
      "Iteration 1, loss = 1.21834342\n",
      "Iteration 2, loss = 1.10231364\n",
      "Iteration 3, loss = 0.98648012\n",
      "Iteration 4, loss = 0.95564123\n",
      "Iteration 5, loss = 0.94071379\n",
      "Iteration 6, loss = 0.97965309\n",
      "Iteration 5, loss = 0.97507855\n",
      "Iteration 6, loss = 0.98918908\n",
      "Iteration 7, loss = 0.98308687\n",
      "Iteration 8, loss = 0.96046551\n",
      "Iteration 9, loss = 0.93628703\n",
      "Iteration 10, loss = 0.93675703\n",
      "Iteration 1, loss = 1.21834342\n",
      "Iteration 2, loss = 1.10231364\n",
      "Iteration 3, loss = 0.98648012\n",
      "Iteration 4, loss = 0.95564123\n",
      "Iteration 5, loss = 0.94071379\n",
      "Iteration 6, loss = 0.97965309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.90636274\n",
      "Iteration 8, loss = 0.89088923\n",
      "Iteration 9, loss = 0.92759408\n",
      "Iteration 10, loss = 0.87752469\n",
      "Iteration 1, loss = 1.23427048\n",
      "Iteration 2, loss = 1.12657655\n",
      "Iteration 3, loss = 1.06119695\n",
      "Iteration 4, loss = 1.00917858\n",
      "Iteration 5, loss = 0.98877187\n",
      "Iteration 6, loss = 1.02490843\n",
      "Iteration 7, loss = 0.96920969\n",
      "Iteration 7, loss = 0.90636274\n",
      "Iteration 8, loss = 0.89088923\n",
      "Iteration 9, loss = 0.92759408\n",
      "Iteration 10, loss = 0.87752469\n",
      "Iteration 1, loss = 1.23427048\n",
      "Iteration 2, loss = 1.12657655\n",
      "Iteration 3, loss = 1.06119695\n",
      "Iteration 4, loss = 1.00917858\n",
      "Iteration 5, loss = 0.98877187\n",
      "Iteration 6, loss = 1.02490843\n",
      "Iteration 7, loss = 0.96920969\n",
      "Iteration 8, loss = 0.94759457\n",
      "Iteration 9, loss = 1.00050338\n",
      "Iteration 10, loss = 0.91936335\n",
      "Iteration 1, loss = 1.21219307\n",
      "Iteration 2, loss = 1.14852409\n",
      "Iteration 3, loss = 1.10527272\n",
      "Iteration 4, loss = 1.07082947\n",
      "Iteration 5, loss = 1.00698453\n",
      "Iteration 6, loss = 1.04912915\n",
      "Iteration 7, loss = 0.97726965\n",
      "Iteration 8, loss = 0.97040008\n",
      "Iteration 9, loss = 0.97054324\n",
      "Iteration 10, loss = 0.93252782\n",
      "Iteration 8, loss = 0.94759457\n",
      "Iteration 9, loss = 1.00050338\n",
      "Iteration 10, loss = 0.91936335\n",
      "Iteration 1, loss = 1.21219307\n",
      "Iteration 2, loss = 1.14852409\n",
      "Iteration 3, loss = 1.10527272\n",
      "Iteration 4, loss = 1.07082947\n",
      "Iteration 5, loss = 1.00698453\n",
      "Iteration 6, loss = 1.04912915\n",
      "Iteration 7, loss = 0.97726965\n",
      "Iteration 8, loss = 0.97040008\n",
      "Iteration 9, loss = 0.97054324\n",
      "Iteration 10, loss = 0.93252782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21674953\n",
      "Iteration 2, loss = 1.11777475\n",
      "Iteration 3, loss = 1.09372839\n",
      "Iteration 4, loss = 1.04528100\n",
      "Iteration 5, loss = 0.97450577\n",
      "Iteration 6, loss = 0.97647145\n",
      "Iteration 7, loss = 0.95227185\n",
      "Iteration 8, loss = 0.96059838\n",
      "Iteration 9, loss = 0.97711563\n",
      "Iteration 10, loss = 0.94751256\n",
      "Iteration 1, loss = 1.18953148\n",
      "Iteration 2, loss = 1.09233516\n",
      "Iteration 3, loss = 1.02646607\n",
      "Iteration 1, loss = 1.21674953\n",
      "Iteration 2, loss = 1.11777475\n",
      "Iteration 3, loss = 1.09372839\n",
      "Iteration 4, loss = 1.04528100\n",
      "Iteration 5, loss = 0.97450577\n",
      "Iteration 6, loss = 0.97647145\n",
      "Iteration 7, loss = 0.95227185\n",
      "Iteration 8, loss = 0.96059838\n",
      "Iteration 9, loss = 0.97711563\n",
      "Iteration 10, loss = 0.94751256\n",
      "Iteration 1, loss = 1.18953148\n",
      "Iteration 2, loss = 1.09233516\n",
      "Iteration 3, loss = 1.02646607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.04314350\n",
      "Iteration 5, loss = 0.97507855\n",
      "Iteration 6, loss = 0.98918908\n",
      "Iteration 7, loss = 0.98308687\n",
      "Iteration 8, loss = 0.96046551\n",
      "Iteration 9, loss = 0.93628703\n",
      "Iteration 10, loss = 0.93675703\n",
      "Iteration 11, loss = 0.93663419\n",
      "Iteration 12, loss = 0.93010523\n",
      "Iteration 13, loss = 0.93404739\n",
      "Iteration 14, loss = 0.89761515\n",
      "Iteration 15, loss = 0.95791213\n",
      "Iteration 16, loss = 0.93385622\n",
      "Iteration 17, loss = 0.89956568\n",
      "Iteration 4, loss = 1.04314350\n",
      "Iteration 5, loss = 0.97507855\n",
      "Iteration 6, loss = 0.98918908\n",
      "Iteration 7, loss = 0.98308687\n",
      "Iteration 8, loss = 0.96046551\n",
      "Iteration 9, loss = 0.93628703\n",
      "Iteration 10, loss = 0.93675703\n",
      "Iteration 11, loss = 0.93663419\n",
      "Iteration 12, loss = 0.93010523\n",
      "Iteration 13, loss = 0.93404739\n",
      "Iteration 14, loss = 0.89761515\n",
      "Iteration 15, loss = 0.95791213\n",
      "Iteration 16, loss = 0.93385622\n",
      "Iteration 17, loss = 0.89956568\n",
      "Iteration 18, loss = 0.90217024\n",
      "Iteration 19, loss = 0.87630699\n",
      "Iteration 20, loss = 0.88200163\n",
      "Iteration 21, loss = 0.88084785\n",
      "Iteration 22, loss = 0.89350218\n",
      "Iteration 23, loss = 0.88070720\n",
      "Iteration 24, loss = 0.87291558\n",
      "Iteration 25, loss = 0.84758675\n",
      "Iteration 26, loss = 0.84637495\n",
      "Iteration 27, loss = 0.88635948\n",
      "Iteration 28, loss = 0.85146965\n",
      "Iteration 29, loss = 0.84207315\n",
      "Iteration 30, loss = 0.84088338\n",
      "Iteration 31, loss = 0.86800269\n",
      "Iteration 32, loss = 0.83519375\n",
      "Iteration 33, loss = 0.87079596\n",
      "Iteration 18, loss = 0.90217024\n",
      "Iteration 19, loss = 0.87630699\n",
      "Iteration 20, loss = 0.88200163\n",
      "Iteration 21, loss = 0.88084785\n",
      "Iteration 22, loss = 0.89350218\n",
      "Iteration 23, loss = 0.88070720\n",
      "Iteration 24, loss = 0.87291558\n",
      "Iteration 25, loss = 0.84758675\n",
      "Iteration 26, loss = 0.84637495\n",
      "Iteration 27, loss = 0.88635948\n",
      "Iteration 28, loss = 0.85146965\n",
      "Iteration 29, loss = 0.84207315\n",
      "Iteration 30, loss = 0.84088338\n",
      "Iteration 31, loss = 0.86800269\n",
      "Iteration 32, loss = 0.83519375\n",
      "Iteration 33, loss = 0.87079596\n",
      "Iteration 34, loss = 0.83405681\n",
      "Iteration 35, loss = 0.81245499\n",
      "Iteration 36, loss = 0.84876753\n",
      "Iteration 37, loss = 0.85304936\n",
      "Iteration 38, loss = 0.82857793\n",
      "Iteration 39, loss = 0.79288035\n",
      "Iteration 40, loss = 0.84102231\n",
      "Iteration 41, loss = 0.79483968\n",
      "Iteration 42, loss = 0.80911359\n",
      "Iteration 43, loss = 0.84345591\n",
      "Iteration 44, loss = 0.78967713\n",
      "Iteration 45, loss = 0.80960857\n",
      "Iteration 46, loss = 0.79426031\n",
      "Iteration 47, loss = 0.77660454\n",
      "Iteration 48, loss = 0.85608806\n",
      "Iteration 34, loss = 0.83405681\n",
      "Iteration 35, loss = 0.81245499\n",
      "Iteration 36, loss = 0.84876753\n",
      "Iteration 37, loss = 0.85304936\n",
      "Iteration 38, loss = 0.82857793\n",
      "Iteration 39, loss = 0.79288035\n",
      "Iteration 40, loss = 0.84102231\n",
      "Iteration 41, loss = 0.79483968\n",
      "Iteration 42, loss = 0.80911359\n",
      "Iteration 43, loss = 0.84345591\n",
      "Iteration 44, loss = 0.78967713\n",
      "Iteration 45, loss = 0.80960857\n",
      "Iteration 46, loss = 0.79426031\n",
      "Iteration 47, loss = 0.77660454\n",
      "Iteration 48, loss = 0.85608806\n",
      "Iteration 49, loss = 0.93637284\n",
      "Iteration 50, loss = 0.86804172\n",
      "Iteration 1, loss = 1.21834342\n",
      "Iteration 2, loss = 1.10231364\n",
      "Iteration 3, loss = 0.98648012\n",
      "Iteration 4, loss = 0.95564123\n",
      "Iteration 5, loss = 0.94071379\n",
      "Iteration 6, loss = 0.97965309\n",
      "Iteration 7, loss = 0.90636274\n",
      "Iteration 8, loss = 0.89088923\n",
      "Iteration 9, loss = 0.92759408\n",
      "Iteration 10, loss = 0.87752469\n",
      "Iteration 49, loss = 0.93637284\n",
      "Iteration 50, loss = 0.86804172\n",
      "Iteration 1, loss = 1.21834342\n",
      "Iteration 2, loss = 1.10231364\n",
      "Iteration 3, loss = 0.98648012\n",
      "Iteration 4, loss = 0.95564123\n",
      "Iteration 5, loss = 0.94071379\n",
      "Iteration 6, loss = 0.97965309\n",
      "Iteration 7, loss = 0.90636274\n",
      "Iteration 8, loss = 0.89088923\n",
      "Iteration 9, loss = 0.92759408\n",
      "Iteration 10, loss = 0.87752469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.91998159\n",
      "Iteration 12, loss = 0.89880381\n",
      "Iteration 13, loss = 0.89490122\n",
      "Iteration 14, loss = 0.88048531\n",
      "Iteration 15, loss = 0.92805123\n",
      "Iteration 16, loss = 0.89509252\n",
      "Iteration 17, loss = 0.92667572\n",
      "Iteration 18, loss = 0.87451653\n",
      "Iteration 19, loss = 0.86119958\n",
      "Iteration 20, loss = 0.86563041\n",
      "Iteration 21, loss = 0.86016433\n",
      "Iteration 22, loss = 0.83594113\n",
      "Iteration 23, loss = 0.85418027\n",
      "Iteration 24, loss = 0.83985314\n",
      "Iteration 25, loss = 0.84589020\n",
      "Iteration 11, loss = 0.91998159\n",
      "Iteration 12, loss = 0.89880381\n",
      "Iteration 13, loss = 0.89490122\n",
      "Iteration 14, loss = 0.88048531\n",
      "Iteration 15, loss = 0.92805123\n",
      "Iteration 16, loss = 0.89509252\n",
      "Iteration 17, loss = 0.92667572\n",
      "Iteration 18, loss = 0.87451653\n",
      "Iteration 19, loss = 0.86119958\n",
      "Iteration 20, loss = 0.86563041\n",
      "Iteration 21, loss = 0.86016433\n",
      "Iteration 22, loss = 0.83594113\n",
      "Iteration 23, loss = 0.85418027\n",
      "Iteration 24, loss = 0.83985314\n",
      "Iteration 25, loss = 0.84589020\n",
      "Iteration 26, loss = 0.85363787\n",
      "Iteration 27, loss = 0.86142535\n",
      "Iteration 28, loss = 0.83028324\n",
      "Iteration 29, loss = 0.81653435\n",
      "Iteration 30, loss = 0.82922909\n",
      "Iteration 31, loss = 0.81266742\n",
      "Iteration 32, loss = 0.80120384\n",
      "Iteration 33, loss = 0.82840399\n",
      "Iteration 34, loss = 0.80832734\n",
      "Iteration 35, loss = 0.79350469\n",
      "Iteration 36, loss = 0.84182727\n",
      "Iteration 37, loss = 0.80222919\n",
      "Iteration 38, loss = 0.77720812\n",
      "Iteration 39, loss = 0.75385918\n",
      "Iteration 40, loss = 0.78186215\n",
      "Iteration 41, loss = 0.76990508\n",
      "Iteration 26, loss = 0.85363787\n",
      "Iteration 27, loss = 0.86142535\n",
      "Iteration 28, loss = 0.83028324\n",
      "Iteration 29, loss = 0.81653435\n",
      "Iteration 30, loss = 0.82922909\n",
      "Iteration 31, loss = 0.81266742\n",
      "Iteration 32, loss = 0.80120384\n",
      "Iteration 33, loss = 0.82840399\n",
      "Iteration 34, loss = 0.80832734\n",
      "Iteration 35, loss = 0.79350469\n",
      "Iteration 36, loss = 0.84182727\n",
      "Iteration 37, loss = 0.80222919\n",
      "Iteration 38, loss = 0.77720812\n",
      "Iteration 39, loss = 0.75385918\n",
      "Iteration 40, loss = 0.78186215\n",
      "Iteration 41, loss = 0.76990508\n",
      "Iteration 42, loss = 0.77539163\n",
      "Iteration 43, loss = 0.73544392\n",
      "Iteration 44, loss = 0.75760182\n",
      "Iteration 45, loss = 0.73398494\n",
      "Iteration 46, loss = 0.75761298\n",
      "Iteration 47, loss = 0.74914966\n",
      "Iteration 48, loss = 0.75335684\n",
      "Iteration 49, loss = 0.87654227\n",
      "Iteration 50, loss = 0.80242772\n",
      "Iteration 1, loss = 1.23427048\n",
      "Iteration 2, loss = 1.12657655\n",
      "Iteration 3, loss = 1.06119695\n",
      "Iteration 4, loss = 1.00917858\n",
      "Iteration 5, loss = 0.98877187\n",
      "Iteration 42, loss = 0.77539163\n",
      "Iteration 43, loss = 0.73544392\n",
      "Iteration 44, loss = 0.75760182\n",
      "Iteration 45, loss = 0.73398494\n",
      "Iteration 46, loss = 0.75761298\n",
      "Iteration 47, loss = 0.74914966\n",
      "Iteration 48, loss = 0.75335684\n",
      "Iteration 49, loss = 0.87654227\n",
      "Iteration 50, loss = 0.80242772\n",
      "Iteration 1, loss = 1.23427048\n",
      "Iteration 2, loss = 1.12657655\n",
      "Iteration 3, loss = 1.06119695\n",
      "Iteration 4, loss = 1.00917858\n",
      "Iteration 5, loss = 0.98877187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.02490843\n",
      "Iteration 7, loss = 0.96920969\n",
      "Iteration 8, loss = 0.94759457\n",
      "Iteration 9, loss = 1.00050338\n",
      "Iteration 10, loss = 0.91936335\n",
      "Iteration 11, loss = 0.97018674\n",
      "Iteration 12, loss = 0.93938147\n",
      "Iteration 13, loss = 0.92846185\n",
      "Iteration 14, loss = 0.93404041\n",
      "Iteration 15, loss = 0.95782876\n",
      "Iteration 16, loss = 0.95123734\n",
      "Iteration 17, loss = 0.94666784\n",
      "Iteration 18, loss = 0.91970926\n",
      "Iteration 19, loss = 0.93830327\n",
      "Iteration 6, loss = 1.02490843\n",
      "Iteration 7, loss = 0.96920969\n",
      "Iteration 8, loss = 0.94759457\n",
      "Iteration 9, loss = 1.00050338\n",
      "Iteration 10, loss = 0.91936335\n",
      "Iteration 11, loss = 0.97018674\n",
      "Iteration 12, loss = 0.93938147\n",
      "Iteration 13, loss = 0.92846185\n",
      "Iteration 14, loss = 0.93404041\n",
      "Iteration 15, loss = 0.95782876\n",
      "Iteration 16, loss = 0.95123734\n",
      "Iteration 17, loss = 0.94666784\n",
      "Iteration 18, loss = 0.91970926\n",
      "Iteration 19, loss = 0.93830327\n",
      "Iteration 20, loss = 0.89825957\n",
      "Iteration 21, loss = 0.89534965\n",
      "Iteration 22, loss = 0.91498613\n",
      "Iteration 23, loss = 0.92924596\n",
      "Iteration 24, loss = 0.91141291\n",
      "Iteration 25, loss = 0.89725643\n",
      "Iteration 26, loss = 0.91267409\n",
      "Iteration 27, loss = 0.89456502\n",
      "Iteration 28, loss = 0.86164946\n",
      "Iteration 29, loss = 0.88039089\n",
      "Iteration 30, loss = 0.85191012\n",
      "Iteration 31, loss = 0.85080864\n",
      "Iteration 32, loss = 0.84149592\n",
      "Iteration 33, loss = 0.88171171\n",
      "Iteration 34, loss = 0.90076430\n",
      "Iteration 20, loss = 0.89825957\n",
      "Iteration 21, loss = 0.89534965\n",
      "Iteration 22, loss = 0.91498613\n",
      "Iteration 23, loss = 0.92924596\n",
      "Iteration 24, loss = 0.91141291\n",
      "Iteration 25, loss = 0.89725643\n",
      "Iteration 26, loss = 0.91267409\n",
      "Iteration 27, loss = 0.89456502\n",
      "Iteration 28, loss = 0.86164946\n",
      "Iteration 29, loss = 0.88039089\n",
      "Iteration 30, loss = 0.85191012\n",
      "Iteration 31, loss = 0.85080864\n",
      "Iteration 32, loss = 0.84149592\n",
      "Iteration 33, loss = 0.88171171\n",
      "Iteration 34, loss = 0.90076430\n",
      "Iteration 35, loss = 0.88502936\n",
      "Iteration 36, loss = 0.85163364\n",
      "Iteration 37, loss = 0.86305679\n",
      "Iteration 38, loss = 0.84817759\n",
      "Iteration 39, loss = 0.84341141\n",
      "Iteration 40, loss = 0.84625594\n",
      "Iteration 41, loss = 0.84465790\n",
      "Iteration 42, loss = 0.81916662\n",
      "Iteration 43, loss = 0.82193274\n",
      "Iteration 44, loss = 0.80963993\n",
      "Iteration 45, loss = 0.80301585\n",
      "Iteration 46, loss = 0.84545509\n",
      "Iteration 47, loss = 0.81046559\n",
      "Iteration 48, loss = 0.84578890\n",
      "Iteration 49, loss = 0.88402504\n",
      "Iteration 50, loss = 0.82767154\n",
      "Iteration 35, loss = 0.88502936\n",
      "Iteration 36, loss = 0.85163364\n",
      "Iteration 37, loss = 0.86305679\n",
      "Iteration 38, loss = 0.84817759\n",
      "Iteration 39, loss = 0.84341141\n",
      "Iteration 40, loss = 0.84625594\n",
      "Iteration 41, loss = 0.84465790\n",
      "Iteration 42, loss = 0.81916662\n",
      "Iteration 43, loss = 0.82193274\n",
      "Iteration 44, loss = 0.80963993\n",
      "Iteration 45, loss = 0.80301585\n",
      "Iteration 46, loss = 0.84545509\n",
      "Iteration 47, loss = 0.81046559\n",
      "Iteration 48, loss = 0.84578890\n",
      "Iteration 49, loss = 0.88402504\n",
      "Iteration 50, loss = 0.82767154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21219307\n",
      "Iteration 2, loss = 1.14852409\n",
      "Iteration 3, loss = 1.10527272\n",
      "Iteration 4, loss = 1.07082947\n",
      "Iteration 5, loss = 1.00698453\n",
      "Iteration 6, loss = 1.04912915\n",
      "Iteration 7, loss = 0.97726965\n",
      "Iteration 8, loss = 0.97040008\n",
      "Iteration 9, loss = 0.97054324\n",
      "Iteration 10, loss = 0.93252782\n",
      "Iteration 11, loss = 0.96448423\n",
      "Iteration 12, loss = 0.93382675\n",
      "Iteration 13, loss = 0.94024420\n",
      "Iteration 1, loss = 1.21219307\n",
      "Iteration 2, loss = 1.14852409\n",
      "Iteration 3, loss = 1.10527272\n",
      "Iteration 4, loss = 1.07082947\n",
      "Iteration 5, loss = 1.00698453\n",
      "Iteration 6, loss = 1.04912915\n",
      "Iteration 7, loss = 0.97726965\n",
      "Iteration 8, loss = 0.97040008\n",
      "Iteration 9, loss = 0.97054324\n",
      "Iteration 10, loss = 0.93252782\n",
      "Iteration 11, loss = 0.96448423\n",
      "Iteration 12, loss = 0.93382675\n",
      "Iteration 13, loss = 0.94024420\n",
      "Iteration 14, loss = 0.93068797\n",
      "Iteration 15, loss = 0.95493349\n",
      "Iteration 16, loss = 0.93767423\n",
      "Iteration 17, loss = 0.96017641\n",
      "Iteration 18, loss = 0.91772348\n",
      "Iteration 19, loss = 0.97231432\n",
      "Iteration 20, loss = 0.90018515\n",
      "Iteration 21, loss = 0.91683242\n",
      "Iteration 22, loss = 0.91423883\n",
      "Iteration 23, loss = 0.91596110\n",
      "Iteration 24, loss = 0.90840116\n",
      "Iteration 25, loss = 0.90976547\n",
      "Iteration 26, loss = 0.89064313\n",
      "Iteration 27, loss = 0.86970466\n",
      "Iteration 28, loss = 0.87152292\n",
      "Iteration 29, loss = 0.88471333\n",
      "Iteration 14, loss = 0.93068797\n",
      "Iteration 15, loss = 0.95493349\n",
      "Iteration 16, loss = 0.93767423\n",
      "Iteration 17, loss = 0.96017641\n",
      "Iteration 18, loss = 0.91772348\n",
      "Iteration 19, loss = 0.97231432\n",
      "Iteration 20, loss = 0.90018515\n",
      "Iteration 21, loss = 0.91683242\n",
      "Iteration 22, loss = 0.91423883\n",
      "Iteration 23, loss = 0.91596110\n",
      "Iteration 24, loss = 0.90840116\n",
      "Iteration 25, loss = 0.90976547\n",
      "Iteration 26, loss = 0.89064313\n",
      "Iteration 27, loss = 0.86970466\n",
      "Iteration 28, loss = 0.87152292\n",
      "Iteration 29, loss = 0.88471333\n",
      "Iteration 30, loss = 0.82500482\n",
      "Iteration 31, loss = 0.85899776\n",
      "Iteration 32, loss = 0.85853731\n",
      "Iteration 33, loss = 0.83113631\n",
      "Iteration 34, loss = 0.91431818\n",
      "Iteration 35, loss = 0.85463646\n",
      "Iteration 36, loss = 0.89322114\n",
      "Iteration 37, loss = 0.85007296\n",
      "Iteration 38, loss = 0.83436308\n",
      "Iteration 39, loss = 0.82149282\n",
      "Iteration 40, loss = 0.82782544\n",
      "Iteration 41, loss = 0.80603007\n",
      "Iteration 42, loss = 0.79464969\n",
      "Iteration 43, loss = 0.90367798\n",
      "Iteration 44, loss = 0.84574144\n",
      "Iteration 45, loss = 0.84479762\n",
      "Iteration 30, loss = 0.82500482\n",
      "Iteration 31, loss = 0.85899776\n",
      "Iteration 32, loss = 0.85853731\n",
      "Iteration 33, loss = 0.83113631\n",
      "Iteration 34, loss = 0.91431818\n",
      "Iteration 35, loss = 0.85463646\n",
      "Iteration 36, loss = 0.89322114\n",
      "Iteration 37, loss = 0.85007296\n",
      "Iteration 38, loss = 0.83436308\n",
      "Iteration 39, loss = 0.82149282\n",
      "Iteration 40, loss = 0.82782544\n",
      "Iteration 41, loss = 0.80603007\n",
      "Iteration 42, loss = 0.79464969\n",
      "Iteration 43, loss = 0.90367798\n",
      "Iteration 44, loss = 0.84574144\n",
      "Iteration 45, loss = 0.84479762\n",
      "Iteration 46, loss = 0.83528683\n",
      "Iteration 47, loss = 0.81307807\n",
      "Iteration 48, loss = 0.81354062\n",
      "Iteration 49, loss = 0.81145126\n",
      "Iteration 50, loss = 0.79349218\n",
      "Iteration 1, loss = 1.21674953\n",
      "Iteration 2, loss = 1.11777475\n",
      "Iteration 3, loss = 1.09372839\n",
      "Iteration 4, loss = 1.04528100\n",
      "Iteration 5, loss = 0.97450577\n",
      "Iteration 6, loss = 0.97647145\n",
      "Iteration 7, loss = 0.95227185\n",
      "Iteration 46, loss = 0.83528683\n",
      "Iteration 47, loss = 0.81307807\n",
      "Iteration 48, loss = 0.81354062\n",
      "Iteration 49, loss = 0.81145126\n",
      "Iteration 50, loss = 0.79349218\n",
      "Iteration 1, loss = 1.21674953\n",
      "Iteration 2, loss = 1.11777475\n",
      "Iteration 3, loss = 1.09372839\n",
      "Iteration 4, loss = 1.04528100\n",
      "Iteration 5, loss = 0.97450577\n",
      "Iteration 6, loss = 0.97647145\n",
      "Iteration 7, loss = 0.95227185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.96059838\n",
      "Iteration 9, loss = 0.97711563\n",
      "Iteration 10, loss = 0.94751256\n",
      "Iteration 11, loss = 0.93215661\n",
      "Iteration 12, loss = 0.93908439\n",
      "Iteration 13, loss = 0.92188406\n",
      "Iteration 14, loss = 0.92147790\n",
      "Iteration 15, loss = 0.94224870\n",
      "Iteration 16, loss = 0.90920281\n",
      "Iteration 17, loss = 0.93446940\n",
      "Iteration 18, loss = 0.89337546\n",
      "Iteration 19, loss = 0.95141946\n",
      "Iteration 20, loss = 0.88602164\n",
      "Iteration 21, loss = 0.88832789\n",
      "Iteration 8, loss = 0.96059838\n",
      "Iteration 9, loss = 0.97711563\n",
      "Iteration 10, loss = 0.94751256\n",
      "Iteration 11, loss = 0.93215661\n",
      "Iteration 12, loss = 0.93908439\n",
      "Iteration 13, loss = 0.92188406\n",
      "Iteration 14, loss = 0.92147790\n",
      "Iteration 15, loss = 0.94224870\n",
      "Iteration 16, loss = 0.90920281\n",
      "Iteration 17, loss = 0.93446940\n",
      "Iteration 18, loss = 0.89337546\n",
      "Iteration 19, loss = 0.95141946\n",
      "Iteration 20, loss = 0.88602164\n",
      "Iteration 21, loss = 0.88832789\n",
      "Iteration 22, loss = 0.87660729\n",
      "Iteration 23, loss = 0.87640843\n",
      "Iteration 24, loss = 0.88750725\n",
      "Iteration 25, loss = 0.88065680\n",
      "Iteration 26, loss = 0.87664618\n",
      "Iteration 27, loss = 0.86631439\n",
      "Iteration 28, loss = 0.87063533\n",
      "Iteration 29, loss = 0.86959414\n",
      "Iteration 30, loss = 0.87181378\n",
      "Iteration 31, loss = 0.85789416\n",
      "Iteration 32, loss = 0.85183622\n",
      "Iteration 33, loss = 0.86068005\n",
      "Iteration 34, loss = 0.85578099\n",
      "Iteration 35, loss = 0.87639496\n",
      "Iteration 36, loss = 0.84150916\n",
      "Iteration 22, loss = 0.87660729\n",
      "Iteration 23, loss = 0.87640843\n",
      "Iteration 24, loss = 0.88750725\n",
      "Iteration 25, loss = 0.88065680\n",
      "Iteration 26, loss = 0.87664618\n",
      "Iteration 27, loss = 0.86631439\n",
      "Iteration 28, loss = 0.87063533\n",
      "Iteration 29, loss = 0.86959414\n",
      "Iteration 30, loss = 0.87181378\n",
      "Iteration 31, loss = 0.85789416\n",
      "Iteration 32, loss = 0.85183622\n",
      "Iteration 33, loss = 0.86068005\n",
      "Iteration 34, loss = 0.85578099\n",
      "Iteration 35, loss = 0.87639496\n",
      "Iteration 36, loss = 0.84150916\n",
      "Iteration 37, loss = 0.87595115\n",
      "Iteration 38, loss = 0.81929231\n",
      "Iteration 39, loss = 0.82887918\n",
      "Iteration 40, loss = 0.84118883\n",
      "Iteration 41, loss = 0.80160020\n",
      "Iteration 42, loss = 0.78762863\n",
      "Iteration 43, loss = 0.87434982\n",
      "Iteration 44, loss = 0.82766517\n",
      "Iteration 45, loss = 0.84388611\n",
      "Iteration 46, loss = 0.84867694\n",
      "Iteration 47, loss = 0.80404868\n",
      "Iteration 48, loss = 0.79467183\n",
      "Iteration 49, loss = 0.80782670\n",
      "Iteration 50, loss = 0.78889386\n",
      "Iteration 1, loss = 1.18953148\n",
      "Iteration 37, loss = 0.87595115\n",
      "Iteration 38, loss = 0.81929231\n",
      "Iteration 39, loss = 0.82887918\n",
      "Iteration 40, loss = 0.84118883\n",
      "Iteration 41, loss = 0.80160020\n",
      "Iteration 42, loss = 0.78762863\n",
      "Iteration 43, loss = 0.87434982\n",
      "Iteration 44, loss = 0.82766517\n",
      "Iteration 45, loss = 0.84388611\n",
      "Iteration 46, loss = 0.84867694\n",
      "Iteration 47, loss = 0.80404868\n",
      "Iteration 48, loss = 0.79467183\n",
      "Iteration 49, loss = 0.80782670\n",
      "Iteration 50, loss = 0.78889386\n",
      "Iteration 1, loss = 1.18953148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.09233516\n",
      "Iteration 3, loss = 1.02646607\n",
      "Iteration 4, loss = 1.04314350\n",
      "Iteration 5, loss = 0.97507855\n",
      "Iteration 6, loss = 0.98918908\n",
      "Iteration 7, loss = 0.98308687\n",
      "Iteration 8, loss = 0.96046551\n",
      "Iteration 9, loss = 0.93628703\n",
      "Iteration 10, loss = 0.93675703\n",
      "Iteration 11, loss = 0.93663419\n",
      "Iteration 12, loss = 0.93010523\n",
      "Iteration 13, loss = 0.93404739\n",
      "Iteration 14, loss = 0.89761515\n",
      "Iteration 15, loss = 0.95791213\n",
      "Iteration 2, loss = 1.09233516\n",
      "Iteration 3, loss = 1.02646607\n",
      "Iteration 4, loss = 1.04314350\n",
      "Iteration 5, loss = 0.97507855\n",
      "Iteration 6, loss = 0.98918908\n",
      "Iteration 7, loss = 0.98308687\n",
      "Iteration 8, loss = 0.96046551\n",
      "Iteration 9, loss = 0.93628703\n",
      "Iteration 10, loss = 0.93675703\n",
      "Iteration 11, loss = 0.93663419\n",
      "Iteration 12, loss = 0.93010523\n",
      "Iteration 13, loss = 0.93404739\n",
      "Iteration 14, loss = 0.89761515\n",
      "Iteration 15, loss = 0.95791213\n",
      "Iteration 16, loss = 0.93385622\n",
      "Iteration 17, loss = 0.89956568\n",
      "Iteration 18, loss = 0.90217024\n",
      "Iteration 19, loss = 0.87630699\n",
      "Iteration 20, loss = 0.88200163\n",
      "Iteration 21, loss = 0.88084785\n",
      "Iteration 22, loss = 0.89350218\n",
      "Iteration 23, loss = 0.88070720\n",
      "Iteration 24, loss = 0.87291558\n",
      "Iteration 25, loss = 0.84758675\n",
      "Iteration 26, loss = 0.84637495\n",
      "Iteration 27, loss = 0.88635948\n",
      "Iteration 28, loss = 0.85146965\n",
      "Iteration 29, loss = 0.84207315\n",
      "Iteration 30, loss = 0.84088338\n",
      "Iteration 16, loss = 0.93385622\n",
      "Iteration 17, loss = 0.89956568\n",
      "Iteration 18, loss = 0.90217024\n",
      "Iteration 19, loss = 0.87630699\n",
      "Iteration 20, loss = 0.88200163\n",
      "Iteration 21, loss = 0.88084785\n",
      "Iteration 22, loss = 0.89350218\n",
      "Iteration 23, loss = 0.88070720\n",
      "Iteration 24, loss = 0.87291558\n",
      "Iteration 25, loss = 0.84758675\n",
      "Iteration 26, loss = 0.84637495\n",
      "Iteration 27, loss = 0.88635948\n",
      "Iteration 28, loss = 0.85146965\n",
      "Iteration 29, loss = 0.84207315\n",
      "Iteration 30, loss = 0.84088338\n",
      "Iteration 31, loss = 0.86800269\n",
      "Iteration 32, loss = 0.83519375\n",
      "Iteration 33, loss = 0.87079596\n",
      "Iteration 34, loss = 0.83405681\n",
      "Iteration 35, loss = 0.81245499\n",
      "Iteration 36, loss = 0.84876753\n",
      "Iteration 37, loss = 0.85304936\n",
      "Iteration 38, loss = 0.82857793\n",
      "Iteration 39, loss = 0.79288035\n",
      "Iteration 40, loss = 0.84102231\n",
      "Iteration 41, loss = 0.79483968\n",
      "Iteration 42, loss = 0.80911359\n",
      "Iteration 43, loss = 0.84345591\n",
      "Iteration 44, loss = 0.78967713\n",
      "Iteration 45, loss = 0.80960857\n",
      "Iteration 46, loss = 0.79426031\n",
      "Iteration 31, loss = 0.86800269\n",
      "Iteration 32, loss = 0.83519375\n",
      "Iteration 33, loss = 0.87079596\n",
      "Iteration 34, loss = 0.83405681\n",
      "Iteration 35, loss = 0.81245499\n",
      "Iteration 36, loss = 0.84876753\n",
      "Iteration 37, loss = 0.85304936\n",
      "Iteration 38, loss = 0.82857793\n",
      "Iteration 39, loss = 0.79288035\n",
      "Iteration 40, loss = 0.84102231\n",
      "Iteration 41, loss = 0.79483968\n",
      "Iteration 42, loss = 0.80911359\n",
      "Iteration 43, loss = 0.84345591\n",
      "Iteration 44, loss = 0.78967713\n",
      "Iteration 45, loss = 0.80960857\n",
      "Iteration 46, loss = 0.79426031\n",
      "Iteration 47, loss = 0.77660454\n",
      "Iteration 48, loss = 0.85608806\n",
      "Iteration 49, loss = 0.93637284\n",
      "Iteration 50, loss = 0.86804172\n",
      "Iteration 51, loss = 0.82039300\n",
      "Iteration 52, loss = 0.80732861\n",
      "Iteration 53, loss = 0.80888121\n",
      "Iteration 54, loss = 0.78007908\n",
      "Iteration 55, loss = 0.77553809\n",
      "Iteration 56, loss = 0.76937168\n",
      "Iteration 57, loss = 0.83812836\n",
      "Iteration 58, loss = 0.83632854\n",
      "Iteration 59, loss = 0.83949118\n",
      "Iteration 60, loss = 0.79569145\n",
      "Iteration 61, loss = 0.80058894\n",
      "Iteration 62, loss = 0.84642211\n",
      "Iteration 47, loss = 0.77660454\n",
      "Iteration 48, loss = 0.85608806\n",
      "Iteration 49, loss = 0.93637284\n",
      "Iteration 50, loss = 0.86804172\n",
      "Iteration 51, loss = 0.82039300\n",
      "Iteration 52, loss = 0.80732861\n",
      "Iteration 53, loss = 0.80888121\n",
      "Iteration 54, loss = 0.78007908\n",
      "Iteration 55, loss = 0.77553809\n",
      "Iteration 56, loss = 0.76937168\n",
      "Iteration 57, loss = 0.83812836\n",
      "Iteration 58, loss = 0.83632854\n",
      "Iteration 59, loss = 0.83949118\n",
      "Iteration 60, loss = 0.79569145\n",
      "Iteration 61, loss = 0.80058894\n",
      "Iteration 62, loss = 0.84642211\n",
      "Iteration 63, loss = 0.76233740\n",
      "Iteration 64, loss = 0.74730386\n",
      "Iteration 65, loss = 0.80746045\n",
      "Iteration 66, loss = 0.75891430\n",
      "Iteration 67, loss = 0.75486558\n",
      "Iteration 68, loss = 0.75111121\n",
      "Iteration 69, loss = 0.72594702\n",
      "Iteration 70, loss = 0.73710779\n",
      "Iteration 71, loss = 0.81787251\n",
      "Iteration 72, loss = 0.87513631\n",
      "Iteration 73, loss = 0.80570711\n",
      "Iteration 74, loss = 0.78814422\n",
      "Iteration 75, loss = 0.72719002\n",
      "Iteration 76, loss = 0.76424277\n",
      "Iteration 77, loss = 0.71940686\n",
      "Iteration 78, loss = 0.80203320\n",
      "Iteration 63, loss = 0.76233740\n",
      "Iteration 64, loss = 0.74730386\n",
      "Iteration 65, loss = 0.80746045\n",
      "Iteration 66, loss = 0.75891430\n",
      "Iteration 67, loss = 0.75486558\n",
      "Iteration 68, loss = 0.75111121\n",
      "Iteration 69, loss = 0.72594702\n",
      "Iteration 70, loss = 0.73710779\n",
      "Iteration 71, loss = 0.81787251\n",
      "Iteration 72, loss = 0.87513631\n",
      "Iteration 73, loss = 0.80570711\n",
      "Iteration 74, loss = 0.78814422\n",
      "Iteration 75, loss = 0.72719002\n",
      "Iteration 76, loss = 0.76424277\n",
      "Iteration 77, loss = 0.71940686\n",
      "Iteration 78, loss = 0.80203320\n",
      "Iteration 79, loss = 0.80257482\n",
      "Iteration 80, loss = 0.77517689\n",
      "Iteration 81, loss = 0.77187628\n",
      "Iteration 82, loss = 0.75129843\n",
      "Iteration 83, loss = 0.79955701\n",
      "Iteration 84, loss = 0.79805786\n",
      "Iteration 85, loss = 0.80030277\n",
      "Iteration 86, loss = 0.88499062\n",
      "Iteration 87, loss = 0.83018425\n",
      "Iteration 88, loss = 0.78049180\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21834342\n",
      "Iteration 2, loss = 1.10231364\n",
      "Iteration 3, loss = 0.98648012\n",
      "Iteration 4, loss = 0.95564123\n",
      "Iteration 79, loss = 0.80257482\n",
      "Iteration 80, loss = 0.77517689\n",
      "Iteration 81, loss = 0.77187628\n",
      "Iteration 82, loss = 0.75129843\n",
      "Iteration 83, loss = 0.79955701\n",
      "Iteration 84, loss = 0.79805786\n",
      "Iteration 85, loss = 0.80030277\n",
      "Iteration 86, loss = 0.88499062\n",
      "Iteration 87, loss = 0.83018425\n",
      "Iteration 88, loss = 0.78049180\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21834342\n",
      "Iteration 2, loss = 1.10231364\n",
      "Iteration 3, loss = 0.98648012\n",
      "Iteration 4, loss = 0.95564123\n",
      "Iteration 5, loss = 0.94071379\n",
      "Iteration 6, loss = 0.97965309\n",
      "Iteration 7, loss = 0.90636274\n",
      "Iteration 8, loss = 0.89088923\n",
      "Iteration 9, loss = 0.92759408\n",
      "Iteration 10, loss = 0.87752469\n",
      "Iteration 11, loss = 0.91998159\n",
      "Iteration 12, loss = 0.89880381\n",
      "Iteration 13, loss = 0.89490122\n",
      "Iteration 14, loss = 0.88048531\n",
      "Iteration 15, loss = 0.92805123\n",
      "Iteration 16, loss = 0.89509252\n",
      "Iteration 17, loss = 0.92667572\n",
      "Iteration 5, loss = 0.94071379\n",
      "Iteration 6, loss = 0.97965309\n",
      "Iteration 7, loss = 0.90636274\n",
      "Iteration 8, loss = 0.89088923\n",
      "Iteration 9, loss = 0.92759408\n",
      "Iteration 10, loss = 0.87752469\n",
      "Iteration 11, loss = 0.91998159\n",
      "Iteration 12, loss = 0.89880381\n",
      "Iteration 13, loss = 0.89490122\n",
      "Iteration 14, loss = 0.88048531\n",
      "Iteration 15, loss = 0.92805123\n",
      "Iteration 16, loss = 0.89509252\n",
      "Iteration 17, loss = 0.92667572\n",
      "Iteration 18, loss = 0.87451653\n",
      "Iteration 19, loss = 0.86119958\n",
      "Iteration 20, loss = 0.86563041\n",
      "Iteration 21, loss = 0.86016433\n",
      "Iteration 22, loss = 0.83594113\n",
      "Iteration 23, loss = 0.85418027\n",
      "Iteration 24, loss = 0.83985314\n",
      "Iteration 25, loss = 0.84589020\n",
      "Iteration 26, loss = 0.85363787\n",
      "Iteration 27, loss = 0.86142535\n",
      "Iteration 28, loss = 0.83028324\n",
      "Iteration 29, loss = 0.81653435\n",
      "Iteration 30, loss = 0.82922909\n",
      "Iteration 31, loss = 0.81266742\n",
      "Iteration 32, loss = 0.80120384\n",
      "Iteration 18, loss = 0.87451653\n",
      "Iteration 19, loss = 0.86119958\n",
      "Iteration 20, loss = 0.86563041\n",
      "Iteration 21, loss = 0.86016433\n",
      "Iteration 22, loss = 0.83594113\n",
      "Iteration 23, loss = 0.85418027\n",
      "Iteration 24, loss = 0.83985314\n",
      "Iteration 25, loss = 0.84589020\n",
      "Iteration 26, loss = 0.85363787\n",
      "Iteration 27, loss = 0.86142535\n",
      "Iteration 28, loss = 0.83028324\n",
      "Iteration 29, loss = 0.81653435\n",
      "Iteration 30, loss = 0.82922909\n",
      "Iteration 31, loss = 0.81266742\n",
      "Iteration 32, loss = 0.80120384\n",
      "Iteration 33, loss = 0.82840399\n",
      "Iteration 34, loss = 0.80832734\n",
      "Iteration 35, loss = 0.79350469\n",
      "Iteration 36, loss = 0.84182727\n",
      "Iteration 37, loss = 0.80222919\n",
      "Iteration 38, loss = 0.77720812\n",
      "Iteration 39, loss = 0.75385918\n",
      "Iteration 40, loss = 0.78186215\n",
      "Iteration 41, loss = 0.76990508\n",
      "Iteration 42, loss = 0.77539163\n",
      "Iteration 43, loss = 0.73544392\n",
      "Iteration 44, loss = 0.75760182\n",
      "Iteration 45, loss = 0.73398494\n",
      "Iteration 46, loss = 0.75761298\n",
      "Iteration 47, loss = 0.74914966\n",
      "Iteration 48, loss = 0.75335684\n",
      "Iteration 33, loss = 0.82840399\n",
      "Iteration 34, loss = 0.80832734\n",
      "Iteration 35, loss = 0.79350469\n",
      "Iteration 36, loss = 0.84182727\n",
      "Iteration 37, loss = 0.80222919\n",
      "Iteration 38, loss = 0.77720812\n",
      "Iteration 39, loss = 0.75385918\n",
      "Iteration 40, loss = 0.78186215\n",
      "Iteration 41, loss = 0.76990508\n",
      "Iteration 42, loss = 0.77539163\n",
      "Iteration 43, loss = 0.73544392\n",
      "Iteration 44, loss = 0.75760182\n",
      "Iteration 45, loss = 0.73398494\n",
      "Iteration 46, loss = 0.75761298\n",
      "Iteration 47, loss = 0.74914966\n",
      "Iteration 48, loss = 0.75335684\n",
      "Iteration 49, loss = 0.87654227\n",
      "Iteration 50, loss = 0.80242772\n",
      "Iteration 51, loss = 0.79878685\n",
      "Iteration 52, loss = 0.80136964\n",
      "Iteration 53, loss = 0.79502405\n",
      "Iteration 54, loss = 0.75609965\n",
      "Iteration 55, loss = 0.73194268\n",
      "Iteration 56, loss = 0.71081724\n",
      "Iteration 57, loss = 0.71685975\n",
      "Iteration 58, loss = 0.71064986\n",
      "Iteration 59, loss = 0.70452782\n",
      "Iteration 60, loss = 0.70186845\n",
      "Iteration 61, loss = 0.69812069\n",
      "Iteration 62, loss = 0.73253126\n",
      "Iteration 63, loss = 0.68638369\n",
      "Iteration 64, loss = 0.78552263\n",
      "Iteration 49, loss = 0.87654227\n",
      "Iteration 50, loss = 0.80242772\n",
      "Iteration 51, loss = 0.79878685\n",
      "Iteration 52, loss = 0.80136964\n",
      "Iteration 53, loss = 0.79502405\n",
      "Iteration 54, loss = 0.75609965\n",
      "Iteration 55, loss = 0.73194268\n",
      "Iteration 56, loss = 0.71081724\n",
      "Iteration 57, loss = 0.71685975\n",
      "Iteration 58, loss = 0.71064986\n",
      "Iteration 59, loss = 0.70452782\n",
      "Iteration 60, loss = 0.70186845\n",
      "Iteration 61, loss = 0.69812069\n",
      "Iteration 62, loss = 0.73253126\n",
      "Iteration 63, loss = 0.68638369\n",
      "Iteration 64, loss = 0.78552263\n",
      "Iteration 65, loss = 0.73120472\n",
      "Iteration 66, loss = 0.70492488\n",
      "Iteration 67, loss = 0.68255915\n",
      "Iteration 68, loss = 0.68704850\n",
      "Iteration 69, loss = 0.65966580\n",
      "Iteration 70, loss = 0.69310593\n",
      "Iteration 71, loss = 0.78792164\n",
      "Iteration 72, loss = 0.72645487\n",
      "Iteration 73, loss = 0.66481886\n",
      "Iteration 74, loss = 0.67797214\n",
      "Iteration 75, loss = 0.66600515\n",
      "Iteration 76, loss = 0.70789525\n",
      "Iteration 77, loss = 0.74987913\n",
      "Iteration 78, loss = 0.74474811\n",
      "Iteration 79, loss = 0.70654413\n",
      "Iteration 65, loss = 0.73120472\n",
      "Iteration 66, loss = 0.70492488\n",
      "Iteration 67, loss = 0.68255915\n",
      "Iteration 68, loss = 0.68704850\n",
      "Iteration 69, loss = 0.65966580\n",
      "Iteration 70, loss = 0.69310593\n",
      "Iteration 71, loss = 0.78792164\n",
      "Iteration 72, loss = 0.72645487\n",
      "Iteration 73, loss = 0.66481886\n",
      "Iteration 74, loss = 0.67797214\n",
      "Iteration 75, loss = 0.66600515\n",
      "Iteration 76, loss = 0.70789525\n",
      "Iteration 77, loss = 0.74987913\n",
      "Iteration 78, loss = 0.74474811\n",
      "Iteration 79, loss = 0.70654413\n",
      "Iteration 80, loss = 0.69852109\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23427048\n",
      "Iteration 2, loss = 1.12657655\n",
      "Iteration 3, loss = 1.06119695\n",
      "Iteration 4, loss = 1.00917858\n",
      "Iteration 5, loss = 0.98877187\n",
      "Iteration 6, loss = 1.02490843\n",
      "Iteration 7, loss = 0.96920969\n",
      "Iteration 8, loss = 0.94759457\n",
      "Iteration 9, loss = 1.00050338\n",
      "Iteration 10, loss = 0.91936335\n",
      "Iteration 11, loss = 0.97018674\n",
      "Iteration 80, loss = 0.69852109\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23427048\n",
      "Iteration 2, loss = 1.12657655\n",
      "Iteration 3, loss = 1.06119695\n",
      "Iteration 4, loss = 1.00917858\n",
      "Iteration 5, loss = 0.98877187\n",
      "Iteration 6, loss = 1.02490843\n",
      "Iteration 7, loss = 0.96920969\n",
      "Iteration 8, loss = 0.94759457\n",
      "Iteration 9, loss = 1.00050338\n",
      "Iteration 10, loss = 0.91936335\n",
      "Iteration 11, loss = 0.97018674\n",
      "Iteration 12, loss = 0.93938147\n",
      "Iteration 13, loss = 0.92846185\n",
      "Iteration 14, loss = 0.93404041\n",
      "Iteration 15, loss = 0.95782876\n",
      "Iteration 16, loss = 0.95123734\n",
      "Iteration 17, loss = 0.94666784\n",
      "Iteration 18, loss = 0.91970926\n",
      "Iteration 19, loss = 0.93830327\n",
      "Iteration 20, loss = 0.89825957\n",
      "Iteration 21, loss = 0.89534965\n",
      "Iteration 22, loss = 0.91498613\n",
      "Iteration 23, loss = 0.92924596\n",
      "Iteration 24, loss = 0.91141291\n",
      "Iteration 25, loss = 0.89725643\n",
      "Iteration 26, loss = 0.91267409\n",
      "Iteration 12, loss = 0.93938147\n",
      "Iteration 13, loss = 0.92846185\n",
      "Iteration 14, loss = 0.93404041\n",
      "Iteration 15, loss = 0.95782876\n",
      "Iteration 16, loss = 0.95123734\n",
      "Iteration 17, loss = 0.94666784\n",
      "Iteration 18, loss = 0.91970926\n",
      "Iteration 19, loss = 0.93830327\n",
      "Iteration 20, loss = 0.89825957\n",
      "Iteration 21, loss = 0.89534965\n",
      "Iteration 22, loss = 0.91498613\n",
      "Iteration 23, loss = 0.92924596\n",
      "Iteration 24, loss = 0.91141291\n",
      "Iteration 25, loss = 0.89725643\n",
      "Iteration 26, loss = 0.91267409\n",
      "Iteration 27, loss = 0.89456502\n",
      "Iteration 28, loss = 0.86164946\n",
      "Iteration 29, loss = 0.88039089\n",
      "Iteration 30, loss = 0.85191012\n",
      "Iteration 31, loss = 0.85080864\n",
      "Iteration 32, loss = 0.84149592\n",
      "Iteration 33, loss = 0.88171171\n",
      "Iteration 34, loss = 0.90076430\n",
      "Iteration 35, loss = 0.88502936\n",
      "Iteration 36, loss = 0.85163364\n",
      "Iteration 37, loss = 0.86305679\n",
      "Iteration 38, loss = 0.84817759\n",
      "Iteration 39, loss = 0.84341141\n",
      "Iteration 40, loss = 0.84625594\n",
      "Iteration 41, loss = 0.84465790\n",
      "Iteration 27, loss = 0.89456502\n",
      "Iteration 28, loss = 0.86164946\n",
      "Iteration 29, loss = 0.88039089\n",
      "Iteration 30, loss = 0.85191012\n",
      "Iteration 31, loss = 0.85080864\n",
      "Iteration 32, loss = 0.84149592\n",
      "Iteration 33, loss = 0.88171171\n",
      "Iteration 34, loss = 0.90076430\n",
      "Iteration 35, loss = 0.88502936\n",
      "Iteration 36, loss = 0.85163364\n",
      "Iteration 37, loss = 0.86305679\n",
      "Iteration 38, loss = 0.84817759\n",
      "Iteration 39, loss = 0.84341141\n",
      "Iteration 40, loss = 0.84625594\n",
      "Iteration 41, loss = 0.84465790\n",
      "Iteration 42, loss = 0.81916662\n",
      "Iteration 43, loss = 0.82193274\n",
      "Iteration 44, loss = 0.80963993\n",
      "Iteration 45, loss = 0.80301585\n",
      "Iteration 46, loss = 0.84545509\n",
      "Iteration 47, loss = 0.81046559\n",
      "Iteration 48, loss = 0.84578890\n",
      "Iteration 49, loss = 0.88402504\n",
      "Iteration 50, loss = 0.82767154\n",
      "Iteration 51, loss = 0.81033566\n",
      "Iteration 52, loss = 0.83283087\n",
      "Iteration 53, loss = 0.85798683\n",
      "Iteration 54, loss = 0.81194375\n",
      "Iteration 55, loss = 0.78846127\n",
      "Iteration 56, loss = 0.78546821\n",
      "Iteration 42, loss = 0.81916662\n",
      "Iteration 43, loss = 0.82193274\n",
      "Iteration 44, loss = 0.80963993\n",
      "Iteration 45, loss = 0.80301585\n",
      "Iteration 46, loss = 0.84545509\n",
      "Iteration 47, loss = 0.81046559\n",
      "Iteration 48, loss = 0.84578890\n",
      "Iteration 49, loss = 0.88402504\n",
      "Iteration 50, loss = 0.82767154\n",
      "Iteration 51, loss = 0.81033566\n",
      "Iteration 52, loss = 0.83283087\n",
      "Iteration 53, loss = 0.85798683\n",
      "Iteration 54, loss = 0.81194375\n",
      "Iteration 55, loss = 0.78846127\n",
      "Iteration 56, loss = 0.78546821\n",
      "Iteration 57, loss = 0.77907332\n",
      "Iteration 58, loss = 0.83848115\n",
      "Iteration 59, loss = 0.77673791\n",
      "Iteration 60, loss = 0.81924206\n",
      "Iteration 61, loss = 0.79599733\n",
      "Iteration 62, loss = 0.79867957\n",
      "Iteration 63, loss = 0.80529725\n",
      "Iteration 64, loss = 0.79017020\n",
      "Iteration 65, loss = 0.79587432\n",
      "Iteration 66, loss = 0.78831039\n",
      "Iteration 67, loss = 0.76612569\n",
      "Iteration 68, loss = 0.79183718\n",
      "Iteration 69, loss = 0.74805279\n",
      "Iteration 70, loss = 0.76430509\n",
      "Iteration 71, loss = 0.75702148\n",
      "Iteration 57, loss = 0.77907332\n",
      "Iteration 58, loss = 0.83848115\n",
      "Iteration 59, loss = 0.77673791\n",
      "Iteration 60, loss = 0.81924206\n",
      "Iteration 61, loss = 0.79599733\n",
      "Iteration 62, loss = 0.79867957\n",
      "Iteration 63, loss = 0.80529725\n",
      "Iteration 64, loss = 0.79017020\n",
      "Iteration 65, loss = 0.79587432\n",
      "Iteration 66, loss = 0.78831039\n",
      "Iteration 67, loss = 0.76612569\n",
      "Iteration 68, loss = 0.79183718\n",
      "Iteration 69, loss = 0.74805279\n",
      "Iteration 70, loss = 0.76430509\n",
      "Iteration 71, loss = 0.75702148\n",
      "Iteration 72, loss = 0.79049300\n",
      "Iteration 73, loss = 0.76880691\n",
      "Iteration 74, loss = 0.76797257\n",
      "Iteration 75, loss = 0.76777538\n",
      "Iteration 76, loss = 0.78321124\n",
      "Iteration 77, loss = 0.74083949\n",
      "Iteration 78, loss = 0.80101970\n",
      "Iteration 79, loss = 0.74357305\n",
      "Iteration 80, loss = 0.74513350\n",
      "Iteration 81, loss = 0.77809454\n",
      "Iteration 82, loss = 0.73035588\n",
      "Iteration 83, loss = 0.73123435\n",
      "Iteration 84, loss = 0.76113470\n",
      "Iteration 85, loss = 0.74430689\n",
      "Iteration 86, loss = 0.71835313\n",
      "Iteration 87, loss = 0.77255740\n",
      "Iteration 72, loss = 0.79049300\n",
      "Iteration 73, loss = 0.76880691\n",
      "Iteration 74, loss = 0.76797257\n",
      "Iteration 75, loss = 0.76777538\n",
      "Iteration 76, loss = 0.78321124\n",
      "Iteration 77, loss = 0.74083949\n",
      "Iteration 78, loss = 0.80101970\n",
      "Iteration 79, loss = 0.74357305\n",
      "Iteration 80, loss = 0.74513350\n",
      "Iteration 81, loss = 0.77809454\n",
      "Iteration 82, loss = 0.73035588\n",
      "Iteration 83, loss = 0.73123435\n",
      "Iteration 84, loss = 0.76113470\n",
      "Iteration 85, loss = 0.74430689\n",
      "Iteration 86, loss = 0.71835313\n",
      "Iteration 87, loss = 0.77255740\n",
      "Iteration 88, loss = 0.72718717\n",
      "Iteration 89, loss = 0.73697384\n",
      "Iteration 90, loss = 0.75027328\n",
      "Iteration 91, loss = 0.78929560\n",
      "Iteration 92, loss = 0.72899305\n",
      "Iteration 93, loss = 0.72251152\n",
      "Iteration 94, loss = 0.72650012\n",
      "Iteration 95, loss = 0.73678259\n",
      "Iteration 96, loss = 0.81400547\n",
      "Iteration 97, loss = 0.78889936\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21219307\n",
      "Iteration 2, loss = 1.14852409\n",
      "Iteration 3, loss = 1.10527272\n",
      "Iteration 4, loss = 1.07082947\n",
      "Iteration 5, loss = 1.00698453\n",
      "Iteration 88, loss = 0.72718717\n",
      "Iteration 89, loss = 0.73697384\n",
      "Iteration 90, loss = 0.75027328\n",
      "Iteration 91, loss = 0.78929560\n",
      "Iteration 92, loss = 0.72899305\n",
      "Iteration 93, loss = 0.72251152\n",
      "Iteration 94, loss = 0.72650012\n",
      "Iteration 95, loss = 0.73678259\n",
      "Iteration 96, loss = 0.81400547\n",
      "Iteration 97, loss = 0.78889936\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21219307\n",
      "Iteration 2, loss = 1.14852409\n",
      "Iteration 3, loss = 1.10527272\n",
      "Iteration 4, loss = 1.07082947\n",
      "Iteration 5, loss = 1.00698453\n",
      "Iteration 6, loss = 1.04912915\n",
      "Iteration 7, loss = 0.97726965\n",
      "Iteration 8, loss = 0.97040008\n",
      "Iteration 9, loss = 0.97054324\n",
      "Iteration 10, loss = 0.93252782\n",
      "Iteration 11, loss = 0.96448423\n",
      "Iteration 12, loss = 0.93382675\n",
      "Iteration 13, loss = 0.94024420\n",
      "Iteration 14, loss = 0.93068797\n",
      "Iteration 15, loss = 0.95493349\n",
      "Iteration 16, loss = 0.93767423\n",
      "Iteration 17, loss = 0.96017641\n",
      "Iteration 18, loss = 0.91772348\n",
      "Iteration 19, loss = 0.97231432\n",
      "Iteration 6, loss = 1.04912915\n",
      "Iteration 7, loss = 0.97726965\n",
      "Iteration 8, loss = 0.97040008\n",
      "Iteration 9, loss = 0.97054324\n",
      "Iteration 10, loss = 0.93252782\n",
      "Iteration 11, loss = 0.96448423\n",
      "Iteration 12, loss = 0.93382675\n",
      "Iteration 13, loss = 0.94024420\n",
      "Iteration 14, loss = 0.93068797\n",
      "Iteration 15, loss = 0.95493349\n",
      "Iteration 16, loss = 0.93767423\n",
      "Iteration 17, loss = 0.96017641\n",
      "Iteration 18, loss = 0.91772348\n",
      "Iteration 19, loss = 0.97231432\n",
      "Iteration 20, loss = 0.90018515\n",
      "Iteration 21, loss = 0.91683242\n",
      "Iteration 22, loss = 0.91423883\n",
      "Iteration 23, loss = 0.91596110\n",
      "Iteration 24, loss = 0.90840116\n",
      "Iteration 25, loss = 0.90976547\n",
      "Iteration 26, loss = 0.89064313\n",
      "Iteration 27, loss = 0.86970466\n",
      "Iteration 28, loss = 0.87152292\n",
      "Iteration 29, loss = 0.88471333\n",
      "Iteration 30, loss = 0.82500482\n",
      "Iteration 31, loss = 0.85899776\n",
      "Iteration 32, loss = 0.85853731\n",
      "Iteration 33, loss = 0.83113631\n",
      "Iteration 34, loss = 0.91431818\n",
      "Iteration 20, loss = 0.90018515\n",
      "Iteration 21, loss = 0.91683242\n",
      "Iteration 22, loss = 0.91423883\n",
      "Iteration 23, loss = 0.91596110\n",
      "Iteration 24, loss = 0.90840116\n",
      "Iteration 25, loss = 0.90976547\n",
      "Iteration 26, loss = 0.89064313\n",
      "Iteration 27, loss = 0.86970466\n",
      "Iteration 28, loss = 0.87152292\n",
      "Iteration 29, loss = 0.88471333\n",
      "Iteration 30, loss = 0.82500482\n",
      "Iteration 31, loss = 0.85899776\n",
      "Iteration 32, loss = 0.85853731\n",
      "Iteration 33, loss = 0.83113631\n",
      "Iteration 34, loss = 0.91431818\n",
      "Iteration 35, loss = 0.85463646\n",
      "Iteration 36, loss = 0.89322114\n",
      "Iteration 37, loss = 0.85007296\n",
      "Iteration 38, loss = 0.83436308\n",
      "Iteration 39, loss = 0.82149282\n",
      "Iteration 40, loss = 0.82782544\n",
      "Iteration 41, loss = 0.80603007\n",
      "Iteration 42, loss = 0.79464969\n",
      "Iteration 43, loss = 0.90367798\n",
      "Iteration 44, loss = 0.84574144\n",
      "Iteration 45, loss = 0.84479762\n",
      "Iteration 46, loss = 0.83528683\n",
      "Iteration 47, loss = 0.81307807\n",
      "Iteration 48, loss = 0.81354062\n",
      "Iteration 49, loss = 0.81145126\n",
      "Iteration 35, loss = 0.85463646\n",
      "Iteration 36, loss = 0.89322114\n",
      "Iteration 37, loss = 0.85007296\n",
      "Iteration 38, loss = 0.83436308\n",
      "Iteration 39, loss = 0.82149282\n",
      "Iteration 40, loss = 0.82782544\n",
      "Iteration 41, loss = 0.80603007\n",
      "Iteration 42, loss = 0.79464969\n",
      "Iteration 43, loss = 0.90367798\n",
      "Iteration 44, loss = 0.84574144\n",
      "Iteration 45, loss = 0.84479762\n",
      "Iteration 46, loss = 0.83528683\n",
      "Iteration 47, loss = 0.81307807\n",
      "Iteration 48, loss = 0.81354062\n",
      "Iteration 49, loss = 0.81145126\n",
      "Iteration 50, loss = 0.79349218\n",
      "Iteration 51, loss = 0.79245764\n",
      "Iteration 52, loss = 0.77682196\n",
      "Iteration 53, loss = 0.77149214\n",
      "Iteration 54, loss = 0.77023371\n",
      "Iteration 55, loss = 0.78707379\n",
      "Iteration 56, loss = 0.83606385\n",
      "Iteration 57, loss = 0.78258502\n",
      "Iteration 58, loss = 0.78288967\n",
      "Iteration 59, loss = 0.73343053\n",
      "Iteration 60, loss = 0.77023445\n",
      "Iteration 61, loss = 0.77329864\n",
      "Iteration 62, loss = 0.73548042\n",
      "Iteration 63, loss = 0.77043648\n",
      "Iteration 64, loss = 0.79823058\n",
      "Iteration 50, loss = 0.79349218\n",
      "Iteration 51, loss = 0.79245764\n",
      "Iteration 52, loss = 0.77682196\n",
      "Iteration 53, loss = 0.77149214\n",
      "Iteration 54, loss = 0.77023371\n",
      "Iteration 55, loss = 0.78707379\n",
      "Iteration 56, loss = 0.83606385\n",
      "Iteration 57, loss = 0.78258502\n",
      "Iteration 58, loss = 0.78288967\n",
      "Iteration 59, loss = 0.73343053\n",
      "Iteration 60, loss = 0.77023445\n",
      "Iteration 61, loss = 0.77329864\n",
      "Iteration 62, loss = 0.73548042\n",
      "Iteration 63, loss = 0.77043648\n",
      "Iteration 64, loss = 0.79823058\n",
      "Iteration 65, loss = 0.75875081\n",
      "Iteration 66, loss = 0.72567851\n",
      "Iteration 67, loss = 0.77487678\n",
      "Iteration 68, loss = 0.77298997\n",
      "Iteration 69, loss = 0.74971717\n",
      "Iteration 70, loss = 0.72093080\n",
      "Iteration 71, loss = 0.71753516\n",
      "Iteration 72, loss = 0.78439121\n",
      "Iteration 73, loss = 0.74646459\n",
      "Iteration 74, loss = 0.75281424\n",
      "Iteration 75, loss = 0.74295460\n",
      "Iteration 76, loss = 0.72142689\n",
      "Iteration 77, loss = 0.73691111\n",
      "Iteration 78, loss = 0.74674554\n",
      "Iteration 79, loss = 0.73392162\n",
      "Iteration 80, loss = 0.75286687\n",
      "Iteration 65, loss = 0.75875081\n",
      "Iteration 66, loss = 0.72567851\n",
      "Iteration 67, loss = 0.77487678\n",
      "Iteration 68, loss = 0.77298997\n",
      "Iteration 69, loss = 0.74971717\n",
      "Iteration 70, loss = 0.72093080\n",
      "Iteration 71, loss = 0.71753516\n",
      "Iteration 72, loss = 0.78439121\n",
      "Iteration 73, loss = 0.74646459\n",
      "Iteration 74, loss = 0.75281424\n",
      "Iteration 75, loss = 0.74295460\n",
      "Iteration 76, loss = 0.72142689\n",
      "Iteration 77, loss = 0.73691111\n",
      "Iteration 78, loss = 0.74674554\n",
      "Iteration 79, loss = 0.73392162\n",
      "Iteration 80, loss = 0.75286687\n",
      "Iteration 81, loss = 0.71822640\n",
      "Iteration 82, loss = 0.72631511\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21674953\n",
      "Iteration 2, loss = 1.11777475\n",
      "Iteration 3, loss = 1.09372839\n",
      "Iteration 4, loss = 1.04528100\n",
      "Iteration 5, loss = 0.97450577\n",
      "Iteration 6, loss = 0.97647145\n",
      "Iteration 7, loss = 0.95227185\n",
      "Iteration 8, loss = 0.96059838\n",
      "Iteration 9, loss = 0.97711563\n",
      "Iteration 10, loss = 0.94751256\n",
      "Iteration 11, loss = 0.93215661\n",
      "Iteration 81, loss = 0.71822640\n",
      "Iteration 82, loss = 0.72631511\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21674953\n",
      "Iteration 2, loss = 1.11777475\n",
      "Iteration 3, loss = 1.09372839\n",
      "Iteration 4, loss = 1.04528100\n",
      "Iteration 5, loss = 0.97450577\n",
      "Iteration 6, loss = 0.97647145\n",
      "Iteration 7, loss = 0.95227185\n",
      "Iteration 8, loss = 0.96059838\n",
      "Iteration 9, loss = 0.97711563\n",
      "Iteration 10, loss = 0.94751256\n",
      "Iteration 11, loss = 0.93215661\n",
      "Iteration 12, loss = 0.93908439\n",
      "Iteration 13, loss = 0.92188406\n",
      "Iteration 14, loss = 0.92147790\n",
      "Iteration 15, loss = 0.94224870\n",
      "Iteration 16, loss = 0.90920281\n",
      "Iteration 17, loss = 0.93446940\n",
      "Iteration 18, loss = 0.89337546\n",
      "Iteration 19, loss = 0.95141946\n",
      "Iteration 20, loss = 0.88602164\n",
      "Iteration 21, loss = 0.88832789\n",
      "Iteration 22, loss = 0.87660729\n",
      "Iteration 23, loss = 0.87640843\n",
      "Iteration 24, loss = 0.88750725\n",
      "Iteration 25, loss = 0.88065680\n",
      "Iteration 26, loss = 0.87664618\n",
      "Iteration 27, loss = 0.86631439\n",
      "Iteration 12, loss = 0.93908439\n",
      "Iteration 13, loss = 0.92188406\n",
      "Iteration 14, loss = 0.92147790\n",
      "Iteration 15, loss = 0.94224870\n",
      "Iteration 16, loss = 0.90920281\n",
      "Iteration 17, loss = 0.93446940\n",
      "Iteration 18, loss = 0.89337546\n",
      "Iteration 19, loss = 0.95141946\n",
      "Iteration 20, loss = 0.88602164\n",
      "Iteration 21, loss = 0.88832789\n",
      "Iteration 22, loss = 0.87660729\n",
      "Iteration 23, loss = 0.87640843\n",
      "Iteration 24, loss = 0.88750725\n",
      "Iteration 25, loss = 0.88065680\n",
      "Iteration 26, loss = 0.87664618\n",
      "Iteration 27, loss = 0.86631439\n",
      "Iteration 28, loss = 0.87063533\n",
      "Iteration 29, loss = 0.86959414\n",
      "Iteration 30, loss = 0.87181378\n",
      "Iteration 31, loss = 0.85789416\n",
      "Iteration 32, loss = 0.85183622\n",
      "Iteration 33, loss = 0.86068005\n",
      "Iteration 34, loss = 0.85578099\n",
      "Iteration 35, loss = 0.87639496\n",
      "Iteration 36, loss = 0.84150916\n",
      "Iteration 37, loss = 0.87595115\n",
      "Iteration 38, loss = 0.81929231\n",
      "Iteration 39, loss = 0.82887918\n",
      "Iteration 40, loss = 0.84118883\n",
      "Iteration 41, loss = 0.80160020\n",
      "Iteration 42, loss = 0.78762863\n",
      "Iteration 43, loss = 0.87434982\n",
      "Iteration 28, loss = 0.87063533\n",
      "Iteration 29, loss = 0.86959414\n",
      "Iteration 30, loss = 0.87181378\n",
      "Iteration 31, loss = 0.85789416\n",
      "Iteration 32, loss = 0.85183622\n",
      "Iteration 33, loss = 0.86068005\n",
      "Iteration 34, loss = 0.85578099\n",
      "Iteration 35, loss = 0.87639496\n",
      "Iteration 36, loss = 0.84150916\n",
      "Iteration 37, loss = 0.87595115\n",
      "Iteration 38, loss = 0.81929231\n",
      "Iteration 39, loss = 0.82887918\n",
      "Iteration 40, loss = 0.84118883\n",
      "Iteration 41, loss = 0.80160020\n",
      "Iteration 42, loss = 0.78762863\n",
      "Iteration 43, loss = 0.87434982\n",
      "Iteration 44, loss = 0.82766517\n",
      "Iteration 45, loss = 0.84388611\n",
      "Iteration 46, loss = 0.84867694\n",
      "Iteration 47, loss = 0.80404868\n",
      "Iteration 48, loss = 0.79467183\n",
      "Iteration 49, loss = 0.80782670\n",
      "Iteration 50, loss = 0.78889386\n",
      "Iteration 51, loss = 0.79539607\n",
      "Iteration 52, loss = 0.86454881\n",
      "Iteration 53, loss = 0.78930963\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20669770\n",
      "Iteration 2, loss = 1.10259077\n",
      "Iteration 3, loss = 1.05001842\n",
      "Iteration 4, loss = 1.05309645\n",
      "Iteration 5, loss = 0.99569141\n",
      "Iteration 44, loss = 0.82766517\n",
      "Iteration 45, loss = 0.84388611\n",
      "Iteration 46, loss = 0.84867694\n",
      "Iteration 47, loss = 0.80404868\n",
      "Iteration 48, loss = 0.79467183\n",
      "Iteration 49, loss = 0.80782670\n",
      "Iteration 50, loss = 0.78889386\n",
      "Iteration 51, loss = 0.79539607\n",
      "Iteration 52, loss = 0.86454881\n",
      "Iteration 53, loss = 0.78930963\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20669770\n",
      "Iteration 2, loss = 1.10259077\n",
      "Iteration 3, loss = 1.05001842\n",
      "Iteration 4, loss = 1.05309645\n",
      "Iteration 5, loss = 0.99569141\n",
      "Iteration 6, loss = 1.02099105\n",
      "Iteration 7, loss = 1.00900923\n",
      "Iteration 8, loss = 1.00812528\n",
      "Iteration 9, loss = 0.98124629\n",
      "Iteration 10, loss = 0.97779971\n",
      "Iteration 1, loss = 1.22632329\n",
      "Iteration 2, loss = 1.13108260\n",
      "Iteration 3, loss = 0.97224948\n",
      "Iteration 4, loss = 0.93702393\n",
      "Iteration 5, loss = 0.96349635\n",
      "Iteration 6, loss = 0.92662370\n",
      "Iteration 7, loss = 0.92645699\n",
      "Iteration 8, loss = 0.91610355\n",
      "Iteration 9, loss = 0.94474065\n",
      "Iteration 6, loss = 1.02099105\n",
      "Iteration 7, loss = 1.00900923\n",
      "Iteration 8, loss = 1.00812528\n",
      "Iteration 9, loss = 0.98124629\n",
      "Iteration 10, loss = 0.97779971\n",
      "Iteration 1, loss = 1.22632329\n",
      "Iteration 2, loss = 1.13108260\n",
      "Iteration 3, loss = 0.97224948\n",
      "Iteration 4, loss = 0.93702393\n",
      "Iteration 5, loss = 0.96349635\n",
      "Iteration 6, loss = 0.92662370\n",
      "Iteration 7, loss = 0.92645699\n",
      "Iteration 8, loss = 0.91610355\n",
      "Iteration 9, loss = 0.94474065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.94585393\n",
      "Iteration 1, loss = 1.25310318\n",
      "Iteration 2, loss = 1.13224474\n",
      "Iteration 3, loss = 1.13529661\n",
      "Iteration 4, loss = 1.02393307\n",
      "Iteration 5, loss = 1.01318480\n",
      "Iteration 6, loss = 1.00025429\n",
      "Iteration 7, loss = 0.95660498\n",
      "Iteration 8, loss = 0.94114991\n",
      "Iteration 9, loss = 1.05466184\n",
      "Iteration 10, loss = 1.05693268\n",
      "Iteration 10, loss = 0.94585393\n",
      "Iteration 1, loss = 1.25310318\n",
      "Iteration 2, loss = 1.13224474\n",
      "Iteration 3, loss = 1.13529661\n",
      "Iteration 4, loss = 1.02393307\n",
      "Iteration 5, loss = 1.01318480\n",
      "Iteration 6, loss = 1.00025429\n",
      "Iteration 7, loss = 0.95660498\n",
      "Iteration 8, loss = 0.94114991\n",
      "Iteration 9, loss = 1.05466184\n",
      "Iteration 10, loss = 1.05693268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21296933\n",
      "Iteration 2, loss = 1.17804732\n",
      "Iteration 3, loss = 1.18705128\n",
      "Iteration 4, loss = 1.16497162\n",
      "Iteration 5, loss = 1.10969339\n",
      "Iteration 6, loss = 1.05958588\n",
      "Iteration 7, loss = 1.01559635\n",
      "Iteration 8, loss = 0.99019325\n",
      "Iteration 9, loss = 1.00880141\n",
      "Iteration 10, loss = 0.98348246\n",
      "Iteration 1, loss = 1.20019777\n",
      "Iteration 2, loss = 1.15649628\n",
      "Iteration 3, loss = 1.15661778\n",
      "Iteration 1, loss = 1.21296933\n",
      "Iteration 2, loss = 1.17804732\n",
      "Iteration 3, loss = 1.18705128\n",
      "Iteration 4, loss = 1.16497162\n",
      "Iteration 5, loss = 1.10969339\n",
      "Iteration 6, loss = 1.05958588\n",
      "Iteration 7, loss = 1.01559635\n",
      "Iteration 8, loss = 0.99019325\n",
      "Iteration 9, loss = 1.00880141\n",
      "Iteration 10, loss = 0.98348246\n",
      "Iteration 1, loss = 1.20019777\n",
      "Iteration 2, loss = 1.15649628\n",
      "Iteration 3, loss = 1.15661778\n",
      "Iteration 4, loss = 1.03567852\n",
      "Iteration 5, loss = 0.99972171\n",
      "Iteration 6, loss = 1.00853900\n",
      "Iteration 7, loss = 0.99882924\n",
      "Iteration 8, loss = 1.00634913\n",
      "Iteration 9, loss = 1.04046868\n",
      "Iteration 10, loss = 0.97938967\n",
      "Iteration 1, loss = 1.20669770\n",
      "Iteration 2, loss = 1.10259077\n",
      "Iteration 3, loss = 1.05001842\n",
      "Iteration 4, loss = 1.05309645\n",
      "Iteration 5, loss = 0.99569141\n",
      "Iteration 6, loss = 1.02099105\n",
      "Iteration 7, loss = 1.00900923\n",
      "Iteration 4, loss = 1.03567852\n",
      "Iteration 5, loss = 0.99972171\n",
      "Iteration 6, loss = 1.00853900\n",
      "Iteration 7, loss = 0.99882924\n",
      "Iteration 8, loss = 1.00634913\n",
      "Iteration 9, loss = 1.04046868\n",
      "Iteration 10, loss = 0.97938967\n",
      "Iteration 1, loss = 1.20669770\n",
      "Iteration 2, loss = 1.10259077\n",
      "Iteration 3, loss = 1.05001842\n",
      "Iteration 4, loss = 1.05309645\n",
      "Iteration 5, loss = 0.99569141\n",
      "Iteration 6, loss = 1.02099105\n",
      "Iteration 7, loss = 1.00900923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.00812528\n",
      "Iteration 9, loss = 0.98124629\n",
      "Iteration 10, loss = 0.97779971\n",
      "Iteration 11, loss = 0.96737052\n",
      "Iteration 12, loss = 0.96988738\n",
      "Iteration 13, loss = 0.96380326\n",
      "Iteration 14, loss = 0.96551044\n",
      "Iteration 15, loss = 0.95756418\n",
      "Iteration 16, loss = 1.13422899\n",
      "Iteration 17, loss = 1.09280299\n",
      "Iteration 18, loss = 0.99054634\n",
      "Iteration 19, loss = 0.96490314\n",
      "Iteration 20, loss = 0.96062990\n",
      "Iteration 21, loss = 0.96732880\n",
      "Iteration 8, loss = 1.00812528\n",
      "Iteration 9, loss = 0.98124629\n",
      "Iteration 10, loss = 0.97779971\n",
      "Iteration 11, loss = 0.96737052\n",
      "Iteration 12, loss = 0.96988738\n",
      "Iteration 13, loss = 0.96380326\n",
      "Iteration 14, loss = 0.96551044\n",
      "Iteration 15, loss = 0.95756418\n",
      "Iteration 16, loss = 1.13422899\n",
      "Iteration 17, loss = 1.09280299\n",
      "Iteration 18, loss = 0.99054634\n",
      "Iteration 19, loss = 0.96490314\n",
      "Iteration 20, loss = 0.96062990\n",
      "Iteration 21, loss = 0.96732880\n",
      "Iteration 22, loss = 0.96501650\n",
      "Iteration 23, loss = 0.94848517\n",
      "Iteration 24, loss = 0.95526977\n",
      "Iteration 25, loss = 0.93660811\n",
      "Iteration 26, loss = 0.96408535\n",
      "Iteration 27, loss = 0.99290836\n",
      "Iteration 28, loss = 0.95742305\n",
      "Iteration 29, loss = 0.94660452\n",
      "Iteration 30, loss = 0.94009866\n",
      "Iteration 31, loss = 0.93386448\n",
      "Iteration 32, loss = 0.94709782\n",
      "Iteration 33, loss = 0.94910304\n",
      "Iteration 34, loss = 1.03707887\n",
      "Iteration 35, loss = 0.99368977\n",
      "Iteration 36, loss = 0.94635530\n",
      "Iteration 37, loss = 0.95103695\n",
      "Iteration 22, loss = 0.96501650\n",
      "Iteration 23, loss = 0.94848517\n",
      "Iteration 24, loss = 0.95526977\n",
      "Iteration 25, loss = 0.93660811\n",
      "Iteration 26, loss = 0.96408535\n",
      "Iteration 27, loss = 0.99290836\n",
      "Iteration 28, loss = 0.95742305\n",
      "Iteration 29, loss = 0.94660452\n",
      "Iteration 30, loss = 0.94009866\n",
      "Iteration 31, loss = 0.93386448\n",
      "Iteration 32, loss = 0.94709782\n",
      "Iteration 33, loss = 0.94910304\n",
      "Iteration 34, loss = 1.03707887\n",
      "Iteration 35, loss = 0.99368977\n",
      "Iteration 36, loss = 0.94635530\n",
      "Iteration 37, loss = 0.95103695\n",
      "Iteration 38, loss = 0.96404112\n",
      "Iteration 39, loss = 0.93374441\n",
      "Iteration 40, loss = 0.94330244\n",
      "Iteration 41, loss = 0.92408130\n",
      "Iteration 42, loss = 0.93833133\n",
      "Iteration 43, loss = 0.93071436\n",
      "Iteration 44, loss = 0.93439436\n",
      "Iteration 45, loss = 0.93753120\n",
      "Iteration 46, loss = 0.94071729\n",
      "Iteration 47, loss = 0.92502654\n",
      "Iteration 48, loss = 0.92307376\n",
      "Iteration 49, loss = 0.91996953\n",
      "Iteration 50, loss = 0.94733554\n",
      "Iteration 1, loss = 1.22632329\n",
      "Iteration 2, loss = 1.13108260\n",
      "Iteration 38, loss = 0.96404112\n",
      "Iteration 39, loss = 0.93374441\n",
      "Iteration 40, loss = 0.94330244\n",
      "Iteration 41, loss = 0.92408130\n",
      "Iteration 42, loss = 0.93833133\n",
      "Iteration 43, loss = 0.93071436\n",
      "Iteration 44, loss = 0.93439436\n",
      "Iteration 45, loss = 0.93753120\n",
      "Iteration 46, loss = 0.94071729\n",
      "Iteration 47, loss = 0.92502654\n",
      "Iteration 48, loss = 0.92307376\n",
      "Iteration 49, loss = 0.91996953\n",
      "Iteration 50, loss = 0.94733554\n",
      "Iteration 1, loss = 1.22632329\n",
      "Iteration 2, loss = 1.13108260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.97224948\n",
      "Iteration 4, loss = 0.93702393\n",
      "Iteration 5, loss = 0.96349635\n",
      "Iteration 6, loss = 0.92662370\n",
      "Iteration 7, loss = 0.92645699\n",
      "Iteration 8, loss = 0.91610355\n",
      "Iteration 9, loss = 0.94474065\n",
      "Iteration 10, loss = 0.94585393\n",
      "Iteration 11, loss = 0.98037905\n",
      "Iteration 12, loss = 1.01105887\n",
      "Iteration 13, loss = 1.00414614\n",
      "Iteration 14, loss = 0.93395986\n",
      "Iteration 15, loss = 0.97373878\n",
      "Iteration 16, loss = 0.94664850\n",
      "Iteration 17, loss = 0.96772177\n",
      "Iteration 3, loss = 0.97224948\n",
      "Iteration 4, loss = 0.93702393\n",
      "Iteration 5, loss = 0.96349635\n",
      "Iteration 6, loss = 0.92662370\n",
      "Iteration 7, loss = 0.92645699\n",
      "Iteration 8, loss = 0.91610355\n",
      "Iteration 9, loss = 0.94474065\n",
      "Iteration 10, loss = 0.94585393\n",
      "Iteration 11, loss = 0.98037905\n",
      "Iteration 12, loss = 1.01105887\n",
      "Iteration 13, loss = 1.00414614\n",
      "Iteration 14, loss = 0.93395986\n",
      "Iteration 15, loss = 0.97373878\n",
      "Iteration 16, loss = 0.94664850\n",
      "Iteration 17, loss = 0.96772177\n",
      "Iteration 18, loss = 0.98819233\n",
      "Iteration 19, loss = 1.02094684\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25310318\n",
      "Iteration 2, loss = 1.13224474\n",
      "Iteration 3, loss = 1.13529661\n",
      "Iteration 4, loss = 1.02393307\n",
      "Iteration 5, loss = 1.01318480\n",
      "Iteration 6, loss = 1.00025429\n",
      "Iteration 7, loss = 0.95660498\n",
      "Iteration 8, loss = 0.94114991\n",
      "Iteration 9, loss = 1.05466184\n",
      "Iteration 10, loss = 1.05693268\n",
      "Iteration 18, loss = 0.98819233\n",
      "Iteration 19, loss = 1.02094684\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25310318\n",
      "Iteration 2, loss = 1.13224474\n",
      "Iteration 3, loss = 1.13529661\n",
      "Iteration 4, loss = 1.02393307\n",
      "Iteration 5, loss = 1.01318480\n",
      "Iteration 6, loss = 1.00025429\n",
      "Iteration 7, loss = 0.95660498\n",
      "Iteration 8, loss = 0.94114991\n",
      "Iteration 9, loss = 1.05466184\n",
      "Iteration 10, loss = 1.05693268\n",
      "Iteration 11, loss = 0.99925722\n",
      "Iteration 12, loss = 1.00867679\n",
      "Iteration 13, loss = 0.97554700\n",
      "Iteration 14, loss = 0.97352140\n",
      "Iteration 15, loss = 1.00260021\n",
      "Iteration 16, loss = 0.98474110\n",
      "Iteration 17, loss = 0.94870340\n",
      "Iteration 18, loss = 1.01463639\n",
      "Iteration 19, loss = 0.97134555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21296933\n",
      "Iteration 2, loss = 1.17804732\n",
      "Iteration 3, loss = 1.18705128\n",
      "Iteration 4, loss = 1.16497162\n",
      "Iteration 5, loss = 1.10969339\n",
      "Iteration 11, loss = 0.99925722\n",
      "Iteration 12, loss = 1.00867679\n",
      "Iteration 13, loss = 0.97554700\n",
      "Iteration 14, loss = 0.97352140\n",
      "Iteration 15, loss = 1.00260021\n",
      "Iteration 16, loss = 0.98474110\n",
      "Iteration 17, loss = 0.94870340\n",
      "Iteration 18, loss = 1.01463639\n",
      "Iteration 19, loss = 0.97134555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21296933\n",
      "Iteration 2, loss = 1.17804732\n",
      "Iteration 3, loss = 1.18705128\n",
      "Iteration 4, loss = 1.16497162\n",
      "Iteration 5, loss = 1.10969339\n",
      "Iteration 6, loss = 1.05958588\n",
      "Iteration 7, loss = 1.01559635\n",
      "Iteration 8, loss = 0.99019325\n",
      "Iteration 9, loss = 1.00880141\n",
      "Iteration 10, loss = 0.98348246\n",
      "Iteration 11, loss = 1.03778000\n",
      "Iteration 12, loss = 1.00158575\n",
      "Iteration 13, loss = 1.00003040\n",
      "Iteration 14, loss = 0.97684120\n",
      "Iteration 15, loss = 1.08602305\n",
      "Iteration 16, loss = 1.06213652\n",
      "Iteration 17, loss = 0.99862376\n",
      "Iteration 18, loss = 0.97138303\n",
      "Iteration 19, loss = 1.01088389\n",
      "Iteration 20, loss = 0.96658374\n",
      "Iteration 6, loss = 1.05958588\n",
      "Iteration 7, loss = 1.01559635\n",
      "Iteration 8, loss = 0.99019325\n",
      "Iteration 9, loss = 1.00880141\n",
      "Iteration 10, loss = 0.98348246\n",
      "Iteration 11, loss = 1.03778000\n",
      "Iteration 12, loss = 1.00158575\n",
      "Iteration 13, loss = 1.00003040\n",
      "Iteration 14, loss = 0.97684120\n",
      "Iteration 15, loss = 1.08602305\n",
      "Iteration 16, loss = 1.06213652\n",
      "Iteration 17, loss = 0.99862376\n",
      "Iteration 18, loss = 0.97138303\n",
      "Iteration 19, loss = 1.01088389\n",
      "Iteration 20, loss = 0.96658374\n",
      "Iteration 21, loss = 1.01125760\n",
      "Iteration 22, loss = 0.98366887\n",
      "Iteration 23, loss = 0.95268832\n",
      "Iteration 24, loss = 1.01515632\n",
      "Iteration 25, loss = 0.96953565\n",
      "Iteration 26, loss = 0.93606436\n",
      "Iteration 27, loss = 1.00994647\n",
      "Iteration 28, loss = 0.91709396\n",
      "Iteration 29, loss = 0.91440129\n",
      "Iteration 30, loss = 0.90641248\n",
      "Iteration 31, loss = 0.91574021\n",
      "Iteration 32, loss = 1.02057243\n",
      "Iteration 33, loss = 0.96853685\n",
      "Iteration 34, loss = 1.00079523\n",
      "Iteration 35, loss = 0.97582120\n",
      "Iteration 36, loss = 0.99359451\n",
      "Iteration 21, loss = 1.01125760\n",
      "Iteration 22, loss = 0.98366887\n",
      "Iteration 23, loss = 0.95268832\n",
      "Iteration 24, loss = 1.01515632\n",
      "Iteration 25, loss = 0.96953565\n",
      "Iteration 26, loss = 0.93606436\n",
      "Iteration 27, loss = 1.00994647\n",
      "Iteration 28, loss = 0.91709396\n",
      "Iteration 29, loss = 0.91440129\n",
      "Iteration 30, loss = 0.90641248\n",
      "Iteration 31, loss = 0.91574021\n",
      "Iteration 32, loss = 1.02057243\n",
      "Iteration 33, loss = 0.96853685\n",
      "Iteration 34, loss = 1.00079523\n",
      "Iteration 35, loss = 0.97582120\n",
      "Iteration 36, loss = 0.99359451\n",
      "Iteration 37, loss = 0.95989996\n",
      "Iteration 38, loss = 0.92288190\n",
      "Iteration 39, loss = 0.94523354\n",
      "Iteration 40, loss = 0.94995393\n",
      "Iteration 41, loss = 0.95680857\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20019777\n",
      "Iteration 2, loss = 1.15649628\n",
      "Iteration 3, loss = 1.15661778\n",
      "Iteration 4, loss = 1.03567852\n",
      "Iteration 5, loss = 0.99972171\n",
      "Iteration 6, loss = 1.00853900\n",
      "Iteration 7, loss = 0.99882924\n",
      "Iteration 8, loss = 1.00634913\n",
      "Iteration 37, loss = 0.95989996\n",
      "Iteration 38, loss = 0.92288190\n",
      "Iteration 39, loss = 0.94523354\n",
      "Iteration 40, loss = 0.94995393\n",
      "Iteration 41, loss = 0.95680857\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20019777\n",
      "Iteration 2, loss = 1.15649628\n",
      "Iteration 3, loss = 1.15661778\n",
      "Iteration 4, loss = 1.03567852\n",
      "Iteration 5, loss = 0.99972171\n",
      "Iteration 6, loss = 1.00853900\n",
      "Iteration 7, loss = 0.99882924\n",
      "Iteration 8, loss = 1.00634913\n",
      "Iteration 9, loss = 1.04046868\n",
      "Iteration 10, loss = 0.97938967\n",
      "Iteration 11, loss = 0.97465529\n",
      "Iteration 12, loss = 0.98761125\n",
      "Iteration 13, loss = 1.00669531\n",
      "Iteration 14, loss = 0.94124705\n",
      "Iteration 15, loss = 1.07555353\n",
      "Iteration 16, loss = 0.99701614\n",
      "Iteration 17, loss = 0.91771629\n",
      "Iteration 18, loss = 0.94358485\n",
      "Iteration 19, loss = 1.03240668\n",
      "Iteration 20, loss = 1.01312124\n",
      "Iteration 21, loss = 0.98624099\n",
      "Iteration 22, loss = 1.03953748\n",
      "Iteration 9, loss = 1.04046868\n",
      "Iteration 10, loss = 0.97938967\n",
      "Iteration 11, loss = 0.97465529\n",
      "Iteration 12, loss = 0.98761125\n",
      "Iteration 13, loss = 1.00669531\n",
      "Iteration 14, loss = 0.94124705\n",
      "Iteration 15, loss = 1.07555353\n",
      "Iteration 16, loss = 0.99701614\n",
      "Iteration 17, loss = 0.91771629\n",
      "Iteration 18, loss = 0.94358485\n",
      "Iteration 19, loss = 1.03240668\n",
      "Iteration 20, loss = 1.01312124\n",
      "Iteration 21, loss = 0.98624099\n",
      "Iteration 22, loss = 1.03953748\n",
      "Iteration 23, loss = 0.99936004\n",
      "Iteration 24, loss = 1.01504266\n",
      "Iteration 25, loss = 0.99178635\n",
      "Iteration 26, loss = 1.01722071\n",
      "Iteration 27, loss = 0.95410906\n",
      "Iteration 28, loss = 0.95091582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20669770\n",
      "Iteration 2, loss = 1.10259077\n",
      "Iteration 3, loss = 1.05001842\n",
      "Iteration 4, loss = 1.05309645\n",
      "Iteration 5, loss = 0.99569141\n",
      "Iteration 6, loss = 1.02099105\n",
      "Iteration 7, loss = 1.00900923\n",
      "Iteration 23, loss = 0.99936004\n",
      "Iteration 24, loss = 1.01504266\n",
      "Iteration 25, loss = 0.99178635\n",
      "Iteration 26, loss = 1.01722071\n",
      "Iteration 27, loss = 0.95410906\n",
      "Iteration 28, loss = 0.95091582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20669770\n",
      "Iteration 2, loss = 1.10259077\n",
      "Iteration 3, loss = 1.05001842\n",
      "Iteration 4, loss = 1.05309645\n",
      "Iteration 5, loss = 0.99569141\n",
      "Iteration 6, loss = 1.02099105\n",
      "Iteration 7, loss = 1.00900923\n",
      "Iteration 8, loss = 1.00812528\n",
      "Iteration 9, loss = 0.98124629\n",
      "Iteration 10, loss = 0.97779971\n",
      "Iteration 11, loss = 0.96737052\n",
      "Iteration 12, loss = 0.96988738\n",
      "Iteration 13, loss = 0.96380326\n",
      "Iteration 14, loss = 0.96551044\n",
      "Iteration 15, loss = 0.95756418\n",
      "Iteration 16, loss = 1.13422899\n",
      "Iteration 17, loss = 1.09280299\n",
      "Iteration 18, loss = 0.99054634\n",
      "Iteration 19, loss = 0.96490314\n",
      "Iteration 20, loss = 0.96062990\n",
      "Iteration 8, loss = 1.00812528\n",
      "Iteration 9, loss = 0.98124629\n",
      "Iteration 10, loss = 0.97779971\n",
      "Iteration 11, loss = 0.96737052\n",
      "Iteration 12, loss = 0.96988738\n",
      "Iteration 13, loss = 0.96380326\n",
      "Iteration 14, loss = 0.96551044\n",
      "Iteration 15, loss = 0.95756418\n",
      "Iteration 16, loss = 1.13422899\n",
      "Iteration 17, loss = 1.09280299\n",
      "Iteration 18, loss = 0.99054634\n",
      "Iteration 19, loss = 0.96490314\n",
      "Iteration 20, loss = 0.96062990\n",
      "Iteration 21, loss = 0.96732880\n",
      "Iteration 22, loss = 0.96501650\n",
      "Iteration 23, loss = 0.94848517\n",
      "Iteration 24, loss = 0.95526977\n",
      "Iteration 25, loss = 0.93660811\n",
      "Iteration 26, loss = 0.96408535\n",
      "Iteration 27, loss = 0.99290836\n",
      "Iteration 28, loss = 0.95742305\n",
      "Iteration 29, loss = 0.94660452\n",
      "Iteration 30, loss = 0.94009866\n",
      "Iteration 31, loss = 0.93386448\n",
      "Iteration 32, loss = 0.94709782\n",
      "Iteration 33, loss = 0.94910304\n",
      "Iteration 34, loss = 1.03707887\n",
      "Iteration 35, loss = 0.99368977\n",
      "Iteration 21, loss = 0.96732880\n",
      "Iteration 22, loss = 0.96501650\n",
      "Iteration 23, loss = 0.94848517\n",
      "Iteration 24, loss = 0.95526977\n",
      "Iteration 25, loss = 0.93660811\n",
      "Iteration 26, loss = 0.96408535\n",
      "Iteration 27, loss = 0.99290836\n",
      "Iteration 28, loss = 0.95742305\n",
      "Iteration 29, loss = 0.94660452\n",
      "Iteration 30, loss = 0.94009866\n",
      "Iteration 31, loss = 0.93386448\n",
      "Iteration 32, loss = 0.94709782\n",
      "Iteration 33, loss = 0.94910304\n",
      "Iteration 34, loss = 1.03707887\n",
      "Iteration 35, loss = 0.99368977\n",
      "Iteration 36, loss = 0.94635530\n",
      "Iteration 37, loss = 0.95103695\n",
      "Iteration 38, loss = 0.96404112\n",
      "Iteration 39, loss = 0.93374441\n",
      "Iteration 40, loss = 0.94330244\n",
      "Iteration 41, loss = 0.92408130\n",
      "Iteration 42, loss = 0.93833133\n",
      "Iteration 43, loss = 0.93071436\n",
      "Iteration 44, loss = 0.93439436\n",
      "Iteration 45, loss = 0.93753120\n",
      "Iteration 46, loss = 0.94071729\n",
      "Iteration 47, loss = 0.92502654\n",
      "Iteration 48, loss = 0.92307376\n",
      "Iteration 49, loss = 0.91996953\n",
      "Iteration 50, loss = 0.94733554\n",
      "Iteration 36, loss = 0.94635530\n",
      "Iteration 37, loss = 0.95103695\n",
      "Iteration 38, loss = 0.96404112\n",
      "Iteration 39, loss = 0.93374441\n",
      "Iteration 40, loss = 0.94330244\n",
      "Iteration 41, loss = 0.92408130\n",
      "Iteration 42, loss = 0.93833133\n",
      "Iteration 43, loss = 0.93071436\n",
      "Iteration 44, loss = 0.93439436\n",
      "Iteration 45, loss = 0.93753120\n",
      "Iteration 46, loss = 0.94071729\n",
      "Iteration 47, loss = 0.92502654\n",
      "Iteration 48, loss = 0.92307376\n",
      "Iteration 49, loss = 0.91996953\n",
      "Iteration 50, loss = 0.94733554\n",
      "Iteration 51, loss = 0.93073327\n",
      "Iteration 52, loss = 0.92543664\n",
      "Iteration 53, loss = 0.92419213\n",
      "Iteration 54, loss = 0.91867340\n",
      "Iteration 55, loss = 0.92800630\n",
      "Iteration 56, loss = 0.91832740\n",
      "Iteration 57, loss = 0.91899947\n",
      "Iteration 58, loss = 0.92528762\n",
      "Iteration 59, loss = 0.91819218\n",
      "Iteration 60, loss = 0.94654664\n",
      "Iteration 61, loss = 1.05523779\n",
      "Iteration 62, loss = 0.96642917\n",
      "Iteration 63, loss = 0.94883353\n",
      "Iteration 64, loss = 0.95734685\n",
      "Iteration 65, loss = 0.93287810\n",
      "Iteration 51, loss = 0.93073327\n",
      "Iteration 52, loss = 0.92543664\n",
      "Iteration 53, loss = 0.92419213\n",
      "Iteration 54, loss = 0.91867340\n",
      "Iteration 55, loss = 0.92800630\n",
      "Iteration 56, loss = 0.91832740\n",
      "Iteration 57, loss = 0.91899947\n",
      "Iteration 58, loss = 0.92528762\n",
      "Iteration 59, loss = 0.91819218\n",
      "Iteration 60, loss = 0.94654664\n",
      "Iteration 61, loss = 1.05523779\n",
      "Iteration 62, loss = 0.96642917\n",
      "Iteration 63, loss = 0.94883353\n",
      "Iteration 64, loss = 0.95734685\n",
      "Iteration 65, loss = 0.93287810\n",
      "Iteration 66, loss = 0.93065584\n",
      "Iteration 67, loss = 0.94509590\n",
      "Iteration 68, loss = 0.94535597\n",
      "Iteration 69, loss = 0.92118018\n",
      "Iteration 70, loss = 0.92225367\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22632329\n",
      "Iteration 2, loss = 1.13108260\n",
      "Iteration 3, loss = 0.97224948\n",
      "Iteration 4, loss = 0.93702393\n",
      "Iteration 5, loss = 0.96349635\n",
      "Iteration 6, loss = 0.92662370\n",
      "Iteration 7, loss = 0.92645699\n",
      "Iteration 8, loss = 0.91610355\n",
      "Iteration 66, loss = 0.93065584\n",
      "Iteration 67, loss = 0.94509590\n",
      "Iteration 68, loss = 0.94535597\n",
      "Iteration 69, loss = 0.92118018\n",
      "Iteration 70, loss = 0.92225367\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22632329\n",
      "Iteration 2, loss = 1.13108260\n",
      "Iteration 3, loss = 0.97224948\n",
      "Iteration 4, loss = 0.93702393\n",
      "Iteration 5, loss = 0.96349635\n",
      "Iteration 6, loss = 0.92662370\n",
      "Iteration 7, loss = 0.92645699\n",
      "Iteration 8, loss = 0.91610355\n",
      "Iteration 9, loss = 0.94474065\n",
      "Iteration 10, loss = 0.94585393\n",
      "Iteration 11, loss = 0.98037905\n",
      "Iteration 12, loss = 1.01105887\n",
      "Iteration 13, loss = 1.00414614\n",
      "Iteration 14, loss = 0.93395986\n",
      "Iteration 15, loss = 0.97373878\n",
      "Iteration 16, loss = 0.94664850\n",
      "Iteration 17, loss = 0.96772177\n",
      "Iteration 18, loss = 0.98819233\n",
      "Iteration 19, loss = 1.02094684\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25310318\n",
      "Iteration 2, loss = 1.13224474\n",
      "Iteration 3, loss = 1.13529661\n",
      "Iteration 9, loss = 0.94474065\n",
      "Iteration 10, loss = 0.94585393\n",
      "Iteration 11, loss = 0.98037905\n",
      "Iteration 12, loss = 1.01105887\n",
      "Iteration 13, loss = 1.00414614\n",
      "Iteration 14, loss = 0.93395986\n",
      "Iteration 15, loss = 0.97373878\n",
      "Iteration 16, loss = 0.94664850\n",
      "Iteration 17, loss = 0.96772177\n",
      "Iteration 18, loss = 0.98819233\n",
      "Iteration 19, loss = 1.02094684\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25310318\n",
      "Iteration 2, loss = 1.13224474\n",
      "Iteration 3, loss = 1.13529661\n",
      "Iteration 4, loss = 1.02393307\n",
      "Iteration 5, loss = 1.01318480\n",
      "Iteration 6, loss = 1.00025429\n",
      "Iteration 7, loss = 0.95660498\n",
      "Iteration 8, loss = 0.94114991\n",
      "Iteration 9, loss = 1.05466184\n",
      "Iteration 10, loss = 1.05693268\n",
      "Iteration 11, loss = 0.99925722\n",
      "Iteration 12, loss = 1.00867679\n",
      "Iteration 13, loss = 0.97554700\n",
      "Iteration 14, loss = 0.97352140\n",
      "Iteration 15, loss = 1.00260021\n",
      "Iteration 4, loss = 1.02393307\n",
      "Iteration 5, loss = 1.01318480\n",
      "Iteration 6, loss = 1.00025429\n",
      "Iteration 7, loss = 0.95660498\n",
      "Iteration 8, loss = 0.94114991\n",
      "Iteration 9, loss = 1.05466184\n",
      "Iteration 10, loss = 1.05693268\n",
      "Iteration 11, loss = 0.99925722\n",
      "Iteration 12, loss = 1.00867679\n",
      "Iteration 13, loss = 0.97554700\n",
      "Iteration 14, loss = 0.97352140\n",
      "Iteration 15, loss = 1.00260021\n",
      "Iteration 16, loss = 0.98474110\n",
      "Iteration 17, loss = 0.94870340\n",
      "Iteration 18, loss = 1.01463639\n",
      "Iteration 19, loss = 0.97134555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21296933\n",
      "Iteration 2, loss = 1.17804732\n",
      "Iteration 3, loss = 1.18705128\n",
      "Iteration 4, loss = 1.16497162\n",
      "Iteration 5, loss = 1.10969339\n",
      "Iteration 6, loss = 1.05958588\n",
      "Iteration 7, loss = 1.01559635\n",
      "Iteration 8, loss = 0.99019325\n",
      "Iteration 9, loss = 1.00880141\n",
      "Iteration 16, loss = 0.98474110\n",
      "Iteration 17, loss = 0.94870340\n",
      "Iteration 18, loss = 1.01463639\n",
      "Iteration 19, loss = 0.97134555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21296933\n",
      "Iteration 2, loss = 1.17804732\n",
      "Iteration 3, loss = 1.18705128\n",
      "Iteration 4, loss = 1.16497162\n",
      "Iteration 5, loss = 1.10969339\n",
      "Iteration 6, loss = 1.05958588\n",
      "Iteration 7, loss = 1.01559635\n",
      "Iteration 8, loss = 0.99019325\n",
      "Iteration 9, loss = 1.00880141\n",
      "Iteration 10, loss = 0.98348246\n",
      "Iteration 11, loss = 1.03778000\n",
      "Iteration 12, loss = 1.00158575\n",
      "Iteration 13, loss = 1.00003040\n",
      "Iteration 14, loss = 0.97684120\n",
      "Iteration 15, loss = 1.08602305\n",
      "Iteration 16, loss = 1.06213652\n",
      "Iteration 17, loss = 0.99862376\n",
      "Iteration 18, loss = 0.97138303\n",
      "Iteration 19, loss = 1.01088389\n",
      "Iteration 20, loss = 0.96658374\n",
      "Iteration 21, loss = 1.01125760\n",
      "Iteration 22, loss = 0.98366887\n",
      "Iteration 23, loss = 0.95268832\n",
      "Iteration 24, loss = 1.01515632\n",
      "Iteration 25, loss = 0.96953565\n",
      "Iteration 10, loss = 0.98348246\n",
      "Iteration 11, loss = 1.03778000\n",
      "Iteration 12, loss = 1.00158575\n",
      "Iteration 13, loss = 1.00003040\n",
      "Iteration 14, loss = 0.97684120\n",
      "Iteration 15, loss = 1.08602305\n",
      "Iteration 16, loss = 1.06213652\n",
      "Iteration 17, loss = 0.99862376\n",
      "Iteration 18, loss = 0.97138303\n",
      "Iteration 19, loss = 1.01088389\n",
      "Iteration 20, loss = 0.96658374\n",
      "Iteration 21, loss = 1.01125760\n",
      "Iteration 22, loss = 0.98366887\n",
      "Iteration 23, loss = 0.95268832\n",
      "Iteration 24, loss = 1.01515632\n",
      "Iteration 25, loss = 0.96953565\n",
      "Iteration 26, loss = 0.93606436\n",
      "Iteration 27, loss = 1.00994647\n",
      "Iteration 28, loss = 0.91709396\n",
      "Iteration 29, loss = 0.91440129\n",
      "Iteration 30, loss = 0.90641248\n",
      "Iteration 31, loss = 0.91574021\n",
      "Iteration 32, loss = 1.02057243\n",
      "Iteration 33, loss = 0.96853685\n",
      "Iteration 34, loss = 1.00079523\n",
      "Iteration 35, loss = 0.97582120\n",
      "Iteration 36, loss = 0.99359451\n",
      "Iteration 37, loss = 0.95989996\n",
      "Iteration 38, loss = 0.92288190\n",
      "Iteration 26, loss = 0.93606436\n",
      "Iteration 27, loss = 1.00994647\n",
      "Iteration 28, loss = 0.91709396\n",
      "Iteration 29, loss = 0.91440129\n",
      "Iteration 30, loss = 0.90641248\n",
      "Iteration 31, loss = 0.91574021\n",
      "Iteration 32, loss = 1.02057243\n",
      "Iteration 33, loss = 0.96853685\n",
      "Iteration 34, loss = 1.00079523\n",
      "Iteration 35, loss = 0.97582120\n",
      "Iteration 36, loss = 0.99359451\n",
      "Iteration 37, loss = 0.95989996\n",
      "Iteration 38, loss = 0.92288190\n",
      "Iteration 39, loss = 0.94523354\n",
      "Iteration 40, loss = 0.94995393\n",
      "Iteration 41, loss = 0.95680857\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20019777\n",
      "Iteration 2, loss = 1.15649628\n",
      "Iteration 3, loss = 1.15661778\n",
      "Iteration 4, loss = 1.03567852\n",
      "Iteration 5, loss = 0.99972171\n",
      "Iteration 6, loss = 1.00853900\n",
      "Iteration 7, loss = 0.99882924\n",
      "Iteration 8, loss = 1.00634913\n",
      "Iteration 9, loss = 1.04046868\n",
      "Iteration 39, loss = 0.94523354\n",
      "Iteration 40, loss = 0.94995393\n",
      "Iteration 41, loss = 0.95680857\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20019777\n",
      "Iteration 2, loss = 1.15649628\n",
      "Iteration 3, loss = 1.15661778\n",
      "Iteration 4, loss = 1.03567852\n",
      "Iteration 5, loss = 0.99972171\n",
      "Iteration 6, loss = 1.00853900\n",
      "Iteration 7, loss = 0.99882924\n",
      "Iteration 8, loss = 1.00634913\n",
      "Iteration 9, loss = 1.04046868\n",
      "Iteration 10, loss = 0.97938967\n",
      "Iteration 11, loss = 0.97465529\n",
      "Iteration 12, loss = 0.98761125\n",
      "Iteration 13, loss = 1.00669531\n",
      "Iteration 14, loss = 0.94124705\n",
      "Iteration 15, loss = 1.07555353\n",
      "Iteration 16, loss = 0.99701614\n",
      "Iteration 17, loss = 0.91771629\n",
      "Iteration 18, loss = 0.94358485\n",
      "Iteration 19, loss = 1.03240668\n",
      "Iteration 20, loss = 1.01312124\n",
      "Iteration 21, loss = 0.98624099\n",
      "Iteration 22, loss = 1.03953748\n",
      "Iteration 23, loss = 0.99936004\n",
      "Iteration 24, loss = 1.01504266\n",
      "Iteration 10, loss = 0.97938967\n",
      "Iteration 11, loss = 0.97465529\n",
      "Iteration 12, loss = 0.98761125\n",
      "Iteration 13, loss = 1.00669531\n",
      "Iteration 14, loss = 0.94124705\n",
      "Iteration 15, loss = 1.07555353\n",
      "Iteration 16, loss = 0.99701614\n",
      "Iteration 17, loss = 0.91771629\n",
      "Iteration 18, loss = 0.94358485\n",
      "Iteration 19, loss = 1.03240668\n",
      "Iteration 20, loss = 1.01312124\n",
      "Iteration 21, loss = 0.98624099\n",
      "Iteration 22, loss = 1.03953748\n",
      "Iteration 23, loss = 0.99936004\n",
      "Iteration 24, loss = 1.01504266\n",
      "Iteration 25, loss = 0.99178635\n",
      "Iteration 26, loss = 1.01722071\n",
      "Iteration 27, loss = 0.95410906\n",
      "Iteration 28, loss = 0.95091582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23422176\n",
      "Iteration 2, loss = 1.09572067\n",
      "Iteration 3, loss = 1.04570791\n",
      "Iteration 4, loss = 0.99585313\n",
      "Iteration 5, loss = 1.04743889\n",
      "Iteration 6, loss = 1.10240142\n",
      "Iteration 7, loss = 1.06357851\n",
      "Iteration 8, loss = 1.02411523\n",
      "Iteration 9, loss = 1.03169459\n",
      "Iteration 10, loss = 0.99504863\n",
      "Iteration 25, loss = 0.99178635\n",
      "Iteration 26, loss = 1.01722071\n",
      "Iteration 27, loss = 0.95410906\n",
      "Iteration 28, loss = 0.95091582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23422176\n",
      "Iteration 2, loss = 1.09572067\n",
      "Iteration 3, loss = 1.04570791\n",
      "Iteration 4, loss = 0.99585313\n",
      "Iteration 5, loss = 1.04743889\n",
      "Iteration 6, loss = 1.10240142\n",
      "Iteration 7, loss = 1.06357851\n",
      "Iteration 8, loss = 1.02411523\n",
      "Iteration 9, loss = 1.03169459\n",
      "Iteration 10, loss = 0.99504863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21871185\n",
      "Iteration 2, loss = 1.08057926\n",
      "Iteration 3, loss = 1.19026987\n",
      "Iteration 4, loss = 1.13689316\n",
      "Iteration 5, loss = 1.01885224\n",
      "Iteration 6, loss = 0.99495508\n",
      "Iteration 7, loss = 0.97424803\n",
      "Iteration 8, loss = 0.96838849\n",
      "Iteration 9, loss = 0.95589879\n",
      "Iteration 10, loss = 0.98027255\n",
      "Iteration 1, loss = 1.27270509\n",
      "Iteration 1, loss = 1.21871185\n",
      "Iteration 2, loss = 1.08057926\n",
      "Iteration 3, loss = 1.19026987\n",
      "Iteration 4, loss = 1.13689316\n",
      "Iteration 5, loss = 1.01885224\n",
      "Iteration 6, loss = 0.99495508\n",
      "Iteration 7, loss = 0.97424803\n",
      "Iteration 8, loss = 0.96838849\n",
      "Iteration 9, loss = 0.95589879\n",
      "Iteration 10, loss = 0.98027255\n",
      "Iteration 1, loss = 1.27270509\n",
      "Iteration 2, loss = 1.14384581\n",
      "Iteration 3, loss = 1.08693866\n",
      "Iteration 4, loss = 0.98628455\n",
      "Iteration 5, loss = 1.00210013\n",
      "Iteration 6, loss = 1.00466254\n",
      "Iteration 7, loss = 0.96583070\n",
      "Iteration 8, loss = 0.96691989\n",
      "Iteration 9, loss = 1.04483541\n",
      "Iteration 10, loss = 1.07087480\n",
      "Iteration 1, loss = 1.22187948\n",
      "Iteration 2, loss = 1.21179441\n",
      "Iteration 3, loss = 1.19599892\n",
      "Iteration 2, loss = 1.14384581\n",
      "Iteration 3, loss = 1.08693866\n",
      "Iteration 4, loss = 0.98628455\n",
      "Iteration 5, loss = 1.00210013\n",
      "Iteration 6, loss = 1.00466254\n",
      "Iteration 7, loss = 0.96583070\n",
      "Iteration 8, loss = 0.96691989\n",
      "Iteration 9, loss = 1.04483541\n",
      "Iteration 10, loss = 1.07087480\n",
      "Iteration 1, loss = 1.22187948\n",
      "Iteration 2, loss = 1.21179441\n",
      "Iteration 3, loss = 1.19599892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.17062443\n",
      "Iteration 5, loss = 1.06908739\n",
      "Iteration 6, loss = 1.24853289\n",
      "Iteration 7, loss = 1.14491205\n",
      "Iteration 8, loss = 1.06072826\n",
      "Iteration 9, loss = 1.05601595\n",
      "Iteration 10, loss = 1.02751121\n",
      "Iteration 1, loss = 1.23770567\n",
      "Iteration 2, loss = 1.15675595\n",
      "Iteration 3, loss = 1.14299937\n",
      "Iteration 4, loss = 1.13482639\n",
      "Iteration 5, loss = 1.06228006\n",
      "Iteration 6, loss = 1.05941376\n",
      "Iteration 4, loss = 1.17062443\n",
      "Iteration 5, loss = 1.06908739\n",
      "Iteration 6, loss = 1.24853289\n",
      "Iteration 7, loss = 1.14491205\n",
      "Iteration 8, loss = 1.06072826\n",
      "Iteration 9, loss = 1.05601595\n",
      "Iteration 10, loss = 1.02751121\n",
      "Iteration 1, loss = 1.23770567\n",
      "Iteration 2, loss = 1.15675595\n",
      "Iteration 3, loss = 1.14299937\n",
      "Iteration 4, loss = 1.13482639\n",
      "Iteration 5, loss = 1.06228006\n",
      "Iteration 6, loss = 1.05941376\n",
      "Iteration 7, loss = 1.04430716\n",
      "Iteration 8, loss = 1.07314651\n",
      "Iteration 9, loss = 1.05130798\n",
      "Iteration 10, loss = 1.06330878\n",
      "Iteration 1, loss = 1.23422176\n",
      "Iteration 2, loss = 1.09572067\n",
      "Iteration 3, loss = 1.04570791\n",
      "Iteration 4, loss = 0.99585313\n",
      "Iteration 5, loss = 1.04743889\n",
      "Iteration 6, loss = 1.10240142\n",
      "Iteration 7, loss = 1.06357851\n",
      "Iteration 8, loss = 1.02411523\n",
      "Iteration 7, loss = 1.04430716\n",
      "Iteration 8, loss = 1.07314651\n",
      "Iteration 9, loss = 1.05130798\n",
      "Iteration 10, loss = 1.06330878\n",
      "Iteration 1, loss = 1.23422176\n",
      "Iteration 2, loss = 1.09572067\n",
      "Iteration 3, loss = 1.04570791\n",
      "Iteration 4, loss = 0.99585313\n",
      "Iteration 5, loss = 1.04743889\n",
      "Iteration 6, loss = 1.10240142\n",
      "Iteration 7, loss = 1.06357851\n",
      "Iteration 8, loss = 1.02411523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.03169459\n",
      "Iteration 10, loss = 0.99504863\n",
      "Iteration 11, loss = 0.97770209\n",
      "Iteration 12, loss = 0.97996883\n",
      "Iteration 13, loss = 1.00068493\n",
      "Iteration 14, loss = 0.99060732\n",
      "Iteration 15, loss = 0.99721625\n",
      "Iteration 16, loss = 1.03018454\n",
      "Iteration 17, loss = 0.99453603\n",
      "Iteration 18, loss = 0.96794729\n",
      "Iteration 19, loss = 0.96286734\n",
      "Iteration 20, loss = 1.09714935\n",
      "Iteration 21, loss = 1.07072263\n",
      "Iteration 22, loss = 1.07750742\n",
      "Iteration 9, loss = 1.03169459\n",
      "Iteration 10, loss = 0.99504863\n",
      "Iteration 11, loss = 0.97770209\n",
      "Iteration 12, loss = 0.97996883\n",
      "Iteration 13, loss = 1.00068493\n",
      "Iteration 14, loss = 0.99060732\n",
      "Iteration 15, loss = 0.99721625\n",
      "Iteration 16, loss = 1.03018454\n",
      "Iteration 17, loss = 0.99453603\n",
      "Iteration 18, loss = 0.96794729\n",
      "Iteration 19, loss = 0.96286734\n",
      "Iteration 20, loss = 1.09714935\n",
      "Iteration 21, loss = 1.07072263\n",
      "Iteration 22, loss = 1.07750742\n",
      "Iteration 23, loss = 1.08415492\n",
      "Iteration 24, loss = 0.99003350\n",
      "Iteration 25, loss = 0.96447568\n",
      "Iteration 26, loss = 1.00311755\n",
      "Iteration 27, loss = 1.01178086\n",
      "Iteration 28, loss = 0.95955357\n",
      "Iteration 29, loss = 0.96645270\n",
      "Iteration 30, loss = 0.97026503\n",
      "Iteration 31, loss = 0.95568096\n",
      "Iteration 32, loss = 0.96762429\n",
      "Iteration 33, loss = 0.96591994\n",
      "Iteration 34, loss = 0.98463219\n",
      "Iteration 35, loss = 0.96153377\n",
      "Iteration 36, loss = 0.96133550\n",
      "Iteration 37, loss = 0.98046940\n",
      "Iteration 38, loss = 1.04345399\n",
      "Iteration 23, loss = 1.08415492\n",
      "Iteration 24, loss = 0.99003350\n",
      "Iteration 25, loss = 0.96447568\n",
      "Iteration 26, loss = 1.00311755\n",
      "Iteration 27, loss = 1.01178086\n",
      "Iteration 28, loss = 0.95955357\n",
      "Iteration 29, loss = 0.96645270\n",
      "Iteration 30, loss = 0.97026503\n",
      "Iteration 31, loss = 0.95568096\n",
      "Iteration 32, loss = 0.96762429\n",
      "Iteration 33, loss = 0.96591994\n",
      "Iteration 34, loss = 0.98463219\n",
      "Iteration 35, loss = 0.96153377\n",
      "Iteration 36, loss = 0.96133550\n",
      "Iteration 37, loss = 0.98046940\n",
      "Iteration 38, loss = 1.04345399\n",
      "Iteration 39, loss = 0.97698398\n",
      "Iteration 40, loss = 0.98500717\n",
      "Iteration 41, loss = 0.95429530\n",
      "Iteration 42, loss = 0.98973291\n",
      "Iteration 43, loss = 0.99127823\n",
      "Iteration 44, loss = 0.97588453\n",
      "Iteration 45, loss = 0.98043108\n",
      "Iteration 46, loss = 0.97342875\n",
      "Iteration 47, loss = 0.97294179\n",
      "Iteration 48, loss = 0.96474714\n",
      "Iteration 49, loss = 0.99700829\n",
      "Iteration 50, loss = 0.98120871\n",
      "Iteration 1, loss = 1.21871185\n",
      "Iteration 2, loss = 1.08057926\n",
      "Iteration 3, loss = 1.19026987\n",
      "Iteration 39, loss = 0.97698398\n",
      "Iteration 40, loss = 0.98500717\n",
      "Iteration 41, loss = 0.95429530\n",
      "Iteration 42, loss = 0.98973291\n",
      "Iteration 43, loss = 0.99127823\n",
      "Iteration 44, loss = 0.97588453\n",
      "Iteration 45, loss = 0.98043108\n",
      "Iteration 46, loss = 0.97342875\n",
      "Iteration 47, loss = 0.97294179\n",
      "Iteration 48, loss = 0.96474714\n",
      "Iteration 49, loss = 0.99700829\n",
      "Iteration 50, loss = 0.98120871\n",
      "Iteration 1, loss = 1.21871185\n",
      "Iteration 2, loss = 1.08057926\n",
      "Iteration 3, loss = 1.19026987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.13689316\n",
      "Iteration 5, loss = 1.01885224\n",
      "Iteration 6, loss = 0.99495508\n",
      "Iteration 7, loss = 0.97424803\n",
      "Iteration 8, loss = 0.96838849\n",
      "Iteration 9, loss = 0.95589879\n",
      "Iteration 10, loss = 0.98027255\n",
      "Iteration 11, loss = 1.06166522\n",
      "Iteration 12, loss = 1.04324203\n",
      "Iteration 13, loss = 0.97451883\n",
      "Iteration 14, loss = 0.98124069\n",
      "Iteration 15, loss = 0.96577484\n",
      "Iteration 16, loss = 0.95629691\n",
      "Iteration 17, loss = 0.95519515\n",
      "Iteration 18, loss = 0.93112840\n",
      "Iteration 4, loss = 1.13689316\n",
      "Iteration 5, loss = 1.01885224\n",
      "Iteration 6, loss = 0.99495508\n",
      "Iteration 7, loss = 0.97424803\n",
      "Iteration 8, loss = 0.96838849\n",
      "Iteration 9, loss = 0.95589879\n",
      "Iteration 10, loss = 0.98027255\n",
      "Iteration 11, loss = 1.06166522\n",
      "Iteration 12, loss = 1.04324203\n",
      "Iteration 13, loss = 0.97451883\n",
      "Iteration 14, loss = 0.98124069\n",
      "Iteration 15, loss = 0.96577484\n",
      "Iteration 16, loss = 0.95629691\n",
      "Iteration 17, loss = 0.95519515\n",
      "Iteration 18, loss = 0.93112840\n",
      "Iteration 19, loss = 0.94728617\n",
      "Iteration 20, loss = 0.95320327\n",
      "Iteration 21, loss = 0.96828480\n",
      "Iteration 22, loss = 0.94517760\n",
      "Iteration 23, loss = 0.94419222\n",
      "Iteration 24, loss = 0.93960702\n",
      "Iteration 25, loss = 0.92560884\n",
      "Iteration 26, loss = 0.98180937\n",
      "Iteration 27, loss = 0.94064876\n",
      "Iteration 28, loss = 0.94050654\n",
      "Iteration 29, loss = 1.00032637\n",
      "Iteration 30, loss = 0.93165262\n",
      "Iteration 31, loss = 0.93590714\n",
      "Iteration 32, loss = 0.94382885\n",
      "Iteration 33, loss = 0.93389373\n",
      "Iteration 19, loss = 0.94728617\n",
      "Iteration 20, loss = 0.95320327\n",
      "Iteration 21, loss = 0.96828480\n",
      "Iteration 22, loss = 0.94517760\n",
      "Iteration 23, loss = 0.94419222\n",
      "Iteration 24, loss = 0.93960702\n",
      "Iteration 25, loss = 0.92560884\n",
      "Iteration 26, loss = 0.98180937\n",
      "Iteration 27, loss = 0.94064876\n",
      "Iteration 28, loss = 0.94050654\n",
      "Iteration 29, loss = 1.00032637\n",
      "Iteration 30, loss = 0.93165262\n",
      "Iteration 31, loss = 0.93590714\n",
      "Iteration 32, loss = 0.94382885\n",
      "Iteration 33, loss = 0.93389373\n",
      "Iteration 34, loss = 0.95597426\n",
      "Iteration 35, loss = 0.96046772\n",
      "Iteration 36, loss = 0.93870154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27270509\n",
      "Iteration 2, loss = 1.14384581\n",
      "Iteration 3, loss = 1.08693866\n",
      "Iteration 4, loss = 0.98628455\n",
      "Iteration 5, loss = 1.00210013\n",
      "Iteration 6, loss = 1.00466254\n",
      "Iteration 7, loss = 0.96583070\n",
      "Iteration 8, loss = 0.96691989\n",
      "Iteration 9, loss = 1.04483541\n",
      "Iteration 34, loss = 0.95597426\n",
      "Iteration 35, loss = 0.96046772\n",
      "Iteration 36, loss = 0.93870154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27270509\n",
      "Iteration 2, loss = 1.14384581\n",
      "Iteration 3, loss = 1.08693866\n",
      "Iteration 4, loss = 0.98628455\n",
      "Iteration 5, loss = 1.00210013\n",
      "Iteration 6, loss = 1.00466254\n",
      "Iteration 7, loss = 0.96583070\n",
      "Iteration 8, loss = 0.96691989\n",
      "Iteration 9, loss = 1.04483541\n",
      "Iteration 10, loss = 1.07087480\n",
      "Iteration 11, loss = 1.19224639\n",
      "Iteration 12, loss = 1.19120665\n",
      "Iteration 13, loss = 1.02186835\n",
      "Iteration 14, loss = 1.04709290\n",
      "Iteration 15, loss = 1.01474421\n",
      "Iteration 16, loss = 0.97716540\n",
      "Iteration 17, loss = 0.96084619\n",
      "Iteration 18, loss = 0.97879728\n",
      "Iteration 19, loss = 0.95099569\n",
      "Iteration 20, loss = 0.97204639\n",
      "Iteration 21, loss = 0.97862582\n",
      "Iteration 22, loss = 0.93337149\n",
      "Iteration 23, loss = 0.94321313\n",
      "Iteration 24, loss = 0.96432784\n",
      "Iteration 10, loss = 1.07087480\n",
      "Iteration 11, loss = 1.19224639\n",
      "Iteration 12, loss = 1.19120665\n",
      "Iteration 13, loss = 1.02186835\n",
      "Iteration 14, loss = 1.04709290\n",
      "Iteration 15, loss = 1.01474421\n",
      "Iteration 16, loss = 0.97716540\n",
      "Iteration 17, loss = 0.96084619\n",
      "Iteration 18, loss = 0.97879728\n",
      "Iteration 19, loss = 0.95099569\n",
      "Iteration 20, loss = 0.97204639\n",
      "Iteration 21, loss = 0.97862582\n",
      "Iteration 22, loss = 0.93337149\n",
      "Iteration 23, loss = 0.94321313\n",
      "Iteration 24, loss = 0.96432784\n",
      "Iteration 25, loss = 0.95455306\n",
      "Iteration 26, loss = 1.03321284\n",
      "Iteration 27, loss = 0.99825771\n",
      "Iteration 28, loss = 1.01085100\n",
      "Iteration 29, loss = 0.97522996\n",
      "Iteration 30, loss = 0.96095806\n",
      "Iteration 31, loss = 1.00145087\n",
      "Iteration 32, loss = 1.20277302\n",
      "Iteration 33, loss = 1.35646043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22187948\n",
      "Iteration 2, loss = 1.21179441\n",
      "Iteration 3, loss = 1.19599892\n",
      "Iteration 4, loss = 1.17062443\n",
      "Iteration 25, loss = 0.95455306\n",
      "Iteration 26, loss = 1.03321284\n",
      "Iteration 27, loss = 0.99825771\n",
      "Iteration 28, loss = 1.01085100\n",
      "Iteration 29, loss = 0.97522996\n",
      "Iteration 30, loss = 0.96095806\n",
      "Iteration 31, loss = 1.00145087\n",
      "Iteration 32, loss = 1.20277302\n",
      "Iteration 33, loss = 1.35646043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22187948\n",
      "Iteration 2, loss = 1.21179441\n",
      "Iteration 3, loss = 1.19599892\n",
      "Iteration 4, loss = 1.17062443\n",
      "Iteration 5, loss = 1.06908739\n",
      "Iteration 6, loss = 1.24853289\n",
      "Iteration 7, loss = 1.14491205\n",
      "Iteration 8, loss = 1.06072826\n",
      "Iteration 9, loss = 1.05601595\n",
      "Iteration 10, loss = 1.02751121\n",
      "Iteration 11, loss = 1.06212105\n",
      "Iteration 12, loss = 1.10589474\n",
      "Iteration 13, loss = 1.10789803\n",
      "Iteration 14, loss = 1.08296080\n",
      "Iteration 15, loss = 1.23506569\n",
      "Iteration 16, loss = 1.15319072\n",
      "Iteration 17, loss = 1.09975427\n",
      "Iteration 18, loss = 1.04470564\n",
      "Iteration 5, loss = 1.06908739\n",
      "Iteration 6, loss = 1.24853289\n",
      "Iteration 7, loss = 1.14491205\n",
      "Iteration 8, loss = 1.06072826\n",
      "Iteration 9, loss = 1.05601595\n",
      "Iteration 10, loss = 1.02751121\n",
      "Iteration 11, loss = 1.06212105\n",
      "Iteration 12, loss = 1.10589474\n",
      "Iteration 13, loss = 1.10789803\n",
      "Iteration 14, loss = 1.08296080\n",
      "Iteration 15, loss = 1.23506569\n",
      "Iteration 16, loss = 1.15319072\n",
      "Iteration 17, loss = 1.09975427\n",
      "Iteration 18, loss = 1.04470564\n",
      "Iteration 19, loss = 1.04768475\n",
      "Iteration 20, loss = 1.03483148\n",
      "Iteration 21, loss = 1.05446222\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23770567\n",
      "Iteration 2, loss = 1.15675595\n",
      "Iteration 3, loss = 1.14299937\n",
      "Iteration 4, loss = 1.13482639\n",
      "Iteration 5, loss = 1.06228006\n",
      "Iteration 6, loss = 1.05941376\n",
      "Iteration 7, loss = 1.04430716\n",
      "Iteration 8, loss = 1.07314651\n",
      "Iteration 9, loss = 1.05130798\n",
      "Iteration 10, loss = 1.06330878\n",
      "Iteration 19, loss = 1.04768475\n",
      "Iteration 20, loss = 1.03483148\n",
      "Iteration 21, loss = 1.05446222\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23770567\n",
      "Iteration 2, loss = 1.15675595\n",
      "Iteration 3, loss = 1.14299937\n",
      "Iteration 4, loss = 1.13482639\n",
      "Iteration 5, loss = 1.06228006\n",
      "Iteration 6, loss = 1.05941376\n",
      "Iteration 7, loss = 1.04430716\n",
      "Iteration 8, loss = 1.07314651\n",
      "Iteration 9, loss = 1.05130798\n",
      "Iteration 10, loss = 1.06330878\n",
      "Iteration 11, loss = 1.04032547\n",
      "Iteration 12, loss = 1.04591856\n",
      "Iteration 13, loss = 1.09494360\n",
      "Iteration 14, loss = 1.12373433\n",
      "Iteration 15, loss = 1.28005993\n",
      "Iteration 16, loss = 1.13413549\n",
      "Iteration 17, loss = 1.08638326\n",
      "Iteration 18, loss = 1.10844379\n",
      "Iteration 19, loss = 1.13643055\n",
      "Iteration 20, loss = 1.05543963\n",
      "Iteration 21, loss = 1.03402708\n",
      "Iteration 22, loss = 1.02887252\n",
      "Iteration 23, loss = 0.98743492\n",
      "Iteration 24, loss = 1.14963107\n",
      "Iteration 25, loss = 1.07049262\n",
      "Iteration 11, loss = 1.04032547\n",
      "Iteration 12, loss = 1.04591856\n",
      "Iteration 13, loss = 1.09494360\n",
      "Iteration 14, loss = 1.12373433\n",
      "Iteration 15, loss = 1.28005993\n",
      "Iteration 16, loss = 1.13413549\n",
      "Iteration 17, loss = 1.08638326\n",
      "Iteration 18, loss = 1.10844379\n",
      "Iteration 19, loss = 1.13643055\n",
      "Iteration 20, loss = 1.05543963\n",
      "Iteration 21, loss = 1.03402708\n",
      "Iteration 22, loss = 1.02887252\n",
      "Iteration 23, loss = 0.98743492\n",
      "Iteration 24, loss = 1.14963107\n",
      "Iteration 25, loss = 1.07049262\n",
      "Iteration 26, loss = 1.06743618\n",
      "Iteration 27, loss = 1.05240240\n",
      "Iteration 28, loss = 1.03987250\n",
      "Iteration 29, loss = 1.03981192\n",
      "Iteration 30, loss = 0.98463890\n",
      "Iteration 31, loss = 1.01087377\n",
      "Iteration 32, loss = 1.03621770\n",
      "Iteration 33, loss = 1.07628244\n",
      "Iteration 34, loss = 1.03235837\n",
      "Iteration 35, loss = 1.02415596\n",
      "Iteration 36, loss = 1.03031895\n",
      "Iteration 37, loss = 1.08771278\n",
      "Iteration 38, loss = 0.99974755\n",
      "Iteration 39, loss = 0.97968238\n",
      "Iteration 40, loss = 1.02149434\n",
      "Iteration 41, loss = 1.03436988\n",
      "Iteration 26, loss = 1.06743618\n",
      "Iteration 27, loss = 1.05240240\n",
      "Iteration 28, loss = 1.03987250\n",
      "Iteration 29, loss = 1.03981192\n",
      "Iteration 30, loss = 0.98463890\n",
      "Iteration 31, loss = 1.01087377\n",
      "Iteration 32, loss = 1.03621770\n",
      "Iteration 33, loss = 1.07628244\n",
      "Iteration 34, loss = 1.03235837\n",
      "Iteration 35, loss = 1.02415596\n",
      "Iteration 36, loss = 1.03031895\n",
      "Iteration 37, loss = 1.08771278\n",
      "Iteration 38, loss = 0.99974755\n",
      "Iteration 39, loss = 0.97968238\n",
      "Iteration 40, loss = 1.02149434\n",
      "Iteration 41, loss = 1.03436988\n",
      "Iteration 42, loss = 0.97518546\n",
      "Iteration 43, loss = 1.17770135\n",
      "Iteration 44, loss = 1.07456367\n",
      "Iteration 45, loss = 1.02918128\n",
      "Iteration 46, loss = 1.03161259\n",
      "Iteration 47, loss = 1.07707640\n",
      "Iteration 48, loss = 1.07014718\n",
      "Iteration 49, loss = 0.99349137\n",
      "Iteration 50, loss = 1.11613936\n",
      "Iteration 1, loss = 1.23422176\n",
      "Iteration 2, loss = 1.09572067\n",
      "Iteration 3, loss = 1.04570791\n",
      "Iteration 4, loss = 0.99585313\n",
      "Iteration 5, loss = 1.04743889\n",
      "Iteration 42, loss = 0.97518546\n",
      "Iteration 43, loss = 1.17770135\n",
      "Iteration 44, loss = 1.07456367\n",
      "Iteration 45, loss = 1.02918128\n",
      "Iteration 46, loss = 1.03161259\n",
      "Iteration 47, loss = 1.07707640\n",
      "Iteration 48, loss = 1.07014718\n",
      "Iteration 49, loss = 0.99349137\n",
      "Iteration 50, loss = 1.11613936\n",
      "Iteration 1, loss = 1.23422176\n",
      "Iteration 2, loss = 1.09572067\n",
      "Iteration 3, loss = 1.04570791\n",
      "Iteration 4, loss = 0.99585313\n",
      "Iteration 5, loss = 1.04743889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.10240142\n",
      "Iteration 7, loss = 1.06357851\n",
      "Iteration 8, loss = 1.02411523\n",
      "Iteration 9, loss = 1.03169459\n",
      "Iteration 10, loss = 0.99504863\n",
      "Iteration 11, loss = 0.97770209\n",
      "Iteration 12, loss = 0.97996883\n",
      "Iteration 13, loss = 1.00068493\n",
      "Iteration 14, loss = 0.99060732\n",
      "Iteration 15, loss = 0.99721625\n",
      "Iteration 16, loss = 1.03018454\n",
      "Iteration 17, loss = 0.99453603\n",
      "Iteration 18, loss = 0.96794729\n",
      "Iteration 19, loss = 0.96286734\n",
      "Iteration 6, loss = 1.10240142\n",
      "Iteration 7, loss = 1.06357851\n",
      "Iteration 8, loss = 1.02411523\n",
      "Iteration 9, loss = 1.03169459\n",
      "Iteration 10, loss = 0.99504863\n",
      "Iteration 11, loss = 0.97770209\n",
      "Iteration 12, loss = 0.97996883\n",
      "Iteration 13, loss = 1.00068493\n",
      "Iteration 14, loss = 0.99060732\n",
      "Iteration 15, loss = 0.99721625\n",
      "Iteration 16, loss = 1.03018454\n",
      "Iteration 17, loss = 0.99453603\n",
      "Iteration 18, loss = 0.96794729\n",
      "Iteration 19, loss = 0.96286734\n",
      "Iteration 20, loss = 1.09714935\n",
      "Iteration 21, loss = 1.07072263\n",
      "Iteration 22, loss = 1.07750742\n",
      "Iteration 23, loss = 1.08415492\n",
      "Iteration 24, loss = 0.99003350\n",
      "Iteration 25, loss = 0.96447568\n",
      "Iteration 26, loss = 1.00311755\n",
      "Iteration 27, loss = 1.01178086\n",
      "Iteration 28, loss = 0.95955357\n",
      "Iteration 29, loss = 0.96645270\n",
      "Iteration 30, loss = 0.97026503\n",
      "Iteration 31, loss = 0.95568096\n",
      "Iteration 32, loss = 0.96762429\n",
      "Iteration 33, loss = 0.96591994\n",
      "Iteration 34, loss = 0.98463219\n",
      "Iteration 20, loss = 1.09714935\n",
      "Iteration 21, loss = 1.07072263\n",
      "Iteration 22, loss = 1.07750742\n",
      "Iteration 23, loss = 1.08415492\n",
      "Iteration 24, loss = 0.99003350\n",
      "Iteration 25, loss = 0.96447568\n",
      "Iteration 26, loss = 1.00311755\n",
      "Iteration 27, loss = 1.01178086\n",
      "Iteration 28, loss = 0.95955357\n",
      "Iteration 29, loss = 0.96645270\n",
      "Iteration 30, loss = 0.97026503\n",
      "Iteration 31, loss = 0.95568096\n",
      "Iteration 32, loss = 0.96762429\n",
      "Iteration 33, loss = 0.96591994\n",
      "Iteration 34, loss = 0.98463219\n",
      "Iteration 35, loss = 0.96153377\n",
      "Iteration 36, loss = 0.96133550\n",
      "Iteration 37, loss = 0.98046940\n",
      "Iteration 38, loss = 1.04345399\n",
      "Iteration 39, loss = 0.97698398\n",
      "Iteration 40, loss = 0.98500717\n",
      "Iteration 41, loss = 0.95429530\n",
      "Iteration 42, loss = 0.98973291\n",
      "Iteration 43, loss = 0.99127823\n",
      "Iteration 44, loss = 0.97588453\n",
      "Iteration 45, loss = 0.98043108\n",
      "Iteration 46, loss = 0.97342875\n",
      "Iteration 47, loss = 0.97294179\n",
      "Iteration 48, loss = 0.96474714\n",
      "Iteration 49, loss = 0.99700829\n",
      "Iteration 50, loss = 0.98120871\n",
      "Iteration 35, loss = 0.96153377\n",
      "Iteration 36, loss = 0.96133550\n",
      "Iteration 37, loss = 0.98046940\n",
      "Iteration 38, loss = 1.04345399\n",
      "Iteration 39, loss = 0.97698398\n",
      "Iteration 40, loss = 0.98500717\n",
      "Iteration 41, loss = 0.95429530\n",
      "Iteration 42, loss = 0.98973291\n",
      "Iteration 43, loss = 0.99127823\n",
      "Iteration 44, loss = 0.97588453\n",
      "Iteration 45, loss = 0.98043108\n",
      "Iteration 46, loss = 0.97342875\n",
      "Iteration 47, loss = 0.97294179\n",
      "Iteration 48, loss = 0.96474714\n",
      "Iteration 49, loss = 0.99700829\n",
      "Iteration 50, loss = 0.98120871\n",
      "Iteration 51, loss = 0.97139559\n",
      "Iteration 52, loss = 0.97897385\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21871185\n",
      "Iteration 2, loss = 1.08057926\n",
      "Iteration 3, loss = 1.19026987\n",
      "Iteration 4, loss = 1.13689316\n",
      "Iteration 5, loss = 1.01885224\n",
      "Iteration 6, loss = 0.99495508\n",
      "Iteration 7, loss = 0.97424803\n",
      "Iteration 8, loss = 0.96838849\n",
      "Iteration 9, loss = 0.95589879\n",
      "Iteration 10, loss = 0.98027255\n",
      "Iteration 11, loss = 1.06166522\n",
      "Iteration 12, loss = 1.04324203\n",
      "Iteration 51, loss = 0.97139559\n",
      "Iteration 52, loss = 0.97897385\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21871185\n",
      "Iteration 2, loss = 1.08057926\n",
      "Iteration 3, loss = 1.19026987\n",
      "Iteration 4, loss = 1.13689316\n",
      "Iteration 5, loss = 1.01885224\n",
      "Iteration 6, loss = 0.99495508\n",
      "Iteration 7, loss = 0.97424803\n",
      "Iteration 8, loss = 0.96838849\n",
      "Iteration 9, loss = 0.95589879\n",
      "Iteration 10, loss = 0.98027255\n",
      "Iteration 11, loss = 1.06166522\n",
      "Iteration 12, loss = 1.04324203\n",
      "Iteration 13, loss = 0.97451883\n",
      "Iteration 14, loss = 0.98124069\n",
      "Iteration 15, loss = 0.96577484\n",
      "Iteration 16, loss = 0.95629691\n",
      "Iteration 17, loss = 0.95519515\n",
      "Iteration 18, loss = 0.93112840\n",
      "Iteration 19, loss = 0.94728617\n",
      "Iteration 20, loss = 0.95320327\n",
      "Iteration 21, loss = 0.96828480\n",
      "Iteration 22, loss = 0.94517760\n",
      "Iteration 23, loss = 0.94419222\n",
      "Iteration 24, loss = 0.93960702\n",
      "Iteration 25, loss = 0.92560884\n",
      "Iteration 26, loss = 0.98180937\n",
      "Iteration 27, loss = 0.94064876\n",
      "Iteration 13, loss = 0.97451883\n",
      "Iteration 14, loss = 0.98124069\n",
      "Iteration 15, loss = 0.96577484\n",
      "Iteration 16, loss = 0.95629691\n",
      "Iteration 17, loss = 0.95519515\n",
      "Iteration 18, loss = 0.93112840\n",
      "Iteration 19, loss = 0.94728617\n",
      "Iteration 20, loss = 0.95320327\n",
      "Iteration 21, loss = 0.96828480\n",
      "Iteration 22, loss = 0.94517760\n",
      "Iteration 23, loss = 0.94419222\n",
      "Iteration 24, loss = 0.93960702\n",
      "Iteration 25, loss = 0.92560884\n",
      "Iteration 26, loss = 0.98180937\n",
      "Iteration 27, loss = 0.94064876\n",
      "Iteration 28, loss = 0.94050654\n",
      "Iteration 29, loss = 1.00032637\n",
      "Iteration 30, loss = 0.93165262\n",
      "Iteration 31, loss = 0.93590714\n",
      "Iteration 32, loss = 0.94382885\n",
      "Iteration 33, loss = 0.93389373\n",
      "Iteration 34, loss = 0.95597426\n",
      "Iteration 35, loss = 0.96046772\n",
      "Iteration 36, loss = 0.93870154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27270509\n",
      "Iteration 2, loss = 1.14384581\n",
      "Iteration 3, loss = 1.08693866\n",
      "Iteration 4, loss = 0.98628455\n",
      "Iteration 5, loss = 1.00210013\n",
      "Iteration 28, loss = 0.94050654\n",
      "Iteration 29, loss = 1.00032637\n",
      "Iteration 30, loss = 0.93165262\n",
      "Iteration 31, loss = 0.93590714\n",
      "Iteration 32, loss = 0.94382885\n",
      "Iteration 33, loss = 0.93389373\n",
      "Iteration 34, loss = 0.95597426\n",
      "Iteration 35, loss = 0.96046772\n",
      "Iteration 36, loss = 0.93870154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27270509\n",
      "Iteration 2, loss = 1.14384581\n",
      "Iteration 3, loss = 1.08693866\n",
      "Iteration 4, loss = 0.98628455\n",
      "Iteration 5, loss = 1.00210013\n",
      "Iteration 6, loss = 1.00466254\n",
      "Iteration 7, loss = 0.96583070\n",
      "Iteration 8, loss = 0.96691989\n",
      "Iteration 9, loss = 1.04483541\n",
      "Iteration 10, loss = 1.07087480\n",
      "Iteration 11, loss = 1.19224639\n",
      "Iteration 12, loss = 1.19120665\n",
      "Iteration 13, loss = 1.02186835\n",
      "Iteration 14, loss = 1.04709290\n",
      "Iteration 15, loss = 1.01474421\n",
      "Iteration 16, loss = 0.97716540\n",
      "Iteration 17, loss = 0.96084619\n",
      "Iteration 18, loss = 0.97879728\n",
      "Iteration 19, loss = 0.95099569\n",
      "Iteration 6, loss = 1.00466254\n",
      "Iteration 7, loss = 0.96583070\n",
      "Iteration 8, loss = 0.96691989\n",
      "Iteration 9, loss = 1.04483541\n",
      "Iteration 10, loss = 1.07087480\n",
      "Iteration 11, loss = 1.19224639\n",
      "Iteration 12, loss = 1.19120665\n",
      "Iteration 13, loss = 1.02186835\n",
      "Iteration 14, loss = 1.04709290\n",
      "Iteration 15, loss = 1.01474421\n",
      "Iteration 16, loss = 0.97716540\n",
      "Iteration 17, loss = 0.96084619\n",
      "Iteration 18, loss = 0.97879728\n",
      "Iteration 19, loss = 0.95099569\n",
      "Iteration 20, loss = 0.97204639\n",
      "Iteration 21, loss = 0.97862582\n",
      "Iteration 22, loss = 0.93337149\n",
      "Iteration 23, loss = 0.94321313\n",
      "Iteration 24, loss = 0.96432784\n",
      "Iteration 25, loss = 0.95455306\n",
      "Iteration 26, loss = 1.03321284\n",
      "Iteration 27, loss = 0.99825771\n",
      "Iteration 28, loss = 1.01085100\n",
      "Iteration 29, loss = 0.97522996\n",
      "Iteration 30, loss = 0.96095806\n",
      "Iteration 31, loss = 1.00145087\n",
      "Iteration 32, loss = 1.20277302\n",
      "Iteration 33, loss = 1.35646043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22187948\n",
      "Iteration 20, loss = 0.97204639\n",
      "Iteration 21, loss = 0.97862582\n",
      "Iteration 22, loss = 0.93337149\n",
      "Iteration 23, loss = 0.94321313\n",
      "Iteration 24, loss = 0.96432784\n",
      "Iteration 25, loss = 0.95455306\n",
      "Iteration 26, loss = 1.03321284\n",
      "Iteration 27, loss = 0.99825771\n",
      "Iteration 28, loss = 1.01085100\n",
      "Iteration 29, loss = 0.97522996\n",
      "Iteration 30, loss = 0.96095806\n",
      "Iteration 31, loss = 1.00145087\n",
      "Iteration 32, loss = 1.20277302\n",
      "Iteration 33, loss = 1.35646043\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22187948\n",
      "Iteration 2, loss = 1.21179441\n",
      "Iteration 3, loss = 1.19599892\n",
      "Iteration 4, loss = 1.17062443\n",
      "Iteration 5, loss = 1.06908739\n",
      "Iteration 6, loss = 1.24853289\n",
      "Iteration 7, loss = 1.14491205\n",
      "Iteration 8, loss = 1.06072826\n",
      "Iteration 9, loss = 1.05601595\n",
      "Iteration 10, loss = 1.02751121\n",
      "Iteration 11, loss = 1.06212105\n",
      "Iteration 12, loss = 1.10589474\n",
      "Iteration 13, loss = 1.10789803\n",
      "Iteration 14, loss = 1.08296080\n",
      "Iteration 15, loss = 1.23506569\n",
      "Iteration 16, loss = 1.15319072\n",
      "Iteration 2, loss = 1.21179441\n",
      "Iteration 3, loss = 1.19599892\n",
      "Iteration 4, loss = 1.17062443\n",
      "Iteration 5, loss = 1.06908739\n",
      "Iteration 6, loss = 1.24853289\n",
      "Iteration 7, loss = 1.14491205\n",
      "Iteration 8, loss = 1.06072826\n",
      "Iteration 9, loss = 1.05601595\n",
      "Iteration 10, loss = 1.02751121\n",
      "Iteration 11, loss = 1.06212105\n",
      "Iteration 12, loss = 1.10589474\n",
      "Iteration 13, loss = 1.10789803\n",
      "Iteration 14, loss = 1.08296080\n",
      "Iteration 15, loss = 1.23506569\n",
      "Iteration 16, loss = 1.15319072\n",
      "Iteration 17, loss = 1.09975427\n",
      "Iteration 18, loss = 1.04470564\n",
      "Iteration 19, loss = 1.04768475\n",
      "Iteration 20, loss = 1.03483148\n",
      "Iteration 21, loss = 1.05446222\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23770567\n",
      "Iteration 2, loss = 1.15675595\n",
      "Iteration 3, loss = 1.14299937\n",
      "Iteration 4, loss = 1.13482639\n",
      "Iteration 5, loss = 1.06228006\n",
      "Iteration 6, loss = 1.05941376\n",
      "Iteration 7, loss = 1.04430716\n",
      "Iteration 17, loss = 1.09975427\n",
      "Iteration 18, loss = 1.04470564\n",
      "Iteration 19, loss = 1.04768475\n",
      "Iteration 20, loss = 1.03483148\n",
      "Iteration 21, loss = 1.05446222\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23770567\n",
      "Iteration 2, loss = 1.15675595\n",
      "Iteration 3, loss = 1.14299937\n",
      "Iteration 4, loss = 1.13482639\n",
      "Iteration 5, loss = 1.06228006\n",
      "Iteration 6, loss = 1.05941376\n",
      "Iteration 7, loss = 1.04430716\n",
      "Iteration 8, loss = 1.07314651\n",
      "Iteration 9, loss = 1.05130798\n",
      "Iteration 10, loss = 1.06330878\n",
      "Iteration 11, loss = 1.04032547\n",
      "Iteration 12, loss = 1.04591856\n",
      "Iteration 13, loss = 1.09494360\n",
      "Iteration 14, loss = 1.12373433\n",
      "Iteration 15, loss = 1.28005993\n",
      "Iteration 16, loss = 1.13413549\n",
      "Iteration 17, loss = 1.08638326\n",
      "Iteration 18, loss = 1.10844379\n",
      "Iteration 19, loss = 1.13643055\n",
      "Iteration 20, loss = 1.05543963\n",
      "Iteration 21, loss = 1.03402708\n",
      "Iteration 22, loss = 1.02887252\n",
      "Iteration 8, loss = 1.07314651\n",
      "Iteration 9, loss = 1.05130798\n",
      "Iteration 10, loss = 1.06330878\n",
      "Iteration 11, loss = 1.04032547\n",
      "Iteration 12, loss = 1.04591856\n",
      "Iteration 13, loss = 1.09494360\n",
      "Iteration 14, loss = 1.12373433\n",
      "Iteration 15, loss = 1.28005993\n",
      "Iteration 16, loss = 1.13413549\n",
      "Iteration 17, loss = 1.08638326\n",
      "Iteration 18, loss = 1.10844379\n",
      "Iteration 19, loss = 1.13643055\n",
      "Iteration 20, loss = 1.05543963\n",
      "Iteration 21, loss = 1.03402708\n",
      "Iteration 22, loss = 1.02887252\n",
      "Iteration 23, loss = 0.98743492\n",
      "Iteration 24, loss = 1.14963107\n",
      "Iteration 25, loss = 1.07049262\n",
      "Iteration 26, loss = 1.06743618\n",
      "Iteration 27, loss = 1.05240240\n",
      "Iteration 28, loss = 1.03987250\n",
      "Iteration 29, loss = 1.03981192\n",
      "Iteration 30, loss = 0.98463890\n",
      "Iteration 31, loss = 1.01087377\n",
      "Iteration 32, loss = 1.03621770\n",
      "Iteration 33, loss = 1.07628244\n",
      "Iteration 34, loss = 1.03235837\n",
      "Iteration 35, loss = 1.02415596\n",
      "Iteration 36, loss = 1.03031895\n",
      "Iteration 37, loss = 1.08771278\n",
      "Iteration 38, loss = 0.99974755\n",
      "Iteration 23, loss = 0.98743492\n",
      "Iteration 24, loss = 1.14963107\n",
      "Iteration 25, loss = 1.07049262\n",
      "Iteration 26, loss = 1.06743618\n",
      "Iteration 27, loss = 1.05240240\n",
      "Iteration 28, loss = 1.03987250\n",
      "Iteration 29, loss = 1.03981192\n",
      "Iteration 30, loss = 0.98463890\n",
      "Iteration 31, loss = 1.01087377\n",
      "Iteration 32, loss = 1.03621770\n",
      "Iteration 33, loss = 1.07628244\n",
      "Iteration 34, loss = 1.03235837\n",
      "Iteration 35, loss = 1.02415596\n",
      "Iteration 36, loss = 1.03031895\n",
      "Iteration 37, loss = 1.08771278\n",
      "Iteration 38, loss = 0.99974755\n",
      "Iteration 39, loss = 0.97968238\n",
      "Iteration 40, loss = 1.02149434\n",
      "Iteration 41, loss = 1.03436988\n",
      "Iteration 42, loss = 0.97518546\n",
      "Iteration 43, loss = 1.17770135\n",
      "Iteration 44, loss = 1.07456367\n",
      "Iteration 45, loss = 1.02918128\n",
      "Iteration 46, loss = 1.03161259\n",
      "Iteration 47, loss = 1.07707640\n",
      "Iteration 48, loss = 1.07014718\n",
      "Iteration 49, loss = 0.99349137\n",
      "Iteration 50, loss = 1.11613936\n",
      "Iteration 51, loss = 1.06986574\n",
      "Iteration 52, loss = 1.08214966\n",
      "Iteration 53, loss = 1.04726766\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25292723\n",
      "Iteration 39, loss = 0.97968238\n",
      "Iteration 40, loss = 1.02149434\n",
      "Iteration 41, loss = 1.03436988\n",
      "Iteration 42, loss = 0.97518546\n",
      "Iteration 43, loss = 1.17770135\n",
      "Iteration 44, loss = 1.07456367\n",
      "Iteration 45, loss = 1.02918128\n",
      "Iteration 46, loss = 1.03161259\n",
      "Iteration 47, loss = 1.07707640\n",
      "Iteration 48, loss = 1.07014718\n",
      "Iteration 49, loss = 0.99349137\n",
      "Iteration 50, loss = 1.11613936\n",
      "Iteration 51, loss = 1.06986574\n",
      "Iteration 52, loss = 1.08214966\n",
      "Iteration 53, loss = 1.04726766\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25292723\n",
      "Iteration 2, loss = 1.26360829\n",
      "Iteration 3, loss = 1.25412656\n",
      "Iteration 4, loss = 1.24562557\n",
      "Iteration 5, loss = 1.23411221\n",
      "Iteration 6, loss = 1.25988878\n",
      "Iteration 7, loss = 1.25897527\n",
      "Iteration 8, loss = 1.25297929\n",
      "Iteration 9, loss = 1.24709162\n",
      "Iteration 10, loss = 1.24398026\n",
      "Iteration 1, loss = 1.21878556\n",
      "Iteration 2, loss = 1.09182204\n",
      "Iteration 3, loss = 1.04772113\n",
      "Iteration 4, loss = 0.99200451\n",
      "Iteration 5, loss = 1.05034743\n",
      "Iteration 2, loss = 1.26360829\n",
      "Iteration 3, loss = 1.25412656\n",
      "Iteration 4, loss = 1.24562557\n",
      "Iteration 5, loss = 1.23411221\n",
      "Iteration 6, loss = 1.25988878\n",
      "Iteration 7, loss = 1.25897527\n",
      "Iteration 8, loss = 1.25297929\n",
      "Iteration 9, loss = 1.24709162\n",
      "Iteration 10, loss = 1.24398026\n",
      "Iteration 1, loss = 1.21878556\n",
      "Iteration 2, loss = 1.09182204\n",
      "Iteration 3, loss = 1.04772113\n",
      "Iteration 4, loss = 0.99200451\n",
      "Iteration 5, loss = 1.05034743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.07286522\n",
      "Iteration 7, loss = 1.01525907\n",
      "Iteration 8, loss = 0.95994522\n",
      "Iteration 9, loss = 1.05053059\n",
      "Iteration 10, loss = 1.09518024\n",
      "Iteration 1, loss = 1.27784310\n",
      "Iteration 2, loss = 1.15609206\n",
      "Iteration 3, loss = 1.09678414\n",
      "Iteration 4, loss = 1.02352263\n",
      "Iteration 5, loss = 1.16726125\n",
      "Iteration 6, loss = 1.12927487\n",
      "Iteration 7, loss = 1.10249686\n",
      "Iteration 6, loss = 1.07286522\n",
      "Iteration 7, loss = 1.01525907\n",
      "Iteration 8, loss = 0.95994522\n",
      "Iteration 9, loss = 1.05053059\n",
      "Iteration 10, loss = 1.09518024\n",
      "Iteration 1, loss = 1.27784310\n",
      "Iteration 2, loss = 1.15609206\n",
      "Iteration 3, loss = 1.09678414\n",
      "Iteration 4, loss = 1.02352263\n",
      "Iteration 5, loss = 1.16726125\n",
      "Iteration 6, loss = 1.12927487\n",
      "Iteration 7, loss = 1.10249686\n",
      "Iteration 8, loss = 0.99737498\n",
      "Iteration 9, loss = 1.11172295\n",
      "Iteration 10, loss = 1.21065855\n",
      "Iteration 1, loss = 1.26268721\n",
      "Iteration 2, loss = 1.24873742\n",
      "Iteration 3, loss = 1.17962558\n",
      "Iteration 4, loss = 1.43249689\n",
      "Iteration 5, loss = 1.25938014\n",
      "Iteration 6, loss = 1.27918276\n",
      "Iteration 7, loss = 1.29208922\n",
      "Iteration 8, loss = 1.26404742\n",
      "Iteration 9, loss = 1.27142854\n",
      "Iteration 8, loss = 0.99737498\n",
      "Iteration 9, loss = 1.11172295\n",
      "Iteration 10, loss = 1.21065855\n",
      "Iteration 1, loss = 1.26268721\n",
      "Iteration 2, loss = 1.24873742\n",
      "Iteration 3, loss = 1.17962558\n",
      "Iteration 4, loss = 1.43249689\n",
      "Iteration 5, loss = 1.25938014\n",
      "Iteration 6, loss = 1.27918276\n",
      "Iteration 7, loss = 1.29208922\n",
      "Iteration 8, loss = 1.26404742\n",
      "Iteration 9, loss = 1.27142854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25638501\n",
      "Iteration 1, loss = 1.24862715\n",
      "Iteration 2, loss = 1.19380010\n",
      "Iteration 3, loss = 1.13316530\n",
      "Iteration 4, loss = 1.29067164\n",
      "Iteration 5, loss = 1.24441530\n",
      "Iteration 6, loss = 1.20089924\n",
      "Iteration 7, loss = 1.18547225\n",
      "Iteration 8, loss = 1.21304186\n",
      "Iteration 9, loss = 1.27410467\n",
      "Iteration 10, loss = 1.26760028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25638501\n",
      "Iteration 1, loss = 1.24862715\n",
      "Iteration 2, loss = 1.19380010\n",
      "Iteration 3, loss = 1.13316530\n",
      "Iteration 4, loss = 1.29067164\n",
      "Iteration 5, loss = 1.24441530\n",
      "Iteration 6, loss = 1.20089924\n",
      "Iteration 7, loss = 1.18547225\n",
      "Iteration 8, loss = 1.21304186\n",
      "Iteration 9, loss = 1.27410467\n",
      "Iteration 10, loss = 1.26760028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.25292723\n",
      "Iteration 2, loss = 1.26360829\n",
      "Iteration 3, loss = 1.25412656\n",
      "Iteration 4, loss = 1.24562557\n",
      "Iteration 5, loss = 1.23411221\n",
      "Iteration 6, loss = 1.25988878\n",
      "Iteration 7, loss = 1.25897527\n",
      "Iteration 8, loss = 1.25297929\n",
      "Iteration 9, loss = 1.24709162\n",
      "Iteration 10, loss = 1.24398026\n",
      "Iteration 11, loss = 1.24764440\n",
      "Iteration 12, loss = 1.25231417\n",
      "Iteration 13, loss = 1.24721552\n",
      "Iteration 14, loss = 1.24578581\n",
      "Iteration 15, loss = 1.24603134\n",
      "Iteration 1, loss = 1.25292723\n",
      "Iteration 2, loss = 1.26360829\n",
      "Iteration 3, loss = 1.25412656\n",
      "Iteration 4, loss = 1.24562557\n",
      "Iteration 5, loss = 1.23411221\n",
      "Iteration 6, loss = 1.25988878\n",
      "Iteration 7, loss = 1.25897527\n",
      "Iteration 8, loss = 1.25297929\n",
      "Iteration 9, loss = 1.24709162\n",
      "Iteration 10, loss = 1.24398026\n",
      "Iteration 11, loss = 1.24764440\n",
      "Iteration 12, loss = 1.25231417\n",
      "Iteration 13, loss = 1.24721552\n",
      "Iteration 14, loss = 1.24578581\n",
      "Iteration 15, loss = 1.24603134\n",
      "Iteration 16, loss = 1.24607540\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21878556\n",
      "Iteration 2, loss = 1.09182204\n",
      "Iteration 3, loss = 1.04772113\n",
      "Iteration 4, loss = 0.99200451\n",
      "Iteration 5, loss = 1.05034743\n",
      "Iteration 6, loss = 1.07286522\n",
      "Iteration 7, loss = 1.01525907\n",
      "Iteration 8, loss = 0.95994522\n",
      "Iteration 9, loss = 1.05053059\n",
      "Iteration 10, loss = 1.09518024\n",
      "Iteration 11, loss = 1.01880749\n",
      "Iteration 16, loss = 1.24607540\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21878556\n",
      "Iteration 2, loss = 1.09182204\n",
      "Iteration 3, loss = 1.04772113\n",
      "Iteration 4, loss = 0.99200451\n",
      "Iteration 5, loss = 1.05034743\n",
      "Iteration 6, loss = 1.07286522\n",
      "Iteration 7, loss = 1.01525907\n",
      "Iteration 8, loss = 0.95994522\n",
      "Iteration 9, loss = 1.05053059\n",
      "Iteration 10, loss = 1.09518024\n",
      "Iteration 11, loss = 1.01880749\n",
      "Iteration 12, loss = 0.97008740\n",
      "Iteration 13, loss = 0.97768454\n",
      "Iteration 14, loss = 0.94756703\n",
      "Iteration 15, loss = 0.96232492\n",
      "Iteration 16, loss = 0.96838114\n",
      "Iteration 17, loss = 0.95964866\n",
      "Iteration 18, loss = 0.94822541\n",
      "Iteration 19, loss = 0.93390908\n",
      "Iteration 20, loss = 0.96989126\n",
      "Iteration 21, loss = 1.01053655\n",
      "Iteration 22, loss = 0.93759876\n",
      "Iteration 23, loss = 0.94492560\n",
      "Iteration 24, loss = 0.94255319\n",
      "Iteration 25, loss = 0.93772564\n",
      "Iteration 26, loss = 0.96985615\n",
      "Iteration 27, loss = 0.94490883\n",
      "Iteration 12, loss = 0.97008740\n",
      "Iteration 13, loss = 0.97768454\n",
      "Iteration 14, loss = 0.94756703\n",
      "Iteration 15, loss = 0.96232492\n",
      "Iteration 16, loss = 0.96838114\n",
      "Iteration 17, loss = 0.95964866\n",
      "Iteration 18, loss = 0.94822541\n",
      "Iteration 19, loss = 0.93390908\n",
      "Iteration 20, loss = 0.96989126\n",
      "Iteration 21, loss = 1.01053655\n",
      "Iteration 22, loss = 0.93759876\n",
      "Iteration 23, loss = 0.94492560\n",
      "Iteration 24, loss = 0.94255319\n",
      "Iteration 25, loss = 0.93772564\n",
      "Iteration 26, loss = 0.96985615\n",
      "Iteration 27, loss = 0.94490883\n",
      "Iteration 28, loss = 1.01011057\n",
      "Iteration 29, loss = 1.06062326\n",
      "Iteration 30, loss = 0.96802568\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27784310\n",
      "Iteration 2, loss = 1.15609206\n",
      "Iteration 3, loss = 1.09678414\n",
      "Iteration 4, loss = 1.02352263\n",
      "Iteration 5, loss = 1.16726125\n",
      "Iteration 6, loss = 1.12927487\n",
      "Iteration 7, loss = 1.10249686\n",
      "Iteration 8, loss = 0.99737498\n",
      "Iteration 9, loss = 1.11172295\n",
      "Iteration 28, loss = 1.01011057\n",
      "Iteration 29, loss = 1.06062326\n",
      "Iteration 30, loss = 0.96802568\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27784310\n",
      "Iteration 2, loss = 1.15609206\n",
      "Iteration 3, loss = 1.09678414\n",
      "Iteration 4, loss = 1.02352263\n",
      "Iteration 5, loss = 1.16726125\n",
      "Iteration 6, loss = 1.12927487\n",
      "Iteration 7, loss = 1.10249686\n",
      "Iteration 8, loss = 0.99737498\n",
      "Iteration 9, loss = 1.11172295\n",
      "Iteration 10, loss = 1.21065855\n",
      "Iteration 11, loss = 1.26076408\n",
      "Iteration 12, loss = 1.20979621\n",
      "Iteration 13, loss = 1.28175505\n",
      "Iteration 14, loss = 1.28786867\n",
      "Iteration 15, loss = 1.27960663\n",
      "Iteration 16, loss = 1.28954342\n",
      "Iteration 17, loss = 1.28605887\n",
      "Iteration 18, loss = 1.27422147\n",
      "Iteration 19, loss = 1.29706383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26268721\n",
      "Iteration 2, loss = 1.24873742\n",
      "Iteration 3, loss = 1.17962558\n",
      "Iteration 10, loss = 1.21065855\n",
      "Iteration 11, loss = 1.26076408\n",
      "Iteration 12, loss = 1.20979621\n",
      "Iteration 13, loss = 1.28175505\n",
      "Iteration 14, loss = 1.28786867\n",
      "Iteration 15, loss = 1.27960663\n",
      "Iteration 16, loss = 1.28954342\n",
      "Iteration 17, loss = 1.28605887\n",
      "Iteration 18, loss = 1.27422147\n",
      "Iteration 19, loss = 1.29706383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26268721\n",
      "Iteration 2, loss = 1.24873742\n",
      "Iteration 3, loss = 1.17962558\n",
      "Iteration 4, loss = 1.43249689\n",
      "Iteration 5, loss = 1.25938014\n",
      "Iteration 6, loss = 1.27918276\n",
      "Iteration 7, loss = 1.29208922\n",
      "Iteration 8, loss = 1.26404742\n",
      "Iteration 9, loss = 1.27142854\n",
      "Iteration 10, loss = 1.25638501\n",
      "Iteration 11, loss = 1.29101090\n",
      "Iteration 12, loss = 1.27256318\n",
      "Iteration 13, loss = 1.26719944\n",
      "Iteration 14, loss = 1.29090620\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24862715\n",
      "Iteration 2, loss = 1.19380010\n",
      "Iteration 4, loss = 1.43249689\n",
      "Iteration 5, loss = 1.25938014\n",
      "Iteration 6, loss = 1.27918276\n",
      "Iteration 7, loss = 1.29208922\n",
      "Iteration 8, loss = 1.26404742\n",
      "Iteration 9, loss = 1.27142854\n",
      "Iteration 10, loss = 1.25638501\n",
      "Iteration 11, loss = 1.29101090\n",
      "Iteration 12, loss = 1.27256318\n",
      "Iteration 13, loss = 1.26719944\n",
      "Iteration 14, loss = 1.29090620\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24862715\n",
      "Iteration 2, loss = 1.19380010\n",
      "Iteration 3, loss = 1.13316530\n",
      "Iteration 4, loss = 1.29067164\n",
      "Iteration 5, loss = 1.24441530\n",
      "Iteration 6, loss = 1.20089924\n",
      "Iteration 7, loss = 1.18547225\n",
      "Iteration 8, loss = 1.21304186\n",
      "Iteration 9, loss = 1.27410467\n",
      "Iteration 10, loss = 1.26760028\n",
      "Iteration 11, loss = 1.16411926\n",
      "Iteration 12, loss = 1.18385647\n",
      "Iteration 13, loss = 1.39286688\n",
      "Iteration 14, loss = 1.31186725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25292723\n",
      "Iteration 2, loss = 1.26360829\n",
      "Iteration 3, loss = 1.13316530\n",
      "Iteration 4, loss = 1.29067164\n",
      "Iteration 5, loss = 1.24441530\n",
      "Iteration 6, loss = 1.20089924\n",
      "Iteration 7, loss = 1.18547225\n",
      "Iteration 8, loss = 1.21304186\n",
      "Iteration 9, loss = 1.27410467\n",
      "Iteration 10, loss = 1.26760028\n",
      "Iteration 11, loss = 1.16411926\n",
      "Iteration 12, loss = 1.18385647\n",
      "Iteration 13, loss = 1.39286688\n",
      "Iteration 14, loss = 1.31186725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25292723\n",
      "Iteration 2, loss = 1.26360829\n",
      "Iteration 3, loss = 1.25412656\n",
      "Iteration 4, loss = 1.24562557\n",
      "Iteration 5, loss = 1.23411221\n",
      "Iteration 6, loss = 1.25988878\n",
      "Iteration 7, loss = 1.25897527\n",
      "Iteration 8, loss = 1.25297929\n",
      "Iteration 9, loss = 1.24709162\n",
      "Iteration 10, loss = 1.24398026\n",
      "Iteration 11, loss = 1.24764440\n",
      "Iteration 12, loss = 1.25231417\n",
      "Iteration 13, loss = 1.24721552\n",
      "Iteration 14, loss = 1.24578581\n",
      "Iteration 15, loss = 1.24603134\n",
      "Iteration 3, loss = 1.25412656\n",
      "Iteration 4, loss = 1.24562557\n",
      "Iteration 5, loss = 1.23411221\n",
      "Iteration 6, loss = 1.25988878\n",
      "Iteration 7, loss = 1.25897527\n",
      "Iteration 8, loss = 1.25297929\n",
      "Iteration 9, loss = 1.24709162\n",
      "Iteration 10, loss = 1.24398026\n",
      "Iteration 11, loss = 1.24764440\n",
      "Iteration 12, loss = 1.25231417\n",
      "Iteration 13, loss = 1.24721552\n",
      "Iteration 14, loss = 1.24578581\n",
      "Iteration 15, loss = 1.24603134\n",
      "Iteration 16, loss = 1.24607540\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21878556\n",
      "Iteration 2, loss = 1.09182204\n",
      "Iteration 3, loss = 1.04772113\n",
      "Iteration 4, loss = 0.99200451\n",
      "Iteration 5, loss = 1.05034743\n",
      "Iteration 6, loss = 1.07286522\n",
      "Iteration 7, loss = 1.01525907\n",
      "Iteration 8, loss = 0.95994522\n",
      "Iteration 9, loss = 1.05053059\n",
      "Iteration 10, loss = 1.09518024\n",
      "Iteration 11, loss = 1.01880749\n",
      "Iteration 12, loss = 0.97008740\n",
      "Iteration 16, loss = 1.24607540\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21878556\n",
      "Iteration 2, loss = 1.09182204\n",
      "Iteration 3, loss = 1.04772113\n",
      "Iteration 4, loss = 0.99200451\n",
      "Iteration 5, loss = 1.05034743\n",
      "Iteration 6, loss = 1.07286522\n",
      "Iteration 7, loss = 1.01525907\n",
      "Iteration 8, loss = 0.95994522\n",
      "Iteration 9, loss = 1.05053059\n",
      "Iteration 10, loss = 1.09518024\n",
      "Iteration 11, loss = 1.01880749\n",
      "Iteration 12, loss = 0.97008740\n",
      "Iteration 13, loss = 0.97768454\n",
      "Iteration 14, loss = 0.94756703\n",
      "Iteration 15, loss = 0.96232492\n",
      "Iteration 16, loss = 0.96838114\n",
      "Iteration 17, loss = 0.95964866\n",
      "Iteration 18, loss = 0.94822541\n",
      "Iteration 19, loss = 0.93390908\n",
      "Iteration 20, loss = 0.96989126\n",
      "Iteration 21, loss = 1.01053655\n",
      "Iteration 22, loss = 0.93759876\n",
      "Iteration 23, loss = 0.94492560\n",
      "Iteration 24, loss = 0.94255319\n",
      "Iteration 25, loss = 0.93772564\n",
      "Iteration 26, loss = 0.96985615\n",
      "Iteration 27, loss = 0.94490883\n",
      "Iteration 13, loss = 0.97768454\n",
      "Iteration 14, loss = 0.94756703\n",
      "Iteration 15, loss = 0.96232492\n",
      "Iteration 16, loss = 0.96838114\n",
      "Iteration 17, loss = 0.95964866\n",
      "Iteration 18, loss = 0.94822541\n",
      "Iteration 19, loss = 0.93390908\n",
      "Iteration 20, loss = 0.96989126\n",
      "Iteration 21, loss = 1.01053655\n",
      "Iteration 22, loss = 0.93759876\n",
      "Iteration 23, loss = 0.94492560\n",
      "Iteration 24, loss = 0.94255319\n",
      "Iteration 25, loss = 0.93772564\n",
      "Iteration 26, loss = 0.96985615\n",
      "Iteration 27, loss = 0.94490883\n",
      "Iteration 28, loss = 1.01011057\n",
      "Iteration 29, loss = 1.06062326\n",
      "Iteration 30, loss = 0.96802568\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27784310\n",
      "Iteration 2, loss = 1.15609206\n",
      "Iteration 3, loss = 1.09678414\n",
      "Iteration 4, loss = 1.02352263\n",
      "Iteration 5, loss = 1.16726125\n",
      "Iteration 6, loss = 1.12927487\n",
      "Iteration 7, loss = 1.10249686\n",
      "Iteration 8, loss = 0.99737498\n",
      "Iteration 9, loss = 1.11172295\n",
      "Iteration 10, loss = 1.21065855\n",
      "Iteration 11, loss = 1.26076408\n",
      "Iteration 28, loss = 1.01011057\n",
      "Iteration 29, loss = 1.06062326\n",
      "Iteration 30, loss = 0.96802568\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27784310\n",
      "Iteration 2, loss = 1.15609206\n",
      "Iteration 3, loss = 1.09678414\n",
      "Iteration 4, loss = 1.02352263\n",
      "Iteration 5, loss = 1.16726125\n",
      "Iteration 6, loss = 1.12927487\n",
      "Iteration 7, loss = 1.10249686\n",
      "Iteration 8, loss = 0.99737498\n",
      "Iteration 9, loss = 1.11172295\n",
      "Iteration 10, loss = 1.21065855\n",
      "Iteration 11, loss = 1.26076408\n",
      "Iteration 12, loss = 1.20979621\n",
      "Iteration 13, loss = 1.28175505\n",
      "Iteration 14, loss = 1.28786867\n",
      "Iteration 15, loss = 1.27960663\n",
      "Iteration 16, loss = 1.28954342\n",
      "Iteration 17, loss = 1.28605887\n",
      "Iteration 18, loss = 1.27422147\n",
      "Iteration 19, loss = 1.29706383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26268721\n",
      "Iteration 2, loss = 1.24873742\n",
      "Iteration 3, loss = 1.17962558\n",
      "Iteration 4, loss = 1.43249689\n",
      "Iteration 5, loss = 1.25938014\n",
      "Iteration 6, loss = 1.27918276\n",
      "Iteration 12, loss = 1.20979621\n",
      "Iteration 13, loss = 1.28175505\n",
      "Iteration 14, loss = 1.28786867\n",
      "Iteration 15, loss = 1.27960663\n",
      "Iteration 16, loss = 1.28954342\n",
      "Iteration 17, loss = 1.28605887\n",
      "Iteration 18, loss = 1.27422147\n",
      "Iteration 19, loss = 1.29706383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26268721\n",
      "Iteration 2, loss = 1.24873742\n",
      "Iteration 3, loss = 1.17962558\n",
      "Iteration 4, loss = 1.43249689\n",
      "Iteration 5, loss = 1.25938014\n",
      "Iteration 6, loss = 1.27918276\n",
      "Iteration 7, loss = 1.29208922\n",
      "Iteration 8, loss = 1.26404742\n",
      "Iteration 9, loss = 1.27142854\n",
      "Iteration 10, loss = 1.25638501\n",
      "Iteration 11, loss = 1.29101090\n",
      "Iteration 12, loss = 1.27256318\n",
      "Iteration 13, loss = 1.26719944\n",
      "Iteration 14, loss = 1.29090620\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24862715\n",
      "Iteration 2, loss = 1.19380010\n",
      "Iteration 3, loss = 1.13316530\n",
      "Iteration 4, loss = 1.29067164\n",
      "Iteration 5, loss = 1.24441530\n",
      "Iteration 7, loss = 1.29208922\n",
      "Iteration 8, loss = 1.26404742\n",
      "Iteration 9, loss = 1.27142854\n",
      "Iteration 10, loss = 1.25638501\n",
      "Iteration 11, loss = 1.29101090\n",
      "Iteration 12, loss = 1.27256318\n",
      "Iteration 13, loss = 1.26719944\n",
      "Iteration 14, loss = 1.29090620\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24862715\n",
      "Iteration 2, loss = 1.19380010\n",
      "Iteration 3, loss = 1.13316530\n",
      "Iteration 4, loss = 1.29067164\n",
      "Iteration 5, loss = 1.24441530\n",
      "Iteration 6, loss = 1.20089924\n",
      "Iteration 7, loss = 1.18547225\n",
      "Iteration 8, loss = 1.21304186\n",
      "Iteration 9, loss = 1.27410467\n",
      "Iteration 10, loss = 1.26760028\n",
      "Iteration 11, loss = 1.16411926\n",
      "Iteration 12, loss = 1.18385647\n",
      "Iteration 13, loss = 1.39286688\n",
      "Iteration 14, loss = 1.31186725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23080033\n",
      "Iteration 2, loss = 1.11854189\n",
      "Iteration 3, loss = 1.04658396\n",
      "Iteration 4, loss = 0.99717892\n",
      "Iteration 6, loss = 1.20089924\n",
      "Iteration 7, loss = 1.18547225\n",
      "Iteration 8, loss = 1.21304186\n",
      "Iteration 9, loss = 1.27410467\n",
      "Iteration 10, loss = 1.26760028\n",
      "Iteration 11, loss = 1.16411926\n",
      "Iteration 12, loss = 1.18385647\n",
      "Iteration 13, loss = 1.39286688\n",
      "Iteration 14, loss = 1.31186725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23080033\n",
      "Iteration 2, loss = 1.11854189\n",
      "Iteration 3, loss = 1.04658396\n",
      "Iteration 4, loss = 0.99717892\n",
      "Iteration 5, loss = 1.08952582\n",
      "Iteration 6, loss = 0.97340922\n",
      "Iteration 7, loss = 0.99086221\n",
      "Iteration 8, loss = 0.99962648\n",
      "Iteration 9, loss = 0.99196622\n",
      "Iteration 10, loss = 0.95819398\n",
      "Iteration 1, loss = 1.22545543\n",
      "Iteration 2, loss = 1.13959934\n",
      "Iteration 3, loss = 1.02527037\n",
      "Iteration 4, loss = 0.96645641\n",
      "Iteration 5, loss = 0.94484655\n",
      "Iteration 6, loss = 0.92924328\n",
      "Iteration 7, loss = 0.93874390\n",
      "Iteration 5, loss = 1.08952582\n",
      "Iteration 6, loss = 0.97340922\n",
      "Iteration 7, loss = 0.99086221\n",
      "Iteration 8, loss = 0.99962648\n",
      "Iteration 9, loss = 0.99196622\n",
      "Iteration 10, loss = 0.95819398\n",
      "Iteration 1, loss = 1.22545543\n",
      "Iteration 2, loss = 1.13959934\n",
      "Iteration 3, loss = 1.02527037\n",
      "Iteration 4, loss = 0.96645641\n",
      "Iteration 5, loss = 0.94484655\n",
      "Iteration 6, loss = 0.92924328\n",
      "Iteration 7, loss = 0.93874390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.94328859\n",
      "Iteration 9, loss = 0.92541432\n",
      "Iteration 10, loss = 0.90015338\n",
      "Iteration 1, loss = 1.26808768\n",
      "Iteration 2, loss = 1.17739602\n",
      "Iteration 3, loss = 1.09341492\n",
      "Iteration 4, loss = 0.99226485\n",
      "Iteration 5, loss = 0.98255189\n",
      "Iteration 6, loss = 0.98378994\n",
      "Iteration 7, loss = 0.96837223\n",
      "Iteration 8, loss = 0.95878796\n",
      "Iteration 9, loss = 0.93769322\n",
      "Iteration 10, loss = 0.96835429\n",
      "Iteration 8, loss = 0.94328859\n",
      "Iteration 9, loss = 0.92541432\n",
      "Iteration 10, loss = 0.90015338\n",
      "Iteration 1, loss = 1.26808768\n",
      "Iteration 2, loss = 1.17739602\n",
      "Iteration 3, loss = 1.09341492\n",
      "Iteration 4, loss = 0.99226485\n",
      "Iteration 5, loss = 0.98255189\n",
      "Iteration 6, loss = 0.98378994\n",
      "Iteration 7, loss = 0.96837223\n",
      "Iteration 8, loss = 0.95878796\n",
      "Iteration 9, loss = 0.93769322\n",
      "Iteration 10, loss = 0.96835429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.24618095\n",
      "Iteration 2, loss = 1.17935117\n",
      "Iteration 3, loss = 1.09885900\n",
      "Iteration 4, loss = 1.06361860\n",
      "Iteration 5, loss = 1.04496983\n",
      "Iteration 6, loss = 1.03589680\n",
      "Iteration 7, loss = 0.99467625\n",
      "Iteration 8, loss = 1.03099272\n",
      "Iteration 9, loss = 0.97445144\n",
      "Iteration 10, loss = 0.97669018\n",
      "Iteration 1, loss = 1.24747586\n",
      "Iteration 2, loss = 1.14287430\n",
      "Iteration 3, loss = 1.10000536\n",
      "Iteration 1, loss = 1.24618095\n",
      "Iteration 2, loss = 1.17935117\n",
      "Iteration 3, loss = 1.09885900\n",
      "Iteration 4, loss = 1.06361860\n",
      "Iteration 5, loss = 1.04496983\n",
      "Iteration 6, loss = 1.03589680\n",
      "Iteration 7, loss = 0.99467625\n",
      "Iteration 8, loss = 1.03099272\n",
      "Iteration 9, loss = 0.97445144\n",
      "Iteration 10, loss = 0.97669018\n",
      "Iteration 1, loss = 1.24747586\n",
      "Iteration 2, loss = 1.14287430\n",
      "Iteration 3, loss = 1.10000536\n",
      "Iteration 4, loss = 1.02374281\n",
      "Iteration 5, loss = 0.99546540\n",
      "Iteration 6, loss = 0.97419591\n",
      "Iteration 7, loss = 0.97178115\n",
      "Iteration 8, loss = 0.97487262\n",
      "Iteration 9, loss = 0.95673342\n",
      "Iteration 10, loss = 0.92786522\n",
      "Iteration 1, loss = 1.23080033\n",
      "Iteration 2, loss = 1.11854189\n",
      "Iteration 3, loss = 1.04658396\n",
      "Iteration 4, loss = 0.99717892\n",
      "Iteration 5, loss = 1.08952582\n",
      "Iteration 6, loss = 0.97340922\n",
      "Iteration 4, loss = 1.02374281\n",
      "Iteration 5, loss = 0.99546540\n",
      "Iteration 6, loss = 0.97419591\n",
      "Iteration 7, loss = 0.97178115\n",
      "Iteration 8, loss = 0.97487262\n",
      "Iteration 9, loss = 0.95673342\n",
      "Iteration 10, loss = 0.92786522\n",
      "Iteration 1, loss = 1.23080033\n",
      "Iteration 2, loss = 1.11854189\n",
      "Iteration 3, loss = 1.04658396\n",
      "Iteration 4, loss = 0.99717892\n",
      "Iteration 5, loss = 1.08952582\n",
      "Iteration 6, loss = 0.97340922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.99086221\n",
      "Iteration 8, loss = 0.99962648\n",
      "Iteration 9, loss = 0.99196622\n",
      "Iteration 10, loss = 0.95819398\n",
      "Iteration 11, loss = 0.95550824\n",
      "Iteration 12, loss = 0.92018928\n",
      "Iteration 13, loss = 0.94193503\n",
      "Iteration 14, loss = 0.91525672\n",
      "Iteration 15, loss = 0.92781996\n",
      "Iteration 16, loss = 0.95781651\n",
      "Iteration 17, loss = 0.92172132\n",
      "Iteration 18, loss = 0.90630252\n",
      "Iteration 19, loss = 0.87906742\n",
      "Iteration 20, loss = 0.88924957\n",
      "Iteration 21, loss = 0.88376451\n",
      "Iteration 7, loss = 0.99086221\n",
      "Iteration 8, loss = 0.99962648\n",
      "Iteration 9, loss = 0.99196622\n",
      "Iteration 10, loss = 0.95819398\n",
      "Iteration 11, loss = 0.95550824\n",
      "Iteration 12, loss = 0.92018928\n",
      "Iteration 13, loss = 0.94193503\n",
      "Iteration 14, loss = 0.91525672\n",
      "Iteration 15, loss = 0.92781996\n",
      "Iteration 16, loss = 0.95781651\n",
      "Iteration 17, loss = 0.92172132\n",
      "Iteration 18, loss = 0.90630252\n",
      "Iteration 19, loss = 0.87906742\n",
      "Iteration 20, loss = 0.88924957\n",
      "Iteration 21, loss = 0.88376451\n",
      "Iteration 22, loss = 0.92366107\n",
      "Iteration 23, loss = 0.88275286\n",
      "Iteration 24, loss = 0.89331275\n",
      "Iteration 25, loss = 0.91081769\n",
      "Iteration 26, loss = 0.88963643\n",
      "Iteration 27, loss = 0.86687756\n",
      "Iteration 28, loss = 0.84857955\n",
      "Iteration 29, loss = 0.85624694\n",
      "Iteration 30, loss = 0.83367814\n",
      "Iteration 31, loss = 0.84924239\n",
      "Iteration 32, loss = 0.89693634\n",
      "Iteration 33, loss = 0.84494287\n",
      "Iteration 34, loss = 0.85171809\n",
      "Iteration 35, loss = 0.82875259\n",
      "Iteration 36, loss = 0.84055336\n",
      "Iteration 37, loss = 0.81017858\n",
      "Iteration 22, loss = 0.92366107\n",
      "Iteration 23, loss = 0.88275286\n",
      "Iteration 24, loss = 0.89331275\n",
      "Iteration 25, loss = 0.91081769\n",
      "Iteration 26, loss = 0.88963643\n",
      "Iteration 27, loss = 0.86687756\n",
      "Iteration 28, loss = 0.84857955\n",
      "Iteration 29, loss = 0.85624694\n",
      "Iteration 30, loss = 0.83367814\n",
      "Iteration 31, loss = 0.84924239\n",
      "Iteration 32, loss = 0.89693634\n",
      "Iteration 33, loss = 0.84494287\n",
      "Iteration 34, loss = 0.85171809\n",
      "Iteration 35, loss = 0.82875259\n",
      "Iteration 36, loss = 0.84055336\n",
      "Iteration 37, loss = 0.81017858\n",
      "Iteration 38, loss = 0.84283145\n",
      "Iteration 39, loss = 0.89355958\n",
      "Iteration 40, loss = 0.84240141\n",
      "Iteration 41, loss = 0.78490465\n",
      "Iteration 42, loss = 0.82908810\n",
      "Iteration 43, loss = 0.83465251\n",
      "Iteration 44, loss = 0.85725451\n",
      "Iteration 45, loss = 0.85155817\n",
      "Iteration 46, loss = 0.85962407\n",
      "Iteration 47, loss = 0.88182705\n",
      "Iteration 48, loss = 0.82467794\n",
      "Iteration 49, loss = 0.85183802\n",
      "Iteration 50, loss = 0.82204154\n",
      "Iteration 1, loss = 1.22545543\n",
      "Iteration 38, loss = 0.84283145\n",
      "Iteration 39, loss = 0.89355958\n",
      "Iteration 40, loss = 0.84240141\n",
      "Iteration 41, loss = 0.78490465\n",
      "Iteration 42, loss = 0.82908810\n",
      "Iteration 43, loss = 0.83465251\n",
      "Iteration 44, loss = 0.85725451\n",
      "Iteration 45, loss = 0.85155817\n",
      "Iteration 46, loss = 0.85962407\n",
      "Iteration 47, loss = 0.88182705\n",
      "Iteration 48, loss = 0.82467794\n",
      "Iteration 49, loss = 0.85183802\n",
      "Iteration 50, loss = 0.82204154\n",
      "Iteration 1, loss = 1.22545543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.13959934\n",
      "Iteration 3, loss = 1.02527037\n",
      "Iteration 4, loss = 0.96645641\n",
      "Iteration 5, loss = 0.94484655\n",
      "Iteration 6, loss = 0.92924328\n",
      "Iteration 7, loss = 0.93874390\n",
      "Iteration 8, loss = 0.94328859\n",
      "Iteration 9, loss = 0.92541432\n",
      "Iteration 10, loss = 0.90015338\n",
      "Iteration 11, loss = 0.89550845\n",
      "Iteration 12, loss = 0.86630047\n",
      "Iteration 13, loss = 0.85997297\n",
      "Iteration 14, loss = 0.90734193\n",
      "Iteration 15, loss = 0.91453922\n",
      "Iteration 2, loss = 1.13959934\n",
      "Iteration 3, loss = 1.02527037\n",
      "Iteration 4, loss = 0.96645641\n",
      "Iteration 5, loss = 0.94484655\n",
      "Iteration 6, loss = 0.92924328\n",
      "Iteration 7, loss = 0.93874390\n",
      "Iteration 8, loss = 0.94328859\n",
      "Iteration 9, loss = 0.92541432\n",
      "Iteration 10, loss = 0.90015338\n",
      "Iteration 11, loss = 0.89550845\n",
      "Iteration 12, loss = 0.86630047\n",
      "Iteration 13, loss = 0.85997297\n",
      "Iteration 14, loss = 0.90734193\n",
      "Iteration 15, loss = 0.91453922\n",
      "Iteration 16, loss = 0.89867515\n",
      "Iteration 17, loss = 0.86741844\n",
      "Iteration 18, loss = 0.84530369\n",
      "Iteration 19, loss = 0.81969688\n",
      "Iteration 20, loss = 0.84123150\n",
      "Iteration 21, loss = 0.84715038\n",
      "Iteration 22, loss = 0.85101280\n",
      "Iteration 23, loss = 0.81135667\n",
      "Iteration 24, loss = 0.88408925\n",
      "Iteration 25, loss = 0.84859434\n",
      "Iteration 26, loss = 0.85634900\n",
      "Iteration 27, loss = 0.80293176\n",
      "Iteration 28, loss = 0.82286763\n",
      "Iteration 29, loss = 0.82081553\n",
      "Iteration 30, loss = 0.82814276\n",
      "Iteration 16, loss = 0.89867515\n",
      "Iteration 17, loss = 0.86741844\n",
      "Iteration 18, loss = 0.84530369\n",
      "Iteration 19, loss = 0.81969688\n",
      "Iteration 20, loss = 0.84123150\n",
      "Iteration 21, loss = 0.84715038\n",
      "Iteration 22, loss = 0.85101280\n",
      "Iteration 23, loss = 0.81135667\n",
      "Iteration 24, loss = 0.88408925\n",
      "Iteration 25, loss = 0.84859434\n",
      "Iteration 26, loss = 0.85634900\n",
      "Iteration 27, loss = 0.80293176\n",
      "Iteration 28, loss = 0.82286763\n",
      "Iteration 29, loss = 0.82081553\n",
      "Iteration 30, loss = 0.82814276\n",
      "Iteration 31, loss = 0.79272399\n",
      "Iteration 32, loss = 0.77278175\n",
      "Iteration 33, loss = 0.76221707\n",
      "Iteration 34, loss = 0.83694387\n",
      "Iteration 35, loss = 0.80974658\n",
      "Iteration 36, loss = 0.83597352\n",
      "Iteration 37, loss = 0.79299054\n",
      "Iteration 38, loss = 0.81105338\n",
      "Iteration 39, loss = 0.80996363\n",
      "Iteration 40, loss = 0.76909789\n",
      "Iteration 41, loss = 0.76361166\n",
      "Iteration 42, loss = 0.76236485\n",
      "Iteration 43, loss = 0.80495335\n",
      "Iteration 44, loss = 0.78806699\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26808768\n",
      "Iteration 31, loss = 0.79272399\n",
      "Iteration 32, loss = 0.77278175\n",
      "Iteration 33, loss = 0.76221707\n",
      "Iteration 34, loss = 0.83694387\n",
      "Iteration 35, loss = 0.80974658\n",
      "Iteration 36, loss = 0.83597352\n",
      "Iteration 37, loss = 0.79299054\n",
      "Iteration 38, loss = 0.81105338\n",
      "Iteration 39, loss = 0.80996363\n",
      "Iteration 40, loss = 0.76909789\n",
      "Iteration 41, loss = 0.76361166\n",
      "Iteration 42, loss = 0.76236485\n",
      "Iteration 43, loss = 0.80495335\n",
      "Iteration 44, loss = 0.78806699\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26808768\n",
      "Iteration 2, loss = 1.17739602\n",
      "Iteration 3, loss = 1.09341492\n",
      "Iteration 4, loss = 0.99226485\n",
      "Iteration 5, loss = 0.98255189\n",
      "Iteration 6, loss = 0.98378994\n",
      "Iteration 7, loss = 0.96837223\n",
      "Iteration 8, loss = 0.95878796\n",
      "Iteration 9, loss = 0.93769322\n",
      "Iteration 10, loss = 0.96835429\n",
      "Iteration 11, loss = 0.92377780\n",
      "Iteration 12, loss = 0.91676010\n",
      "Iteration 13, loss = 0.91333813\n",
      "Iteration 14, loss = 0.93854804\n",
      "Iteration 15, loss = 0.95250830\n",
      "Iteration 16, loss = 0.91001914\n",
      "Iteration 2, loss = 1.17739602\n",
      "Iteration 3, loss = 1.09341492\n",
      "Iteration 4, loss = 0.99226485\n",
      "Iteration 5, loss = 0.98255189\n",
      "Iteration 6, loss = 0.98378994\n",
      "Iteration 7, loss = 0.96837223\n",
      "Iteration 8, loss = 0.95878796\n",
      "Iteration 9, loss = 0.93769322\n",
      "Iteration 10, loss = 0.96835429\n",
      "Iteration 11, loss = 0.92377780\n",
      "Iteration 12, loss = 0.91676010\n",
      "Iteration 13, loss = 0.91333813\n",
      "Iteration 14, loss = 0.93854804\n",
      "Iteration 15, loss = 0.95250830\n",
      "Iteration 16, loss = 0.91001914\n",
      "Iteration 17, loss = 0.90792355\n",
      "Iteration 18, loss = 0.89857544\n",
      "Iteration 19, loss = 0.89477035\n",
      "Iteration 20, loss = 0.89127282\n",
      "Iteration 21, loss = 0.86373176\n",
      "Iteration 22, loss = 0.90503230\n",
      "Iteration 23, loss = 0.89006183\n",
      "Iteration 24, loss = 0.85536977\n",
      "Iteration 25, loss = 0.84623715\n",
      "Iteration 26, loss = 0.90617611\n",
      "Iteration 27, loss = 0.84196265\n",
      "Iteration 28, loss = 0.88154814\n",
      "Iteration 29, loss = 0.86701984\n",
      "Iteration 30, loss = 0.84145331\n",
      "Iteration 31, loss = 0.83529225\n",
      "Iteration 32, loss = 0.86945776\n",
      "Iteration 17, loss = 0.90792355\n",
      "Iteration 18, loss = 0.89857544\n",
      "Iteration 19, loss = 0.89477035\n",
      "Iteration 20, loss = 0.89127282\n",
      "Iteration 21, loss = 0.86373176\n",
      "Iteration 22, loss = 0.90503230\n",
      "Iteration 23, loss = 0.89006183\n",
      "Iteration 24, loss = 0.85536977\n",
      "Iteration 25, loss = 0.84623715\n",
      "Iteration 26, loss = 0.90617611\n",
      "Iteration 27, loss = 0.84196265\n",
      "Iteration 28, loss = 0.88154814\n",
      "Iteration 29, loss = 0.86701984\n",
      "Iteration 30, loss = 0.84145331\n",
      "Iteration 31, loss = 0.83529225\n",
      "Iteration 32, loss = 0.86945776\n",
      "Iteration 33, loss = 0.90135667\n",
      "Iteration 34, loss = 0.86634434\n",
      "Iteration 35, loss = 0.87151457\n",
      "Iteration 36, loss = 0.87834131\n",
      "Iteration 37, loss = 0.86014974\n",
      "Iteration 38, loss = 0.83792943\n",
      "Iteration 39, loss = 0.85178997\n",
      "Iteration 40, loss = 0.92268289\n",
      "Iteration 41, loss = 0.85341714\n",
      "Iteration 42, loss = 0.85543949\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24618095\n",
      "Iteration 2, loss = 1.17935117\n",
      "Iteration 3, loss = 1.09885900\n",
      "Iteration 33, loss = 0.90135667\n",
      "Iteration 34, loss = 0.86634434\n",
      "Iteration 35, loss = 0.87151457\n",
      "Iteration 36, loss = 0.87834131\n",
      "Iteration 37, loss = 0.86014974\n",
      "Iteration 38, loss = 0.83792943\n",
      "Iteration 39, loss = 0.85178997\n",
      "Iteration 40, loss = 0.92268289\n",
      "Iteration 41, loss = 0.85341714\n",
      "Iteration 42, loss = 0.85543949\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24618095\n",
      "Iteration 2, loss = 1.17935117\n",
      "Iteration 3, loss = 1.09885900\n",
      "Iteration 4, loss = 1.06361860\n",
      "Iteration 5, loss = 1.04496983\n",
      "Iteration 6, loss = 1.03589680\n",
      "Iteration 7, loss = 0.99467625\n",
      "Iteration 8, loss = 1.03099272\n",
      "Iteration 9, loss = 0.97445144\n",
      "Iteration 10, loss = 0.97669018\n",
      "Iteration 11, loss = 0.95923237\n",
      "Iteration 12, loss = 0.98351899\n",
      "Iteration 13, loss = 0.96806752\n",
      "Iteration 14, loss = 0.94071048\n",
      "Iteration 15, loss = 0.95821821\n",
      "Iteration 16, loss = 0.90992737\n",
      "Iteration 17, loss = 0.89639346\n",
      "Iteration 18, loss = 0.90082152\n",
      "Iteration 4, loss = 1.06361860\n",
      "Iteration 5, loss = 1.04496983\n",
      "Iteration 6, loss = 1.03589680\n",
      "Iteration 7, loss = 0.99467625\n",
      "Iteration 8, loss = 1.03099272\n",
      "Iteration 9, loss = 0.97445144\n",
      "Iteration 10, loss = 0.97669018\n",
      "Iteration 11, loss = 0.95923237\n",
      "Iteration 12, loss = 0.98351899\n",
      "Iteration 13, loss = 0.96806752\n",
      "Iteration 14, loss = 0.94071048\n",
      "Iteration 15, loss = 0.95821821\n",
      "Iteration 16, loss = 0.90992737\n",
      "Iteration 17, loss = 0.89639346\n",
      "Iteration 18, loss = 0.90082152\n",
      "Iteration 19, loss = 0.88002777\n",
      "Iteration 20, loss = 0.89653016\n",
      "Iteration 21, loss = 0.88273630\n",
      "Iteration 22, loss = 0.87925899\n",
      "Iteration 23, loss = 0.88387152\n",
      "Iteration 24, loss = 0.84251701\n",
      "Iteration 25, loss = 0.86199224\n",
      "Iteration 26, loss = 0.86887944\n",
      "Iteration 27, loss = 0.80183937\n",
      "Iteration 28, loss = 0.89743190\n",
      "Iteration 29, loss = 0.85467919\n",
      "Iteration 30, loss = 0.88068344\n",
      "Iteration 31, loss = 0.86843675\n",
      "Iteration 32, loss = 0.83542571\n",
      "Iteration 33, loss = 0.84151916\n",
      "Iteration 19, loss = 0.88002777\n",
      "Iteration 20, loss = 0.89653016\n",
      "Iteration 21, loss = 0.88273630\n",
      "Iteration 22, loss = 0.87925899\n",
      "Iteration 23, loss = 0.88387152\n",
      "Iteration 24, loss = 0.84251701\n",
      "Iteration 25, loss = 0.86199224\n",
      "Iteration 26, loss = 0.86887944\n",
      "Iteration 27, loss = 0.80183937\n",
      "Iteration 28, loss = 0.89743190\n",
      "Iteration 29, loss = 0.85467919\n",
      "Iteration 30, loss = 0.88068344\n",
      "Iteration 31, loss = 0.86843675\n",
      "Iteration 32, loss = 0.83542571\n",
      "Iteration 33, loss = 0.84151916\n",
      "Iteration 34, loss = 0.79745211\n",
      "Iteration 35, loss = 0.77555659\n",
      "Iteration 36, loss = 0.83485369\n",
      "Iteration 37, loss = 0.84139744\n",
      "Iteration 38, loss = 0.81849808\n",
      "Iteration 39, loss = 0.83066168\n",
      "Iteration 40, loss = 0.78309043\n",
      "Iteration 41, loss = 0.79659829\n",
      "Iteration 42, loss = 0.77360745\n",
      "Iteration 43, loss = 0.81781087\n",
      "Iteration 44, loss = 0.84230169\n",
      "Iteration 45, loss = 0.83668567\n",
      "Iteration 46, loss = 0.80837643\n",
      "Iteration 47, loss = 0.78249065\n",
      "Iteration 48, loss = 0.72826018\n",
      "Iteration 49, loss = 0.75343623\n",
      "Iteration 34, loss = 0.79745211\n",
      "Iteration 35, loss = 0.77555659\n",
      "Iteration 36, loss = 0.83485369\n",
      "Iteration 37, loss = 0.84139744\n",
      "Iteration 38, loss = 0.81849808\n",
      "Iteration 39, loss = 0.83066168\n",
      "Iteration 40, loss = 0.78309043\n",
      "Iteration 41, loss = 0.79659829\n",
      "Iteration 42, loss = 0.77360745\n",
      "Iteration 43, loss = 0.81781087\n",
      "Iteration 44, loss = 0.84230169\n",
      "Iteration 45, loss = 0.83668567\n",
      "Iteration 46, loss = 0.80837643\n",
      "Iteration 47, loss = 0.78249065\n",
      "Iteration 48, loss = 0.72826018\n",
      "Iteration 49, loss = 0.75343623\n",
      "Iteration 50, loss = 0.80699704\n",
      "Iteration 1, loss = 1.24747586\n",
      "Iteration 2, loss = 1.14287430\n",
      "Iteration 3, loss = 1.10000536\n",
      "Iteration 4, loss = 1.02374281\n",
      "Iteration 5, loss = 0.99546540\n",
      "Iteration 6, loss = 0.97419591\n",
      "Iteration 7, loss = 0.97178115\n",
      "Iteration 8, loss = 0.97487262\n",
      "Iteration 9, loss = 0.95673342\n",
      "Iteration 10, loss = 0.92786522\n",
      "Iteration 11, loss = 0.91467423\n",
      "Iteration 12, loss = 0.95127840\n",
      "Iteration 50, loss = 0.80699704\n",
      "Iteration 1, loss = 1.24747586\n",
      "Iteration 2, loss = 1.14287430\n",
      "Iteration 3, loss = 1.10000536\n",
      "Iteration 4, loss = 1.02374281\n",
      "Iteration 5, loss = 0.99546540\n",
      "Iteration 6, loss = 0.97419591\n",
      "Iteration 7, loss = 0.97178115\n",
      "Iteration 8, loss = 0.97487262\n",
      "Iteration 9, loss = 0.95673342\n",
      "Iteration 10, loss = 0.92786522\n",
      "Iteration 11, loss = 0.91467423\n",
      "Iteration 12, loss = 0.95127840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.96412875\n",
      "Iteration 14, loss = 0.93213069\n",
      "Iteration 15, loss = 0.91983863\n",
      "Iteration 16, loss = 0.90453666\n",
      "Iteration 17, loss = 0.90225789\n",
      "Iteration 18, loss = 0.89612834\n",
      "Iteration 19, loss = 0.87201824\n",
      "Iteration 20, loss = 0.85201660\n",
      "Iteration 21, loss = 0.87941950\n",
      "Iteration 22, loss = 0.88626513\n",
      "Iteration 23, loss = 0.93801837\n",
      "Iteration 24, loss = 0.87255868\n",
      "Iteration 25, loss = 0.88809367\n",
      "Iteration 26, loss = 0.86583723\n",
      "Iteration 27, loss = 0.83119251\n",
      "Iteration 13, loss = 0.96412875\n",
      "Iteration 14, loss = 0.93213069\n",
      "Iteration 15, loss = 0.91983863\n",
      "Iteration 16, loss = 0.90453666\n",
      "Iteration 17, loss = 0.90225789\n",
      "Iteration 18, loss = 0.89612834\n",
      "Iteration 19, loss = 0.87201824\n",
      "Iteration 20, loss = 0.85201660\n",
      "Iteration 21, loss = 0.87941950\n",
      "Iteration 22, loss = 0.88626513\n",
      "Iteration 23, loss = 0.93801837\n",
      "Iteration 24, loss = 0.87255868\n",
      "Iteration 25, loss = 0.88809367\n",
      "Iteration 26, loss = 0.86583723\n",
      "Iteration 27, loss = 0.83119251\n",
      "Iteration 28, loss = 0.88675512\n",
      "Iteration 29, loss = 0.85928547\n",
      "Iteration 30, loss = 0.86054084\n",
      "Iteration 31, loss = 0.80967856\n",
      "Iteration 32, loss = 0.86987437\n",
      "Iteration 33, loss = 0.82723609\n",
      "Iteration 34, loss = 0.82137438\n",
      "Iteration 35, loss = 0.81281030\n",
      "Iteration 36, loss = 0.81193434\n",
      "Iteration 37, loss = 0.89149730\n",
      "Iteration 38, loss = 0.87990976\n",
      "Iteration 39, loss = 0.84045130\n",
      "Iteration 40, loss = 0.79501107\n",
      "Iteration 41, loss = 0.81824474\n",
      "Iteration 42, loss = 0.81672341\n",
      "Iteration 43, loss = 0.82571779\n",
      "Iteration 28, loss = 0.88675512\n",
      "Iteration 29, loss = 0.85928547\n",
      "Iteration 30, loss = 0.86054084\n",
      "Iteration 31, loss = 0.80967856\n",
      "Iteration 32, loss = 0.86987437\n",
      "Iteration 33, loss = 0.82723609\n",
      "Iteration 34, loss = 0.82137438\n",
      "Iteration 35, loss = 0.81281030\n",
      "Iteration 36, loss = 0.81193434\n",
      "Iteration 37, loss = 0.89149730\n",
      "Iteration 38, loss = 0.87990976\n",
      "Iteration 39, loss = 0.84045130\n",
      "Iteration 40, loss = 0.79501107\n",
      "Iteration 41, loss = 0.81824474\n",
      "Iteration 42, loss = 0.81672341\n",
      "Iteration 43, loss = 0.82571779\n",
      "Iteration 44, loss = 0.86294253\n",
      "Iteration 45, loss = 0.87610994\n",
      "Iteration 46, loss = 0.83235840\n",
      "Iteration 47, loss = 0.79843988\n",
      "Iteration 48, loss = 0.85002912\n",
      "Iteration 49, loss = 0.85061986\n",
      "Iteration 50, loss = 0.79057935\n",
      "Iteration 1, loss = 1.23080033\n",
      "Iteration 2, loss = 1.11854189\n",
      "Iteration 3, loss = 1.04658396\n",
      "Iteration 4, loss = 0.99717892\n",
      "Iteration 5, loss = 1.08952582\n",
      "Iteration 6, loss = 0.97340922\n",
      "Iteration 7, loss = 0.99086221\n",
      "Iteration 44, loss = 0.86294253\n",
      "Iteration 45, loss = 0.87610994\n",
      "Iteration 46, loss = 0.83235840\n",
      "Iteration 47, loss = 0.79843988\n",
      "Iteration 48, loss = 0.85002912\n",
      "Iteration 49, loss = 0.85061986\n",
      "Iteration 50, loss = 0.79057935\n",
      "Iteration 1, loss = 1.23080033\n",
      "Iteration 2, loss = 1.11854189\n",
      "Iteration 3, loss = 1.04658396\n",
      "Iteration 4, loss = 0.99717892\n",
      "Iteration 5, loss = 1.08952582\n",
      "Iteration 6, loss = 0.97340922\n",
      "Iteration 7, loss = 0.99086221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.99962648\n",
      "Iteration 9, loss = 0.99196622\n",
      "Iteration 10, loss = 0.95819398\n",
      "Iteration 11, loss = 0.95550824\n",
      "Iteration 12, loss = 0.92018928\n",
      "Iteration 13, loss = 0.94193503\n",
      "Iteration 14, loss = 0.91525672\n",
      "Iteration 15, loss = 0.92781996\n",
      "Iteration 16, loss = 0.95781651\n",
      "Iteration 17, loss = 0.92172132\n",
      "Iteration 18, loss = 0.90630252\n",
      "Iteration 19, loss = 0.87906742\n",
      "Iteration 20, loss = 0.88924957\n",
      "Iteration 21, loss = 0.88376451\n",
      "Iteration 8, loss = 0.99962648\n",
      "Iteration 9, loss = 0.99196622\n",
      "Iteration 10, loss = 0.95819398\n",
      "Iteration 11, loss = 0.95550824\n",
      "Iteration 12, loss = 0.92018928\n",
      "Iteration 13, loss = 0.94193503\n",
      "Iteration 14, loss = 0.91525672\n",
      "Iteration 15, loss = 0.92781996\n",
      "Iteration 16, loss = 0.95781651\n",
      "Iteration 17, loss = 0.92172132\n",
      "Iteration 18, loss = 0.90630252\n",
      "Iteration 19, loss = 0.87906742\n",
      "Iteration 20, loss = 0.88924957\n",
      "Iteration 21, loss = 0.88376451\n",
      "Iteration 22, loss = 0.92366107\n",
      "Iteration 23, loss = 0.88275286\n",
      "Iteration 24, loss = 0.89331275\n",
      "Iteration 25, loss = 0.91081769\n",
      "Iteration 26, loss = 0.88963643\n",
      "Iteration 27, loss = 0.86687756\n",
      "Iteration 28, loss = 0.84857955\n",
      "Iteration 29, loss = 0.85624694\n",
      "Iteration 30, loss = 0.83367814\n",
      "Iteration 31, loss = 0.84924239\n",
      "Iteration 32, loss = 0.89693634\n",
      "Iteration 33, loss = 0.84494287\n",
      "Iteration 34, loss = 0.85171809\n",
      "Iteration 35, loss = 0.82875259\n",
      "Iteration 36, loss = 0.84055336\n",
      "Iteration 37, loss = 0.81017858\n",
      "Iteration 22, loss = 0.92366107\n",
      "Iteration 23, loss = 0.88275286\n",
      "Iteration 24, loss = 0.89331275\n",
      "Iteration 25, loss = 0.91081769\n",
      "Iteration 26, loss = 0.88963643\n",
      "Iteration 27, loss = 0.86687756\n",
      "Iteration 28, loss = 0.84857955\n",
      "Iteration 29, loss = 0.85624694\n",
      "Iteration 30, loss = 0.83367814\n",
      "Iteration 31, loss = 0.84924239\n",
      "Iteration 32, loss = 0.89693634\n",
      "Iteration 33, loss = 0.84494287\n",
      "Iteration 34, loss = 0.85171809\n",
      "Iteration 35, loss = 0.82875259\n",
      "Iteration 36, loss = 0.84055336\n",
      "Iteration 37, loss = 0.81017858\n",
      "Iteration 38, loss = 0.84283145\n",
      "Iteration 39, loss = 0.89355958\n",
      "Iteration 40, loss = 0.84240141\n",
      "Iteration 41, loss = 0.78490465\n",
      "Iteration 42, loss = 0.82908810\n",
      "Iteration 43, loss = 0.83465251\n",
      "Iteration 44, loss = 0.85725451\n",
      "Iteration 45, loss = 0.85155817\n",
      "Iteration 46, loss = 0.85962407\n",
      "Iteration 47, loss = 0.88182705\n",
      "Iteration 48, loss = 0.82467794\n",
      "Iteration 49, loss = 0.85183802\n",
      "Iteration 50, loss = 0.82204154\n",
      "Iteration 51, loss = 0.82682198\n",
      "Iteration 52, loss = 0.83306945\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.84283145\n",
      "Iteration 39, loss = 0.89355958\n",
      "Iteration 40, loss = 0.84240141\n",
      "Iteration 41, loss = 0.78490465\n",
      "Iteration 42, loss = 0.82908810\n",
      "Iteration 43, loss = 0.83465251\n",
      "Iteration 44, loss = 0.85725451\n",
      "Iteration 45, loss = 0.85155817\n",
      "Iteration 46, loss = 0.85962407\n",
      "Iteration 47, loss = 0.88182705\n",
      "Iteration 48, loss = 0.82467794\n",
      "Iteration 49, loss = 0.85183802\n",
      "Iteration 50, loss = 0.82204154\n",
      "Iteration 51, loss = 0.82682198\n",
      "Iteration 52, loss = 0.83306945\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22545543\n",
      "Iteration 2, loss = 1.13959934\n",
      "Iteration 3, loss = 1.02527037\n",
      "Iteration 4, loss = 0.96645641\n",
      "Iteration 5, loss = 0.94484655\n",
      "Iteration 6, loss = 0.92924328\n",
      "Iteration 7, loss = 0.93874390\n",
      "Iteration 8, loss = 0.94328859\n",
      "Iteration 9, loss = 0.92541432\n",
      "Iteration 10, loss = 0.90015338\n",
      "Iteration 11, loss = 0.89550845\n",
      "Iteration 12, loss = 0.86630047\n",
      "Iteration 13, loss = 0.85997297\n",
      "Iteration 14, loss = 0.90734193\n",
      "Iteration 1, loss = 1.22545543\n",
      "Iteration 2, loss = 1.13959934\n",
      "Iteration 3, loss = 1.02527037\n",
      "Iteration 4, loss = 0.96645641\n",
      "Iteration 5, loss = 0.94484655\n",
      "Iteration 6, loss = 0.92924328\n",
      "Iteration 7, loss = 0.93874390\n",
      "Iteration 8, loss = 0.94328859\n",
      "Iteration 9, loss = 0.92541432\n",
      "Iteration 10, loss = 0.90015338\n",
      "Iteration 11, loss = 0.89550845\n",
      "Iteration 12, loss = 0.86630047\n",
      "Iteration 13, loss = 0.85997297\n",
      "Iteration 14, loss = 0.90734193\n",
      "Iteration 15, loss = 0.91453922\n",
      "Iteration 16, loss = 0.89867515\n",
      "Iteration 17, loss = 0.86741844\n",
      "Iteration 18, loss = 0.84530369\n",
      "Iteration 19, loss = 0.81969688\n",
      "Iteration 20, loss = 0.84123150\n",
      "Iteration 21, loss = 0.84715038\n",
      "Iteration 22, loss = 0.85101280\n",
      "Iteration 23, loss = 0.81135667\n",
      "Iteration 24, loss = 0.88408925\n",
      "Iteration 25, loss = 0.84859434\n",
      "Iteration 26, loss = 0.85634900\n",
      "Iteration 27, loss = 0.80293176\n",
      "Iteration 28, loss = 0.82286763\n",
      "Iteration 29, loss = 0.82081553\n",
      "Iteration 15, loss = 0.91453922\n",
      "Iteration 16, loss = 0.89867515\n",
      "Iteration 17, loss = 0.86741844\n",
      "Iteration 18, loss = 0.84530369\n",
      "Iteration 19, loss = 0.81969688\n",
      "Iteration 20, loss = 0.84123150\n",
      "Iteration 21, loss = 0.84715038\n",
      "Iteration 22, loss = 0.85101280\n",
      "Iteration 23, loss = 0.81135667\n",
      "Iteration 24, loss = 0.88408925\n",
      "Iteration 25, loss = 0.84859434\n",
      "Iteration 26, loss = 0.85634900\n",
      "Iteration 27, loss = 0.80293176\n",
      "Iteration 28, loss = 0.82286763\n",
      "Iteration 29, loss = 0.82081553\n",
      "Iteration 30, loss = 0.82814276\n",
      "Iteration 31, loss = 0.79272399\n",
      "Iteration 32, loss = 0.77278175\n",
      "Iteration 33, loss = 0.76221707\n",
      "Iteration 34, loss = 0.83694387\n",
      "Iteration 35, loss = 0.80974658\n",
      "Iteration 36, loss = 0.83597352\n",
      "Iteration 37, loss = 0.79299054\n",
      "Iteration 38, loss = 0.81105338\n",
      "Iteration 39, loss = 0.80996363\n",
      "Iteration 40, loss = 0.76909789\n",
      "Iteration 41, loss = 0.76361166\n",
      "Iteration 42, loss = 0.76236485\n",
      "Iteration 43, loss = 0.80495335\n",
      "Iteration 44, loss = 0.78806699\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.82814276\n",
      "Iteration 31, loss = 0.79272399\n",
      "Iteration 32, loss = 0.77278175\n",
      "Iteration 33, loss = 0.76221707\n",
      "Iteration 34, loss = 0.83694387\n",
      "Iteration 35, loss = 0.80974658\n",
      "Iteration 36, loss = 0.83597352\n",
      "Iteration 37, loss = 0.79299054\n",
      "Iteration 38, loss = 0.81105338\n",
      "Iteration 39, loss = 0.80996363\n",
      "Iteration 40, loss = 0.76909789\n",
      "Iteration 41, loss = 0.76361166\n",
      "Iteration 42, loss = 0.76236485\n",
      "Iteration 43, loss = 0.80495335\n",
      "Iteration 44, loss = 0.78806699\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26808768\n",
      "Iteration 2, loss = 1.17739602\n",
      "Iteration 3, loss = 1.09341492\n",
      "Iteration 4, loss = 0.99226485\n",
      "Iteration 5, loss = 0.98255189\n",
      "Iteration 6, loss = 0.98378994\n",
      "Iteration 7, loss = 0.96837223\n",
      "Iteration 8, loss = 0.95878796\n",
      "Iteration 9, loss = 0.93769322\n",
      "Iteration 10, loss = 0.96835429\n",
      "Iteration 11, loss = 0.92377780\n",
      "Iteration 12, loss = 0.91676010\n",
      "Iteration 13, loss = 0.91333813\n",
      "Iteration 1, loss = 1.26808768\n",
      "Iteration 2, loss = 1.17739602\n",
      "Iteration 3, loss = 1.09341492\n",
      "Iteration 4, loss = 0.99226485\n",
      "Iteration 5, loss = 0.98255189\n",
      "Iteration 6, loss = 0.98378994\n",
      "Iteration 7, loss = 0.96837223\n",
      "Iteration 8, loss = 0.95878796\n",
      "Iteration 9, loss = 0.93769322\n",
      "Iteration 10, loss = 0.96835429\n",
      "Iteration 11, loss = 0.92377780\n",
      "Iteration 12, loss = 0.91676010\n",
      "Iteration 13, loss = 0.91333813\n",
      "Iteration 14, loss = 0.93854804\n",
      "Iteration 15, loss = 0.95250830\n",
      "Iteration 16, loss = 0.91001914\n",
      "Iteration 17, loss = 0.90792355\n",
      "Iteration 18, loss = 0.89857544\n",
      "Iteration 19, loss = 0.89477035\n",
      "Iteration 20, loss = 0.89127282\n",
      "Iteration 21, loss = 0.86373176\n",
      "Iteration 22, loss = 0.90503230\n",
      "Iteration 23, loss = 0.89006183\n",
      "Iteration 24, loss = 0.85536977\n",
      "Iteration 25, loss = 0.84623715\n",
      "Iteration 26, loss = 0.90617611\n",
      "Iteration 27, loss = 0.84196265\n",
      "Iteration 28, loss = 0.88154814\n",
      "Iteration 29, loss = 0.86701984\n",
      "Iteration 14, loss = 0.93854804\n",
      "Iteration 15, loss = 0.95250830\n",
      "Iteration 16, loss = 0.91001914\n",
      "Iteration 17, loss = 0.90792355\n",
      "Iteration 18, loss = 0.89857544\n",
      "Iteration 19, loss = 0.89477035\n",
      "Iteration 20, loss = 0.89127282\n",
      "Iteration 21, loss = 0.86373176\n",
      "Iteration 22, loss = 0.90503230\n",
      "Iteration 23, loss = 0.89006183\n",
      "Iteration 24, loss = 0.85536977\n",
      "Iteration 25, loss = 0.84623715\n",
      "Iteration 26, loss = 0.90617611\n",
      "Iteration 27, loss = 0.84196265\n",
      "Iteration 28, loss = 0.88154814\n",
      "Iteration 29, loss = 0.86701984\n",
      "Iteration 30, loss = 0.84145331\n",
      "Iteration 31, loss = 0.83529225\n",
      "Iteration 32, loss = 0.86945776\n",
      "Iteration 33, loss = 0.90135667\n",
      "Iteration 34, loss = 0.86634434\n",
      "Iteration 35, loss = 0.87151457\n",
      "Iteration 36, loss = 0.87834131\n",
      "Iteration 37, loss = 0.86014974\n",
      "Iteration 38, loss = 0.83792943\n",
      "Iteration 39, loss = 0.85178997\n",
      "Iteration 40, loss = 0.92268289\n",
      "Iteration 41, loss = 0.85341714\n",
      "Iteration 42, loss = 0.85543949\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24618095\n",
      "Iteration 2, loss = 1.17935117\n",
      "Iteration 30, loss = 0.84145331\n",
      "Iteration 31, loss = 0.83529225\n",
      "Iteration 32, loss = 0.86945776\n",
      "Iteration 33, loss = 0.90135667\n",
      "Iteration 34, loss = 0.86634434\n",
      "Iteration 35, loss = 0.87151457\n",
      "Iteration 36, loss = 0.87834131\n",
      "Iteration 37, loss = 0.86014974\n",
      "Iteration 38, loss = 0.83792943\n",
      "Iteration 39, loss = 0.85178997\n",
      "Iteration 40, loss = 0.92268289\n",
      "Iteration 41, loss = 0.85341714\n",
      "Iteration 42, loss = 0.85543949\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24618095\n",
      "Iteration 2, loss = 1.17935117\n",
      "Iteration 3, loss = 1.09885900\n",
      "Iteration 4, loss = 1.06361860\n",
      "Iteration 5, loss = 1.04496983\n",
      "Iteration 6, loss = 1.03589680\n",
      "Iteration 7, loss = 0.99467625\n",
      "Iteration 8, loss = 1.03099272\n",
      "Iteration 9, loss = 0.97445144\n",
      "Iteration 10, loss = 0.97669018\n",
      "Iteration 11, loss = 0.95923237\n",
      "Iteration 12, loss = 0.98351899\n",
      "Iteration 13, loss = 0.96806752\n",
      "Iteration 14, loss = 0.94071048\n",
      "Iteration 15, loss = 0.95821821\n",
      "Iteration 16, loss = 0.90992737\n",
      "Iteration 3, loss = 1.09885900\n",
      "Iteration 4, loss = 1.06361860\n",
      "Iteration 5, loss = 1.04496983\n",
      "Iteration 6, loss = 1.03589680\n",
      "Iteration 7, loss = 0.99467625\n",
      "Iteration 8, loss = 1.03099272\n",
      "Iteration 9, loss = 0.97445144\n",
      "Iteration 10, loss = 0.97669018\n",
      "Iteration 11, loss = 0.95923237\n",
      "Iteration 12, loss = 0.98351899\n",
      "Iteration 13, loss = 0.96806752\n",
      "Iteration 14, loss = 0.94071048\n",
      "Iteration 15, loss = 0.95821821\n",
      "Iteration 16, loss = 0.90992737\n",
      "Iteration 17, loss = 0.89639346\n",
      "Iteration 18, loss = 0.90082152\n",
      "Iteration 19, loss = 0.88002777\n",
      "Iteration 20, loss = 0.89653016\n",
      "Iteration 21, loss = 0.88273630\n",
      "Iteration 22, loss = 0.87925899\n",
      "Iteration 23, loss = 0.88387152\n",
      "Iteration 24, loss = 0.84251701\n",
      "Iteration 25, loss = 0.86199224\n",
      "Iteration 26, loss = 0.86887944\n",
      "Iteration 27, loss = 0.80183937\n",
      "Iteration 28, loss = 0.89743190\n",
      "Iteration 29, loss = 0.85467919\n",
      "Iteration 30, loss = 0.88068344\n",
      "Iteration 31, loss = 0.86843675\n",
      "Iteration 17, loss = 0.89639346\n",
      "Iteration 18, loss = 0.90082152\n",
      "Iteration 19, loss = 0.88002777\n",
      "Iteration 20, loss = 0.89653016\n",
      "Iteration 21, loss = 0.88273630\n",
      "Iteration 22, loss = 0.87925899\n",
      "Iteration 23, loss = 0.88387152\n",
      "Iteration 24, loss = 0.84251701\n",
      "Iteration 25, loss = 0.86199224\n",
      "Iteration 26, loss = 0.86887944\n",
      "Iteration 27, loss = 0.80183937\n",
      "Iteration 28, loss = 0.89743190\n",
      "Iteration 29, loss = 0.85467919\n",
      "Iteration 30, loss = 0.88068344\n",
      "Iteration 31, loss = 0.86843675\n",
      "Iteration 32, loss = 0.83542571\n",
      "Iteration 33, loss = 0.84151916\n",
      "Iteration 34, loss = 0.79745211\n",
      "Iteration 35, loss = 0.77555659\n",
      "Iteration 36, loss = 0.83485369\n",
      "Iteration 37, loss = 0.84139744\n",
      "Iteration 38, loss = 0.81849808\n",
      "Iteration 39, loss = 0.83066168\n",
      "Iteration 40, loss = 0.78309043\n",
      "Iteration 41, loss = 0.79659829\n",
      "Iteration 42, loss = 0.77360745\n",
      "Iteration 43, loss = 0.81781087\n",
      "Iteration 44, loss = 0.84230169\n",
      "Iteration 45, loss = 0.83668567\n",
      "Iteration 46, loss = 0.80837643\n",
      "Iteration 32, loss = 0.83542571\n",
      "Iteration 33, loss = 0.84151916\n",
      "Iteration 34, loss = 0.79745211\n",
      "Iteration 35, loss = 0.77555659\n",
      "Iteration 36, loss = 0.83485369\n",
      "Iteration 37, loss = 0.84139744\n",
      "Iteration 38, loss = 0.81849808\n",
      "Iteration 39, loss = 0.83066168\n",
      "Iteration 40, loss = 0.78309043\n",
      "Iteration 41, loss = 0.79659829\n",
      "Iteration 42, loss = 0.77360745\n",
      "Iteration 43, loss = 0.81781087\n",
      "Iteration 44, loss = 0.84230169\n",
      "Iteration 45, loss = 0.83668567\n",
      "Iteration 46, loss = 0.80837643\n",
      "Iteration 47, loss = 0.78249065\n",
      "Iteration 48, loss = 0.72826018\n",
      "Iteration 49, loss = 0.75343623\n",
      "Iteration 50, loss = 0.80699704\n",
      "Iteration 51, loss = 0.85007630\n",
      "Iteration 52, loss = 0.75486288\n",
      "Iteration 53, loss = 0.77142036\n",
      "Iteration 54, loss = 0.73302125\n",
      "Iteration 55, loss = 0.82651690\n",
      "Iteration 56, loss = 0.77177071\n",
      "Iteration 57, loss = 0.72631066\n",
      "Iteration 58, loss = 0.81401365\n",
      "Iteration 59, loss = 0.76360046\n",
      "Iteration 60, loss = 0.82566900\n",
      "Iteration 61, loss = 0.78126664\n",
      "Iteration 62, loss = 0.80615458\n",
      "Iteration 47, loss = 0.78249065\n",
      "Iteration 48, loss = 0.72826018\n",
      "Iteration 49, loss = 0.75343623\n",
      "Iteration 50, loss = 0.80699704\n",
      "Iteration 51, loss = 0.85007630\n",
      "Iteration 52, loss = 0.75486288\n",
      "Iteration 53, loss = 0.77142036\n",
      "Iteration 54, loss = 0.73302125\n",
      "Iteration 55, loss = 0.82651690\n",
      "Iteration 56, loss = 0.77177071\n",
      "Iteration 57, loss = 0.72631066\n",
      "Iteration 58, loss = 0.81401365\n",
      "Iteration 59, loss = 0.76360046\n",
      "Iteration 60, loss = 0.82566900\n",
      "Iteration 61, loss = 0.78126664\n",
      "Iteration 62, loss = 0.80615458\n",
      "Iteration 63, loss = 0.75453844\n",
      "Iteration 64, loss = 0.74086519\n",
      "Iteration 65, loss = 0.72113836\n",
      "Iteration 66, loss = 0.72103256\n",
      "Iteration 67, loss = 0.76225898\n",
      "Iteration 68, loss = 0.70983235\n",
      "Iteration 69, loss = 0.70334592\n",
      "Iteration 70, loss = 0.80235820\n",
      "Iteration 71, loss = 0.73005430\n",
      "Iteration 72, loss = 0.78060832\n",
      "Iteration 73, loss = 0.70955446\n",
      "Iteration 74, loss = 0.75289376\n",
      "Iteration 75, loss = 0.72830230\n",
      "Iteration 76, loss = 0.79842387\n",
      "Iteration 77, loss = 0.74694595\n",
      "Iteration 78, loss = 0.72941939\n",
      "Iteration 63, loss = 0.75453844\n",
      "Iteration 64, loss = 0.74086519\n",
      "Iteration 65, loss = 0.72113836\n",
      "Iteration 66, loss = 0.72103256\n",
      "Iteration 67, loss = 0.76225898\n",
      "Iteration 68, loss = 0.70983235\n",
      "Iteration 69, loss = 0.70334592\n",
      "Iteration 70, loss = 0.80235820\n",
      "Iteration 71, loss = 0.73005430\n",
      "Iteration 72, loss = 0.78060832\n",
      "Iteration 73, loss = 0.70955446\n",
      "Iteration 74, loss = 0.75289376\n",
      "Iteration 75, loss = 0.72830230\n",
      "Iteration 76, loss = 0.79842387\n",
      "Iteration 77, loss = 0.74694595\n",
      "Iteration 78, loss = 0.72941939\n",
      "Iteration 79, loss = 0.74055832\n",
      "Iteration 80, loss = 0.73724925\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24747586\n",
      "Iteration 2, loss = 1.14287430\n",
      "Iteration 3, loss = 1.10000536\n",
      "Iteration 4, loss = 1.02374281\n",
      "Iteration 5, loss = 0.99546540\n",
      "Iteration 6, loss = 0.97419591\n",
      "Iteration 7, loss = 0.97178115\n",
      "Iteration 8, loss = 0.97487262\n",
      "Iteration 9, loss = 0.95673342\n",
      "Iteration 10, loss = 0.92786522\n",
      "Iteration 79, loss = 0.74055832\n",
      "Iteration 80, loss = 0.73724925\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24747586\n",
      "Iteration 2, loss = 1.14287430\n",
      "Iteration 3, loss = 1.10000536\n",
      "Iteration 4, loss = 1.02374281\n",
      "Iteration 5, loss = 0.99546540\n",
      "Iteration 6, loss = 0.97419591\n",
      "Iteration 7, loss = 0.97178115\n",
      "Iteration 8, loss = 0.97487262\n",
      "Iteration 9, loss = 0.95673342\n",
      "Iteration 10, loss = 0.92786522\n",
      "Iteration 11, loss = 0.91467423\n",
      "Iteration 12, loss = 0.95127840\n",
      "Iteration 13, loss = 0.96412875\n",
      "Iteration 14, loss = 0.93213069\n",
      "Iteration 15, loss = 0.91983863\n",
      "Iteration 16, loss = 0.90453666\n",
      "Iteration 17, loss = 0.90225789\n",
      "Iteration 18, loss = 0.89612834\n",
      "Iteration 19, loss = 0.87201824\n",
      "Iteration 20, loss = 0.85201660\n",
      "Iteration 21, loss = 0.87941950\n",
      "Iteration 22, loss = 0.88626513\n",
      "Iteration 23, loss = 0.93801837\n",
      "Iteration 24, loss = 0.87255868\n",
      "Iteration 25, loss = 0.88809367\n",
      "Iteration 26, loss = 0.86583723\n",
      "Iteration 11, loss = 0.91467423\n",
      "Iteration 12, loss = 0.95127840\n",
      "Iteration 13, loss = 0.96412875\n",
      "Iteration 14, loss = 0.93213069\n",
      "Iteration 15, loss = 0.91983863\n",
      "Iteration 16, loss = 0.90453666\n",
      "Iteration 17, loss = 0.90225789\n",
      "Iteration 18, loss = 0.89612834\n",
      "Iteration 19, loss = 0.87201824\n",
      "Iteration 20, loss = 0.85201660\n",
      "Iteration 21, loss = 0.87941950\n",
      "Iteration 22, loss = 0.88626513\n",
      "Iteration 23, loss = 0.93801837\n",
      "Iteration 24, loss = 0.87255868\n",
      "Iteration 25, loss = 0.88809367\n",
      "Iteration 26, loss = 0.86583723\n",
      "Iteration 27, loss = 0.83119251\n",
      "Iteration 28, loss = 0.88675512\n",
      "Iteration 29, loss = 0.85928547\n",
      "Iteration 30, loss = 0.86054084\n",
      "Iteration 31, loss = 0.80967856\n",
      "Iteration 32, loss = 0.86987437\n",
      "Iteration 33, loss = 0.82723609\n",
      "Iteration 34, loss = 0.82137438\n",
      "Iteration 35, loss = 0.81281030\n",
      "Iteration 36, loss = 0.81193434\n",
      "Iteration 37, loss = 0.89149730\n",
      "Iteration 38, loss = 0.87990976\n",
      "Iteration 39, loss = 0.84045130\n",
      "Iteration 40, loss = 0.79501107\n",
      "Iteration 41, loss = 0.81824474\n",
      "Iteration 27, loss = 0.83119251\n",
      "Iteration 28, loss = 0.88675512\n",
      "Iteration 29, loss = 0.85928547\n",
      "Iteration 30, loss = 0.86054084\n",
      "Iteration 31, loss = 0.80967856\n",
      "Iteration 32, loss = 0.86987437\n",
      "Iteration 33, loss = 0.82723609\n",
      "Iteration 34, loss = 0.82137438\n",
      "Iteration 35, loss = 0.81281030\n",
      "Iteration 36, loss = 0.81193434\n",
      "Iteration 37, loss = 0.89149730\n",
      "Iteration 38, loss = 0.87990976\n",
      "Iteration 39, loss = 0.84045130\n",
      "Iteration 40, loss = 0.79501107\n",
      "Iteration 41, loss = 0.81824474\n",
      "Iteration 42, loss = 0.81672341\n",
      "Iteration 43, loss = 0.82571779\n",
      "Iteration 44, loss = 0.86294253\n",
      "Iteration 45, loss = 0.87610994\n",
      "Iteration 46, loss = 0.83235840\n",
      "Iteration 47, loss = 0.79843988\n",
      "Iteration 48, loss = 0.85002912\n",
      "Iteration 49, loss = 0.85061986\n",
      "Iteration 50, loss = 0.79057935\n",
      "Iteration 51, loss = 0.85752782\n",
      "Iteration 52, loss = 0.79725350\n",
      "Iteration 53, loss = 0.80071523\n",
      "Iteration 54, loss = 0.80046168\n",
      "Iteration 55, loss = 0.82763818\n",
      "Iteration 56, loss = 0.82429695\n",
      "Iteration 42, loss = 0.81672341\n",
      "Iteration 43, loss = 0.82571779\n",
      "Iteration 44, loss = 0.86294253\n",
      "Iteration 45, loss = 0.87610994\n",
      "Iteration 46, loss = 0.83235840\n",
      "Iteration 47, loss = 0.79843988\n",
      "Iteration 48, loss = 0.85002912\n",
      "Iteration 49, loss = 0.85061986\n",
      "Iteration 50, loss = 0.79057935\n",
      "Iteration 51, loss = 0.85752782\n",
      "Iteration 52, loss = 0.79725350\n",
      "Iteration 53, loss = 0.80071523\n",
      "Iteration 54, loss = 0.80046168\n",
      "Iteration 55, loss = 0.82763818\n",
      "Iteration 56, loss = 0.82429695\n",
      "Iteration 57, loss = 0.80244357\n",
      "Iteration 58, loss = 0.76965451\n",
      "Iteration 59, loss = 0.78747355\n",
      "Iteration 60, loss = 0.78974677\n",
      "Iteration 61, loss = 0.80320251\n",
      "Iteration 62, loss = 0.77373026\n",
      "Iteration 63, loss = 0.78810236\n",
      "Iteration 64, loss = 0.81443503\n",
      "Iteration 65, loss = 0.76121968\n",
      "Iteration 66, loss = 0.71190424\n",
      "Iteration 67, loss = 0.81438343\n",
      "Iteration 68, loss = 0.74910836\n",
      "Iteration 69, loss = 0.75625150\n",
      "Iteration 70, loss = 0.73963525\n",
      "Iteration 71, loss = 0.76450186\n",
      "Iteration 72, loss = 0.76117083\n",
      "Iteration 57, loss = 0.80244357\n",
      "Iteration 58, loss = 0.76965451\n",
      "Iteration 59, loss = 0.78747355\n",
      "Iteration 60, loss = 0.78974677\n",
      "Iteration 61, loss = 0.80320251\n",
      "Iteration 62, loss = 0.77373026\n",
      "Iteration 63, loss = 0.78810236\n",
      "Iteration 64, loss = 0.81443503\n",
      "Iteration 65, loss = 0.76121968\n",
      "Iteration 66, loss = 0.71190424\n",
      "Iteration 67, loss = 0.81438343\n",
      "Iteration 68, loss = 0.74910836\n",
      "Iteration 69, loss = 0.75625150\n",
      "Iteration 70, loss = 0.73963525\n",
      "Iteration 71, loss = 0.76450186\n",
      "Iteration 72, loss = 0.76117083\n",
      "Iteration 73, loss = 0.78190240\n",
      "Iteration 74, loss = 0.76422279\n",
      "Iteration 75, loss = 0.77289648\n",
      "Iteration 76, loss = 0.74578995\n",
      "Iteration 77, loss = 0.77911158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22934699\n",
      "Iteration 2, loss = 1.15496262\n",
      "Iteration 3, loss = 1.04598047\n",
      "Iteration 4, loss = 1.00460128\n",
      "Iteration 5, loss = 1.01021448\n",
      "Iteration 6, loss = 1.08224479\n",
      "Iteration 7, loss = 0.99585466\n",
      "Iteration 8, loss = 1.00169715\n",
      "Iteration 73, loss = 0.78190240\n",
      "Iteration 74, loss = 0.76422279\n",
      "Iteration 75, loss = 0.77289648\n",
      "Iteration 76, loss = 0.74578995\n",
      "Iteration 77, loss = 0.77911158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22934699\n",
      "Iteration 2, loss = 1.15496262\n",
      "Iteration 3, loss = 1.04598047\n",
      "Iteration 4, loss = 1.00460128\n",
      "Iteration 5, loss = 1.01021448\n",
      "Iteration 6, loss = 1.08224479\n",
      "Iteration 7, loss = 0.99585466\n",
      "Iteration 8, loss = 1.00169715\n",
      "Iteration 9, loss = 0.99068018\n",
      "Iteration 10, loss = 0.98506475\n",
      "Iteration 1, loss = 1.23641716\n",
      "Iteration 2, loss = 1.24747638\n",
      "Iteration 3, loss = 1.06919900\n",
      "Iteration 4, loss = 0.99251922\n",
      "Iteration 5, loss = 0.98779733\n",
      "Iteration 6, loss = 0.94593574\n",
      "Iteration 7, loss = 0.97160465\n",
      "Iteration 8, loss = 1.01303102\n",
      "Iteration 9, loss = 0.95625681\n",
      "Iteration 10, loss = 0.93262406\n",
      "Iteration 1, loss = 1.24072530\n",
      "Iteration 2, loss = 1.18218135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.99068018\n",
      "Iteration 10, loss = 0.98506475\n",
      "Iteration 1, loss = 1.23641716\n",
      "Iteration 2, loss = 1.24747638\n",
      "Iteration 3, loss = 1.06919900\n",
      "Iteration 4, loss = 0.99251922\n",
      "Iteration 5, loss = 0.98779733\n",
      "Iteration 6, loss = 0.94593574\n",
      "Iteration 7, loss = 0.97160465\n",
      "Iteration 8, loss = 1.01303102\n",
      "Iteration 9, loss = 0.95625681\n",
      "Iteration 10, loss = 0.93262406\n",
      "Iteration 1, loss = 1.24072530\n",
      "Iteration 2, loss = 1.18218135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.09249980\n",
      "Iteration 4, loss = 1.01821538\n",
      "Iteration 5, loss = 1.03174172\n",
      "Iteration 6, loss = 1.05929408\n",
      "Iteration 7, loss = 1.08849188\n",
      "Iteration 8, loss = 1.00381706\n",
      "Iteration 9, loss = 0.99004427\n",
      "Iteration 10, loss = 0.98676076\n",
      "Iteration 1, loss = 1.23017261\n",
      "Iteration 2, loss = 1.23897143\n",
      "Iteration 3, loss = 1.18566755\n",
      "Iteration 4, loss = 1.15508649\n",
      "Iteration 5, loss = 1.07041698\n",
      "Iteration 3, loss = 1.09249980\n",
      "Iteration 4, loss = 1.01821538\n",
      "Iteration 5, loss = 1.03174172\n",
      "Iteration 6, loss = 1.05929408\n",
      "Iteration 7, loss = 1.08849188\n",
      "Iteration 8, loss = 1.00381706\n",
      "Iteration 9, loss = 0.99004427\n",
      "Iteration 10, loss = 0.98676076\n",
      "Iteration 1, loss = 1.23017261\n",
      "Iteration 2, loss = 1.23897143\n",
      "Iteration 3, loss = 1.18566755\n",
      "Iteration 4, loss = 1.15508649\n",
      "Iteration 5, loss = 1.07041698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.03551290\n",
      "Iteration 7, loss = 0.99402759\n",
      "Iteration 8, loss = 1.03733450\n",
      "Iteration 9, loss = 1.01249312\n",
      "Iteration 10, loss = 1.05167387\n",
      "Iteration 1, loss = 1.24700065\n",
      "Iteration 2, loss = 1.17484688\n",
      "Iteration 3, loss = 1.13534065\n",
      "Iteration 4, loss = 1.07154569\n",
      "Iteration 5, loss = 1.07358289\n",
      "Iteration 6, loss = 1.06077461\n",
      "Iteration 7, loss = 1.00084197\n",
      "Iteration 6, loss = 1.03551290\n",
      "Iteration 7, loss = 0.99402759\n",
      "Iteration 8, loss = 1.03733450\n",
      "Iteration 9, loss = 1.01249312\n",
      "Iteration 10, loss = 1.05167387\n",
      "Iteration 1, loss = 1.24700065\n",
      "Iteration 2, loss = 1.17484688\n",
      "Iteration 3, loss = 1.13534065\n",
      "Iteration 4, loss = 1.07154569\n",
      "Iteration 5, loss = 1.07358289\n",
      "Iteration 6, loss = 1.06077461\n",
      "Iteration 7, loss = 1.00084197\n",
      "Iteration 8, loss = 1.03906894\n",
      "Iteration 9, loss = 0.99021384\n",
      "Iteration 10, loss = 0.98666325\n",
      "Iteration 1, loss = 1.22934699\n",
      "Iteration 2, loss = 1.15496262\n",
      "Iteration 3, loss = 1.04598047\n",
      "Iteration 4, loss = 1.00460128\n",
      "Iteration 5, loss = 1.01021448\n",
      "Iteration 6, loss = 1.08224479\n",
      "Iteration 7, loss = 0.99585466\n",
      "Iteration 8, loss = 1.00169715\n",
      "Iteration 9, loss = 0.99068018\n",
      "Iteration 10, loss = 0.98506475\n",
      "Iteration 11, loss = 0.97451740\n",
      "Iteration 8, loss = 1.03906894\n",
      "Iteration 9, loss = 0.99021384\n",
      "Iteration 10, loss = 0.98666325\n",
      "Iteration 1, loss = 1.22934699\n",
      "Iteration 2, loss = 1.15496262\n",
      "Iteration 3, loss = 1.04598047\n",
      "Iteration 4, loss = 1.00460128\n",
      "Iteration 5, loss = 1.01021448\n",
      "Iteration 6, loss = 1.08224479\n",
      "Iteration 7, loss = 0.99585466\n",
      "Iteration 8, loss = 1.00169715\n",
      "Iteration 9, loss = 0.99068018\n",
      "Iteration 10, loss = 0.98506475\n",
      "Iteration 11, loss = 0.97451740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.96085476\n",
      "Iteration 13, loss = 0.96864535\n",
      "Iteration 14, loss = 1.00991397\n",
      "Iteration 15, loss = 0.97919043\n",
      "Iteration 16, loss = 1.08099904\n",
      "Iteration 17, loss = 0.96327954\n",
      "Iteration 18, loss = 1.13210637\n",
      "Iteration 19, loss = 1.09088186\n",
      "Iteration 20, loss = 1.00243285\n",
      "Iteration 21, loss = 0.99454823\n",
      "Iteration 22, loss = 0.96700015\n",
      "Iteration 23, loss = 0.96863057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23641716\n",
      "Iteration 2, loss = 1.24747638\n",
      "Iteration 3, loss = 1.06919900\n",
      "Iteration 12, loss = 0.96085476\n",
      "Iteration 13, loss = 0.96864535\n",
      "Iteration 14, loss = 1.00991397\n",
      "Iteration 15, loss = 0.97919043\n",
      "Iteration 16, loss = 1.08099904\n",
      "Iteration 17, loss = 0.96327954\n",
      "Iteration 18, loss = 1.13210637\n",
      "Iteration 19, loss = 1.09088186\n",
      "Iteration 20, loss = 1.00243285\n",
      "Iteration 21, loss = 0.99454823\n",
      "Iteration 22, loss = 0.96700015\n",
      "Iteration 23, loss = 0.96863057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23641716\n",
      "Iteration 2, loss = 1.24747638\n",
      "Iteration 3, loss = 1.06919900\n",
      "Iteration 4, loss = 0.99251922\n",
      "Iteration 5, loss = 0.98779733\n",
      "Iteration 6, loss = 0.94593574\n",
      "Iteration 7, loss = 0.97160465\n",
      "Iteration 8, loss = 1.01303102\n",
      "Iteration 9, loss = 0.95625681\n",
      "Iteration 10, loss = 0.93262406\n",
      "Iteration 11, loss = 0.96098284\n",
      "Iteration 12, loss = 0.95905992\n",
      "Iteration 13, loss = 0.95132498\n",
      "Iteration 14, loss = 0.93744555\n",
      "Iteration 15, loss = 0.93187265\n",
      "Iteration 16, loss = 1.00108019\n",
      "Iteration 17, loss = 0.93037485\n",
      "Iteration 4, loss = 0.99251922\n",
      "Iteration 5, loss = 0.98779733\n",
      "Iteration 6, loss = 0.94593574\n",
      "Iteration 7, loss = 0.97160465\n",
      "Iteration 8, loss = 1.01303102\n",
      "Iteration 9, loss = 0.95625681\n",
      "Iteration 10, loss = 0.93262406\n",
      "Iteration 11, loss = 0.96098284\n",
      "Iteration 12, loss = 0.95905992\n",
      "Iteration 13, loss = 0.95132498\n",
      "Iteration 14, loss = 0.93744555\n",
      "Iteration 15, loss = 0.93187265\n",
      "Iteration 16, loss = 1.00108019\n",
      "Iteration 17, loss = 0.93037485\n",
      "Iteration 18, loss = 0.90326481\n",
      "Iteration 19, loss = 0.90096146\n",
      "Iteration 20, loss = 0.90134440\n",
      "Iteration 21, loss = 0.93384739\n",
      "Iteration 22, loss = 0.91194706\n",
      "Iteration 23, loss = 0.91124124\n",
      "Iteration 24, loss = 0.91779342\n",
      "Iteration 25, loss = 0.90720681\n",
      "Iteration 26, loss = 0.92461958\n",
      "Iteration 27, loss = 0.91564540\n",
      "Iteration 28, loss = 0.90450694\n",
      "Iteration 29, loss = 0.90970515\n",
      "Iteration 30, loss = 0.91570767\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24072530\n",
      "Iteration 18, loss = 0.90326481\n",
      "Iteration 19, loss = 0.90096146\n",
      "Iteration 20, loss = 0.90134440\n",
      "Iteration 21, loss = 0.93384739\n",
      "Iteration 22, loss = 0.91194706\n",
      "Iteration 23, loss = 0.91124124\n",
      "Iteration 24, loss = 0.91779342\n",
      "Iteration 25, loss = 0.90720681\n",
      "Iteration 26, loss = 0.92461958\n",
      "Iteration 27, loss = 0.91564540\n",
      "Iteration 28, loss = 0.90450694\n",
      "Iteration 29, loss = 0.90970515\n",
      "Iteration 30, loss = 0.91570767\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24072530\n",
      "Iteration 2, loss = 1.18218135\n",
      "Iteration 3, loss = 1.09249980\n",
      "Iteration 4, loss = 1.01821538\n",
      "Iteration 5, loss = 1.03174172\n",
      "Iteration 6, loss = 1.05929408\n",
      "Iteration 7, loss = 1.08849188\n",
      "Iteration 8, loss = 1.00381706\n",
      "Iteration 9, loss = 0.99004427\n",
      "Iteration 10, loss = 0.98676076\n",
      "Iteration 11, loss = 0.96016802\n",
      "Iteration 12, loss = 0.97068978\n",
      "Iteration 13, loss = 0.97594209\n",
      "Iteration 14, loss = 0.94567269\n",
      "Iteration 15, loss = 0.96794224\n",
      "Iteration 2, loss = 1.18218135\n",
      "Iteration 3, loss = 1.09249980\n",
      "Iteration 4, loss = 1.01821538\n",
      "Iteration 5, loss = 1.03174172\n",
      "Iteration 6, loss = 1.05929408\n",
      "Iteration 7, loss = 1.08849188\n",
      "Iteration 8, loss = 1.00381706\n",
      "Iteration 9, loss = 0.99004427\n",
      "Iteration 10, loss = 0.98676076\n",
      "Iteration 11, loss = 0.96016802\n",
      "Iteration 12, loss = 0.97068978\n",
      "Iteration 13, loss = 0.97594209\n",
      "Iteration 14, loss = 0.94567269\n",
      "Iteration 15, loss = 0.96794224\n",
      "Iteration 16, loss = 1.00178142\n",
      "Iteration 17, loss = 0.95218122\n",
      "Iteration 18, loss = 0.97545334\n",
      "Iteration 19, loss = 0.96809627\n",
      "Iteration 20, loss = 0.96673775\n",
      "Iteration 21, loss = 0.94437375\n",
      "Iteration 22, loss = 0.95718051\n",
      "Iteration 23, loss = 0.95414313\n",
      "Iteration 24, loss = 0.93416625\n",
      "Iteration 25, loss = 0.98235989\n",
      "Iteration 26, loss = 0.96362442\n",
      "Iteration 27, loss = 0.94148895\n",
      "Iteration 28, loss = 0.96719765\n",
      "Iteration 29, loss = 0.91352953\n",
      "Iteration 30, loss = 0.90243561\n",
      "Iteration 16, loss = 1.00178142\n",
      "Iteration 17, loss = 0.95218122\n",
      "Iteration 18, loss = 0.97545334\n",
      "Iteration 19, loss = 0.96809627\n",
      "Iteration 20, loss = 0.96673775\n",
      "Iteration 21, loss = 0.94437375\n",
      "Iteration 22, loss = 0.95718051\n",
      "Iteration 23, loss = 0.95414313\n",
      "Iteration 24, loss = 0.93416625\n",
      "Iteration 25, loss = 0.98235989\n",
      "Iteration 26, loss = 0.96362442\n",
      "Iteration 27, loss = 0.94148895\n",
      "Iteration 28, loss = 0.96719765\n",
      "Iteration 29, loss = 0.91352953\n",
      "Iteration 30, loss = 0.90243561\n",
      "Iteration 31, loss = 0.99679646\n",
      "Iteration 32, loss = 0.96026826\n",
      "Iteration 33, loss = 0.92972186\n",
      "Iteration 34, loss = 0.93278064\n",
      "Iteration 35, loss = 0.91713989\n",
      "Iteration 36, loss = 0.95518754\n",
      "Iteration 37, loss = 0.90856707\n",
      "Iteration 38, loss = 0.89648598\n",
      "Iteration 39, loss = 0.96144878\n",
      "Iteration 40, loss = 0.92095254\n",
      "Iteration 41, loss = 0.90619269\n",
      "Iteration 42, loss = 0.91574754\n",
      "Iteration 43, loss = 0.89005418\n",
      "Iteration 44, loss = 0.87776404\n",
      "Iteration 45, loss = 0.93521536\n",
      "Iteration 46, loss = 0.90253883\n",
      "Iteration 31, loss = 0.99679646\n",
      "Iteration 32, loss = 0.96026826\n",
      "Iteration 33, loss = 0.92972186\n",
      "Iteration 34, loss = 0.93278064\n",
      "Iteration 35, loss = 0.91713989\n",
      "Iteration 36, loss = 0.95518754\n",
      "Iteration 37, loss = 0.90856707\n",
      "Iteration 38, loss = 0.89648598\n",
      "Iteration 39, loss = 0.96144878\n",
      "Iteration 40, loss = 0.92095254\n",
      "Iteration 41, loss = 0.90619269\n",
      "Iteration 42, loss = 0.91574754\n",
      "Iteration 43, loss = 0.89005418\n",
      "Iteration 44, loss = 0.87776404\n",
      "Iteration 45, loss = 0.93521536\n",
      "Iteration 46, loss = 0.90253883\n",
      "Iteration 47, loss = 0.89131034\n",
      "Iteration 48, loss = 0.89582165\n",
      "Iteration 49, loss = 0.88764475\n",
      "Iteration 50, loss = 0.88570464\n",
      "Iteration 1, loss = 1.23017261\n",
      "Iteration 2, loss = 1.23897143\n",
      "Iteration 3, loss = 1.18566755\n",
      "Iteration 4, loss = 1.15508649\n",
      "Iteration 5, loss = 1.07041698\n",
      "Iteration 6, loss = 1.03551290\n",
      "Iteration 7, loss = 0.99402759\n",
      "Iteration 8, loss = 1.03733450\n",
      "Iteration 9, loss = 1.01249312\n",
      "Iteration 47, loss = 0.89131034\n",
      "Iteration 48, loss = 0.89582165\n",
      "Iteration 49, loss = 0.88764475\n",
      "Iteration 50, loss = 0.88570464\n",
      "Iteration 1, loss = 1.23017261\n",
      "Iteration 2, loss = 1.23897143\n",
      "Iteration 3, loss = 1.18566755\n",
      "Iteration 4, loss = 1.15508649\n",
      "Iteration 5, loss = 1.07041698\n",
      "Iteration 6, loss = 1.03551290\n",
      "Iteration 7, loss = 0.99402759\n",
      "Iteration 8, loss = 1.03733450\n",
      "Iteration 9, loss = 1.01249312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.05167387\n",
      "Iteration 11, loss = 1.03209065\n",
      "Iteration 12, loss = 1.00615868\n",
      "Iteration 13, loss = 1.06048388\n",
      "Iteration 14, loss = 0.96759257\n",
      "Iteration 15, loss = 1.08423902\n",
      "Iteration 16, loss = 1.19513938\n",
      "Iteration 17, loss = 1.03500052\n",
      "Iteration 18, loss = 0.99133902\n",
      "Iteration 19, loss = 1.04100623\n",
      "Iteration 20, loss = 1.00458009\n",
      "Iteration 21, loss = 1.01570147\n",
      "Iteration 22, loss = 1.03192039\n",
      "Iteration 23, loss = 1.01796311\n",
      "Iteration 24, loss = 0.97435302\n",
      "Iteration 10, loss = 1.05167387\n",
      "Iteration 11, loss = 1.03209065\n",
      "Iteration 12, loss = 1.00615868\n",
      "Iteration 13, loss = 1.06048388\n",
      "Iteration 14, loss = 0.96759257\n",
      "Iteration 15, loss = 1.08423902\n",
      "Iteration 16, loss = 1.19513938\n",
      "Iteration 17, loss = 1.03500052\n",
      "Iteration 18, loss = 0.99133902\n",
      "Iteration 19, loss = 1.04100623\n",
      "Iteration 20, loss = 1.00458009\n",
      "Iteration 21, loss = 1.01570147\n",
      "Iteration 22, loss = 1.03192039\n",
      "Iteration 23, loss = 1.01796311\n",
      "Iteration 24, loss = 0.97435302\n",
      "Iteration 25, loss = 0.96510371\n",
      "Iteration 26, loss = 0.94958464\n",
      "Iteration 27, loss = 0.93208792\n",
      "Iteration 28, loss = 1.02058153\n",
      "Iteration 29, loss = 1.00760066\n",
      "Iteration 30, loss = 0.92357684\n",
      "Iteration 31, loss = 0.98100194\n",
      "Iteration 32, loss = 0.91188833\n",
      "Iteration 33, loss = 0.98164593\n",
      "Iteration 34, loss = 0.90800177\n",
      "Iteration 35, loss = 0.91529759\n",
      "Iteration 36, loss = 0.96255467\n",
      "Iteration 37, loss = 0.94412172\n",
      "Iteration 38, loss = 0.91580170\n",
      "Iteration 39, loss = 0.90047078\n",
      "Iteration 25, loss = 0.96510371\n",
      "Iteration 26, loss = 0.94958464\n",
      "Iteration 27, loss = 0.93208792\n",
      "Iteration 28, loss = 1.02058153\n",
      "Iteration 29, loss = 1.00760066\n",
      "Iteration 30, loss = 0.92357684\n",
      "Iteration 31, loss = 0.98100194\n",
      "Iteration 32, loss = 0.91188833\n",
      "Iteration 33, loss = 0.98164593\n",
      "Iteration 34, loss = 0.90800177\n",
      "Iteration 35, loss = 0.91529759\n",
      "Iteration 36, loss = 0.96255467\n",
      "Iteration 37, loss = 0.94412172\n",
      "Iteration 38, loss = 0.91580170\n",
      "Iteration 39, loss = 0.90047078\n",
      "Iteration 40, loss = 0.90990054\n",
      "Iteration 41, loss = 0.90071403\n",
      "Iteration 42, loss = 0.93248080\n",
      "Iteration 43, loss = 0.96658388\n",
      "Iteration 44, loss = 0.90940071\n",
      "Iteration 45, loss = 0.91049757\n",
      "Iteration 46, loss = 0.93541998\n",
      "Iteration 47, loss = 0.89857999\n",
      "Iteration 48, loss = 0.89085208\n",
      "Iteration 49, loss = 0.85764634\n",
      "Iteration 50, loss = 0.89078152\n",
      "Iteration 1, loss = 1.24700065\n",
      "Iteration 2, loss = 1.17484688\n",
      "Iteration 3, loss = 1.13534065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.90990054\n",
      "Iteration 41, loss = 0.90071403\n",
      "Iteration 42, loss = 0.93248080\n",
      "Iteration 43, loss = 0.96658388\n",
      "Iteration 44, loss = 0.90940071\n",
      "Iteration 45, loss = 0.91049757\n",
      "Iteration 46, loss = 0.93541998\n",
      "Iteration 47, loss = 0.89857999\n",
      "Iteration 48, loss = 0.89085208\n",
      "Iteration 49, loss = 0.85764634\n",
      "Iteration 50, loss = 0.89078152\n",
      "Iteration 1, loss = 1.24700065\n",
      "Iteration 2, loss = 1.17484688\n",
      "Iteration 3, loss = 1.13534065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.07154569\n",
      "Iteration 5, loss = 1.07358289\n",
      "Iteration 6, loss = 1.06077461\n",
      "Iteration 7, loss = 1.00084197\n",
      "Iteration 8, loss = 1.03906894\n",
      "Iteration 9, loss = 0.99021384\n",
      "Iteration 10, loss = 0.98666325\n",
      "Iteration 11, loss = 0.95447152\n",
      "Iteration 12, loss = 1.00829793\n",
      "Iteration 13, loss = 1.01216314\n",
      "Iteration 14, loss = 0.96407888\n",
      "Iteration 15, loss = 0.98602459\n",
      "Iteration 16, loss = 0.97967288\n",
      "Iteration 17, loss = 0.94297643\n",
      "Iteration 4, loss = 1.07154569\n",
      "Iteration 5, loss = 1.07358289\n",
      "Iteration 6, loss = 1.06077461\n",
      "Iteration 7, loss = 1.00084197\n",
      "Iteration 8, loss = 1.03906894\n",
      "Iteration 9, loss = 0.99021384\n",
      "Iteration 10, loss = 0.98666325\n",
      "Iteration 11, loss = 0.95447152\n",
      "Iteration 12, loss = 1.00829793\n",
      "Iteration 13, loss = 1.01216314\n",
      "Iteration 14, loss = 0.96407888\n",
      "Iteration 15, loss = 0.98602459\n",
      "Iteration 16, loss = 0.97967288\n",
      "Iteration 17, loss = 0.94297643\n",
      "Iteration 18, loss = 0.94861708\n",
      "Iteration 19, loss = 0.92475064\n",
      "Iteration 20, loss = 0.89741179\n",
      "Iteration 21, loss = 0.94088899\n",
      "Iteration 22, loss = 0.91824261\n",
      "Iteration 23, loss = 0.95571536\n",
      "Iteration 24, loss = 0.94524396\n",
      "Iteration 25, loss = 0.95050589\n",
      "Iteration 26, loss = 0.96033239\n",
      "Iteration 27, loss = 0.95105963\n",
      "Iteration 28, loss = 0.95486378\n",
      "Iteration 29, loss = 0.90947449\n",
      "Iteration 30, loss = 0.93281039\n",
      "Iteration 31, loss = 0.89445134\n",
      "Iteration 32, loss = 0.93923378\n",
      "Iteration 18, loss = 0.94861708\n",
      "Iteration 19, loss = 0.92475064\n",
      "Iteration 20, loss = 0.89741179\n",
      "Iteration 21, loss = 0.94088899\n",
      "Iteration 22, loss = 0.91824261\n",
      "Iteration 23, loss = 0.95571536\n",
      "Iteration 24, loss = 0.94524396\n",
      "Iteration 25, loss = 0.95050589\n",
      "Iteration 26, loss = 0.96033239\n",
      "Iteration 27, loss = 0.95105963\n",
      "Iteration 28, loss = 0.95486378\n",
      "Iteration 29, loss = 0.90947449\n",
      "Iteration 30, loss = 0.93281039\n",
      "Iteration 31, loss = 0.89445134\n",
      "Iteration 32, loss = 0.93923378\n",
      "Iteration 33, loss = 0.91478285\n",
      "Iteration 34, loss = 0.89205673\n",
      "Iteration 35, loss = 0.95500524\n",
      "Iteration 36, loss = 0.91288700\n",
      "Iteration 37, loss = 0.88618742\n",
      "Iteration 38, loss = 0.97608430\n",
      "Iteration 39, loss = 0.95169630\n",
      "Iteration 40, loss = 0.89252235\n",
      "Iteration 41, loss = 0.91140476\n",
      "Iteration 42, loss = 0.88152895\n",
      "Iteration 43, loss = 1.01214014\n",
      "Iteration 44, loss = 0.93376880\n",
      "Iteration 45, loss = 0.97399647\n",
      "Iteration 46, loss = 0.91630160\n",
      "Iteration 47, loss = 0.97073312\n",
      "Iteration 33, loss = 0.91478285\n",
      "Iteration 34, loss = 0.89205673\n",
      "Iteration 35, loss = 0.95500524\n",
      "Iteration 36, loss = 0.91288700\n",
      "Iteration 37, loss = 0.88618742\n",
      "Iteration 38, loss = 0.97608430\n",
      "Iteration 39, loss = 0.95169630\n",
      "Iteration 40, loss = 0.89252235\n",
      "Iteration 41, loss = 0.91140476\n",
      "Iteration 42, loss = 0.88152895\n",
      "Iteration 43, loss = 1.01214014\n",
      "Iteration 44, loss = 0.93376880\n",
      "Iteration 45, loss = 0.97399647\n",
      "Iteration 46, loss = 0.91630160\n",
      "Iteration 47, loss = 0.97073312\n",
      "Iteration 48, loss = 0.94651354\n",
      "Iteration 49, loss = 0.97385707\n",
      "Iteration 50, loss = 0.86863749\n",
      "Iteration 1, loss = 1.22934699\n",
      "Iteration 2, loss = 1.15496262\n",
      "Iteration 3, loss = 1.04598047\n",
      "Iteration 4, loss = 1.00460128\n",
      "Iteration 5, loss = 1.01021448\n",
      "Iteration 6, loss = 1.08224479\n",
      "Iteration 7, loss = 0.99585466\n",
      "Iteration 8, loss = 1.00169715\n",
      "Iteration 9, loss = 0.99068018\n",
      "Iteration 10, loss = 0.98506475\n",
      "Iteration 48, loss = 0.94651354\n",
      "Iteration 49, loss = 0.97385707\n",
      "Iteration 50, loss = 0.86863749\n",
      "Iteration 1, loss = 1.22934699\n",
      "Iteration 2, loss = 1.15496262\n",
      "Iteration 3, loss = 1.04598047\n",
      "Iteration 4, loss = 1.00460128\n",
      "Iteration 5, loss = 1.01021448\n",
      "Iteration 6, loss = 1.08224479\n",
      "Iteration 7, loss = 0.99585466\n",
      "Iteration 8, loss = 1.00169715\n",
      "Iteration 9, loss = 0.99068018\n",
      "Iteration 10, loss = 0.98506475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.97451740\n",
      "Iteration 12, loss = 0.96085476\n",
      "Iteration 13, loss = 0.96864535\n",
      "Iteration 14, loss = 1.00991397\n",
      "Iteration 15, loss = 0.97919043\n",
      "Iteration 16, loss = 1.08099904\n",
      "Iteration 17, loss = 0.96327954\n",
      "Iteration 18, loss = 1.13210637\n",
      "Iteration 19, loss = 1.09088186\n",
      "Iteration 20, loss = 1.00243285\n",
      "Iteration 21, loss = 0.99454823\n",
      "Iteration 22, loss = 0.96700015\n",
      "Iteration 23, loss = 0.96863057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23641716\n",
      "Iteration 2, loss = 1.24747638\n",
      "Iteration 11, loss = 0.97451740\n",
      "Iteration 12, loss = 0.96085476\n",
      "Iteration 13, loss = 0.96864535\n",
      "Iteration 14, loss = 1.00991397\n",
      "Iteration 15, loss = 0.97919043\n",
      "Iteration 16, loss = 1.08099904\n",
      "Iteration 17, loss = 0.96327954\n",
      "Iteration 18, loss = 1.13210637\n",
      "Iteration 19, loss = 1.09088186\n",
      "Iteration 20, loss = 1.00243285\n",
      "Iteration 21, loss = 0.99454823\n",
      "Iteration 22, loss = 0.96700015\n",
      "Iteration 23, loss = 0.96863057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23641716\n",
      "Iteration 2, loss = 1.24747638\n",
      "Iteration 3, loss = 1.06919900\n",
      "Iteration 4, loss = 0.99251922\n",
      "Iteration 5, loss = 0.98779733\n",
      "Iteration 6, loss = 0.94593574\n",
      "Iteration 7, loss = 0.97160465\n",
      "Iteration 8, loss = 1.01303102\n",
      "Iteration 9, loss = 0.95625681\n",
      "Iteration 10, loss = 0.93262406\n",
      "Iteration 11, loss = 0.96098284\n",
      "Iteration 12, loss = 0.95905992\n",
      "Iteration 13, loss = 0.95132498\n",
      "Iteration 14, loss = 0.93744555\n",
      "Iteration 3, loss = 1.06919900\n",
      "Iteration 4, loss = 0.99251922\n",
      "Iteration 5, loss = 0.98779733\n",
      "Iteration 6, loss = 0.94593574\n",
      "Iteration 7, loss = 0.97160465\n",
      "Iteration 8, loss = 1.01303102\n",
      "Iteration 9, loss = 0.95625681\n",
      "Iteration 10, loss = 0.93262406\n",
      "Iteration 11, loss = 0.96098284\n",
      "Iteration 12, loss = 0.95905992\n",
      "Iteration 13, loss = 0.95132498\n",
      "Iteration 14, loss = 0.93744555\n",
      "Iteration 15, loss = 0.93187265\n",
      "Iteration 16, loss = 1.00108019\n",
      "Iteration 17, loss = 0.93037485\n",
      "Iteration 18, loss = 0.90326481\n",
      "Iteration 19, loss = 0.90096146\n",
      "Iteration 20, loss = 0.90134440\n",
      "Iteration 21, loss = 0.93384739\n",
      "Iteration 22, loss = 0.91194706\n",
      "Iteration 23, loss = 0.91124124\n",
      "Iteration 24, loss = 0.91779342\n",
      "Iteration 25, loss = 0.90720681\n",
      "Iteration 26, loss = 0.92461958\n",
      "Iteration 27, loss = 0.91564540\n",
      "Iteration 28, loss = 0.90450694\n",
      "Iteration 29, loss = 0.90970515\n",
      "Iteration 30, loss = 0.91570767\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.93187265\n",
      "Iteration 16, loss = 1.00108019\n",
      "Iteration 17, loss = 0.93037485\n",
      "Iteration 18, loss = 0.90326481\n",
      "Iteration 19, loss = 0.90096146\n",
      "Iteration 20, loss = 0.90134440\n",
      "Iteration 21, loss = 0.93384739\n",
      "Iteration 22, loss = 0.91194706\n",
      "Iteration 23, loss = 0.91124124\n",
      "Iteration 24, loss = 0.91779342\n",
      "Iteration 25, loss = 0.90720681\n",
      "Iteration 26, loss = 0.92461958\n",
      "Iteration 27, loss = 0.91564540\n",
      "Iteration 28, loss = 0.90450694\n",
      "Iteration 29, loss = 0.90970515\n",
      "Iteration 30, loss = 0.91570767\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24072530\n",
      "Iteration 2, loss = 1.18218135\n",
      "Iteration 3, loss = 1.09249980\n",
      "Iteration 4, loss = 1.01821538\n",
      "Iteration 5, loss = 1.03174172\n",
      "Iteration 6, loss = 1.05929408\n",
      "Iteration 7, loss = 1.08849188\n",
      "Iteration 8, loss = 1.00381706\n",
      "Iteration 9, loss = 0.99004427\n",
      "Iteration 10, loss = 0.98676076\n",
      "Iteration 11, loss = 0.96016802\n",
      "Iteration 12, loss = 0.97068978\n",
      "Iteration 13, loss = 0.97594209\n",
      "Iteration 14, loss = 0.94567269\n",
      "Iteration 15, loss = 0.96794224\n",
      "Iteration 1, loss = 1.24072530\n",
      "Iteration 2, loss = 1.18218135\n",
      "Iteration 3, loss = 1.09249980\n",
      "Iteration 4, loss = 1.01821538\n",
      "Iteration 5, loss = 1.03174172\n",
      "Iteration 6, loss = 1.05929408\n",
      "Iteration 7, loss = 1.08849188\n",
      "Iteration 8, loss = 1.00381706\n",
      "Iteration 9, loss = 0.99004427\n",
      "Iteration 10, loss = 0.98676076\n",
      "Iteration 11, loss = 0.96016802\n",
      "Iteration 12, loss = 0.97068978\n",
      "Iteration 13, loss = 0.97594209\n",
      "Iteration 14, loss = 0.94567269\n",
      "Iteration 15, loss = 0.96794224\n",
      "Iteration 16, loss = 1.00178142\n",
      "Iteration 17, loss = 0.95218122\n",
      "Iteration 18, loss = 0.97545334\n",
      "Iteration 19, loss = 0.96809627\n",
      "Iteration 20, loss = 0.96673775\n",
      "Iteration 21, loss = 0.94437375\n",
      "Iteration 22, loss = 0.95718051\n",
      "Iteration 23, loss = 0.95414313\n",
      "Iteration 24, loss = 0.93416625\n",
      "Iteration 25, loss = 0.98235989\n",
      "Iteration 26, loss = 0.96362442\n",
      "Iteration 27, loss = 0.94148895\n",
      "Iteration 28, loss = 0.96719765\n",
      "Iteration 29, loss = 0.91352953\n",
      "Iteration 30, loss = 0.90243561\n",
      "Iteration 31, loss = 0.99679646\n",
      "Iteration 16, loss = 1.00178142\n",
      "Iteration 17, loss = 0.95218122\n",
      "Iteration 18, loss = 0.97545334\n",
      "Iteration 19, loss = 0.96809627\n",
      "Iteration 20, loss = 0.96673775\n",
      "Iteration 21, loss = 0.94437375\n",
      "Iteration 22, loss = 0.95718051\n",
      "Iteration 23, loss = 0.95414313\n",
      "Iteration 24, loss = 0.93416625\n",
      "Iteration 25, loss = 0.98235989\n",
      "Iteration 26, loss = 0.96362442\n",
      "Iteration 27, loss = 0.94148895\n",
      "Iteration 28, loss = 0.96719765\n",
      "Iteration 29, loss = 0.91352953\n",
      "Iteration 30, loss = 0.90243561\n",
      "Iteration 31, loss = 0.99679646\n",
      "Iteration 32, loss = 0.96026826\n",
      "Iteration 33, loss = 0.92972186\n",
      "Iteration 34, loss = 0.93278064\n",
      "Iteration 35, loss = 0.91713989\n",
      "Iteration 36, loss = 0.95518754\n",
      "Iteration 37, loss = 0.90856707\n",
      "Iteration 38, loss = 0.89648598\n",
      "Iteration 39, loss = 0.96144878\n",
      "Iteration 40, loss = 0.92095254\n",
      "Iteration 41, loss = 0.90619269\n",
      "Iteration 42, loss = 0.91574754\n",
      "Iteration 43, loss = 0.89005418\n",
      "Iteration 44, loss = 0.87776404\n",
      "Iteration 45, loss = 0.93521536\n",
      "Iteration 46, loss = 0.90253883\n",
      "Iteration 32, loss = 0.96026826\n",
      "Iteration 33, loss = 0.92972186\n",
      "Iteration 34, loss = 0.93278064\n",
      "Iteration 35, loss = 0.91713989\n",
      "Iteration 36, loss = 0.95518754\n",
      "Iteration 37, loss = 0.90856707\n",
      "Iteration 38, loss = 0.89648598\n",
      "Iteration 39, loss = 0.96144878\n",
      "Iteration 40, loss = 0.92095254\n",
      "Iteration 41, loss = 0.90619269\n",
      "Iteration 42, loss = 0.91574754\n",
      "Iteration 43, loss = 0.89005418\n",
      "Iteration 44, loss = 0.87776404\n",
      "Iteration 45, loss = 0.93521536\n",
      "Iteration 46, loss = 0.90253883\n",
      "Iteration 47, loss = 0.89131034\n",
      "Iteration 48, loss = 0.89582165\n",
      "Iteration 49, loss = 0.88764475\n",
      "Iteration 50, loss = 0.88570464\n",
      "Iteration 51, loss = 0.89323435\n",
      "Iteration 52, loss = 0.87637338\n",
      "Iteration 53, loss = 0.88935750\n",
      "Iteration 54, loss = 0.88949678\n",
      "Iteration 55, loss = 0.92963045\n",
      "Iteration 56, loss = 0.87514627\n",
      "Iteration 57, loss = 0.87572970\n",
      "Iteration 58, loss = 0.86770484\n",
      "Iteration 59, loss = 0.89785909\n",
      "Iteration 60, loss = 0.90353689\n",
      "Iteration 61, loss = 0.90100869\n",
      "Iteration 47, loss = 0.89131034\n",
      "Iteration 48, loss = 0.89582165\n",
      "Iteration 49, loss = 0.88764475\n",
      "Iteration 50, loss = 0.88570464\n",
      "Iteration 51, loss = 0.89323435\n",
      "Iteration 52, loss = 0.87637338\n",
      "Iteration 53, loss = 0.88935750\n",
      "Iteration 54, loss = 0.88949678\n",
      "Iteration 55, loss = 0.92963045\n",
      "Iteration 56, loss = 0.87514627\n",
      "Iteration 57, loss = 0.87572970\n",
      "Iteration 58, loss = 0.86770484\n",
      "Iteration 59, loss = 0.89785909\n",
      "Iteration 60, loss = 0.90353689\n",
      "Iteration 61, loss = 0.90100869\n",
      "Iteration 62, loss = 0.89011745\n",
      "Iteration 63, loss = 0.87475651\n",
      "Iteration 64, loss = 0.87231475\n",
      "Iteration 65, loss = 0.86980447\n",
      "Iteration 66, loss = 0.89497596\n",
      "Iteration 67, loss = 0.91281438\n",
      "Iteration 68, loss = 0.88876423\n",
      "Iteration 69, loss = 0.84147298\n",
      "Iteration 70, loss = 0.86470999\n",
      "Iteration 71, loss = 0.88233012\n",
      "Iteration 72, loss = 0.86209374\n",
      "Iteration 73, loss = 0.86006846\n",
      "Iteration 74, loss = 0.88646861\n",
      "Iteration 75, loss = 0.85206729\n",
      "Iteration 76, loss = 0.82877109\n",
      "Iteration 77, loss = 0.85294395\n",
      "Iteration 62, loss = 0.89011745\n",
      "Iteration 63, loss = 0.87475651\n",
      "Iteration 64, loss = 0.87231475\n",
      "Iteration 65, loss = 0.86980447\n",
      "Iteration 66, loss = 0.89497596\n",
      "Iteration 67, loss = 0.91281438\n",
      "Iteration 68, loss = 0.88876423\n",
      "Iteration 69, loss = 0.84147298\n",
      "Iteration 70, loss = 0.86470999\n",
      "Iteration 71, loss = 0.88233012\n",
      "Iteration 72, loss = 0.86209374\n",
      "Iteration 73, loss = 0.86006846\n",
      "Iteration 74, loss = 0.88646861\n",
      "Iteration 75, loss = 0.85206729\n",
      "Iteration 76, loss = 0.82877109\n",
      "Iteration 77, loss = 0.85294395\n",
      "Iteration 78, loss = 0.85915254\n",
      "Iteration 79, loss = 0.89770867\n",
      "Iteration 80, loss = 0.85195984\n",
      "Iteration 81, loss = 0.85165744\n",
      "Iteration 82, loss = 0.83961700\n",
      "Iteration 83, loss = 0.87298195\n",
      "Iteration 84, loss = 0.83290916\n",
      "Iteration 85, loss = 0.86627731\n",
      "Iteration 86, loss = 0.83930691\n",
      "Iteration 87, loss = 0.83017234\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23017261\n",
      "Iteration 2, loss = 1.23897143\n",
      "Iteration 3, loss = 1.18566755\n",
      "Iteration 4, loss = 1.15508649\n",
      "Iteration 5, loss = 1.07041698\n",
      "Iteration 78, loss = 0.85915254\n",
      "Iteration 79, loss = 0.89770867\n",
      "Iteration 80, loss = 0.85195984\n",
      "Iteration 81, loss = 0.85165744\n",
      "Iteration 82, loss = 0.83961700\n",
      "Iteration 83, loss = 0.87298195\n",
      "Iteration 84, loss = 0.83290916\n",
      "Iteration 85, loss = 0.86627731\n",
      "Iteration 86, loss = 0.83930691\n",
      "Iteration 87, loss = 0.83017234\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23017261\n",
      "Iteration 2, loss = 1.23897143\n",
      "Iteration 3, loss = 1.18566755\n",
      "Iteration 4, loss = 1.15508649\n",
      "Iteration 5, loss = 1.07041698\n",
      "Iteration 6, loss = 1.03551290\n",
      "Iteration 7, loss = 0.99402759\n",
      "Iteration 8, loss = 1.03733450\n",
      "Iteration 9, loss = 1.01249312\n",
      "Iteration 10, loss = 1.05167387\n",
      "Iteration 11, loss = 1.03209065\n",
      "Iteration 12, loss = 1.00615868\n",
      "Iteration 13, loss = 1.06048388\n",
      "Iteration 14, loss = 0.96759257\n",
      "Iteration 15, loss = 1.08423902\n",
      "Iteration 16, loss = 1.19513938\n",
      "Iteration 17, loss = 1.03500052\n",
      "Iteration 18, loss = 0.99133902\n",
      "Iteration 6, loss = 1.03551290\n",
      "Iteration 7, loss = 0.99402759\n",
      "Iteration 8, loss = 1.03733450\n",
      "Iteration 9, loss = 1.01249312\n",
      "Iteration 10, loss = 1.05167387\n",
      "Iteration 11, loss = 1.03209065\n",
      "Iteration 12, loss = 1.00615868\n",
      "Iteration 13, loss = 1.06048388\n",
      "Iteration 14, loss = 0.96759257\n",
      "Iteration 15, loss = 1.08423902\n",
      "Iteration 16, loss = 1.19513938\n",
      "Iteration 17, loss = 1.03500052\n",
      "Iteration 18, loss = 0.99133902\n",
      "Iteration 19, loss = 1.04100623\n",
      "Iteration 20, loss = 1.00458009\n",
      "Iteration 21, loss = 1.01570147\n",
      "Iteration 22, loss = 1.03192039\n",
      "Iteration 23, loss = 1.01796311\n",
      "Iteration 24, loss = 0.97435302\n",
      "Iteration 25, loss = 0.96510371\n",
      "Iteration 26, loss = 0.94958464\n",
      "Iteration 27, loss = 0.93208792\n",
      "Iteration 28, loss = 1.02058153\n",
      "Iteration 29, loss = 1.00760066\n",
      "Iteration 30, loss = 0.92357684\n",
      "Iteration 31, loss = 0.98100194\n",
      "Iteration 32, loss = 0.91188833\n",
      "Iteration 33, loss = 0.98164593\n",
      "Iteration 19, loss = 1.04100623\n",
      "Iteration 20, loss = 1.00458009\n",
      "Iteration 21, loss = 1.01570147\n",
      "Iteration 22, loss = 1.03192039\n",
      "Iteration 23, loss = 1.01796311\n",
      "Iteration 24, loss = 0.97435302\n",
      "Iteration 25, loss = 0.96510371\n",
      "Iteration 26, loss = 0.94958464\n",
      "Iteration 27, loss = 0.93208792\n",
      "Iteration 28, loss = 1.02058153\n",
      "Iteration 29, loss = 1.00760066\n",
      "Iteration 30, loss = 0.92357684\n",
      "Iteration 31, loss = 0.98100194\n",
      "Iteration 32, loss = 0.91188833\n",
      "Iteration 33, loss = 0.98164593\n",
      "Iteration 34, loss = 0.90800177\n",
      "Iteration 35, loss = 0.91529759\n",
      "Iteration 36, loss = 0.96255467\n",
      "Iteration 37, loss = 0.94412172\n",
      "Iteration 38, loss = 0.91580170\n",
      "Iteration 39, loss = 0.90047078\n",
      "Iteration 40, loss = 0.90990054\n",
      "Iteration 41, loss = 0.90071403\n",
      "Iteration 42, loss = 0.93248080\n",
      "Iteration 43, loss = 0.96658388\n",
      "Iteration 44, loss = 0.90940071\n",
      "Iteration 45, loss = 0.91049757\n",
      "Iteration 46, loss = 0.93541998\n",
      "Iteration 47, loss = 0.89857999\n",
      "Iteration 48, loss = 0.89085208\n",
      "Iteration 49, loss = 0.85764634\n",
      "Iteration 34, loss = 0.90800177\n",
      "Iteration 35, loss = 0.91529759\n",
      "Iteration 36, loss = 0.96255467\n",
      "Iteration 37, loss = 0.94412172\n",
      "Iteration 38, loss = 0.91580170\n",
      "Iteration 39, loss = 0.90047078\n",
      "Iteration 40, loss = 0.90990054\n",
      "Iteration 41, loss = 0.90071403\n",
      "Iteration 42, loss = 0.93248080\n",
      "Iteration 43, loss = 0.96658388\n",
      "Iteration 44, loss = 0.90940071\n",
      "Iteration 45, loss = 0.91049757\n",
      "Iteration 46, loss = 0.93541998\n",
      "Iteration 47, loss = 0.89857999\n",
      "Iteration 48, loss = 0.89085208\n",
      "Iteration 49, loss = 0.85764634\n",
      "Iteration 50, loss = 0.89078152\n",
      "Iteration 51, loss = 0.93719183\n",
      "Iteration 52, loss = 0.89808863\n",
      "Iteration 53, loss = 0.92818316\n",
      "Iteration 54, loss = 0.91842324\n",
      "Iteration 55, loss = 0.92309434\n",
      "Iteration 56, loss = 0.90347141\n",
      "Iteration 57, loss = 0.85112051\n",
      "Iteration 58, loss = 0.95518284\n",
      "Iteration 59, loss = 0.89966121\n",
      "Iteration 60, loss = 0.92598449\n",
      "Iteration 61, loss = 0.87700915\n",
      "Iteration 62, loss = 0.89497977\n",
      "Iteration 63, loss = 0.88782088\n",
      "Iteration 64, loss = 0.82819829\n",
      "Iteration 65, loss = 0.93407886\n",
      "Iteration 50, loss = 0.89078152\n",
      "Iteration 51, loss = 0.93719183\n",
      "Iteration 52, loss = 0.89808863\n",
      "Iteration 53, loss = 0.92818316\n",
      "Iteration 54, loss = 0.91842324\n",
      "Iteration 55, loss = 0.92309434\n",
      "Iteration 56, loss = 0.90347141\n",
      "Iteration 57, loss = 0.85112051\n",
      "Iteration 58, loss = 0.95518284\n",
      "Iteration 59, loss = 0.89966121\n",
      "Iteration 60, loss = 0.92598449\n",
      "Iteration 61, loss = 0.87700915\n",
      "Iteration 62, loss = 0.89497977\n",
      "Iteration 63, loss = 0.88782088\n",
      "Iteration 64, loss = 0.82819829\n",
      "Iteration 65, loss = 0.93407886\n",
      "Iteration 66, loss = 0.91275489\n",
      "Iteration 67, loss = 0.91413143\n",
      "Iteration 68, loss = 0.89526842\n",
      "Iteration 69, loss = 0.88502969\n",
      "Iteration 70, loss = 0.84826728\n",
      "Iteration 71, loss = 0.89434715\n",
      "Iteration 72, loss = 0.88470499\n",
      "Iteration 73, loss = 0.86558164\n",
      "Iteration 74, loss = 0.92923096\n",
      "Iteration 75, loss = 0.90852391\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24700065\n",
      "Iteration 2, loss = 1.17484688\n",
      "Iteration 3, loss = 1.13534065\n",
      "Iteration 4, loss = 1.07154569\n",
      "Iteration 5, loss = 1.07358289\n",
      "Iteration 66, loss = 0.91275489\n",
      "Iteration 67, loss = 0.91413143\n",
      "Iteration 68, loss = 0.89526842\n",
      "Iteration 69, loss = 0.88502969\n",
      "Iteration 70, loss = 0.84826728\n",
      "Iteration 71, loss = 0.89434715\n",
      "Iteration 72, loss = 0.88470499\n",
      "Iteration 73, loss = 0.86558164\n",
      "Iteration 74, loss = 0.92923096\n",
      "Iteration 75, loss = 0.90852391\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24700065\n",
      "Iteration 2, loss = 1.17484688\n",
      "Iteration 3, loss = 1.13534065\n",
      "Iteration 4, loss = 1.07154569\n",
      "Iteration 5, loss = 1.07358289\n",
      "Iteration 6, loss = 1.06077461\n",
      "Iteration 7, loss = 1.00084197\n",
      "Iteration 8, loss = 1.03906894\n",
      "Iteration 9, loss = 0.99021384\n",
      "Iteration 10, loss = 0.98666325\n",
      "Iteration 11, loss = 0.95447152\n",
      "Iteration 12, loss = 1.00829793\n",
      "Iteration 13, loss = 1.01216314\n",
      "Iteration 14, loss = 0.96407888\n",
      "Iteration 15, loss = 0.98602459\n",
      "Iteration 16, loss = 0.97967288\n",
      "Iteration 17, loss = 0.94297643\n",
      "Iteration 18, loss = 0.94861708\n",
      "Iteration 19, loss = 0.92475064\n",
      "Iteration 6, loss = 1.06077461\n",
      "Iteration 7, loss = 1.00084197\n",
      "Iteration 8, loss = 1.03906894\n",
      "Iteration 9, loss = 0.99021384\n",
      "Iteration 10, loss = 0.98666325\n",
      "Iteration 11, loss = 0.95447152\n",
      "Iteration 12, loss = 1.00829793\n",
      "Iteration 13, loss = 1.01216314\n",
      "Iteration 14, loss = 0.96407888\n",
      "Iteration 15, loss = 0.98602459\n",
      "Iteration 16, loss = 0.97967288\n",
      "Iteration 17, loss = 0.94297643\n",
      "Iteration 18, loss = 0.94861708\n",
      "Iteration 19, loss = 0.92475064\n",
      "Iteration 20, loss = 0.89741179\n",
      "Iteration 21, loss = 0.94088899\n",
      "Iteration 22, loss = 0.91824261\n",
      "Iteration 23, loss = 0.95571536\n",
      "Iteration 24, loss = 0.94524396\n",
      "Iteration 25, loss = 0.95050589\n",
      "Iteration 26, loss = 0.96033239\n",
      "Iteration 27, loss = 0.95105963\n",
      "Iteration 28, loss = 0.95486378\n",
      "Iteration 29, loss = 0.90947449\n",
      "Iteration 30, loss = 0.93281039\n",
      "Iteration 31, loss = 0.89445134\n",
      "Iteration 32, loss = 0.93923378\n",
      "Iteration 33, loss = 0.91478285\n",
      "Iteration 34, loss = 0.89205673\n",
      "Iteration 35, loss = 0.95500524\n",
      "Iteration 20, loss = 0.89741179\n",
      "Iteration 21, loss = 0.94088899\n",
      "Iteration 22, loss = 0.91824261\n",
      "Iteration 23, loss = 0.95571536\n",
      "Iteration 24, loss = 0.94524396\n",
      "Iteration 25, loss = 0.95050589\n",
      "Iteration 26, loss = 0.96033239\n",
      "Iteration 27, loss = 0.95105963\n",
      "Iteration 28, loss = 0.95486378\n",
      "Iteration 29, loss = 0.90947449\n",
      "Iteration 30, loss = 0.93281039\n",
      "Iteration 31, loss = 0.89445134\n",
      "Iteration 32, loss = 0.93923378\n",
      "Iteration 33, loss = 0.91478285\n",
      "Iteration 34, loss = 0.89205673\n",
      "Iteration 35, loss = 0.95500524\n",
      "Iteration 36, loss = 0.91288700\n",
      "Iteration 37, loss = 0.88618742\n",
      "Iteration 38, loss = 0.97608430\n",
      "Iteration 39, loss = 0.95169630\n",
      "Iteration 40, loss = 0.89252235\n",
      "Iteration 41, loss = 0.91140476\n",
      "Iteration 42, loss = 0.88152895\n",
      "Iteration 43, loss = 1.01214014\n",
      "Iteration 44, loss = 0.93376880\n",
      "Iteration 45, loss = 0.97399647\n",
      "Iteration 46, loss = 0.91630160\n",
      "Iteration 47, loss = 0.97073312\n",
      "Iteration 48, loss = 0.94651354\n",
      "Iteration 49, loss = 0.97385707\n",
      "Iteration 50, loss = 0.86863749\n",
      "Iteration 36, loss = 0.91288700\n",
      "Iteration 37, loss = 0.88618742\n",
      "Iteration 38, loss = 0.97608430\n",
      "Iteration 39, loss = 0.95169630\n",
      "Iteration 40, loss = 0.89252235\n",
      "Iteration 41, loss = 0.91140476\n",
      "Iteration 42, loss = 0.88152895\n",
      "Iteration 43, loss = 1.01214014\n",
      "Iteration 44, loss = 0.93376880\n",
      "Iteration 45, loss = 0.97399647\n",
      "Iteration 46, loss = 0.91630160\n",
      "Iteration 47, loss = 0.97073312\n",
      "Iteration 48, loss = 0.94651354\n",
      "Iteration 49, loss = 0.97385707\n",
      "Iteration 50, loss = 0.86863749\n",
      "Iteration 51, loss = 0.93565930\n",
      "Iteration 52, loss = 0.87739634\n",
      "Iteration 53, loss = 0.86425232\n",
      "Iteration 54, loss = 0.91174395\n",
      "Iteration 55, loss = 0.88207441\n",
      "Iteration 56, loss = 0.91871583\n",
      "Iteration 57, loss = 0.89906000\n",
      "Iteration 58, loss = 0.87534818\n",
      "Iteration 59, loss = 0.88189411\n",
      "Iteration 60, loss = 0.92753892\n",
      "Iteration 61, loss = 0.87852647\n",
      "Iteration 62, loss = 0.85681174\n",
      "Iteration 63, loss = 0.85509891\n",
      "Iteration 64, loss = 0.88880215\n",
      "Iteration 65, loss = 0.85900647\n",
      "Iteration 51, loss = 0.93565930\n",
      "Iteration 52, loss = 0.87739634\n",
      "Iteration 53, loss = 0.86425232\n",
      "Iteration 54, loss = 0.91174395\n",
      "Iteration 55, loss = 0.88207441\n",
      "Iteration 56, loss = 0.91871583\n",
      "Iteration 57, loss = 0.89906000\n",
      "Iteration 58, loss = 0.87534818\n",
      "Iteration 59, loss = 0.88189411\n",
      "Iteration 60, loss = 0.92753892\n",
      "Iteration 61, loss = 0.87852647\n",
      "Iteration 62, loss = 0.85681174\n",
      "Iteration 63, loss = 0.85509891\n",
      "Iteration 64, loss = 0.88880215\n",
      "Iteration 65, loss = 0.85900647\n",
      "Iteration 66, loss = 0.87364675\n",
      "Iteration 67, loss = 0.91705584\n",
      "Iteration 68, loss = 0.84780896\n",
      "Iteration 69, loss = 0.91158713\n",
      "Iteration 70, loss = 0.92414879\n",
      "Iteration 71, loss = 0.88485248\n",
      "Iteration 72, loss = 0.96961955\n",
      "Iteration 73, loss = 0.90812876\n",
      "Iteration 74, loss = 0.92503438\n",
      "Iteration 75, loss = 0.92434389\n",
      "Iteration 76, loss = 0.93777931\n",
      "Iteration 77, loss = 0.92932966\n",
      "Iteration 78, loss = 0.97440000\n",
      "Iteration 79, loss = 0.89986826\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27047091\n",
      "Iteration 66, loss = 0.87364675\n",
      "Iteration 67, loss = 0.91705584\n",
      "Iteration 68, loss = 0.84780896\n",
      "Iteration 69, loss = 0.91158713\n",
      "Iteration 70, loss = 0.92414879\n",
      "Iteration 71, loss = 0.88485248\n",
      "Iteration 72, loss = 0.96961955\n",
      "Iteration 73, loss = 0.90812876\n",
      "Iteration 74, loss = 0.92503438\n",
      "Iteration 75, loss = 0.92434389\n",
      "Iteration 76, loss = 0.93777931\n",
      "Iteration 77, loss = 0.92932966\n",
      "Iteration 78, loss = 0.97440000\n",
      "Iteration 79, loss = 0.89986826\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27047091\n",
      "Iteration 2, loss = 1.22843211\n",
      "Iteration 3, loss = 1.11611055\n",
      "Iteration 4, loss = 1.03618794\n",
      "Iteration 5, loss = 1.06831401\n",
      "Iteration 6, loss = 1.16562633\n",
      "Iteration 7, loss = 1.16105739\n",
      "Iteration 8, loss = 1.17096163\n",
      "Iteration 9, loss = 1.10546755\n",
      "Iteration 10, loss = 1.03522009\n",
      "Iteration 1, loss = 1.24719889\n",
      "Iteration 2, loss = 1.18506028\n",
      "Iteration 3, loss = 1.07789091\n",
      "Iteration 4, loss = 1.01062703\n",
      "Iteration 5, loss = 1.06369158\n",
      "Iteration 2, loss = 1.22843211\n",
      "Iteration 3, loss = 1.11611055\n",
      "Iteration 4, loss = 1.03618794\n",
      "Iteration 5, loss = 1.06831401\n",
      "Iteration 6, loss = 1.16562633\n",
      "Iteration 7, loss = 1.16105739\n",
      "Iteration 8, loss = 1.17096163\n",
      "Iteration 9, loss = 1.10546755\n",
      "Iteration 10, loss = 1.03522009\n",
      "Iteration 1, loss = 1.24719889\n",
      "Iteration 2, loss = 1.18506028\n",
      "Iteration 3, loss = 1.07789091\n",
      "Iteration 4, loss = 1.01062703\n",
      "Iteration 5, loss = 1.06369158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.02113691\n",
      "Iteration 7, loss = 0.97434321\n",
      "Iteration 8, loss = 1.02877057\n",
      "Iteration 9, loss = 0.94928444\n",
      "Iteration 10, loss = 0.93541607\n",
      "Iteration 1, loss = 1.25175571\n",
      "Iteration 2, loss = 1.27264966\n",
      "Iteration 3, loss = 1.26633507\n",
      "Iteration 4, loss = 1.27159052\n",
      "Iteration 5, loss = 1.26459982\n",
      "Iteration 6, loss = 1.25331734\n",
      "Iteration 7, loss = 1.25662939\n",
      "Iteration 8, loss = 1.25477176\n",
      "Iteration 6, loss = 1.02113691\n",
      "Iteration 7, loss = 0.97434321\n",
      "Iteration 8, loss = 1.02877057\n",
      "Iteration 9, loss = 0.94928444\n",
      "Iteration 10, loss = 0.93541607\n",
      "Iteration 1, loss = 1.25175571\n",
      "Iteration 2, loss = 1.27264966\n",
      "Iteration 3, loss = 1.26633507\n",
      "Iteration 4, loss = 1.27159052\n",
      "Iteration 5, loss = 1.26459982\n",
      "Iteration 6, loss = 1.25331734\n",
      "Iteration 7, loss = 1.25662939\n",
      "Iteration 8, loss = 1.25477176\n",
      "Iteration 9, loss = 1.26087636\n",
      "Iteration 10, loss = 1.25440386\n",
      "Iteration 1, loss = 1.21674817\n",
      "Iteration 2, loss = 1.22594418\n",
      "Iteration 3, loss = 1.18980626\n",
      "Iteration 4, loss = 1.18398750\n",
      "Iteration 5, loss = 1.10301864\n",
      "Iteration 6, loss = 1.05005192\n",
      "Iteration 7, loss = 1.05964813\n",
      "Iteration 8, loss = 1.13162188\n",
      "Iteration 9, loss = 1.16121585\n",
      "Iteration 10, loss = 1.09376044\n",
      "Iteration 1, loss = 1.25081727\n",
      "Iteration 2, loss = 1.16497603\n",
      "Iteration 9, loss = 1.26087636\n",
      "Iteration 10, loss = 1.25440386\n",
      "Iteration 1, loss = 1.21674817\n",
      "Iteration 2, loss = 1.22594418\n",
      "Iteration 3, loss = 1.18980626\n",
      "Iteration 4, loss = 1.18398750\n",
      "Iteration 5, loss = 1.10301864\n",
      "Iteration 6, loss = 1.05005192\n",
      "Iteration 7, loss = 1.05964813\n",
      "Iteration 8, loss = 1.13162188\n",
      "Iteration 9, loss = 1.16121585\n",
      "Iteration 10, loss = 1.09376044\n",
      "Iteration 1, loss = 1.25081727\n",
      "Iteration 2, loss = 1.16497603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.29322893\n",
      "Iteration 4, loss = 1.25710500\n",
      "Iteration 5, loss = 1.18850427\n",
      "Iteration 6, loss = 1.18690581\n",
      "Iteration 7, loss = 1.26253968\n",
      "Iteration 8, loss = 1.26214672\n",
      "Iteration 9, loss = 1.26489421\n",
      "Iteration 10, loss = 1.28092457\n",
      "Iteration 1, loss = 1.27047091\n",
      "Iteration 2, loss = 1.22843211\n",
      "Iteration 3, loss = 1.11611055\n",
      "Iteration 4, loss = 1.03618794\n",
      "Iteration 5, loss = 1.06831401\n",
      "Iteration 6, loss = 1.16562633\n",
      "Iteration 3, loss = 1.29322893\n",
      "Iteration 4, loss = 1.25710500\n",
      "Iteration 5, loss = 1.18850427\n",
      "Iteration 6, loss = 1.18690581\n",
      "Iteration 7, loss = 1.26253968\n",
      "Iteration 8, loss = 1.26214672\n",
      "Iteration 9, loss = 1.26489421\n",
      "Iteration 10, loss = 1.28092457\n",
      "Iteration 1, loss = 1.27047091\n",
      "Iteration 2, loss = 1.22843211\n",
      "Iteration 3, loss = 1.11611055\n",
      "Iteration 4, loss = 1.03618794\n",
      "Iteration 5, loss = 1.06831401\n",
      "Iteration 6, loss = 1.16562633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.16105739\n",
      "Iteration 8, loss = 1.17096163\n",
      "Iteration 9, loss = 1.10546755\n",
      "Iteration 10, loss = 1.03522009\n",
      "Iteration 11, loss = 1.01228294\n",
      "Iteration 12, loss = 0.98745216\n",
      "Iteration 13, loss = 1.04232699\n",
      "Iteration 14, loss = 1.01902671\n",
      "Iteration 15, loss = 1.26521157\n",
      "Iteration 16, loss = 1.24730328\n",
      "Iteration 17, loss = 1.24519138\n",
      "Iteration 18, loss = 1.24194556\n",
      "Iteration 19, loss = 1.24765539\n",
      "Iteration 20, loss = 1.27150548\n",
      "Iteration 7, loss = 1.16105739\n",
      "Iteration 8, loss = 1.17096163\n",
      "Iteration 9, loss = 1.10546755\n",
      "Iteration 10, loss = 1.03522009\n",
      "Iteration 11, loss = 1.01228294\n",
      "Iteration 12, loss = 0.98745216\n",
      "Iteration 13, loss = 1.04232699\n",
      "Iteration 14, loss = 1.01902671\n",
      "Iteration 15, loss = 1.26521157\n",
      "Iteration 16, loss = 1.24730328\n",
      "Iteration 17, loss = 1.24519138\n",
      "Iteration 18, loss = 1.24194556\n",
      "Iteration 19, loss = 1.24765539\n",
      "Iteration 20, loss = 1.27150548\n",
      "Iteration 21, loss = 1.25633055\n",
      "Iteration 22, loss = 1.24481945\n",
      "Iteration 23, loss = 1.23980200\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24719889\n",
      "Iteration 2, loss = 1.18506028\n",
      "Iteration 3, loss = 1.07789091\n",
      "Iteration 4, loss = 1.01062703\n",
      "Iteration 5, loss = 1.06369158\n",
      "Iteration 6, loss = 1.02113691\n",
      "Iteration 7, loss = 0.97434321\n",
      "Iteration 8, loss = 1.02877057\n",
      "Iteration 9, loss = 0.94928444\n",
      "Iteration 10, loss = 0.93541607\n",
      "Iteration 21, loss = 1.25633055\n",
      "Iteration 22, loss = 1.24481945\n",
      "Iteration 23, loss = 1.23980200\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24719889\n",
      "Iteration 2, loss = 1.18506028\n",
      "Iteration 3, loss = 1.07789091\n",
      "Iteration 4, loss = 1.01062703\n",
      "Iteration 5, loss = 1.06369158\n",
      "Iteration 6, loss = 1.02113691\n",
      "Iteration 7, loss = 0.97434321\n",
      "Iteration 8, loss = 1.02877057\n",
      "Iteration 9, loss = 0.94928444\n",
      "Iteration 10, loss = 0.93541607\n",
      "Iteration 11, loss = 0.94313746\n",
      "Iteration 12, loss = 0.93242954\n",
      "Iteration 13, loss = 0.99012424\n",
      "Iteration 14, loss = 1.00588343\n",
      "Iteration 15, loss = 0.96487115\n",
      "Iteration 16, loss = 0.94335062\n",
      "Iteration 17, loss = 0.96841352\n",
      "Iteration 18, loss = 0.94826705\n",
      "Iteration 19, loss = 0.91898836\n",
      "Iteration 20, loss = 0.93546402\n",
      "Iteration 21, loss = 0.92936774\n",
      "Iteration 22, loss = 0.92889652\n",
      "Iteration 23, loss = 0.96238953\n",
      "Iteration 24, loss = 0.92666236\n",
      "Iteration 25, loss = 0.94630294\n",
      "Iteration 11, loss = 0.94313746\n",
      "Iteration 12, loss = 0.93242954\n",
      "Iteration 13, loss = 0.99012424\n",
      "Iteration 14, loss = 1.00588343\n",
      "Iteration 15, loss = 0.96487115\n",
      "Iteration 16, loss = 0.94335062\n",
      "Iteration 17, loss = 0.96841352\n",
      "Iteration 18, loss = 0.94826705\n",
      "Iteration 19, loss = 0.91898836\n",
      "Iteration 20, loss = 0.93546402\n",
      "Iteration 21, loss = 0.92936774\n",
      "Iteration 22, loss = 0.92889652\n",
      "Iteration 23, loss = 0.96238953\n",
      "Iteration 24, loss = 0.92666236\n",
      "Iteration 25, loss = 0.94630294\n",
      "Iteration 26, loss = 0.95750738\n",
      "Iteration 27, loss = 0.92924021\n",
      "Iteration 28, loss = 0.97250978\n",
      "Iteration 29, loss = 0.93404613\n",
      "Iteration 30, loss = 0.94854401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25175571\n",
      "Iteration 2, loss = 1.27264966\n",
      "Iteration 3, loss = 1.26633507\n",
      "Iteration 4, loss = 1.27159052\n",
      "Iteration 5, loss = 1.26459982\n",
      "Iteration 6, loss = 1.25331734\n",
      "Iteration 7, loss = 1.25662939\n",
      "Iteration 8, loss = 1.25477176\n",
      "Iteration 26, loss = 0.95750738\n",
      "Iteration 27, loss = 0.92924021\n",
      "Iteration 28, loss = 0.97250978\n",
      "Iteration 29, loss = 0.93404613\n",
      "Iteration 30, loss = 0.94854401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25175571\n",
      "Iteration 2, loss = 1.27264966\n",
      "Iteration 3, loss = 1.26633507\n",
      "Iteration 4, loss = 1.27159052\n",
      "Iteration 5, loss = 1.26459982\n",
      "Iteration 6, loss = 1.25331734\n",
      "Iteration 7, loss = 1.25662939\n",
      "Iteration 8, loss = 1.25477176\n",
      "Iteration 9, loss = 1.26087636\n",
      "Iteration 10, loss = 1.25440386\n",
      "Iteration 11, loss = 1.25117936\n",
      "Iteration 12, loss = 1.25185301\n",
      "Iteration 13, loss = 1.28632078\n",
      "Iteration 14, loss = 1.25533752\n",
      "Iteration 15, loss = 1.26343409\n",
      "Iteration 16, loss = 1.25327532\n",
      "Iteration 17, loss = 1.26527509\n",
      "Iteration 18, loss = 1.25517576\n",
      "Iteration 19, loss = 1.25928188\n",
      "Iteration 20, loss = 1.30275046\n",
      "Iteration 21, loss = 1.26012992\n",
      "Iteration 22, loss = 1.25646654\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21674817\n",
      "Iteration 9, loss = 1.26087636\n",
      "Iteration 10, loss = 1.25440386\n",
      "Iteration 11, loss = 1.25117936\n",
      "Iteration 12, loss = 1.25185301\n",
      "Iteration 13, loss = 1.28632078\n",
      "Iteration 14, loss = 1.25533752\n",
      "Iteration 15, loss = 1.26343409\n",
      "Iteration 16, loss = 1.25327532\n",
      "Iteration 17, loss = 1.26527509\n",
      "Iteration 18, loss = 1.25517576\n",
      "Iteration 19, loss = 1.25928188\n",
      "Iteration 20, loss = 1.30275046\n",
      "Iteration 21, loss = 1.26012992\n",
      "Iteration 22, loss = 1.25646654\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21674817\n",
      "Iteration 2, loss = 1.22594418\n",
      "Iteration 3, loss = 1.18980626\n",
      "Iteration 4, loss = 1.18398750\n",
      "Iteration 5, loss = 1.10301864\n",
      "Iteration 6, loss = 1.05005192\n",
      "Iteration 7, loss = 1.05964813\n",
      "Iteration 8, loss = 1.13162188\n",
      "Iteration 9, loss = 1.16121585\n",
      "Iteration 10, loss = 1.09376044\n",
      "Iteration 11, loss = 1.05847196\n",
      "Iteration 12, loss = 1.08277469\n",
      "Iteration 13, loss = 1.11730862\n",
      "Iteration 14, loss = 1.03332662\n",
      "Iteration 15, loss = 1.04892851\n",
      "Iteration 16, loss = 1.03658023\n",
      "Iteration 2, loss = 1.22594418\n",
      "Iteration 3, loss = 1.18980626\n",
      "Iteration 4, loss = 1.18398750\n",
      "Iteration 5, loss = 1.10301864\n",
      "Iteration 6, loss = 1.05005192\n",
      "Iteration 7, loss = 1.05964813\n",
      "Iteration 8, loss = 1.13162188\n",
      "Iteration 9, loss = 1.16121585\n",
      "Iteration 10, loss = 1.09376044\n",
      "Iteration 11, loss = 1.05847196\n",
      "Iteration 12, loss = 1.08277469\n",
      "Iteration 13, loss = 1.11730862\n",
      "Iteration 14, loss = 1.03332662\n",
      "Iteration 15, loss = 1.04892851\n",
      "Iteration 16, loss = 1.03658023\n",
      "Iteration 17, loss = 1.02106505\n",
      "Iteration 18, loss = 1.08787726\n",
      "Iteration 19, loss = 1.05172270\n",
      "Iteration 20, loss = 1.03276491\n",
      "Iteration 21, loss = 0.99198140\n",
      "Iteration 22, loss = 1.07650277\n",
      "Iteration 23, loss = 1.09321093\n",
      "Iteration 24, loss = 1.05134956\n",
      "Iteration 25, loss = 1.01984694\n",
      "Iteration 26, loss = 1.02531013\n",
      "Iteration 27, loss = 1.08668266\n",
      "Iteration 28, loss = 1.25259463\n",
      "Iteration 29, loss = 1.23355416\n",
      "Iteration 30, loss = 1.20647520\n",
      "Iteration 31, loss = 1.11836375\n",
      "Iteration 17, loss = 1.02106505\n",
      "Iteration 18, loss = 1.08787726\n",
      "Iteration 19, loss = 1.05172270\n",
      "Iteration 20, loss = 1.03276491\n",
      "Iteration 21, loss = 0.99198140\n",
      "Iteration 22, loss = 1.07650277\n",
      "Iteration 23, loss = 1.09321093\n",
      "Iteration 24, loss = 1.05134956\n",
      "Iteration 25, loss = 1.01984694\n",
      "Iteration 26, loss = 1.02531013\n",
      "Iteration 27, loss = 1.08668266\n",
      "Iteration 28, loss = 1.25259463\n",
      "Iteration 29, loss = 1.23355416\n",
      "Iteration 30, loss = 1.20647520\n",
      "Iteration 31, loss = 1.11836375\n",
      "Iteration 32, loss = 1.09985796\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25081727\n",
      "Iteration 2, loss = 1.16497603\n",
      "Iteration 3, loss = 1.29322893\n",
      "Iteration 4, loss = 1.25710500\n",
      "Iteration 5, loss = 1.18850427\n",
      "Iteration 6, loss = 1.18690581\n",
      "Iteration 7, loss = 1.26253968\n",
      "Iteration 8, loss = 1.26214672\n",
      "Iteration 9, loss = 1.26489421\n",
      "Iteration 10, loss = 1.28092457\n",
      "Iteration 11, loss = 1.27235322\n",
      "Iteration 12, loss = 1.27333661\n",
      "Iteration 13, loss = 1.26756263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 1.09985796\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25081727\n",
      "Iteration 2, loss = 1.16497603\n",
      "Iteration 3, loss = 1.29322893\n",
      "Iteration 4, loss = 1.25710500\n",
      "Iteration 5, loss = 1.18850427\n",
      "Iteration 6, loss = 1.18690581\n",
      "Iteration 7, loss = 1.26253968\n",
      "Iteration 8, loss = 1.26214672\n",
      "Iteration 9, loss = 1.26489421\n",
      "Iteration 10, loss = 1.28092457\n",
      "Iteration 11, loss = 1.27235322\n",
      "Iteration 12, loss = 1.27333661\n",
      "Iteration 13, loss = 1.26756263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27047091\n",
      "Iteration 2, loss = 1.22843211\n",
      "Iteration 3, loss = 1.11611055\n",
      "Iteration 4, loss = 1.03618794\n",
      "Iteration 5, loss = 1.06831401\n",
      "Iteration 6, loss = 1.16562633\n",
      "Iteration 7, loss = 1.16105739\n",
      "Iteration 8, loss = 1.17096163\n",
      "Iteration 9, loss = 1.10546755\n",
      "Iteration 10, loss = 1.03522009\n",
      "Iteration 11, loss = 1.01228294\n",
      "Iteration 12, loss = 0.98745216\n",
      "Iteration 13, loss = 1.04232699\n",
      "Iteration 1, loss = 1.27047091\n",
      "Iteration 2, loss = 1.22843211\n",
      "Iteration 3, loss = 1.11611055\n",
      "Iteration 4, loss = 1.03618794\n",
      "Iteration 5, loss = 1.06831401\n",
      "Iteration 6, loss = 1.16562633\n",
      "Iteration 7, loss = 1.16105739\n",
      "Iteration 8, loss = 1.17096163\n",
      "Iteration 9, loss = 1.10546755\n",
      "Iteration 10, loss = 1.03522009\n",
      "Iteration 11, loss = 1.01228294\n",
      "Iteration 12, loss = 0.98745216\n",
      "Iteration 13, loss = 1.04232699\n",
      "Iteration 14, loss = 1.01902671\n",
      "Iteration 15, loss = 1.26521157\n",
      "Iteration 16, loss = 1.24730328\n",
      "Iteration 17, loss = 1.24519138\n",
      "Iteration 18, loss = 1.24194556\n",
      "Iteration 19, loss = 1.24765539\n",
      "Iteration 20, loss = 1.27150548\n",
      "Iteration 21, loss = 1.25633055\n",
      "Iteration 22, loss = 1.24481945\n",
      "Iteration 23, loss = 1.23980200\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24719889\n",
      "Iteration 2, loss = 1.18506028\n",
      "Iteration 3, loss = 1.07789091\n",
      "Iteration 4, loss = 1.01062703\n",
      "Iteration 14, loss = 1.01902671\n",
      "Iteration 15, loss = 1.26521157\n",
      "Iteration 16, loss = 1.24730328\n",
      "Iteration 17, loss = 1.24519138\n",
      "Iteration 18, loss = 1.24194556\n",
      "Iteration 19, loss = 1.24765539\n",
      "Iteration 20, loss = 1.27150548\n",
      "Iteration 21, loss = 1.25633055\n",
      "Iteration 22, loss = 1.24481945\n",
      "Iteration 23, loss = 1.23980200\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24719889\n",
      "Iteration 2, loss = 1.18506028\n",
      "Iteration 3, loss = 1.07789091\n",
      "Iteration 4, loss = 1.01062703\n",
      "Iteration 5, loss = 1.06369158\n",
      "Iteration 6, loss = 1.02113691\n",
      "Iteration 7, loss = 0.97434321\n",
      "Iteration 8, loss = 1.02877057\n",
      "Iteration 9, loss = 0.94928444\n",
      "Iteration 10, loss = 0.93541607\n",
      "Iteration 11, loss = 0.94313746\n",
      "Iteration 12, loss = 0.93242954\n",
      "Iteration 13, loss = 0.99012424\n",
      "Iteration 14, loss = 1.00588343\n",
      "Iteration 15, loss = 0.96487115\n",
      "Iteration 16, loss = 0.94335062\n",
      "Iteration 17, loss = 0.96841352\n",
      "Iteration 18, loss = 0.94826705\n",
      "Iteration 19, loss = 0.91898836\n",
      "Iteration 5, loss = 1.06369158\n",
      "Iteration 6, loss = 1.02113691\n",
      "Iteration 7, loss = 0.97434321\n",
      "Iteration 8, loss = 1.02877057\n",
      "Iteration 9, loss = 0.94928444\n",
      "Iteration 10, loss = 0.93541607\n",
      "Iteration 11, loss = 0.94313746\n",
      "Iteration 12, loss = 0.93242954\n",
      "Iteration 13, loss = 0.99012424\n",
      "Iteration 14, loss = 1.00588343\n",
      "Iteration 15, loss = 0.96487115\n",
      "Iteration 16, loss = 0.94335062\n",
      "Iteration 17, loss = 0.96841352\n",
      "Iteration 18, loss = 0.94826705\n",
      "Iteration 19, loss = 0.91898836\n",
      "Iteration 20, loss = 0.93546402\n",
      "Iteration 21, loss = 0.92936774\n",
      "Iteration 22, loss = 0.92889652\n",
      "Iteration 23, loss = 0.96238953\n",
      "Iteration 24, loss = 0.92666236\n",
      "Iteration 25, loss = 0.94630294\n",
      "Iteration 26, loss = 0.95750738\n",
      "Iteration 27, loss = 0.92924021\n",
      "Iteration 28, loss = 0.97250978\n",
      "Iteration 29, loss = 0.93404613\n",
      "Iteration 30, loss = 0.94854401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25175571\n",
      "Iteration 2, loss = 1.27264966\n",
      "Iteration 3, loss = 1.26633507\n",
      "Iteration 4, loss = 1.27159052\n",
      "Iteration 20, loss = 0.93546402\n",
      "Iteration 21, loss = 0.92936774\n",
      "Iteration 22, loss = 0.92889652\n",
      "Iteration 23, loss = 0.96238953\n",
      "Iteration 24, loss = 0.92666236\n",
      "Iteration 25, loss = 0.94630294\n",
      "Iteration 26, loss = 0.95750738\n",
      "Iteration 27, loss = 0.92924021\n",
      "Iteration 28, loss = 0.97250978\n",
      "Iteration 29, loss = 0.93404613\n",
      "Iteration 30, loss = 0.94854401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25175571\n",
      "Iteration 2, loss = 1.27264966\n",
      "Iteration 3, loss = 1.26633507\n",
      "Iteration 4, loss = 1.27159052\n",
      "Iteration 5, loss = 1.26459982\n",
      "Iteration 6, loss = 1.25331734\n",
      "Iteration 7, loss = 1.25662939\n",
      "Iteration 8, loss = 1.25477176\n",
      "Iteration 9, loss = 1.26087636\n",
      "Iteration 10, loss = 1.25440386\n",
      "Iteration 11, loss = 1.25117936\n",
      "Iteration 12, loss = 1.25185301\n",
      "Iteration 13, loss = 1.28632078\n",
      "Iteration 14, loss = 1.25533752\n",
      "Iteration 15, loss = 1.26343409\n",
      "Iteration 16, loss = 1.25327532\n",
      "Iteration 17, loss = 1.26527509\n",
      "Iteration 18, loss = 1.25517576\n",
      "Iteration 19, loss = 1.25928188\n",
      "Iteration 5, loss = 1.26459982\n",
      "Iteration 6, loss = 1.25331734\n",
      "Iteration 7, loss = 1.25662939\n",
      "Iteration 8, loss = 1.25477176\n",
      "Iteration 9, loss = 1.26087636\n",
      "Iteration 10, loss = 1.25440386\n",
      "Iteration 11, loss = 1.25117936\n",
      "Iteration 12, loss = 1.25185301\n",
      "Iteration 13, loss = 1.28632078\n",
      "Iteration 14, loss = 1.25533752\n",
      "Iteration 15, loss = 1.26343409\n",
      "Iteration 16, loss = 1.25327532\n",
      "Iteration 17, loss = 1.26527509\n",
      "Iteration 18, loss = 1.25517576\n",
      "Iteration 19, loss = 1.25928188\n",
      "Iteration 20, loss = 1.30275046\n",
      "Iteration 21, loss = 1.26012992\n",
      "Iteration 22, loss = 1.25646654\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21674817\n",
      "Iteration 2, loss = 1.22594418\n",
      "Iteration 3, loss = 1.18980626\n",
      "Iteration 4, loss = 1.18398750\n",
      "Iteration 5, loss = 1.10301864\n",
      "Iteration 6, loss = 1.05005192\n",
      "Iteration 7, loss = 1.05964813\n",
      "Iteration 8, loss = 1.13162188\n",
      "Iteration 9, loss = 1.16121585\n",
      "Iteration 10, loss = 1.09376044\n",
      "Iteration 11, loss = 1.05847196\n",
      "Iteration 12, loss = 1.08277469\n",
      "Iteration 20, loss = 1.30275046\n",
      "Iteration 21, loss = 1.26012992\n",
      "Iteration 22, loss = 1.25646654\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21674817\n",
      "Iteration 2, loss = 1.22594418\n",
      "Iteration 3, loss = 1.18980626\n",
      "Iteration 4, loss = 1.18398750\n",
      "Iteration 5, loss = 1.10301864\n",
      "Iteration 6, loss = 1.05005192\n",
      "Iteration 7, loss = 1.05964813\n",
      "Iteration 8, loss = 1.13162188\n",
      "Iteration 9, loss = 1.16121585\n",
      "Iteration 10, loss = 1.09376044\n",
      "Iteration 11, loss = 1.05847196\n",
      "Iteration 12, loss = 1.08277469\n",
      "Iteration 13, loss = 1.11730862\n",
      "Iteration 14, loss = 1.03332662\n",
      "Iteration 15, loss = 1.04892851\n",
      "Iteration 16, loss = 1.03658023\n",
      "Iteration 17, loss = 1.02106505\n",
      "Iteration 18, loss = 1.08787726\n",
      "Iteration 19, loss = 1.05172270\n",
      "Iteration 20, loss = 1.03276491\n",
      "Iteration 21, loss = 0.99198140\n",
      "Iteration 22, loss = 1.07650277\n",
      "Iteration 23, loss = 1.09321093\n",
      "Iteration 24, loss = 1.05134956\n",
      "Iteration 25, loss = 1.01984694\n",
      "Iteration 26, loss = 1.02531013\n",
      "Iteration 27, loss = 1.08668266\n",
      "Iteration 13, loss = 1.11730862\n",
      "Iteration 14, loss = 1.03332662\n",
      "Iteration 15, loss = 1.04892851\n",
      "Iteration 16, loss = 1.03658023\n",
      "Iteration 17, loss = 1.02106505\n",
      "Iteration 18, loss = 1.08787726\n",
      "Iteration 19, loss = 1.05172270\n",
      "Iteration 20, loss = 1.03276491\n",
      "Iteration 21, loss = 0.99198140\n",
      "Iteration 22, loss = 1.07650277\n",
      "Iteration 23, loss = 1.09321093\n",
      "Iteration 24, loss = 1.05134956\n",
      "Iteration 25, loss = 1.01984694\n",
      "Iteration 26, loss = 1.02531013\n",
      "Iteration 27, loss = 1.08668266\n",
      "Iteration 28, loss = 1.25259463\n",
      "Iteration 29, loss = 1.23355416\n",
      "Iteration 30, loss = 1.20647520\n",
      "Iteration 31, loss = 1.11836375\n",
      "Iteration 32, loss = 1.09985796\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25081727\n",
      "Iteration 2, loss = 1.16497603\n",
      "Iteration 3, loss = 1.29322893\n",
      "Iteration 4, loss = 1.25710500\n",
      "Iteration 5, loss = 1.18850427\n",
      "Iteration 6, loss = 1.18690581\n",
      "Iteration 7, loss = 1.26253968\n",
      "Iteration 8, loss = 1.26214672\n",
      "Iteration 9, loss = 1.26489421\n",
      "Iteration 28, loss = 1.25259463\n",
      "Iteration 29, loss = 1.23355416\n",
      "Iteration 30, loss = 1.20647520\n",
      "Iteration 31, loss = 1.11836375\n",
      "Iteration 32, loss = 1.09985796\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25081727\n",
      "Iteration 2, loss = 1.16497603\n",
      "Iteration 3, loss = 1.29322893\n",
      "Iteration 4, loss = 1.25710500\n",
      "Iteration 5, loss = 1.18850427\n",
      "Iteration 6, loss = 1.18690581\n",
      "Iteration 7, loss = 1.26253968\n",
      "Iteration 8, loss = 1.26214672\n",
      "Iteration 9, loss = 1.26489421\n",
      "Iteration 10, loss = 1.28092457\n",
      "Iteration 11, loss = 1.27235322\n",
      "Iteration 12, loss = 1.27333661\n",
      "Iteration 13, loss = 1.26756263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29404312\n",
      "Iteration 2, loss = 1.24533904\n",
      "Iteration 3, loss = 1.24730037\n",
      "Iteration 4, loss = 1.25059402\n",
      "Iteration 5, loss = 1.25762259\n",
      "Iteration 6, loss = 1.22288999\n",
      "Iteration 7, loss = 1.10817901\n",
      "Iteration 8, loss = 1.10329139\n",
      "Iteration 9, loss = 1.13507044\n",
      "Iteration 10, loss = 1.28092457\n",
      "Iteration 11, loss = 1.27235322\n",
      "Iteration 12, loss = 1.27333661\n",
      "Iteration 13, loss = 1.26756263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29404312\n",
      "Iteration 2, loss = 1.24533904\n",
      "Iteration 3, loss = 1.24730037\n",
      "Iteration 4, loss = 1.25059402\n",
      "Iteration 5, loss = 1.25762259\n",
      "Iteration 6, loss = 1.22288999\n",
      "Iteration 7, loss = 1.10817901\n",
      "Iteration 8, loss = 1.10329139\n",
      "Iteration 9, loss = 1.13507044\n",
      "Iteration 10, loss = 1.24594354\n",
      "Iteration 1, loss = 1.20849233\n",
      "Iteration 2, loss = 1.22076401\n",
      "Iteration 3, loss = 1.14290884\n",
      "Iteration 4, loss = 1.10840360\n",
      "Iteration 5, loss = 1.05010002\n",
      "Iteration 6, loss = 1.33770218\n",
      "Iteration 7, loss = 1.24591397\n",
      "Iteration 8, loss = 1.25961457\n",
      "Iteration 9, loss = 1.26369272\n",
      "Iteration 10, loss = 1.24296710\n",
      "Iteration 1, loss = 1.24427062\n",
      "Iteration 2, loss = 1.16732459\n",
      "Iteration 3, loss = 1.33030060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.24594354\n",
      "Iteration 1, loss = 1.20849233\n",
      "Iteration 2, loss = 1.22076401\n",
      "Iteration 3, loss = 1.14290884\n",
      "Iteration 4, loss = 1.10840360\n",
      "Iteration 5, loss = 1.05010002\n",
      "Iteration 6, loss = 1.33770218\n",
      "Iteration 7, loss = 1.24591397\n",
      "Iteration 8, loss = 1.25961457\n",
      "Iteration 9, loss = 1.26369272\n",
      "Iteration 10, loss = 1.24296710\n",
      "Iteration 1, loss = 1.24427062\n",
      "Iteration 2, loss = 1.16732459\n",
      "Iteration 3, loss = 1.33030060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.28308553\n",
      "Iteration 5, loss = 1.26811913\n",
      "Iteration 6, loss = 1.25545435\n",
      "Iteration 7, loss = 1.26778023\n",
      "Iteration 8, loss = 1.25997204\n",
      "Iteration 9, loss = 1.26964799\n",
      "Iteration 10, loss = 1.26053149\n",
      "Iteration 1, loss = 1.25311004\n",
      "Iteration 2, loss = 1.22602527\n",
      "Iteration 3, loss = 1.26043673\n",
      "Iteration 4, loss = 1.20826878\n",
      "Iteration 5, loss = 1.25202725\n",
      "Iteration 6, loss = 1.15011507\n",
      "Iteration 4, loss = 1.28308553\n",
      "Iteration 5, loss = 1.26811913\n",
      "Iteration 6, loss = 1.25545435\n",
      "Iteration 7, loss = 1.26778023\n",
      "Iteration 8, loss = 1.25997204\n",
      "Iteration 9, loss = 1.26964799\n",
      "Iteration 10, loss = 1.26053149\n",
      "Iteration 1, loss = 1.25311004\n",
      "Iteration 2, loss = 1.22602527\n",
      "Iteration 3, loss = 1.26043673\n",
      "Iteration 4, loss = 1.20826878\n",
      "Iteration 5, loss = 1.25202725\n",
      "Iteration 6, loss = 1.15011507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.09949261\n",
      "Iteration 8, loss = 1.14581269\n",
      "Iteration 9, loss = 1.15306879\n",
      "Iteration 10, loss = 1.10416622\n",
      "Iteration 1, loss = 1.27968560\n",
      "Iteration 2, loss = 1.18312029\n",
      "Iteration 3, loss = 1.16004993\n",
      "Iteration 4, loss = 1.11147872\n",
      "Iteration 5, loss = 1.13555570\n",
      "Iteration 6, loss = 1.05475583\n",
      "Iteration 7, loss = 1.22378655\n",
      "Iteration 8, loss = 1.24878425\n",
      "Iteration 9, loss = 1.15545200\n",
      "Iteration 7, loss = 1.09949261\n",
      "Iteration 8, loss = 1.14581269\n",
      "Iteration 9, loss = 1.15306879\n",
      "Iteration 10, loss = 1.10416622\n",
      "Iteration 1, loss = 1.27968560\n",
      "Iteration 2, loss = 1.18312029\n",
      "Iteration 3, loss = 1.16004993\n",
      "Iteration 4, loss = 1.11147872\n",
      "Iteration 5, loss = 1.13555570\n",
      "Iteration 6, loss = 1.05475583\n",
      "Iteration 7, loss = 1.22378655\n",
      "Iteration 8, loss = 1.24878425\n",
      "Iteration 9, loss = 1.15545200\n",
      "Iteration 10, loss = 1.24360279\n",
      "Iteration 1, loss = 1.29404312\n",
      "Iteration 2, loss = 1.24533904\n",
      "Iteration 3, loss = 1.24730037\n",
      "Iteration 4, loss = 1.25059402\n",
      "Iteration 5, loss = 1.25762259\n",
      "Iteration 6, loss = 1.22288999\n",
      "Iteration 7, loss = 1.10817901\n",
      "Iteration 8, loss = 1.10329139\n",
      "Iteration 9, loss = 1.13507044\n",
      "Iteration 10, loss = 1.24594354\n",
      "Iteration 11, loss = 1.26112225\n",
      "Iteration 12, loss = 1.14433984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.24360279\n",
      "Iteration 1, loss = 1.29404312\n",
      "Iteration 2, loss = 1.24533904\n",
      "Iteration 3, loss = 1.24730037\n",
      "Iteration 4, loss = 1.25059402\n",
      "Iteration 5, loss = 1.25762259\n",
      "Iteration 6, loss = 1.22288999\n",
      "Iteration 7, loss = 1.10817901\n",
      "Iteration 8, loss = 1.10329139\n",
      "Iteration 9, loss = 1.13507044\n",
      "Iteration 10, loss = 1.24594354\n",
      "Iteration 11, loss = 1.26112225\n",
      "Iteration 12, loss = 1.14433984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.10583403\n",
      "Iteration 14, loss = 1.18180099\n",
      "Iteration 15, loss = 1.19558845\n",
      "Iteration 16, loss = 1.25333815\n",
      "Iteration 17, loss = 1.25732759\n",
      "Iteration 18, loss = 1.25142024\n",
      "Iteration 19, loss = 1.26302164\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20849233\n",
      "Iteration 2, loss = 1.22076401\n",
      "Iteration 3, loss = 1.14290884\n",
      "Iteration 4, loss = 1.10840360\n",
      "Iteration 5, loss = 1.05010002\n",
      "Iteration 6, loss = 1.33770218\n",
      "Iteration 7, loss = 1.24591397\n",
      "Iteration 13, loss = 1.10583403\n",
      "Iteration 14, loss = 1.18180099\n",
      "Iteration 15, loss = 1.19558845\n",
      "Iteration 16, loss = 1.25333815\n",
      "Iteration 17, loss = 1.25732759\n",
      "Iteration 18, loss = 1.25142024\n",
      "Iteration 19, loss = 1.26302164\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20849233\n",
      "Iteration 2, loss = 1.22076401\n",
      "Iteration 3, loss = 1.14290884\n",
      "Iteration 4, loss = 1.10840360\n",
      "Iteration 5, loss = 1.05010002\n",
      "Iteration 6, loss = 1.33770218\n",
      "Iteration 7, loss = 1.24591397\n",
      "Iteration 8, loss = 1.25961457\n",
      "Iteration 9, loss = 1.26369272\n",
      "Iteration 10, loss = 1.24296710\n",
      "Iteration 11, loss = 1.24025099\n",
      "Iteration 12, loss = 1.24978957\n",
      "Iteration 13, loss = 1.26496259\n",
      "Iteration 14, loss = 1.24716931\n",
      "Iteration 15, loss = 1.26343731\n",
      "Iteration 16, loss = 1.25810751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24427062\n",
      "Iteration 2, loss = 1.16732459\n",
      "Iteration 3, loss = 1.33030060\n",
      "Iteration 4, loss = 1.28308553\n",
      "Iteration 5, loss = 1.26811913\n",
      "Iteration 6, loss = 1.25545435\n",
      "Iteration 8, loss = 1.25961457\n",
      "Iteration 9, loss = 1.26369272\n",
      "Iteration 10, loss = 1.24296710\n",
      "Iteration 11, loss = 1.24025099\n",
      "Iteration 12, loss = 1.24978957\n",
      "Iteration 13, loss = 1.26496259\n",
      "Iteration 14, loss = 1.24716931\n",
      "Iteration 15, loss = 1.26343731\n",
      "Iteration 16, loss = 1.25810751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24427062\n",
      "Iteration 2, loss = 1.16732459\n",
      "Iteration 3, loss = 1.33030060\n",
      "Iteration 4, loss = 1.28308553\n",
      "Iteration 5, loss = 1.26811913\n",
      "Iteration 6, loss = 1.25545435\n",
      "Iteration 7, loss = 1.26778023\n",
      "Iteration 8, loss = 1.25997204\n",
      "Iteration 9, loss = 1.26964799\n",
      "Iteration 10, loss = 1.26053149\n",
      "Iteration 11, loss = 1.25434244\n",
      "Iteration 12, loss = 1.25826870\n",
      "Iteration 13, loss = 1.28535364\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25311004\n",
      "Iteration 2, loss = 1.22602527\n",
      "Iteration 3, loss = 1.26043673\n",
      "Iteration 4, loss = 1.20826878\n",
      "Iteration 5, loss = 1.25202725\n",
      "Iteration 6, loss = 1.15011507\n",
      "Iteration 7, loss = 1.09949261\n",
      "Iteration 7, loss = 1.26778023\n",
      "Iteration 8, loss = 1.25997204\n",
      "Iteration 9, loss = 1.26964799\n",
      "Iteration 10, loss = 1.26053149\n",
      "Iteration 11, loss = 1.25434244\n",
      "Iteration 12, loss = 1.25826870\n",
      "Iteration 13, loss = 1.28535364\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25311004\n",
      "Iteration 2, loss = 1.22602527\n",
      "Iteration 3, loss = 1.26043673\n",
      "Iteration 4, loss = 1.20826878\n",
      "Iteration 5, loss = 1.25202725\n",
      "Iteration 6, loss = 1.15011507\n",
      "Iteration 7, loss = 1.09949261\n",
      "Iteration 8, loss = 1.14581269\n",
      "Iteration 9, loss = 1.15306879\n",
      "Iteration 10, loss = 1.10416622\n",
      "Iteration 11, loss = 1.13476257\n",
      "Iteration 12, loss = 1.12943259\n",
      "Iteration 13, loss = 1.09345483\n",
      "Iteration 14, loss = 1.06653757\n",
      "Iteration 15, loss = 1.12885323\n",
      "Iteration 16, loss = 1.13613863\n",
      "Iteration 17, loss = 1.11656027\n",
      "Iteration 18, loss = 1.07247710\n",
      "Iteration 19, loss = 1.11087609\n",
      "Iteration 20, loss = 1.11227841\n",
      "Iteration 21, loss = 1.08604388\n",
      "Iteration 22, loss = 1.08219011\n",
      "Iteration 8, loss = 1.14581269\n",
      "Iteration 9, loss = 1.15306879\n",
      "Iteration 10, loss = 1.10416622\n",
      "Iteration 11, loss = 1.13476257\n",
      "Iteration 12, loss = 1.12943259\n",
      "Iteration 13, loss = 1.09345483\n",
      "Iteration 14, loss = 1.06653757\n",
      "Iteration 15, loss = 1.12885323\n",
      "Iteration 16, loss = 1.13613863\n",
      "Iteration 17, loss = 1.11656027\n",
      "Iteration 18, loss = 1.07247710\n",
      "Iteration 19, loss = 1.11087609\n",
      "Iteration 20, loss = 1.11227841\n",
      "Iteration 21, loss = 1.08604388\n",
      "Iteration 22, loss = 1.08219011\n",
      "Iteration 23, loss = 1.13443225\n",
      "Iteration 24, loss = 1.06854455\n",
      "Iteration 25, loss = 1.12319048\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27968560\n",
      "Iteration 2, loss = 1.18312029\n",
      "Iteration 3, loss = 1.16004993\n",
      "Iteration 4, loss = 1.11147872\n",
      "Iteration 5, loss = 1.13555570\n",
      "Iteration 6, loss = 1.05475583\n",
      "Iteration 7, loss = 1.22378655\n",
      "Iteration 8, loss = 1.24878425\n",
      "Iteration 9, loss = 1.15545200\n",
      "Iteration 23, loss = 1.13443225\n",
      "Iteration 24, loss = 1.06854455\n",
      "Iteration 25, loss = 1.12319048\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27968560\n",
      "Iteration 2, loss = 1.18312029\n",
      "Iteration 3, loss = 1.16004993\n",
      "Iteration 4, loss = 1.11147872\n",
      "Iteration 5, loss = 1.13555570\n",
      "Iteration 6, loss = 1.05475583\n",
      "Iteration 7, loss = 1.22378655\n",
      "Iteration 8, loss = 1.24878425\n",
      "Iteration 9, loss = 1.15545200\n",
      "Iteration 10, loss = 1.24360279\n",
      "Iteration 11, loss = 1.18944438\n",
      "Iteration 12, loss = 1.16142992\n",
      "Iteration 13, loss = 1.07704310\n",
      "Iteration 14, loss = 1.03684706\n",
      "Iteration 15, loss = 1.10739316\n",
      "Iteration 16, loss = 1.11597187\n",
      "Iteration 17, loss = 1.04985603\n",
      "Iteration 18, loss = 1.04943010\n",
      "Iteration 19, loss = 1.04965878\n",
      "Iteration 20, loss = 1.03284400\n",
      "Iteration 21, loss = 1.05043594\n",
      "Iteration 22, loss = 1.29464291\n",
      "Iteration 23, loss = 1.29390008\n",
      "Iteration 24, loss = 1.27987272\n",
      "Iteration 10, loss = 1.24360279\n",
      "Iteration 11, loss = 1.18944438\n",
      "Iteration 12, loss = 1.16142992\n",
      "Iteration 13, loss = 1.07704310\n",
      "Iteration 14, loss = 1.03684706\n",
      "Iteration 15, loss = 1.10739316\n",
      "Iteration 16, loss = 1.11597187\n",
      "Iteration 17, loss = 1.04985603\n",
      "Iteration 18, loss = 1.04943010\n",
      "Iteration 19, loss = 1.04965878\n",
      "Iteration 20, loss = 1.03284400\n",
      "Iteration 21, loss = 1.05043594\n",
      "Iteration 22, loss = 1.29464291\n",
      "Iteration 23, loss = 1.29390008\n",
      "Iteration 24, loss = 1.27987272\n",
      "Iteration 25, loss = 1.29541153\n",
      "Iteration 26, loss = 1.27117327\n",
      "Iteration 27, loss = 1.27886632\n",
      "Iteration 28, loss = 1.27987212\n",
      "Iteration 29, loss = 1.27708665\n",
      "Iteration 30, loss = 1.28570777\n",
      "Iteration 31, loss = 1.27178938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29404312\n",
      "Iteration 2, loss = 1.24533904\n",
      "Iteration 3, loss = 1.24730037\n",
      "Iteration 4, loss = 1.25059402\n",
      "Iteration 5, loss = 1.25762259\n",
      "Iteration 6, loss = 1.22288999\n",
      "Iteration 25, loss = 1.29541153\n",
      "Iteration 26, loss = 1.27117327\n",
      "Iteration 27, loss = 1.27886632\n",
      "Iteration 28, loss = 1.27987212\n",
      "Iteration 29, loss = 1.27708665\n",
      "Iteration 30, loss = 1.28570777\n",
      "Iteration 31, loss = 1.27178938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29404312\n",
      "Iteration 2, loss = 1.24533904\n",
      "Iteration 3, loss = 1.24730037\n",
      "Iteration 4, loss = 1.25059402\n",
      "Iteration 5, loss = 1.25762259\n",
      "Iteration 6, loss = 1.22288999\n",
      "Iteration 7, loss = 1.10817901\n",
      "Iteration 8, loss = 1.10329139\n",
      "Iteration 9, loss = 1.13507044\n",
      "Iteration 10, loss = 1.24594354\n",
      "Iteration 11, loss = 1.26112225\n",
      "Iteration 12, loss = 1.14433984\n",
      "Iteration 13, loss = 1.10583403\n",
      "Iteration 14, loss = 1.18180099\n",
      "Iteration 15, loss = 1.19558845\n",
      "Iteration 16, loss = 1.25333815\n",
      "Iteration 17, loss = 1.25732759\n",
      "Iteration 18, loss = 1.25142024\n",
      "Iteration 19, loss = 1.26302164\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20849233\n",
      "Iteration 7, loss = 1.10817901\n",
      "Iteration 8, loss = 1.10329139\n",
      "Iteration 9, loss = 1.13507044\n",
      "Iteration 10, loss = 1.24594354\n",
      "Iteration 11, loss = 1.26112225\n",
      "Iteration 12, loss = 1.14433984\n",
      "Iteration 13, loss = 1.10583403\n",
      "Iteration 14, loss = 1.18180099\n",
      "Iteration 15, loss = 1.19558845\n",
      "Iteration 16, loss = 1.25333815\n",
      "Iteration 17, loss = 1.25732759\n",
      "Iteration 18, loss = 1.25142024\n",
      "Iteration 19, loss = 1.26302164\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20849233\n",
      "Iteration 2, loss = 1.22076401\n",
      "Iteration 3, loss = 1.14290884\n",
      "Iteration 4, loss = 1.10840360\n",
      "Iteration 5, loss = 1.05010002\n",
      "Iteration 6, loss = 1.33770218\n",
      "Iteration 7, loss = 1.24591397\n",
      "Iteration 8, loss = 1.25961457\n",
      "Iteration 9, loss = 1.26369272\n",
      "Iteration 10, loss = 1.24296710\n",
      "Iteration 11, loss = 1.24025099\n",
      "Iteration 12, loss = 1.24978957\n",
      "Iteration 13, loss = 1.26496259\n",
      "Iteration 14, loss = 1.24716931\n",
      "Iteration 15, loss = 1.26343731\n",
      "Iteration 16, loss = 1.25810751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 1.22076401\n",
      "Iteration 3, loss = 1.14290884\n",
      "Iteration 4, loss = 1.10840360\n",
      "Iteration 5, loss = 1.05010002\n",
      "Iteration 6, loss = 1.33770218\n",
      "Iteration 7, loss = 1.24591397\n",
      "Iteration 8, loss = 1.25961457\n",
      "Iteration 9, loss = 1.26369272\n",
      "Iteration 10, loss = 1.24296710\n",
      "Iteration 11, loss = 1.24025099\n",
      "Iteration 12, loss = 1.24978957\n",
      "Iteration 13, loss = 1.26496259\n",
      "Iteration 14, loss = 1.24716931\n",
      "Iteration 15, loss = 1.26343731\n",
      "Iteration 16, loss = 1.25810751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24427062\n",
      "Iteration 2, loss = 1.16732459\n",
      "Iteration 3, loss = 1.33030060\n",
      "Iteration 4, loss = 1.28308553\n",
      "Iteration 5, loss = 1.26811913\n",
      "Iteration 6, loss = 1.25545435\n",
      "Iteration 7, loss = 1.26778023\n",
      "Iteration 8, loss = 1.25997204\n",
      "Iteration 9, loss = 1.26964799\n",
      "Iteration 10, loss = 1.26053149\n",
      "Iteration 11, loss = 1.25434244\n",
      "Iteration 1, loss = 1.24427062\n",
      "Iteration 2, loss = 1.16732459\n",
      "Iteration 3, loss = 1.33030060\n",
      "Iteration 4, loss = 1.28308553\n",
      "Iteration 5, loss = 1.26811913\n",
      "Iteration 6, loss = 1.25545435\n",
      "Iteration 7, loss = 1.26778023\n",
      "Iteration 8, loss = 1.25997204\n",
      "Iteration 9, loss = 1.26964799\n",
      "Iteration 10, loss = 1.26053149\n",
      "Iteration 11, loss = 1.25434244\n",
      "Iteration 12, loss = 1.25826870\n",
      "Iteration 13, loss = 1.28535364\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25311004\n",
      "Iteration 2, loss = 1.22602527\n",
      "Iteration 3, loss = 1.26043673\n",
      "Iteration 4, loss = 1.20826878\n",
      "Iteration 5, loss = 1.25202725\n",
      "Iteration 6, loss = 1.15011507\n",
      "Iteration 7, loss = 1.09949261\n",
      "Iteration 8, loss = 1.14581269\n",
      "Iteration 9, loss = 1.15306879\n",
      "Iteration 10, loss = 1.10416622\n",
      "Iteration 11, loss = 1.13476257\n",
      "Iteration 12, loss = 1.12943259\n",
      "Iteration 12, loss = 1.25826870\n",
      "Iteration 13, loss = 1.28535364\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25311004\n",
      "Iteration 2, loss = 1.22602527\n",
      "Iteration 3, loss = 1.26043673\n",
      "Iteration 4, loss = 1.20826878\n",
      "Iteration 5, loss = 1.25202725\n",
      "Iteration 6, loss = 1.15011507\n",
      "Iteration 7, loss = 1.09949261\n",
      "Iteration 8, loss = 1.14581269\n",
      "Iteration 9, loss = 1.15306879\n",
      "Iteration 10, loss = 1.10416622\n",
      "Iteration 11, loss = 1.13476257\n",
      "Iteration 12, loss = 1.12943259\n",
      "Iteration 13, loss = 1.09345483\n",
      "Iteration 14, loss = 1.06653757\n",
      "Iteration 15, loss = 1.12885323\n",
      "Iteration 16, loss = 1.13613863\n",
      "Iteration 17, loss = 1.11656027\n",
      "Iteration 18, loss = 1.07247710\n",
      "Iteration 19, loss = 1.11087609\n",
      "Iteration 20, loss = 1.11227841\n",
      "Iteration 21, loss = 1.08604388\n",
      "Iteration 22, loss = 1.08219011\n",
      "Iteration 23, loss = 1.13443225\n",
      "Iteration 24, loss = 1.06854455\n",
      "Iteration 25, loss = 1.12319048\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27968560\n",
      "Iteration 2, loss = 1.18312029\n",
      "Iteration 13, loss = 1.09345483\n",
      "Iteration 14, loss = 1.06653757\n",
      "Iteration 15, loss = 1.12885323\n",
      "Iteration 16, loss = 1.13613863\n",
      "Iteration 17, loss = 1.11656027\n",
      "Iteration 18, loss = 1.07247710\n",
      "Iteration 19, loss = 1.11087609\n",
      "Iteration 20, loss = 1.11227841\n",
      "Iteration 21, loss = 1.08604388\n",
      "Iteration 22, loss = 1.08219011\n",
      "Iteration 23, loss = 1.13443225\n",
      "Iteration 24, loss = 1.06854455\n",
      "Iteration 25, loss = 1.12319048\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27968560\n",
      "Iteration 2, loss = 1.18312029\n",
      "Iteration 3, loss = 1.16004993\n",
      "Iteration 4, loss = 1.11147872\n",
      "Iteration 5, loss = 1.13555570\n",
      "Iteration 6, loss = 1.05475583\n",
      "Iteration 7, loss = 1.22378655\n",
      "Iteration 8, loss = 1.24878425\n",
      "Iteration 9, loss = 1.15545200\n",
      "Iteration 10, loss = 1.24360279\n",
      "Iteration 11, loss = 1.18944438\n",
      "Iteration 12, loss = 1.16142992\n",
      "Iteration 13, loss = 1.07704310\n",
      "Iteration 14, loss = 1.03684706\n",
      "Iteration 15, loss = 1.10739316\n",
      "Iteration 16, loss = 1.11597187\n",
      "Iteration 3, loss = 1.16004993\n",
      "Iteration 4, loss = 1.11147872\n",
      "Iteration 5, loss = 1.13555570\n",
      "Iteration 6, loss = 1.05475583\n",
      "Iteration 7, loss = 1.22378655\n",
      "Iteration 8, loss = 1.24878425\n",
      "Iteration 9, loss = 1.15545200\n",
      "Iteration 10, loss = 1.24360279\n",
      "Iteration 11, loss = 1.18944438\n",
      "Iteration 12, loss = 1.16142992\n",
      "Iteration 13, loss = 1.07704310\n",
      "Iteration 14, loss = 1.03684706\n",
      "Iteration 15, loss = 1.10739316\n",
      "Iteration 16, loss = 1.11597187\n",
      "Iteration 17, loss = 1.04985603\n",
      "Iteration 18, loss = 1.04943010\n",
      "Iteration 19, loss = 1.04965878\n",
      "Iteration 20, loss = 1.03284400\n",
      "Iteration 21, loss = 1.05043594\n",
      "Iteration 22, loss = 1.29464291\n",
      "Iteration 23, loss = 1.29390008\n",
      "Iteration 24, loss = 1.27987272\n",
      "Iteration 25, loss = 1.29541153\n",
      "Iteration 26, loss = 1.27117327\n",
      "Iteration 27, loss = 1.27886632\n",
      "Iteration 28, loss = 1.27987212\n",
      "Iteration 29, loss = 1.27708665\n",
      "Iteration 30, loss = 1.28570777\n",
      "Iteration 31, loss = 1.27178938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 1.04985603\n",
      "Iteration 18, loss = 1.04943010\n",
      "Iteration 19, loss = 1.04965878\n",
      "Iteration 20, loss = 1.03284400\n",
      "Iteration 21, loss = 1.05043594\n",
      "Iteration 22, loss = 1.29464291\n",
      "Iteration 23, loss = 1.29390008\n",
      "Iteration 24, loss = 1.27987272\n",
      "Iteration 25, loss = 1.29541153\n",
      "Iteration 26, loss = 1.27117327\n",
      "Iteration 27, loss = 1.27886632\n",
      "Iteration 28, loss = 1.27987212\n",
      "Iteration 29, loss = 1.27708665\n",
      "Iteration 30, loss = 1.28570777\n",
      "Iteration 31, loss = 1.27178938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26794535\n",
      "Iteration 2, loss = 1.10191499\n",
      "Iteration 3, loss = 1.08100904\n",
      "Iteration 4, loss = 1.00902034\n",
      "Iteration 5, loss = 0.99570202\n",
      "Iteration 6, loss = 1.03065174\n",
      "Iteration 7, loss = 1.04772946\n",
      "Iteration 8, loss = 0.99898002\n",
      "Iteration 9, loss = 1.00049947\n",
      "Iteration 10, loss = 0.97062053\n",
      "Iteration 1, loss = 1.25707860\n",
      "Iteration 1, loss = 1.26794535\n",
      "Iteration 2, loss = 1.10191499\n",
      "Iteration 3, loss = 1.08100904\n",
      "Iteration 4, loss = 1.00902034\n",
      "Iteration 5, loss = 0.99570202\n",
      "Iteration 6, loss = 1.03065174\n",
      "Iteration 7, loss = 1.04772946\n",
      "Iteration 8, loss = 0.99898002\n",
      "Iteration 9, loss = 1.00049947\n",
      "Iteration 10, loss = 0.97062053\n",
      "Iteration 1, loss = 1.25707860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.03853886\n",
      "Iteration 3, loss = 1.00565381\n",
      "Iteration 4, loss = 0.96327088\n",
      "Iteration 5, loss = 0.92140207\n",
      "Iteration 6, loss = 0.97240492\n",
      "Iteration 7, loss = 0.92866819\n",
      "Iteration 8, loss = 0.91126006\n",
      "Iteration 9, loss = 0.90886406\n",
      "Iteration 10, loss = 0.88593398\n",
      "Iteration 1, loss = 1.25272258\n",
      "Iteration 2, loss = 1.09045852\n",
      "Iteration 3, loss = 1.04421704\n",
      "Iteration 4, loss = 1.02229839\n",
      "Iteration 5, loss = 1.02940129\n",
      "Iteration 6, loss = 1.00246248\n",
      "Iteration 7, loss = 0.99673957\n",
      "Iteration 2, loss = 1.03853886\n",
      "Iteration 3, loss = 1.00565381\n",
      "Iteration 4, loss = 0.96327088\n",
      "Iteration 5, loss = 0.92140207\n",
      "Iteration 6, loss = 0.97240492\n",
      "Iteration 7, loss = 0.92866819\n",
      "Iteration 8, loss = 0.91126006\n",
      "Iteration 9, loss = 0.90886406\n",
      "Iteration 10, loss = 0.88593398\n",
      "Iteration 1, loss = 1.25272258\n",
      "Iteration 2, loss = 1.09045852\n",
      "Iteration 3, loss = 1.04421704\n",
      "Iteration 4, loss = 1.02229839\n",
      "Iteration 5, loss = 1.02940129\n",
      "Iteration 6, loss = 1.00246248\n",
      "Iteration 7, loss = 0.99673957\n",
      "Iteration 8, loss = 0.97077803\n",
      "Iteration 9, loss = 0.96360330\n",
      "Iteration 10, loss = 0.96276783\n",
      "Iteration 1, loss = 1.23956856\n",
      "Iteration 2, loss = 1.11780402\n",
      "Iteration 3, loss = 1.04838035\n",
      "Iteration 4, loss = 1.01487693\n",
      "Iteration 5, loss = 0.99896192\n",
      "Iteration 6, loss = 0.99300091\n",
      "Iteration 7, loss = 0.98277593\n",
      "Iteration 8, loss = 0.98105041\n",
      "Iteration 9, loss = 0.95665204\n",
      "Iteration 10, loss = 1.00932518\n",
      "Iteration 8, loss = 0.97077803\n",
      "Iteration 9, loss = 0.96360330\n",
      "Iteration 10, loss = 0.96276783\n",
      "Iteration 1, loss = 1.23956856\n",
      "Iteration 2, loss = 1.11780402\n",
      "Iteration 3, loss = 1.04838035\n",
      "Iteration 4, loss = 1.01487693\n",
      "Iteration 5, loss = 0.99896192\n",
      "Iteration 6, loss = 0.99300091\n",
      "Iteration 7, loss = 0.98277593\n",
      "Iteration 8, loss = 0.98105041\n",
      "Iteration 9, loss = 0.95665204\n",
      "Iteration 10, loss = 1.00932518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22663043\n",
      "Iteration 2, loss = 1.09302757\n",
      "Iteration 3, loss = 1.02386672\n",
      "Iteration 4, loss = 0.98064216\n",
      "Iteration 5, loss = 0.97881386\n",
      "Iteration 6, loss = 0.95220089\n",
      "Iteration 7, loss = 0.93722982\n",
      "Iteration 8, loss = 0.99056637\n",
      "Iteration 9, loss = 0.93305569\n",
      "Iteration 10, loss = 0.94732906\n",
      "Iteration 1, loss = 1.26794535\n",
      "Iteration 2, loss = 1.10191499\n",
      "Iteration 3, loss = 1.08100904\n",
      "Iteration 1, loss = 1.22663043\n",
      "Iteration 2, loss = 1.09302757\n",
      "Iteration 3, loss = 1.02386672\n",
      "Iteration 4, loss = 0.98064216\n",
      "Iteration 5, loss = 0.97881386\n",
      "Iteration 6, loss = 0.95220089\n",
      "Iteration 7, loss = 0.93722982\n",
      "Iteration 8, loss = 0.99056637\n",
      "Iteration 9, loss = 0.93305569\n",
      "Iteration 10, loss = 0.94732906\n",
      "Iteration 1, loss = 1.26794535\n",
      "Iteration 2, loss = 1.10191499\n",
      "Iteration 3, loss = 1.08100904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.00902034\n",
      "Iteration 5, loss = 0.99570202\n",
      "Iteration 6, loss = 1.03065174\n",
      "Iteration 7, loss = 1.04772946\n",
      "Iteration 8, loss = 0.99898002\n",
      "Iteration 9, loss = 1.00049947\n",
      "Iteration 10, loss = 0.97062053\n",
      "Iteration 11, loss = 0.99306951\n",
      "Iteration 12, loss = 1.00122994\n",
      "Iteration 13, loss = 0.97722782\n",
      "Iteration 14, loss = 0.96198786\n",
      "Iteration 15, loss = 0.99197088\n",
      "Iteration 16, loss = 0.94729358\n",
      "Iteration 17, loss = 0.93100009\n",
      "Iteration 18, loss = 0.96553007\n",
      "Iteration 4, loss = 1.00902034\n",
      "Iteration 5, loss = 0.99570202\n",
      "Iteration 6, loss = 1.03065174\n",
      "Iteration 7, loss = 1.04772946\n",
      "Iteration 8, loss = 0.99898002\n",
      "Iteration 9, loss = 1.00049947\n",
      "Iteration 10, loss = 0.97062053\n",
      "Iteration 11, loss = 0.99306951\n",
      "Iteration 12, loss = 1.00122994\n",
      "Iteration 13, loss = 0.97722782\n",
      "Iteration 14, loss = 0.96198786\n",
      "Iteration 15, loss = 0.99197088\n",
      "Iteration 16, loss = 0.94729358\n",
      "Iteration 17, loss = 0.93100009\n",
      "Iteration 18, loss = 0.96553007\n",
      "Iteration 19, loss = 0.92935604\n",
      "Iteration 20, loss = 1.01114320\n",
      "Iteration 21, loss = 0.94057039\n",
      "Iteration 22, loss = 0.92055466\n",
      "Iteration 23, loss = 0.99606318\n",
      "Iteration 24, loss = 0.92895978\n",
      "Iteration 25, loss = 0.88485902\n",
      "Iteration 26, loss = 0.92993684\n",
      "Iteration 27, loss = 0.93428836\n",
      "Iteration 28, loss = 0.89781432\n",
      "Iteration 29, loss = 0.89016437\n",
      "Iteration 30, loss = 0.86382578\n",
      "Iteration 31, loss = 0.87265930\n",
      "Iteration 32, loss = 0.90582422\n",
      "Iteration 33, loss = 0.91381221\n",
      "Iteration 19, loss = 0.92935604\n",
      "Iteration 20, loss = 1.01114320\n",
      "Iteration 21, loss = 0.94057039\n",
      "Iteration 22, loss = 0.92055466\n",
      "Iteration 23, loss = 0.99606318\n",
      "Iteration 24, loss = 0.92895978\n",
      "Iteration 25, loss = 0.88485902\n",
      "Iteration 26, loss = 0.92993684\n",
      "Iteration 27, loss = 0.93428836\n",
      "Iteration 28, loss = 0.89781432\n",
      "Iteration 29, loss = 0.89016437\n",
      "Iteration 30, loss = 0.86382578\n",
      "Iteration 31, loss = 0.87265930\n",
      "Iteration 32, loss = 0.90582422\n",
      "Iteration 33, loss = 0.91381221\n",
      "Iteration 34, loss = 0.91118321\n",
      "Iteration 35, loss = 0.85737212\n",
      "Iteration 36, loss = 0.87454037\n",
      "Iteration 37, loss = 0.90349992\n",
      "Iteration 38, loss = 0.91582399\n",
      "Iteration 39, loss = 0.89309363\n",
      "Iteration 40, loss = 0.82339513\n",
      "Iteration 41, loss = 0.85369594\n",
      "Iteration 42, loss = 0.85027970\n",
      "Iteration 43, loss = 0.83152795\n",
      "Iteration 44, loss = 0.93728483\n",
      "Iteration 45, loss = 0.88318279\n",
      "Iteration 46, loss = 0.87125807\n",
      "Iteration 47, loss = 0.84852649\n",
      "Iteration 48, loss = 0.87119307\n",
      "Iteration 34, loss = 0.91118321\n",
      "Iteration 35, loss = 0.85737212\n",
      "Iteration 36, loss = 0.87454037\n",
      "Iteration 37, loss = 0.90349992\n",
      "Iteration 38, loss = 0.91582399\n",
      "Iteration 39, loss = 0.89309363\n",
      "Iteration 40, loss = 0.82339513\n",
      "Iteration 41, loss = 0.85369594\n",
      "Iteration 42, loss = 0.85027970\n",
      "Iteration 43, loss = 0.83152795\n",
      "Iteration 44, loss = 0.93728483\n",
      "Iteration 45, loss = 0.88318279\n",
      "Iteration 46, loss = 0.87125807\n",
      "Iteration 47, loss = 0.84852649\n",
      "Iteration 48, loss = 0.87119307\n",
      "Iteration 49, loss = 0.86145442\n",
      "Iteration 50, loss = 0.79987701\n",
      "Iteration 1, loss = 1.25707860\n",
      "Iteration 2, loss = 1.03853886\n",
      "Iteration 3, loss = 1.00565381\n",
      "Iteration 4, loss = 0.96327088\n",
      "Iteration 5, loss = 0.92140207\n",
      "Iteration 6, loss = 0.97240492\n",
      "Iteration 7, loss = 0.92866819\n",
      "Iteration 8, loss = 0.91126006\n",
      "Iteration 9, loss = 0.90886406\n",
      "Iteration 10, loss = 0.88593398\n",
      "Iteration 49, loss = 0.86145442\n",
      "Iteration 50, loss = 0.79987701\n",
      "Iteration 1, loss = 1.25707860\n",
      "Iteration 2, loss = 1.03853886\n",
      "Iteration 3, loss = 1.00565381\n",
      "Iteration 4, loss = 0.96327088\n",
      "Iteration 5, loss = 0.92140207\n",
      "Iteration 6, loss = 0.97240492\n",
      "Iteration 7, loss = 0.92866819\n",
      "Iteration 8, loss = 0.91126006\n",
      "Iteration 9, loss = 0.90886406\n",
      "Iteration 10, loss = 0.88593398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.90888374\n",
      "Iteration 12, loss = 0.91216365\n",
      "Iteration 13, loss = 0.87825680\n",
      "Iteration 14, loss = 0.86477570\n",
      "Iteration 15, loss = 0.89512124\n",
      "Iteration 16, loss = 0.86677762\n",
      "Iteration 17, loss = 0.86442756\n",
      "Iteration 18, loss = 0.85187052\n",
      "Iteration 19, loss = 0.84493137\n",
      "Iteration 20, loss = 0.90975622\n",
      "Iteration 21, loss = 0.83830356\n",
      "Iteration 22, loss = 0.90213248\n",
      "Iteration 23, loss = 0.91120016\n",
      "Iteration 24, loss = 0.84385281\n",
      "Iteration 25, loss = 0.81118798\n",
      "Iteration 26, loss = 0.86145988\n",
      "Iteration 11, loss = 0.90888374\n",
      "Iteration 12, loss = 0.91216365\n",
      "Iteration 13, loss = 0.87825680\n",
      "Iteration 14, loss = 0.86477570\n",
      "Iteration 15, loss = 0.89512124\n",
      "Iteration 16, loss = 0.86677762\n",
      "Iteration 17, loss = 0.86442756\n",
      "Iteration 18, loss = 0.85187052\n",
      "Iteration 19, loss = 0.84493137\n",
      "Iteration 20, loss = 0.90975622\n",
      "Iteration 21, loss = 0.83830356\n",
      "Iteration 22, loss = 0.90213248\n",
      "Iteration 23, loss = 0.91120016\n",
      "Iteration 24, loss = 0.84385281\n",
      "Iteration 25, loss = 0.81118798\n",
      "Iteration 26, loss = 0.86145988\n",
      "Iteration 27, loss = 0.82268345\n",
      "Iteration 28, loss = 0.80809154\n",
      "Iteration 29, loss = 0.81424684\n",
      "Iteration 30, loss = 0.80083374\n",
      "Iteration 31, loss = 0.83431375\n",
      "Iteration 32, loss = 0.80995319\n",
      "Iteration 33, loss = 0.79338197\n",
      "Iteration 34, loss = 0.84867136\n",
      "Iteration 35, loss = 0.82016469\n",
      "Iteration 36, loss = 0.86383104\n",
      "Iteration 37, loss = 0.83555020\n",
      "Iteration 38, loss = 0.81585046\n",
      "Iteration 39, loss = 0.79592883\n",
      "Iteration 40, loss = 0.78226769\n",
      "Iteration 41, loss = 0.77232568\n",
      "Iteration 27, loss = 0.82268345\n",
      "Iteration 28, loss = 0.80809154\n",
      "Iteration 29, loss = 0.81424684\n",
      "Iteration 30, loss = 0.80083374\n",
      "Iteration 31, loss = 0.83431375\n",
      "Iteration 32, loss = 0.80995319\n",
      "Iteration 33, loss = 0.79338197\n",
      "Iteration 34, loss = 0.84867136\n",
      "Iteration 35, loss = 0.82016469\n",
      "Iteration 36, loss = 0.86383104\n",
      "Iteration 37, loss = 0.83555020\n",
      "Iteration 38, loss = 0.81585046\n",
      "Iteration 39, loss = 0.79592883\n",
      "Iteration 40, loss = 0.78226769\n",
      "Iteration 41, loss = 0.77232568\n",
      "Iteration 42, loss = 0.77850606\n",
      "Iteration 43, loss = 0.74006227\n",
      "Iteration 44, loss = 0.76554669\n",
      "Iteration 45, loss = 0.82043037\n",
      "Iteration 46, loss = 0.75702523\n",
      "Iteration 47, loss = 0.77380620\n",
      "Iteration 48, loss = 0.79103452\n",
      "Iteration 49, loss = 0.76612336\n",
      "Iteration 50, loss = 0.77588314\n",
      "Iteration 1, loss = 1.25272258\n",
      "Iteration 2, loss = 1.09045852\n",
      "Iteration 3, loss = 1.04421704\n",
      "Iteration 4, loss = 1.02229839\n",
      "Iteration 5, loss = 1.02940129\n",
      "Iteration 42, loss = 0.77850606\n",
      "Iteration 43, loss = 0.74006227\n",
      "Iteration 44, loss = 0.76554669\n",
      "Iteration 45, loss = 0.82043037\n",
      "Iteration 46, loss = 0.75702523\n",
      "Iteration 47, loss = 0.77380620\n",
      "Iteration 48, loss = 0.79103452\n",
      "Iteration 49, loss = 0.76612336\n",
      "Iteration 50, loss = 0.77588314\n",
      "Iteration 1, loss = 1.25272258\n",
      "Iteration 2, loss = 1.09045852\n",
      "Iteration 3, loss = 1.04421704\n",
      "Iteration 4, loss = 1.02229839\n",
      "Iteration 5, loss = 1.02940129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.00246248\n",
      "Iteration 7, loss = 0.99673957\n",
      "Iteration 8, loss = 0.97077803\n",
      "Iteration 9, loss = 0.96360330\n",
      "Iteration 10, loss = 0.96276783\n",
      "Iteration 11, loss = 0.92376681\n",
      "Iteration 12, loss = 0.95278644\n",
      "Iteration 13, loss = 0.97080242\n",
      "Iteration 14, loss = 0.94264677\n",
      "Iteration 15, loss = 0.93510117\n",
      "Iteration 16, loss = 0.92716863\n",
      "Iteration 17, loss = 0.91923035\n",
      "Iteration 18, loss = 0.90506128\n",
      "Iteration 19, loss = 0.89458580\n",
      "Iteration 20, loss = 0.91744386\n",
      "Iteration 6, loss = 1.00246248\n",
      "Iteration 7, loss = 0.99673957\n",
      "Iteration 8, loss = 0.97077803\n",
      "Iteration 9, loss = 0.96360330\n",
      "Iteration 10, loss = 0.96276783\n",
      "Iteration 11, loss = 0.92376681\n",
      "Iteration 12, loss = 0.95278644\n",
      "Iteration 13, loss = 0.97080242\n",
      "Iteration 14, loss = 0.94264677\n",
      "Iteration 15, loss = 0.93510117\n",
      "Iteration 16, loss = 0.92716863\n",
      "Iteration 17, loss = 0.91923035\n",
      "Iteration 18, loss = 0.90506128\n",
      "Iteration 19, loss = 0.89458580\n",
      "Iteration 20, loss = 0.91744386\n",
      "Iteration 21, loss = 0.92805582\n",
      "Iteration 22, loss = 0.95446475\n",
      "Iteration 23, loss = 0.95088495\n",
      "Iteration 24, loss = 0.87543591\n",
      "Iteration 25, loss = 0.87503872\n",
      "Iteration 26, loss = 0.86386971\n",
      "Iteration 27, loss = 0.90058900\n",
      "Iteration 28, loss = 0.90221031\n",
      "Iteration 29, loss = 0.86272312\n",
      "Iteration 30, loss = 0.86556912\n",
      "Iteration 31, loss = 0.84725079\n",
      "Iteration 32, loss = 0.84580059\n",
      "Iteration 33, loss = 0.83004245\n",
      "Iteration 34, loss = 0.85885510\n",
      "Iteration 35, loss = 0.83334849\n",
      "Iteration 21, loss = 0.92805582\n",
      "Iteration 22, loss = 0.95446475\n",
      "Iteration 23, loss = 0.95088495\n",
      "Iteration 24, loss = 0.87543591\n",
      "Iteration 25, loss = 0.87503872\n",
      "Iteration 26, loss = 0.86386971\n",
      "Iteration 27, loss = 0.90058900\n",
      "Iteration 28, loss = 0.90221031\n",
      "Iteration 29, loss = 0.86272312\n",
      "Iteration 30, loss = 0.86556912\n",
      "Iteration 31, loss = 0.84725079\n",
      "Iteration 32, loss = 0.84580059\n",
      "Iteration 33, loss = 0.83004245\n",
      "Iteration 34, loss = 0.85885510\n",
      "Iteration 35, loss = 0.83334849\n",
      "Iteration 36, loss = 0.86311799\n",
      "Iteration 37, loss = 0.83013945\n",
      "Iteration 38, loss = 0.83863346\n",
      "Iteration 39, loss = 0.93036333\n",
      "Iteration 40, loss = 0.85293913\n",
      "Iteration 41, loss = 0.83665516\n",
      "Iteration 42, loss = 0.81870366\n",
      "Iteration 43, loss = 0.82463030\n",
      "Iteration 44, loss = 0.84282182\n",
      "Iteration 45, loss = 0.83655995\n",
      "Iteration 46, loss = 0.79892931\n",
      "Iteration 47, loss = 0.81222269\n",
      "Iteration 48, loss = 0.81904042\n",
      "Iteration 49, loss = 0.80400154\n",
      "Iteration 50, loss = 0.79774282\n",
      "Iteration 36, loss = 0.86311799\n",
      "Iteration 37, loss = 0.83013945\n",
      "Iteration 38, loss = 0.83863346\n",
      "Iteration 39, loss = 0.93036333\n",
      "Iteration 40, loss = 0.85293913\n",
      "Iteration 41, loss = 0.83665516\n",
      "Iteration 42, loss = 0.81870366\n",
      "Iteration 43, loss = 0.82463030\n",
      "Iteration 44, loss = 0.84282182\n",
      "Iteration 45, loss = 0.83655995\n",
      "Iteration 46, loss = 0.79892931\n",
      "Iteration 47, loss = 0.81222269\n",
      "Iteration 48, loss = 0.81904042\n",
      "Iteration 49, loss = 0.80400154\n",
      "Iteration 50, loss = 0.79774282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.23956856\n",
      "Iteration 2, loss = 1.11780402\n",
      "Iteration 3, loss = 1.04838035\n",
      "Iteration 4, loss = 1.01487693\n",
      "Iteration 5, loss = 0.99896192\n",
      "Iteration 6, loss = 0.99300091\n",
      "Iteration 7, loss = 0.98277593\n",
      "Iteration 8, loss = 0.98105041\n",
      "Iteration 9, loss = 0.95665204\n",
      "Iteration 10, loss = 1.00932518\n",
      "Iteration 11, loss = 0.98942057\n",
      "Iteration 12, loss = 0.97582904\n",
      "Iteration 13, loss = 0.95477600\n",
      "Iteration 14, loss = 0.94331929\n",
      "Iteration 15, loss = 0.96528808\n",
      "Iteration 1, loss = 1.23956856\n",
      "Iteration 2, loss = 1.11780402\n",
      "Iteration 3, loss = 1.04838035\n",
      "Iteration 4, loss = 1.01487693\n",
      "Iteration 5, loss = 0.99896192\n",
      "Iteration 6, loss = 0.99300091\n",
      "Iteration 7, loss = 0.98277593\n",
      "Iteration 8, loss = 0.98105041\n",
      "Iteration 9, loss = 0.95665204\n",
      "Iteration 10, loss = 1.00932518\n",
      "Iteration 11, loss = 0.98942057\n",
      "Iteration 12, loss = 0.97582904\n",
      "Iteration 13, loss = 0.95477600\n",
      "Iteration 14, loss = 0.94331929\n",
      "Iteration 15, loss = 0.96528808\n",
      "Iteration 16, loss = 0.91684344\n",
      "Iteration 17, loss = 0.92279801\n",
      "Iteration 18, loss = 0.93697199\n",
      "Iteration 19, loss = 0.89817508\n",
      "Iteration 20, loss = 0.91823359\n",
      "Iteration 21, loss = 0.89011868\n",
      "Iteration 22, loss = 0.95170387\n",
      "Iteration 23, loss = 0.93427875\n",
      "Iteration 24, loss = 0.89709755\n",
      "Iteration 25, loss = 0.88275338\n",
      "Iteration 26, loss = 0.86711997\n",
      "Iteration 27, loss = 0.89644945\n",
      "Iteration 28, loss = 0.91838855\n",
      "Iteration 29, loss = 0.85275408\n",
      "Iteration 30, loss = 0.86739261\n",
      "Iteration 16, loss = 0.91684344\n",
      "Iteration 17, loss = 0.92279801\n",
      "Iteration 18, loss = 0.93697199\n",
      "Iteration 19, loss = 0.89817508\n",
      "Iteration 20, loss = 0.91823359\n",
      "Iteration 21, loss = 0.89011868\n",
      "Iteration 22, loss = 0.95170387\n",
      "Iteration 23, loss = 0.93427875\n",
      "Iteration 24, loss = 0.89709755\n",
      "Iteration 25, loss = 0.88275338\n",
      "Iteration 26, loss = 0.86711997\n",
      "Iteration 27, loss = 0.89644945\n",
      "Iteration 28, loss = 0.91838855\n",
      "Iteration 29, loss = 0.85275408\n",
      "Iteration 30, loss = 0.86739261\n",
      "Iteration 31, loss = 0.83608808\n",
      "Iteration 32, loss = 0.86134823\n",
      "Iteration 33, loss = 0.86272810\n",
      "Iteration 34, loss = 0.84644141\n",
      "Iteration 35, loss = 0.83452068\n",
      "Iteration 36, loss = 0.90361848\n",
      "Iteration 37, loss = 0.85600643\n",
      "Iteration 38, loss = 0.86957270\n",
      "Iteration 39, loss = 0.82912394\n",
      "Iteration 40, loss = 0.84408321\n",
      "Iteration 41, loss = 0.81991040\n",
      "Iteration 42, loss = 0.81543029\n",
      "Iteration 43, loss = 0.81249516\n",
      "Iteration 44, loss = 0.81496320\n",
      "Iteration 45, loss = 0.79810141\n",
      "Iteration 46, loss = 0.83328786\n",
      "Iteration 31, loss = 0.83608808\n",
      "Iteration 32, loss = 0.86134823\n",
      "Iteration 33, loss = 0.86272810\n",
      "Iteration 34, loss = 0.84644141\n",
      "Iteration 35, loss = 0.83452068\n",
      "Iteration 36, loss = 0.90361848\n",
      "Iteration 37, loss = 0.85600643\n",
      "Iteration 38, loss = 0.86957270\n",
      "Iteration 39, loss = 0.82912394\n",
      "Iteration 40, loss = 0.84408321\n",
      "Iteration 41, loss = 0.81991040\n",
      "Iteration 42, loss = 0.81543029\n",
      "Iteration 43, loss = 0.81249516\n",
      "Iteration 44, loss = 0.81496320\n",
      "Iteration 45, loss = 0.79810141\n",
      "Iteration 46, loss = 0.83328786\n",
      "Iteration 47, loss = 0.84261507\n",
      "Iteration 48, loss = 0.87136771\n",
      "Iteration 49, loss = 0.87201439\n",
      "Iteration 50, loss = 0.81030409\n",
      "Iteration 1, loss = 1.22663043\n",
      "Iteration 2, loss = 1.09302757\n",
      "Iteration 3, loss = 1.02386672\n",
      "Iteration 4, loss = 0.98064216\n",
      "Iteration 5, loss = 0.97881386\n",
      "Iteration 6, loss = 0.95220089\n",
      "Iteration 7, loss = 0.93722982\n",
      "Iteration 8, loss = 0.99056637\n",
      "Iteration 9, loss = 0.93305569\n",
      "Iteration 10, loss = 0.94732906\n",
      "Iteration 47, loss = 0.84261507\n",
      "Iteration 48, loss = 0.87136771\n",
      "Iteration 49, loss = 0.87201439\n",
      "Iteration 50, loss = 0.81030409\n",
      "Iteration 1, loss = 1.22663043\n",
      "Iteration 2, loss = 1.09302757\n",
      "Iteration 3, loss = 1.02386672\n",
      "Iteration 4, loss = 0.98064216\n",
      "Iteration 5, loss = 0.97881386\n",
      "Iteration 6, loss = 0.95220089\n",
      "Iteration 7, loss = 0.93722982\n",
      "Iteration 8, loss = 0.99056637\n",
      "Iteration 9, loss = 0.93305569\n",
      "Iteration 10, loss = 0.94732906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.95990377\n",
      "Iteration 12, loss = 1.00765726\n",
      "Iteration 13, loss = 0.94796912\n",
      "Iteration 14, loss = 0.90881125\n",
      "Iteration 15, loss = 0.92310978\n",
      "Iteration 16, loss = 0.90578696\n",
      "Iteration 17, loss = 0.88355465\n",
      "Iteration 18, loss = 0.90677012\n",
      "Iteration 19, loss = 0.90075712\n",
      "Iteration 20, loss = 0.89060735\n",
      "Iteration 21, loss = 0.88010071\n",
      "Iteration 22, loss = 0.96309849\n",
      "Iteration 23, loss = 0.97937316\n",
      "Iteration 24, loss = 0.88259764\n",
      "Iteration 25, loss = 0.89330407\n",
      "Iteration 26, loss = 0.85375849\n",
      "Iteration 11, loss = 0.95990377\n",
      "Iteration 12, loss = 1.00765726\n",
      "Iteration 13, loss = 0.94796912\n",
      "Iteration 14, loss = 0.90881125\n",
      "Iteration 15, loss = 0.92310978\n",
      "Iteration 16, loss = 0.90578696\n",
      "Iteration 17, loss = 0.88355465\n",
      "Iteration 18, loss = 0.90677012\n",
      "Iteration 19, loss = 0.90075712\n",
      "Iteration 20, loss = 0.89060735\n",
      "Iteration 21, loss = 0.88010071\n",
      "Iteration 22, loss = 0.96309849\n",
      "Iteration 23, loss = 0.97937316\n",
      "Iteration 24, loss = 0.88259764\n",
      "Iteration 25, loss = 0.89330407\n",
      "Iteration 26, loss = 0.85375849\n",
      "Iteration 27, loss = 0.88324047\n",
      "Iteration 28, loss = 0.87366150\n",
      "Iteration 29, loss = 0.84382925\n",
      "Iteration 30, loss = 0.86221453\n",
      "Iteration 31, loss = 0.85801273\n",
      "Iteration 32, loss = 0.84841018\n",
      "Iteration 33, loss = 0.83470616\n",
      "Iteration 34, loss = 0.83141565\n",
      "Iteration 35, loss = 0.84748888\n",
      "Iteration 36, loss = 0.83812311\n",
      "Iteration 37, loss = 0.83902854\n",
      "Iteration 38, loss = 0.81627603\n",
      "Iteration 39, loss = 0.85667488\n",
      "Iteration 40, loss = 0.81047072\n",
      "Iteration 41, loss = 0.81446941\n",
      "Iteration 42, loss = 0.87220411\n",
      "Iteration 27, loss = 0.88324047\n",
      "Iteration 28, loss = 0.87366150\n",
      "Iteration 29, loss = 0.84382925\n",
      "Iteration 30, loss = 0.86221453\n",
      "Iteration 31, loss = 0.85801273\n",
      "Iteration 32, loss = 0.84841018\n",
      "Iteration 33, loss = 0.83470616\n",
      "Iteration 34, loss = 0.83141565\n",
      "Iteration 35, loss = 0.84748888\n",
      "Iteration 36, loss = 0.83812311\n",
      "Iteration 37, loss = 0.83902854\n",
      "Iteration 38, loss = 0.81627603\n",
      "Iteration 39, loss = 0.85667488\n",
      "Iteration 40, loss = 0.81047072\n",
      "Iteration 41, loss = 0.81446941\n",
      "Iteration 42, loss = 0.87220411\n",
      "Iteration 43, loss = 0.84268893\n",
      "Iteration 44, loss = 0.86092395\n",
      "Iteration 45, loss = 0.86989138\n",
      "Iteration 46, loss = 0.82851110\n",
      "Iteration 47, loss = 0.81837158\n",
      "Iteration 48, loss = 0.79982789\n",
      "Iteration 49, loss = 0.81835442\n",
      "Iteration 50, loss = 0.78686412\n",
      "Iteration 1, loss = 1.26794535\n",
      "Iteration 2, loss = 1.10191499\n",
      "Iteration 3, loss = 1.08100904\n",
      "Iteration 4, loss = 1.00902034\n",
      "Iteration 5, loss = 0.99570202\n",
      "Iteration 6, loss = 1.03065174\n",
      "Iteration 43, loss = 0.84268893\n",
      "Iteration 44, loss = 0.86092395\n",
      "Iteration 45, loss = 0.86989138\n",
      "Iteration 46, loss = 0.82851110\n",
      "Iteration 47, loss = 0.81837158\n",
      "Iteration 48, loss = 0.79982789\n",
      "Iteration 49, loss = 0.81835442\n",
      "Iteration 50, loss = 0.78686412\n",
      "Iteration 1, loss = 1.26794535\n",
      "Iteration 2, loss = 1.10191499\n",
      "Iteration 3, loss = 1.08100904\n",
      "Iteration 4, loss = 1.00902034\n",
      "Iteration 5, loss = 0.99570202\n",
      "Iteration 6, loss = 1.03065174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.04772946\n",
      "Iteration 8, loss = 0.99898002\n",
      "Iteration 9, loss = 1.00049947\n",
      "Iteration 10, loss = 0.97062053\n",
      "Iteration 11, loss = 0.99306951\n",
      "Iteration 12, loss = 1.00122994\n",
      "Iteration 13, loss = 0.97722782\n",
      "Iteration 14, loss = 0.96198786\n",
      "Iteration 15, loss = 0.99197088\n",
      "Iteration 16, loss = 0.94729358\n",
      "Iteration 17, loss = 0.93100009\n",
      "Iteration 18, loss = 0.96553007\n",
      "Iteration 19, loss = 0.92935604\n",
      "Iteration 20, loss = 1.01114320\n",
      "Iteration 21, loss = 0.94057039\n",
      "Iteration 7, loss = 1.04772946\n",
      "Iteration 8, loss = 0.99898002\n",
      "Iteration 9, loss = 1.00049947\n",
      "Iteration 10, loss = 0.97062053\n",
      "Iteration 11, loss = 0.99306951\n",
      "Iteration 12, loss = 1.00122994\n",
      "Iteration 13, loss = 0.97722782\n",
      "Iteration 14, loss = 0.96198786\n",
      "Iteration 15, loss = 0.99197088\n",
      "Iteration 16, loss = 0.94729358\n",
      "Iteration 17, loss = 0.93100009\n",
      "Iteration 18, loss = 0.96553007\n",
      "Iteration 19, loss = 0.92935604\n",
      "Iteration 20, loss = 1.01114320\n",
      "Iteration 21, loss = 0.94057039\n",
      "Iteration 22, loss = 0.92055466\n",
      "Iteration 23, loss = 0.99606318\n",
      "Iteration 24, loss = 0.92895978\n",
      "Iteration 25, loss = 0.88485902\n",
      "Iteration 26, loss = 0.92993684\n",
      "Iteration 27, loss = 0.93428836\n",
      "Iteration 28, loss = 0.89781432\n",
      "Iteration 29, loss = 0.89016437\n",
      "Iteration 30, loss = 0.86382578\n",
      "Iteration 31, loss = 0.87265930\n",
      "Iteration 32, loss = 0.90582422\n",
      "Iteration 33, loss = 0.91381221\n",
      "Iteration 34, loss = 0.91118321\n",
      "Iteration 35, loss = 0.85737212\n",
      "Iteration 36, loss = 0.87454037\n",
      "Iteration 22, loss = 0.92055466\n",
      "Iteration 23, loss = 0.99606318\n",
      "Iteration 24, loss = 0.92895978\n",
      "Iteration 25, loss = 0.88485902\n",
      "Iteration 26, loss = 0.92993684\n",
      "Iteration 27, loss = 0.93428836\n",
      "Iteration 28, loss = 0.89781432\n",
      "Iteration 29, loss = 0.89016437\n",
      "Iteration 30, loss = 0.86382578\n",
      "Iteration 31, loss = 0.87265930\n",
      "Iteration 32, loss = 0.90582422\n",
      "Iteration 33, loss = 0.91381221\n",
      "Iteration 34, loss = 0.91118321\n",
      "Iteration 35, loss = 0.85737212\n",
      "Iteration 36, loss = 0.87454037\n",
      "Iteration 37, loss = 0.90349992\n",
      "Iteration 38, loss = 0.91582399\n",
      "Iteration 39, loss = 0.89309363\n",
      "Iteration 40, loss = 0.82339513\n",
      "Iteration 41, loss = 0.85369594\n",
      "Iteration 42, loss = 0.85027970\n",
      "Iteration 43, loss = 0.83152795\n",
      "Iteration 44, loss = 0.93728483\n",
      "Iteration 45, loss = 0.88318279\n",
      "Iteration 46, loss = 0.87125807\n",
      "Iteration 47, loss = 0.84852649\n",
      "Iteration 48, loss = 0.87119307\n",
      "Iteration 49, loss = 0.86145442\n",
      "Iteration 50, loss = 0.79987701\n",
      "Iteration 37, loss = 0.90349992\n",
      "Iteration 38, loss = 0.91582399\n",
      "Iteration 39, loss = 0.89309363\n",
      "Iteration 40, loss = 0.82339513\n",
      "Iteration 41, loss = 0.85369594\n",
      "Iteration 42, loss = 0.85027970\n",
      "Iteration 43, loss = 0.83152795\n",
      "Iteration 44, loss = 0.93728483\n",
      "Iteration 45, loss = 0.88318279\n",
      "Iteration 46, loss = 0.87125807\n",
      "Iteration 47, loss = 0.84852649\n",
      "Iteration 48, loss = 0.87119307\n",
      "Iteration 49, loss = 0.86145442\n",
      "Iteration 50, loss = 0.79987701\n",
      "Iteration 51, loss = 0.82758910\n",
      "Iteration 52, loss = 0.88213609\n",
      "Iteration 53, loss = 0.87276069\n",
      "Iteration 54, loss = 0.82962181\n",
      "Iteration 55, loss = 0.81202740\n",
      "Iteration 56, loss = 0.82131591\n",
      "Iteration 57, loss = 0.82952516\n",
      "Iteration 58, loss = 0.81231506\n",
      "Iteration 59, loss = 0.82805580\n",
      "Iteration 60, loss = 0.82183619\n",
      "Iteration 61, loss = 0.85959753\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25707860\n",
      "Iteration 2, loss = 1.03853886\n",
      "Iteration 3, loss = 1.00565381\n",
      "Iteration 4, loss = 0.96327088\n",
      "Iteration 51, loss = 0.82758910\n",
      "Iteration 52, loss = 0.88213609\n",
      "Iteration 53, loss = 0.87276069\n",
      "Iteration 54, loss = 0.82962181\n",
      "Iteration 55, loss = 0.81202740\n",
      "Iteration 56, loss = 0.82131591\n",
      "Iteration 57, loss = 0.82952516\n",
      "Iteration 58, loss = 0.81231506\n",
      "Iteration 59, loss = 0.82805580\n",
      "Iteration 60, loss = 0.82183619\n",
      "Iteration 61, loss = 0.85959753\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25707860\n",
      "Iteration 2, loss = 1.03853886\n",
      "Iteration 3, loss = 1.00565381\n",
      "Iteration 4, loss = 0.96327088\n",
      "Iteration 5, loss = 0.92140207\n",
      "Iteration 6, loss = 0.97240492\n",
      "Iteration 7, loss = 0.92866819\n",
      "Iteration 8, loss = 0.91126006\n",
      "Iteration 9, loss = 0.90886406\n",
      "Iteration 10, loss = 0.88593398\n",
      "Iteration 11, loss = 0.90888374\n",
      "Iteration 12, loss = 0.91216365\n",
      "Iteration 13, loss = 0.87825680\n",
      "Iteration 14, loss = 0.86477570\n",
      "Iteration 15, loss = 0.89512124\n",
      "Iteration 16, loss = 0.86677762\n",
      "Iteration 17, loss = 0.86442756\n",
      "Iteration 5, loss = 0.92140207\n",
      "Iteration 6, loss = 0.97240492\n",
      "Iteration 7, loss = 0.92866819\n",
      "Iteration 8, loss = 0.91126006\n",
      "Iteration 9, loss = 0.90886406\n",
      "Iteration 10, loss = 0.88593398\n",
      "Iteration 11, loss = 0.90888374\n",
      "Iteration 12, loss = 0.91216365\n",
      "Iteration 13, loss = 0.87825680\n",
      "Iteration 14, loss = 0.86477570\n",
      "Iteration 15, loss = 0.89512124\n",
      "Iteration 16, loss = 0.86677762\n",
      "Iteration 17, loss = 0.86442756\n",
      "Iteration 18, loss = 0.85187052\n",
      "Iteration 19, loss = 0.84493137\n",
      "Iteration 20, loss = 0.90975622\n",
      "Iteration 21, loss = 0.83830356\n",
      "Iteration 22, loss = 0.90213248\n",
      "Iteration 23, loss = 0.91120016\n",
      "Iteration 24, loss = 0.84385281\n",
      "Iteration 25, loss = 0.81118798\n",
      "Iteration 26, loss = 0.86145988\n",
      "Iteration 27, loss = 0.82268345\n",
      "Iteration 28, loss = 0.80809154\n",
      "Iteration 29, loss = 0.81424684\n",
      "Iteration 30, loss = 0.80083374\n",
      "Iteration 31, loss = 0.83431375\n",
      "Iteration 32, loss = 0.80995319\n",
      "Iteration 18, loss = 0.85187052\n",
      "Iteration 19, loss = 0.84493137\n",
      "Iteration 20, loss = 0.90975622\n",
      "Iteration 21, loss = 0.83830356\n",
      "Iteration 22, loss = 0.90213248\n",
      "Iteration 23, loss = 0.91120016\n",
      "Iteration 24, loss = 0.84385281\n",
      "Iteration 25, loss = 0.81118798\n",
      "Iteration 26, loss = 0.86145988\n",
      "Iteration 27, loss = 0.82268345\n",
      "Iteration 28, loss = 0.80809154\n",
      "Iteration 29, loss = 0.81424684\n",
      "Iteration 30, loss = 0.80083374\n",
      "Iteration 31, loss = 0.83431375\n",
      "Iteration 32, loss = 0.80995319\n",
      "Iteration 33, loss = 0.79338197\n",
      "Iteration 34, loss = 0.84867136\n",
      "Iteration 35, loss = 0.82016469\n",
      "Iteration 36, loss = 0.86383104\n",
      "Iteration 37, loss = 0.83555020\n",
      "Iteration 38, loss = 0.81585046\n",
      "Iteration 39, loss = 0.79592883\n",
      "Iteration 40, loss = 0.78226769\n",
      "Iteration 41, loss = 0.77232568\n",
      "Iteration 42, loss = 0.77850606\n",
      "Iteration 43, loss = 0.74006227\n",
      "Iteration 44, loss = 0.76554669\n",
      "Iteration 45, loss = 0.82043037\n",
      "Iteration 33, loss = 0.79338197\n",
      "Iteration 34, loss = 0.84867136\n",
      "Iteration 35, loss = 0.82016469\n",
      "Iteration 36, loss = 0.86383104\n",
      "Iteration 37, loss = 0.83555020\n",
      "Iteration 38, loss = 0.81585046\n",
      "Iteration 39, loss = 0.79592883\n",
      "Iteration 40, loss = 0.78226769\n",
      "Iteration 41, loss = 0.77232568\n",
      "Iteration 42, loss = 0.77850606\n",
      "Iteration 43, loss = 0.74006227\n",
      "Iteration 44, loss = 0.76554669\n",
      "Iteration 45, loss = 0.82043037\n",
      "Iteration 46, loss = 0.75702523\n",
      "Iteration 47, loss = 0.77380620\n",
      "Iteration 48, loss = 0.79103452\n",
      "Iteration 49, loss = 0.76612336\n",
      "Iteration 50, loss = 0.77588314\n",
      "Iteration 51, loss = 0.75887047\n",
      "Iteration 52, loss = 0.76102054\n",
      "Iteration 53, loss = 0.74869401\n",
      "Iteration 54, loss = 0.73358568\n",
      "Iteration 55, loss = 0.75746259\n",
      "Iteration 56, loss = 0.74766176\n",
      "Iteration 57, loss = 0.78092343\n",
      "Iteration 58, loss = 0.75283475\n",
      "Iteration 59, loss = 0.73962386\n",
      "Iteration 60, loss = 0.78530276\n",
      "Iteration 46, loss = 0.75702523\n",
      "Iteration 47, loss = 0.77380620\n",
      "Iteration 48, loss = 0.79103452\n",
      "Iteration 49, loss = 0.76612336\n",
      "Iteration 50, loss = 0.77588314\n",
      "Iteration 51, loss = 0.75887047\n",
      "Iteration 52, loss = 0.76102054\n",
      "Iteration 53, loss = 0.74869401\n",
      "Iteration 54, loss = 0.73358568\n",
      "Iteration 55, loss = 0.75746259\n",
      "Iteration 56, loss = 0.74766176\n",
      "Iteration 57, loss = 0.78092343\n",
      "Iteration 58, loss = 0.75283475\n",
      "Iteration 59, loss = 0.73962386\n",
      "Iteration 60, loss = 0.78530276\n",
      "Iteration 61, loss = 0.74131783\n",
      "Iteration 62, loss = 0.75525721\n",
      "Iteration 63, loss = 0.76116081\n",
      "Iteration 64, loss = 0.71972189\n",
      "Iteration 65, loss = 0.73490479\n",
      "Iteration 66, loss = 0.72984781\n",
      "Iteration 67, loss = 0.71235426\n",
      "Iteration 68, loss = 0.72991935\n",
      "Iteration 69, loss = 0.71160719\n",
      "Iteration 70, loss = 0.74176060\n",
      "Iteration 71, loss = 0.71539467\n",
      "Iteration 72, loss = 0.72169693\n",
      "Iteration 73, loss = 0.76099747\n",
      "Iteration 74, loss = 0.72967313\n",
      "Iteration 61, loss = 0.74131783\n",
      "Iteration 62, loss = 0.75525721\n",
      "Iteration 63, loss = 0.76116081\n",
      "Iteration 64, loss = 0.71972189\n",
      "Iteration 65, loss = 0.73490479\n",
      "Iteration 66, loss = 0.72984781\n",
      "Iteration 67, loss = 0.71235426\n",
      "Iteration 68, loss = 0.72991935\n",
      "Iteration 69, loss = 0.71160719\n",
      "Iteration 70, loss = 0.74176060\n",
      "Iteration 71, loss = 0.71539467\n",
      "Iteration 72, loss = 0.72169693\n",
      "Iteration 73, loss = 0.76099747\n",
      "Iteration 74, loss = 0.72967313\n",
      "Iteration 75, loss = 0.69753341\n",
      "Iteration 76, loss = 0.71387154\n",
      "Iteration 77, loss = 0.71661254\n",
      "Iteration 78, loss = 0.70851686\n",
      "Iteration 79, loss = 0.67015918\n",
      "Iteration 80, loss = 0.71752502\n",
      "Iteration 81, loss = 0.68930442\n",
      "Iteration 82, loss = 0.70650554\n",
      "Iteration 83, loss = 0.75763775\n",
      "Iteration 84, loss = 0.74682219\n",
      "Iteration 85, loss = 0.72177928\n",
      "Iteration 86, loss = 0.69323171\n",
      "Iteration 87, loss = 0.70575381\n",
      "Iteration 88, loss = 0.69541575\n",
      "Iteration 89, loss = 0.67752143\n",
      "Iteration 75, loss = 0.69753341\n",
      "Iteration 76, loss = 0.71387154\n",
      "Iteration 77, loss = 0.71661254\n",
      "Iteration 78, loss = 0.70851686\n",
      "Iteration 79, loss = 0.67015918\n",
      "Iteration 80, loss = 0.71752502\n",
      "Iteration 81, loss = 0.68930442\n",
      "Iteration 82, loss = 0.70650554\n",
      "Iteration 83, loss = 0.75763775\n",
      "Iteration 84, loss = 0.74682219\n",
      "Iteration 85, loss = 0.72177928\n",
      "Iteration 86, loss = 0.69323171\n",
      "Iteration 87, loss = 0.70575381\n",
      "Iteration 88, loss = 0.69541575\n",
      "Iteration 89, loss = 0.67752143\n",
      "Iteration 90, loss = 0.68958543\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25272258\n",
      "Iteration 2, loss = 1.09045852\n",
      "Iteration 3, loss = 1.04421704\n",
      "Iteration 4, loss = 1.02229839\n",
      "Iteration 5, loss = 1.02940129\n",
      "Iteration 6, loss = 1.00246248\n",
      "Iteration 7, loss = 0.99673957\n",
      "Iteration 8, loss = 0.97077803\n",
      "Iteration 9, loss = 0.96360330\n",
      "Iteration 10, loss = 0.96276783\n",
      "Iteration 11, loss = 0.92376681\n",
      "Iteration 12, loss = 0.95278644\n",
      "Iteration 13, loss = 0.97080242\n",
      "Iteration 90, loss = 0.68958543\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25272258\n",
      "Iteration 2, loss = 1.09045852\n",
      "Iteration 3, loss = 1.04421704\n",
      "Iteration 4, loss = 1.02229839\n",
      "Iteration 5, loss = 1.02940129\n",
      "Iteration 6, loss = 1.00246248\n",
      "Iteration 7, loss = 0.99673957\n",
      "Iteration 8, loss = 0.97077803\n",
      "Iteration 9, loss = 0.96360330\n",
      "Iteration 10, loss = 0.96276783\n",
      "Iteration 11, loss = 0.92376681\n",
      "Iteration 12, loss = 0.95278644\n",
      "Iteration 13, loss = 0.97080242\n",
      "Iteration 14, loss = 0.94264677\n",
      "Iteration 15, loss = 0.93510117\n",
      "Iteration 16, loss = 0.92716863\n",
      "Iteration 17, loss = 0.91923035\n",
      "Iteration 18, loss = 0.90506128\n",
      "Iteration 19, loss = 0.89458580\n",
      "Iteration 20, loss = 0.91744386\n",
      "Iteration 21, loss = 0.92805582\n",
      "Iteration 22, loss = 0.95446475\n",
      "Iteration 23, loss = 0.95088495\n",
      "Iteration 24, loss = 0.87543591\n",
      "Iteration 25, loss = 0.87503872\n",
      "Iteration 26, loss = 0.86386971\n",
      "Iteration 14, loss = 0.94264677\n",
      "Iteration 15, loss = 0.93510117\n",
      "Iteration 16, loss = 0.92716863\n",
      "Iteration 17, loss = 0.91923035\n",
      "Iteration 18, loss = 0.90506128\n",
      "Iteration 19, loss = 0.89458580\n",
      "Iteration 20, loss = 0.91744386\n",
      "Iteration 21, loss = 0.92805582\n",
      "Iteration 22, loss = 0.95446475\n",
      "Iteration 23, loss = 0.95088495\n",
      "Iteration 24, loss = 0.87543591\n",
      "Iteration 25, loss = 0.87503872\n",
      "Iteration 26, loss = 0.86386971\n",
      "Iteration 27, loss = 0.90058900\n",
      "Iteration 28, loss = 0.90221031\n",
      "Iteration 29, loss = 0.86272312\n",
      "Iteration 30, loss = 0.86556912\n",
      "Iteration 31, loss = 0.84725079\n",
      "Iteration 32, loss = 0.84580059\n",
      "Iteration 33, loss = 0.83004245\n",
      "Iteration 34, loss = 0.85885510\n",
      "Iteration 35, loss = 0.83334849\n",
      "Iteration 36, loss = 0.86311799\n",
      "Iteration 37, loss = 0.83013945\n",
      "Iteration 38, loss = 0.83863346\n",
      "Iteration 39, loss = 0.93036333\n",
      "Iteration 40, loss = 0.85293913\n",
      "Iteration 41, loss = 0.83665516\n",
      "Iteration 42, loss = 0.81870366\n",
      "Iteration 27, loss = 0.90058900\n",
      "Iteration 28, loss = 0.90221031\n",
      "Iteration 29, loss = 0.86272312\n",
      "Iteration 30, loss = 0.86556912\n",
      "Iteration 31, loss = 0.84725079\n",
      "Iteration 32, loss = 0.84580059\n",
      "Iteration 33, loss = 0.83004245\n",
      "Iteration 34, loss = 0.85885510\n",
      "Iteration 35, loss = 0.83334849\n",
      "Iteration 36, loss = 0.86311799\n",
      "Iteration 37, loss = 0.83013945\n",
      "Iteration 38, loss = 0.83863346\n",
      "Iteration 39, loss = 0.93036333\n",
      "Iteration 40, loss = 0.85293913\n",
      "Iteration 41, loss = 0.83665516\n",
      "Iteration 42, loss = 0.81870366\n",
      "Iteration 43, loss = 0.82463030\n",
      "Iteration 44, loss = 0.84282182\n",
      "Iteration 45, loss = 0.83655995\n",
      "Iteration 46, loss = 0.79892931\n",
      "Iteration 47, loss = 0.81222269\n",
      "Iteration 48, loss = 0.81904042\n",
      "Iteration 49, loss = 0.80400154\n",
      "Iteration 50, loss = 0.79774282\n",
      "Iteration 51, loss = 0.84162029\n",
      "Iteration 52, loss = 0.80306295\n",
      "Iteration 53, loss = 0.80699025\n",
      "Iteration 54, loss = 0.81742112\n",
      "Iteration 55, loss = 0.81960751\n",
      "Iteration 56, loss = 0.82651066\n",
      "Iteration 57, loss = 0.82680065\n",
      "Iteration 43, loss = 0.82463030\n",
      "Iteration 44, loss = 0.84282182\n",
      "Iteration 45, loss = 0.83655995\n",
      "Iteration 46, loss = 0.79892931\n",
      "Iteration 47, loss = 0.81222269\n",
      "Iteration 48, loss = 0.81904042\n",
      "Iteration 49, loss = 0.80400154\n",
      "Iteration 50, loss = 0.79774282\n",
      "Iteration 51, loss = 0.84162029\n",
      "Iteration 52, loss = 0.80306295\n",
      "Iteration 53, loss = 0.80699025\n",
      "Iteration 54, loss = 0.81742112\n",
      "Iteration 55, loss = 0.81960751\n",
      "Iteration 56, loss = 0.82651066\n",
      "Iteration 57, loss = 0.82680065\n",
      "Iteration 58, loss = 0.81414190\n",
      "Iteration 59, loss = 0.80667276\n",
      "Iteration 60, loss = 0.80349342\n",
      "Iteration 61, loss = 0.80031354\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23956856\n",
      "Iteration 2, loss = 1.11780402\n",
      "Iteration 3, loss = 1.04838035\n",
      "Iteration 4, loss = 1.01487693\n",
      "Iteration 5, loss = 0.99896192\n",
      "Iteration 6, loss = 0.99300091\n",
      "Iteration 7, loss = 0.98277593\n",
      "Iteration 8, loss = 0.98105041\n",
      "Iteration 58, loss = 0.81414190\n",
      "Iteration 59, loss = 0.80667276\n",
      "Iteration 60, loss = 0.80349342\n",
      "Iteration 61, loss = 0.80031354\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23956856\n",
      "Iteration 2, loss = 1.11780402\n",
      "Iteration 3, loss = 1.04838035\n",
      "Iteration 4, loss = 1.01487693\n",
      "Iteration 5, loss = 0.99896192\n",
      "Iteration 6, loss = 0.99300091\n",
      "Iteration 7, loss = 0.98277593\n",
      "Iteration 8, loss = 0.98105041\n",
      "Iteration 9, loss = 0.95665204\n",
      "Iteration 10, loss = 1.00932518\n",
      "Iteration 11, loss = 0.98942057\n",
      "Iteration 12, loss = 0.97582904\n",
      "Iteration 13, loss = 0.95477600\n",
      "Iteration 14, loss = 0.94331929\n",
      "Iteration 15, loss = 0.96528808\n",
      "Iteration 16, loss = 0.91684344\n",
      "Iteration 17, loss = 0.92279801\n",
      "Iteration 18, loss = 0.93697199\n",
      "Iteration 19, loss = 0.89817508\n",
      "Iteration 20, loss = 0.91823359\n",
      "Iteration 21, loss = 0.89011868\n",
      "Iteration 9, loss = 0.95665204\n",
      "Iteration 10, loss = 1.00932518\n",
      "Iteration 11, loss = 0.98942057\n",
      "Iteration 12, loss = 0.97582904\n",
      "Iteration 13, loss = 0.95477600\n",
      "Iteration 14, loss = 0.94331929\n",
      "Iteration 15, loss = 0.96528808\n",
      "Iteration 16, loss = 0.91684344\n",
      "Iteration 17, loss = 0.92279801\n",
      "Iteration 18, loss = 0.93697199\n",
      "Iteration 19, loss = 0.89817508\n",
      "Iteration 20, loss = 0.91823359\n",
      "Iteration 21, loss = 0.89011868\n",
      "Iteration 22, loss = 0.95170387\n",
      "Iteration 23, loss = 0.93427875\n",
      "Iteration 24, loss = 0.89709755\n",
      "Iteration 25, loss = 0.88275338\n",
      "Iteration 26, loss = 0.86711997\n",
      "Iteration 27, loss = 0.89644945\n",
      "Iteration 28, loss = 0.91838855\n",
      "Iteration 29, loss = 0.85275408\n",
      "Iteration 30, loss = 0.86739261\n",
      "Iteration 31, loss = 0.83608808\n",
      "Iteration 32, loss = 0.86134823\n",
      "Iteration 33, loss = 0.86272810\n",
      "Iteration 34, loss = 0.84644141\n",
      "Iteration 35, loss = 0.83452068\n",
      "Iteration 36, loss = 0.90361848\n",
      "Iteration 22, loss = 0.95170387\n",
      "Iteration 23, loss = 0.93427875\n",
      "Iteration 24, loss = 0.89709755\n",
      "Iteration 25, loss = 0.88275338\n",
      "Iteration 26, loss = 0.86711997\n",
      "Iteration 27, loss = 0.89644945\n",
      "Iteration 28, loss = 0.91838855\n",
      "Iteration 29, loss = 0.85275408\n",
      "Iteration 30, loss = 0.86739261\n",
      "Iteration 31, loss = 0.83608808\n",
      "Iteration 32, loss = 0.86134823\n",
      "Iteration 33, loss = 0.86272810\n",
      "Iteration 34, loss = 0.84644141\n",
      "Iteration 35, loss = 0.83452068\n",
      "Iteration 36, loss = 0.90361848\n",
      "Iteration 37, loss = 0.85600643\n",
      "Iteration 38, loss = 0.86957270\n",
      "Iteration 39, loss = 0.82912394\n",
      "Iteration 40, loss = 0.84408321\n",
      "Iteration 41, loss = 0.81991040\n",
      "Iteration 42, loss = 0.81543029\n",
      "Iteration 43, loss = 0.81249516\n",
      "Iteration 44, loss = 0.81496320\n",
      "Iteration 45, loss = 0.79810141\n",
      "Iteration 46, loss = 0.83328786\n",
      "Iteration 47, loss = 0.84261507\n",
      "Iteration 48, loss = 0.87136771\n",
      "Iteration 49, loss = 0.87201439\n",
      "Iteration 50, loss = 0.81030409\n",
      "Iteration 51, loss = 0.82249416\n",
      "Iteration 52, loss = 0.79807105\n",
      "Iteration 37, loss = 0.85600643\n",
      "Iteration 38, loss = 0.86957270\n",
      "Iteration 39, loss = 0.82912394\n",
      "Iteration 40, loss = 0.84408321\n",
      "Iteration 41, loss = 0.81991040\n",
      "Iteration 42, loss = 0.81543029\n",
      "Iteration 43, loss = 0.81249516\n",
      "Iteration 44, loss = 0.81496320\n",
      "Iteration 45, loss = 0.79810141\n",
      "Iteration 46, loss = 0.83328786\n",
      "Iteration 47, loss = 0.84261507\n",
      "Iteration 48, loss = 0.87136771\n",
      "Iteration 49, loss = 0.87201439\n",
      "Iteration 50, loss = 0.81030409\n",
      "Iteration 51, loss = 0.82249416\n",
      "Iteration 52, loss = 0.79807105\n",
      "Iteration 53, loss = 0.76572402\n",
      "Iteration 54, loss = 0.80713052\n",
      "Iteration 55, loss = 0.83127389\n",
      "Iteration 56, loss = 0.77377118\n",
      "Iteration 57, loss = 0.79389442\n",
      "Iteration 58, loss = 0.78323325\n",
      "Iteration 59, loss = 0.75534249\n",
      "Iteration 60, loss = 0.80627965\n",
      "Iteration 61, loss = 0.76610816\n",
      "Iteration 62, loss = 0.76250449\n",
      "Iteration 63, loss = 0.77385296\n",
      "Iteration 64, loss = 0.82799298\n",
      "Iteration 65, loss = 0.76657944\n",
      "Iteration 66, loss = 0.79107539\n",
      "Iteration 67, loss = 0.76498906\n",
      "Iteration 53, loss = 0.76572402\n",
      "Iteration 54, loss = 0.80713052\n",
      "Iteration 55, loss = 0.83127389\n",
      "Iteration 56, loss = 0.77377118\n",
      "Iteration 57, loss = 0.79389442\n",
      "Iteration 58, loss = 0.78323325\n",
      "Iteration 59, loss = 0.75534249\n",
      "Iteration 60, loss = 0.80627965\n",
      "Iteration 61, loss = 0.76610816\n",
      "Iteration 62, loss = 0.76250449\n",
      "Iteration 63, loss = 0.77385296\n",
      "Iteration 64, loss = 0.82799298\n",
      "Iteration 65, loss = 0.76657944\n",
      "Iteration 66, loss = 0.79107539\n",
      "Iteration 67, loss = 0.76498906\n",
      "Iteration 68, loss = 0.80441572\n",
      "Iteration 69, loss = 0.77833934\n",
      "Iteration 70, loss = 0.71415796\n",
      "Iteration 71, loss = 0.74873758\n",
      "Iteration 72, loss = 0.75078042\n",
      "Iteration 73, loss = 0.78468680\n",
      "Iteration 74, loss = 0.74127390\n",
      "Iteration 75, loss = 0.75666328\n",
      "Iteration 76, loss = 0.74620153\n",
      "Iteration 77, loss = 0.80000483\n",
      "Iteration 78, loss = 0.75085081\n",
      "Iteration 79, loss = 0.73483167\n",
      "Iteration 80, loss = 0.71205723\n",
      "Iteration 68, loss = 0.80441572\n",
      "Iteration 69, loss = 0.77833934\n",
      "Iteration 70, loss = 0.71415796\n",
      "Iteration 71, loss = 0.74873758\n",
      "Iteration 72, loss = 0.75078042\n",
      "Iteration 73, loss = 0.78468680\n",
      "Iteration 74, loss = 0.74127390\n",
      "Iteration 75, loss = 0.75666328\n",
      "Iteration 76, loss = 0.74620153\n",
      "Iteration 77, loss = 0.80000483\n",
      "Iteration 78, loss = 0.75085081\n",
      "Iteration 79, loss = 0.73483167\n",
      "Iteration 80, loss = 0.71205723\n",
      "Iteration 81, loss = 0.71748904\n",
      "Iteration 82, loss = 0.72888356\n",
      "Iteration 83, loss = 0.72998242\n",
      "Iteration 84, loss = 0.72938710\n",
      "Iteration 85, loss = 0.72054429\n",
      "Iteration 86, loss = 0.69977367\n",
      "Iteration 87, loss = 0.74142379\n",
      "Iteration 88, loss = 0.69936028\n",
      "Iteration 89, loss = 0.69355042\n",
      "Iteration 90, loss = 0.72162706\n",
      "Iteration 91, loss = 0.73266027\n",
      "Iteration 92, loss = 0.68517122\n",
      "Iteration 93, loss = 0.73540175\n",
      "Iteration 94, loss = 0.71756966\n",
      "Iteration 81, loss = 0.71748904\n",
      "Iteration 82, loss = 0.72888356\n",
      "Iteration 83, loss = 0.72998242\n",
      "Iteration 84, loss = 0.72938710\n",
      "Iteration 85, loss = 0.72054429\n",
      "Iteration 86, loss = 0.69977367\n",
      "Iteration 87, loss = 0.74142379\n",
      "Iteration 88, loss = 0.69936028\n",
      "Iteration 89, loss = 0.69355042\n",
      "Iteration 90, loss = 0.72162706\n",
      "Iteration 91, loss = 0.73266027\n",
      "Iteration 92, loss = 0.68517122\n",
      "Iteration 93, loss = 0.73540175\n",
      "Iteration 94, loss = 0.71756966\n",
      "Iteration 95, loss = 0.67911559\n",
      "Iteration 96, loss = 0.67254367\n",
      "Iteration 97, loss = 0.72958698\n",
      "Iteration 98, loss = 0.71653403\n",
      "Iteration 99, loss = 0.70928410\n",
      "Iteration 100, loss = 0.69991578\n",
      "Iteration 1, loss = 1.22663043\n",
      "Iteration 2, loss = 1.09302757\n",
      "Iteration 3, loss = 1.02386672\n",
      "Iteration 4, loss = 0.98064216\n",
      "Iteration 5, loss = 0.97881386\n",
      "Iteration 6, loss = 0.95220089\n",
      "Iteration 7, loss = 0.93722982\n",
      "Iteration 95, loss = 0.67911559\n",
      "Iteration 96, loss = 0.67254367\n",
      "Iteration 97, loss = 0.72958698\n",
      "Iteration 98, loss = 0.71653403\n",
      "Iteration 99, loss = 0.70928410\n",
      "Iteration 100, loss = 0.69991578\n",
      "Iteration 1, loss = 1.22663043\n",
      "Iteration 2, loss = 1.09302757\n",
      "Iteration 3, loss = 1.02386672\n",
      "Iteration 4, loss = 0.98064216\n",
      "Iteration 5, loss = 0.97881386\n",
      "Iteration 6, loss = 0.95220089\n",
      "Iteration 7, loss = 0.93722982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.99056637\n",
      "Iteration 9, loss = 0.93305569\n",
      "Iteration 10, loss = 0.94732906\n",
      "Iteration 11, loss = 0.95990377\n",
      "Iteration 12, loss = 1.00765726\n",
      "Iteration 13, loss = 0.94796912\n",
      "Iteration 14, loss = 0.90881125\n",
      "Iteration 15, loss = 0.92310978\n",
      "Iteration 16, loss = 0.90578696\n",
      "Iteration 17, loss = 0.88355465\n",
      "Iteration 18, loss = 0.90677012\n",
      "Iteration 19, loss = 0.90075712\n",
      "Iteration 20, loss = 0.89060735\n",
      "Iteration 21, loss = 0.88010071\n",
      "Iteration 22, loss = 0.96309849\n",
      "Iteration 23, loss = 0.97937316\n",
      "Iteration 8, loss = 0.99056637\n",
      "Iteration 9, loss = 0.93305569\n",
      "Iteration 10, loss = 0.94732906\n",
      "Iteration 11, loss = 0.95990377\n",
      "Iteration 12, loss = 1.00765726\n",
      "Iteration 13, loss = 0.94796912\n",
      "Iteration 14, loss = 0.90881125\n",
      "Iteration 15, loss = 0.92310978\n",
      "Iteration 16, loss = 0.90578696\n",
      "Iteration 17, loss = 0.88355465\n",
      "Iteration 18, loss = 0.90677012\n",
      "Iteration 19, loss = 0.90075712\n",
      "Iteration 20, loss = 0.89060735\n",
      "Iteration 21, loss = 0.88010071\n",
      "Iteration 22, loss = 0.96309849\n",
      "Iteration 23, loss = 0.97937316\n",
      "Iteration 24, loss = 0.88259764\n",
      "Iteration 25, loss = 0.89330407\n",
      "Iteration 26, loss = 0.85375849\n",
      "Iteration 27, loss = 0.88324047\n",
      "Iteration 28, loss = 0.87366150\n",
      "Iteration 29, loss = 0.84382925\n",
      "Iteration 30, loss = 0.86221453\n",
      "Iteration 31, loss = 0.85801273\n",
      "Iteration 32, loss = 0.84841018\n",
      "Iteration 33, loss = 0.83470616\n",
      "Iteration 34, loss = 0.83141565\n",
      "Iteration 35, loss = 0.84748888\n",
      "Iteration 36, loss = 0.83812311\n",
      "Iteration 37, loss = 0.83902854\n",
      "Iteration 24, loss = 0.88259764\n",
      "Iteration 25, loss = 0.89330407\n",
      "Iteration 26, loss = 0.85375849\n",
      "Iteration 27, loss = 0.88324047\n",
      "Iteration 28, loss = 0.87366150\n",
      "Iteration 29, loss = 0.84382925\n",
      "Iteration 30, loss = 0.86221453\n",
      "Iteration 31, loss = 0.85801273\n",
      "Iteration 32, loss = 0.84841018\n",
      "Iteration 33, loss = 0.83470616\n",
      "Iteration 34, loss = 0.83141565\n",
      "Iteration 35, loss = 0.84748888\n",
      "Iteration 36, loss = 0.83812311\n",
      "Iteration 37, loss = 0.83902854\n",
      "Iteration 38, loss = 0.81627603\n",
      "Iteration 39, loss = 0.85667488\n",
      "Iteration 40, loss = 0.81047072\n",
      "Iteration 41, loss = 0.81446941\n",
      "Iteration 42, loss = 0.87220411\n",
      "Iteration 43, loss = 0.84268893\n",
      "Iteration 44, loss = 0.86092395\n",
      "Iteration 45, loss = 0.86989138\n",
      "Iteration 46, loss = 0.82851110\n",
      "Iteration 47, loss = 0.81837158\n",
      "Iteration 48, loss = 0.79982789\n",
      "Iteration 49, loss = 0.81835442\n",
      "Iteration 50, loss = 0.78686412\n",
      "Iteration 51, loss = 0.79832117\n",
      "Iteration 38, loss = 0.81627603\n",
      "Iteration 39, loss = 0.85667488\n",
      "Iteration 40, loss = 0.81047072\n",
      "Iteration 41, loss = 0.81446941\n",
      "Iteration 42, loss = 0.87220411\n",
      "Iteration 43, loss = 0.84268893\n",
      "Iteration 44, loss = 0.86092395\n",
      "Iteration 45, loss = 0.86989138\n",
      "Iteration 46, loss = 0.82851110\n",
      "Iteration 47, loss = 0.81837158\n",
      "Iteration 48, loss = 0.79982789\n",
      "Iteration 49, loss = 0.81835442\n",
      "Iteration 50, loss = 0.78686412\n",
      "Iteration 51, loss = 0.79832117\n",
      "Iteration 52, loss = 0.80402381\n",
      "Iteration 53, loss = 0.84364034\n",
      "Iteration 54, loss = 0.82233308\n",
      "Iteration 55, loss = 0.79835137\n",
      "Iteration 56, loss = 0.81719263\n",
      "Iteration 57, loss = 0.80071998\n",
      "Iteration 58, loss = 0.78141421\n",
      "Iteration 59, loss = 0.87004334\n",
      "Iteration 60, loss = 0.81675454\n",
      "Iteration 61, loss = 0.83449665\n",
      "Iteration 62, loss = 0.78930070\n",
      "Iteration 63, loss = 0.79561315\n",
      "Iteration 64, loss = 0.83867873\n",
      "Iteration 65, loss = 0.79514197\n",
      "Iteration 66, loss = 0.78095408\n",
      "Iteration 67, loss = 0.80473115\n",
      "Iteration 52, loss = 0.80402381\n",
      "Iteration 53, loss = 0.84364034\n",
      "Iteration 54, loss = 0.82233308\n",
      "Iteration 55, loss = 0.79835137\n",
      "Iteration 56, loss = 0.81719263\n",
      "Iteration 57, loss = 0.80071998\n",
      "Iteration 58, loss = 0.78141421\n",
      "Iteration 59, loss = 0.87004334\n",
      "Iteration 60, loss = 0.81675454\n",
      "Iteration 61, loss = 0.83449665\n",
      "Iteration 62, loss = 0.78930070\n",
      "Iteration 63, loss = 0.79561315\n",
      "Iteration 64, loss = 0.83867873\n",
      "Iteration 65, loss = 0.79514197\n",
      "Iteration 66, loss = 0.78095408\n",
      "Iteration 67, loss = 0.80473115\n",
      "Iteration 68, loss = 0.83323199\n",
      "Iteration 69, loss = 0.78381541\n",
      "Iteration 70, loss = 0.78989339\n",
      "Iteration 71, loss = 0.80297445\n",
      "Iteration 72, loss = 0.79232401\n",
      "Iteration 73, loss = 0.78686814\n",
      "Iteration 74, loss = 0.78563812\n",
      "Iteration 75, loss = 0.78579510\n",
      "Iteration 76, loss = 0.77381913\n",
      "Iteration 77, loss = 0.76439342\n",
      "Iteration 78, loss = 0.78117937\n",
      "Iteration 79, loss = 0.79738234\n",
      "Iteration 80, loss = 0.77982876\n",
      "Iteration 81, loss = 0.77653829\n",
      "Iteration 82, loss = 0.79033534\n",
      "Iteration 68, loss = 0.83323199\n",
      "Iteration 69, loss = 0.78381541\n",
      "Iteration 70, loss = 0.78989339\n",
      "Iteration 71, loss = 0.80297445\n",
      "Iteration 72, loss = 0.79232401\n",
      "Iteration 73, loss = 0.78686814\n",
      "Iteration 74, loss = 0.78563812\n",
      "Iteration 75, loss = 0.78579510\n",
      "Iteration 76, loss = 0.77381913\n",
      "Iteration 77, loss = 0.76439342\n",
      "Iteration 78, loss = 0.78117937\n",
      "Iteration 79, loss = 0.79738234\n",
      "Iteration 80, loss = 0.77982876\n",
      "Iteration 81, loss = 0.77653829\n",
      "Iteration 82, loss = 0.79033534\n",
      "Iteration 83, loss = 0.78977739\n",
      "Iteration 84, loss = 0.77174242\n",
      "Iteration 85, loss = 0.77657831\n",
      "Iteration 86, loss = 0.75388145\n",
      "Iteration 87, loss = 0.77489638\n",
      "Iteration 88, loss = 0.78302242\n",
      "Iteration 89, loss = 0.78094501\n",
      "Iteration 90, loss = 0.75768232\n",
      "Iteration 91, loss = 0.75934354\n",
      "Iteration 92, loss = 0.79498139\n",
      "Iteration 93, loss = 0.81201562\n",
      "Iteration 94, loss = 0.75510758\n",
      "Iteration 95, loss = 0.76536186\n",
      "Iteration 96, loss = 0.80569402\n",
      "Iteration 97, loss = 0.78112551\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27635466\n",
      "Iteration 83, loss = 0.78977739\n",
      "Iteration 84, loss = 0.77174242\n",
      "Iteration 85, loss = 0.77657831\n",
      "Iteration 86, loss = 0.75388145\n",
      "Iteration 87, loss = 0.77489638\n",
      "Iteration 88, loss = 0.78302242\n",
      "Iteration 89, loss = 0.78094501\n",
      "Iteration 90, loss = 0.75768232\n",
      "Iteration 91, loss = 0.75934354\n",
      "Iteration 92, loss = 0.79498139\n",
      "Iteration 93, loss = 0.81201562\n",
      "Iteration 94, loss = 0.75510758\n",
      "Iteration 95, loss = 0.76536186\n",
      "Iteration 96, loss = 0.80569402\n",
      "Iteration 97, loss = 0.78112551\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27635466\n",
      "Iteration 2, loss = 1.14101065\n",
      "Iteration 3, loss = 1.16219802\n",
      "Iteration 4, loss = 1.04045614\n",
      "Iteration 5, loss = 1.00619346\n",
      "Iteration 6, loss = 1.05308627\n",
      "Iteration 7, loss = 1.12221102\n",
      "Iteration 8, loss = 1.04065084\n",
      "Iteration 9, loss = 0.99781776\n",
      "Iteration 10, loss = 0.97879065\n",
      "Iteration 1, loss = 1.29740861\n",
      "Iteration 2, loss = 1.07859727\n",
      "Iteration 3, loss = 1.02532204\n",
      "Iteration 2, loss = 1.14101065\n",
      "Iteration 3, loss = 1.16219802\n",
      "Iteration 4, loss = 1.04045614\n",
      "Iteration 5, loss = 1.00619346\n",
      "Iteration 6, loss = 1.05308627\n",
      "Iteration 7, loss = 1.12221102\n",
      "Iteration 8, loss = 1.04065084\n",
      "Iteration 9, loss = 0.99781776\n",
      "Iteration 10, loss = 0.97879065\n",
      "Iteration 1, loss = 1.29740861\n",
      "Iteration 2, loss = 1.07859727\n",
      "Iteration 3, loss = 1.02532204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.98779222\n",
      "Iteration 5, loss = 0.97605538\n",
      "Iteration 6, loss = 1.08224902\n",
      "Iteration 7, loss = 1.02597387\n",
      "Iteration 8, loss = 0.96042568\n",
      "Iteration 9, loss = 0.98056532\n",
      "Iteration 10, loss = 0.95794270\n",
      "Iteration 1, loss = 1.27907223\n",
      "Iteration 2, loss = 1.11971732\n",
      "Iteration 3, loss = 1.04017684\n",
      "Iteration 4, loss = 1.00511439\n",
      "Iteration 4, loss = 0.98779222\n",
      "Iteration 5, loss = 0.97605538\n",
      "Iteration 6, loss = 1.08224902\n",
      "Iteration 7, loss = 1.02597387\n",
      "Iteration 8, loss = 0.96042568\n",
      "Iteration 9, loss = 0.98056532\n",
      "Iteration 10, loss = 0.95794270\n",
      "Iteration 1, loss = 1.27907223\n",
      "Iteration 2, loss = 1.11971732\n",
      "Iteration 3, loss = 1.04017684\n",
      "Iteration 4, loss = 1.00511439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.01055155\n",
      "Iteration 6, loss = 1.05011455\n",
      "Iteration 7, loss = 0.98398336\n",
      "Iteration 8, loss = 0.97720969\n",
      "Iteration 9, loss = 0.95810845\n",
      "Iteration 10, loss = 1.01166025\n",
      "Iteration 1, loss = 1.25049210\n",
      "Iteration 2, loss = 1.31172531\n",
      "Iteration 3, loss = 1.24462960\n",
      "Iteration 4, loss = 1.25865971\n",
      "Iteration 5, loss = 1.24869188\n",
      "Iteration 6, loss = 1.26507956\n",
      "Iteration 7, loss = 1.24666810\n",
      "Iteration 8, loss = 1.24346538\n",
      "Iteration 9, loss = 1.24793530\n",
      "Iteration 5, loss = 1.01055155\n",
      "Iteration 6, loss = 1.05011455\n",
      "Iteration 7, loss = 0.98398336\n",
      "Iteration 8, loss = 0.97720969\n",
      "Iteration 9, loss = 0.95810845\n",
      "Iteration 10, loss = 1.01166025\n",
      "Iteration 1, loss = 1.25049210\n",
      "Iteration 2, loss = 1.31172531\n",
      "Iteration 3, loss = 1.24462960\n",
      "Iteration 4, loss = 1.25865971\n",
      "Iteration 5, loss = 1.24869188\n",
      "Iteration 6, loss = 1.26507956\n",
      "Iteration 7, loss = 1.24666810\n",
      "Iteration 8, loss = 1.24346538\n",
      "Iteration 9, loss = 1.24793530\n",
      "Iteration 10, loss = 1.25460298\n",
      "Iteration 1, loss = 1.24159380\n",
      "Iteration 2, loss = 1.15299959\n",
      "Iteration 3, loss = 1.08317889\n",
      "Iteration 4, loss = 1.06040190\n",
      "Iteration 5, loss = 1.04254791\n",
      "Iteration 6, loss = 1.02105735\n",
      "Iteration 7, loss = 1.01204170\n",
      "Iteration 8, loss = 1.05783031\n",
      "Iteration 9, loss = 0.97381273\n",
      "Iteration 10, loss = 1.02918850\n",
      "Iteration 1, loss = 1.27635466\n",
      "Iteration 2, loss = 1.14101065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25460298\n",
      "Iteration 1, loss = 1.24159380\n",
      "Iteration 2, loss = 1.15299959\n",
      "Iteration 3, loss = 1.08317889\n",
      "Iteration 4, loss = 1.06040190\n",
      "Iteration 5, loss = 1.04254791\n",
      "Iteration 6, loss = 1.02105735\n",
      "Iteration 7, loss = 1.01204170\n",
      "Iteration 8, loss = 1.05783031\n",
      "Iteration 9, loss = 0.97381273\n",
      "Iteration 10, loss = 1.02918850\n",
      "Iteration 1, loss = 1.27635466\n",
      "Iteration 2, loss = 1.14101065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.16219802\n",
      "Iteration 4, loss = 1.04045614\n",
      "Iteration 5, loss = 1.00619346\n",
      "Iteration 6, loss = 1.05308627\n",
      "Iteration 7, loss = 1.12221102\n",
      "Iteration 8, loss = 1.04065084\n",
      "Iteration 9, loss = 0.99781776\n",
      "Iteration 10, loss = 0.97879065\n",
      "Iteration 11, loss = 1.00895149\n",
      "Iteration 12, loss = 0.97611345\n",
      "Iteration 13, loss = 0.99646046\n",
      "Iteration 14, loss = 0.98728685\n",
      "Iteration 15, loss = 0.98818666\n",
      "Iteration 16, loss = 1.02566436\n",
      "Iteration 17, loss = 1.03797107\n",
      "Iteration 3, loss = 1.16219802\n",
      "Iteration 4, loss = 1.04045614\n",
      "Iteration 5, loss = 1.00619346\n",
      "Iteration 6, loss = 1.05308627\n",
      "Iteration 7, loss = 1.12221102\n",
      "Iteration 8, loss = 1.04065084\n",
      "Iteration 9, loss = 0.99781776\n",
      "Iteration 10, loss = 0.97879065\n",
      "Iteration 11, loss = 1.00895149\n",
      "Iteration 12, loss = 0.97611345\n",
      "Iteration 13, loss = 0.99646046\n",
      "Iteration 14, loss = 0.98728685\n",
      "Iteration 15, loss = 0.98818666\n",
      "Iteration 16, loss = 1.02566436\n",
      "Iteration 17, loss = 1.03797107\n",
      "Iteration 18, loss = 1.05250741\n",
      "Iteration 19, loss = 1.11185720\n",
      "Iteration 20, loss = 1.03840345\n",
      "Iteration 21, loss = 1.04854596\n",
      "Iteration 22, loss = 1.01218296\n",
      "Iteration 23, loss = 1.06143046\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29740861\n",
      "Iteration 2, loss = 1.07859727\n",
      "Iteration 3, loss = 1.02532204\n",
      "Iteration 4, loss = 0.98779222\n",
      "Iteration 5, loss = 0.97605538\n",
      "Iteration 6, loss = 1.08224902\n",
      "Iteration 7, loss = 1.02597387\n",
      "Iteration 18, loss = 1.05250741\n",
      "Iteration 19, loss = 1.11185720\n",
      "Iteration 20, loss = 1.03840345\n",
      "Iteration 21, loss = 1.04854596\n",
      "Iteration 22, loss = 1.01218296\n",
      "Iteration 23, loss = 1.06143046\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29740861\n",
      "Iteration 2, loss = 1.07859727\n",
      "Iteration 3, loss = 1.02532204\n",
      "Iteration 4, loss = 0.98779222\n",
      "Iteration 5, loss = 0.97605538\n",
      "Iteration 6, loss = 1.08224902\n",
      "Iteration 7, loss = 1.02597387\n",
      "Iteration 8, loss = 0.96042568\n",
      "Iteration 9, loss = 0.98056532\n",
      "Iteration 10, loss = 0.95794270\n",
      "Iteration 11, loss = 0.97364160\n",
      "Iteration 12, loss = 0.93628555\n",
      "Iteration 13, loss = 0.96025125\n",
      "Iteration 14, loss = 0.93048696\n",
      "Iteration 15, loss = 0.92980956\n",
      "Iteration 16, loss = 0.93084648\n",
      "Iteration 17, loss = 0.92817924\n",
      "Iteration 18, loss = 0.91234537\n",
      "Iteration 19, loss = 1.00817107\n",
      "Iteration 20, loss = 1.03261744\n",
      "Iteration 21, loss = 0.94098339\n",
      "Iteration 22, loss = 0.92756835\n",
      "Iteration 23, loss = 0.93300801\n",
      "Iteration 8, loss = 0.96042568\n",
      "Iteration 9, loss = 0.98056532\n",
      "Iteration 10, loss = 0.95794270\n",
      "Iteration 11, loss = 0.97364160\n",
      "Iteration 12, loss = 0.93628555\n",
      "Iteration 13, loss = 0.96025125\n",
      "Iteration 14, loss = 0.93048696\n",
      "Iteration 15, loss = 0.92980956\n",
      "Iteration 16, loss = 0.93084648\n",
      "Iteration 17, loss = 0.92817924\n",
      "Iteration 18, loss = 0.91234537\n",
      "Iteration 19, loss = 1.00817107\n",
      "Iteration 20, loss = 1.03261744\n",
      "Iteration 21, loss = 0.94098339\n",
      "Iteration 22, loss = 0.92756835\n",
      "Iteration 23, loss = 0.93300801\n",
      "Iteration 24, loss = 0.91225220\n",
      "Iteration 25, loss = 0.92109622\n",
      "Iteration 26, loss = 0.92433589\n",
      "Iteration 27, loss = 0.92357219\n",
      "Iteration 28, loss = 0.91827321\n",
      "Iteration 29, loss = 0.91605734\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27907223\n",
      "Iteration 2, loss = 1.11971732\n",
      "Iteration 3, loss = 1.04017684\n",
      "Iteration 4, loss = 1.00511439\n",
      "Iteration 5, loss = 1.01055155\n",
      "Iteration 6, loss = 1.05011455\n",
      "Iteration 7, loss = 0.98398336\n",
      "Iteration 8, loss = 0.97720969\n",
      "Iteration 24, loss = 0.91225220\n",
      "Iteration 25, loss = 0.92109622\n",
      "Iteration 26, loss = 0.92433589\n",
      "Iteration 27, loss = 0.92357219\n",
      "Iteration 28, loss = 0.91827321\n",
      "Iteration 29, loss = 0.91605734\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27907223\n",
      "Iteration 2, loss = 1.11971732\n",
      "Iteration 3, loss = 1.04017684\n",
      "Iteration 4, loss = 1.00511439\n",
      "Iteration 5, loss = 1.01055155\n",
      "Iteration 6, loss = 1.05011455\n",
      "Iteration 7, loss = 0.98398336\n",
      "Iteration 8, loss = 0.97720969\n",
      "Iteration 9, loss = 0.95810845\n",
      "Iteration 10, loss = 1.01166025\n",
      "Iteration 11, loss = 0.98966506\n",
      "Iteration 12, loss = 0.96072793\n",
      "Iteration 13, loss = 1.00120695\n",
      "Iteration 14, loss = 1.04666543\n",
      "Iteration 15, loss = 0.94503346\n",
      "Iteration 16, loss = 0.95847688\n",
      "Iteration 17, loss = 0.97604467\n",
      "Iteration 18, loss = 0.95063725\n",
      "Iteration 19, loss = 0.98911057\n",
      "Iteration 20, loss = 1.03569193\n",
      "Iteration 21, loss = 0.98383476\n",
      "Iteration 22, loss = 0.96974150\n",
      "Iteration 23, loss = 0.97707051\n",
      "Iteration 9, loss = 0.95810845\n",
      "Iteration 10, loss = 1.01166025\n",
      "Iteration 11, loss = 0.98966506\n",
      "Iteration 12, loss = 0.96072793\n",
      "Iteration 13, loss = 1.00120695\n",
      "Iteration 14, loss = 1.04666543\n",
      "Iteration 15, loss = 0.94503346\n",
      "Iteration 16, loss = 0.95847688\n",
      "Iteration 17, loss = 0.97604467\n",
      "Iteration 18, loss = 0.95063725\n",
      "Iteration 19, loss = 0.98911057\n",
      "Iteration 20, loss = 1.03569193\n",
      "Iteration 21, loss = 0.98383476\n",
      "Iteration 22, loss = 0.96974150\n",
      "Iteration 23, loss = 0.97707051\n",
      "Iteration 24, loss = 1.01147016\n",
      "Iteration 25, loss = 0.94897146\n",
      "Iteration 26, loss = 0.97194598\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25049210\n",
      "Iteration 2, loss = 1.31172531\n",
      "Iteration 3, loss = 1.24462960\n",
      "Iteration 4, loss = 1.25865971\n",
      "Iteration 5, loss = 1.24869188\n",
      "Iteration 6, loss = 1.26507956\n",
      "Iteration 7, loss = 1.24666810\n",
      "Iteration 8, loss = 1.24346538\n",
      "Iteration 9, loss = 1.24793530\n",
      "Iteration 10, loss = 1.25460298\n",
      "Iteration 11, loss = 1.26093047\n",
      "Iteration 24, loss = 1.01147016\n",
      "Iteration 25, loss = 0.94897146\n",
      "Iteration 26, loss = 0.97194598\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25049210\n",
      "Iteration 2, loss = 1.31172531\n",
      "Iteration 3, loss = 1.24462960\n",
      "Iteration 4, loss = 1.25865971\n",
      "Iteration 5, loss = 1.24869188\n",
      "Iteration 6, loss = 1.26507956\n",
      "Iteration 7, loss = 1.24666810\n",
      "Iteration 8, loss = 1.24346538\n",
      "Iteration 9, loss = 1.24793530\n",
      "Iteration 10, loss = 1.25460298\n",
      "Iteration 11, loss = 1.26093047\n",
      "Iteration 12, loss = 1.24867614\n",
      "Iteration 13, loss = 1.24266187\n",
      "Iteration 14, loss = 1.24573426\n",
      "Iteration 15, loss = 1.24740398\n",
      "Iteration 16, loss = 1.24505832\n",
      "Iteration 17, loss = 1.23958674\n",
      "Iteration 18, loss = 1.24440353\n",
      "Iteration 19, loss = 1.23501902\n",
      "Iteration 20, loss = 1.25509184\n",
      "Iteration 21, loss = 1.24271254\n",
      "Iteration 22, loss = 1.25825986\n",
      "Iteration 23, loss = 1.24680918\n",
      "Iteration 24, loss = 1.24571744\n",
      "Iteration 25, loss = 1.25060051\n",
      "Iteration 12, loss = 1.24867614\n",
      "Iteration 13, loss = 1.24266187\n",
      "Iteration 14, loss = 1.24573426\n",
      "Iteration 15, loss = 1.24740398\n",
      "Iteration 16, loss = 1.24505832\n",
      "Iteration 17, loss = 1.23958674\n",
      "Iteration 18, loss = 1.24440353\n",
      "Iteration 19, loss = 1.23501902\n",
      "Iteration 20, loss = 1.25509184\n",
      "Iteration 21, loss = 1.24271254\n",
      "Iteration 22, loss = 1.25825986\n",
      "Iteration 23, loss = 1.24680918\n",
      "Iteration 24, loss = 1.24571744\n",
      "Iteration 25, loss = 1.25060051\n",
      "Iteration 26, loss = 1.24744103\n",
      "Iteration 27, loss = 1.24802862\n",
      "Iteration 28, loss = 1.25385817\n",
      "Iteration 29, loss = 1.24021018\n",
      "Iteration 30, loss = 1.26635686\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24159380\n",
      "Iteration 2, loss = 1.15299959\n",
      "Iteration 3, loss = 1.08317889\n",
      "Iteration 4, loss = 1.06040190\n",
      "Iteration 5, loss = 1.04254791\n",
      "Iteration 6, loss = 1.02105735\n",
      "Iteration 7, loss = 1.01204170\n",
      "Iteration 8, loss = 1.05783031\n",
      "Iteration 26, loss = 1.24744103\n",
      "Iteration 27, loss = 1.24802862\n",
      "Iteration 28, loss = 1.25385817\n",
      "Iteration 29, loss = 1.24021018\n",
      "Iteration 30, loss = 1.26635686\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24159380\n",
      "Iteration 2, loss = 1.15299959\n",
      "Iteration 3, loss = 1.08317889\n",
      "Iteration 4, loss = 1.06040190\n",
      "Iteration 5, loss = 1.04254791\n",
      "Iteration 6, loss = 1.02105735\n",
      "Iteration 7, loss = 1.01204170\n",
      "Iteration 8, loss = 1.05783031\n",
      "Iteration 9, loss = 0.97381273\n",
      "Iteration 10, loss = 1.02918850\n",
      "Iteration 11, loss = 1.04657241\n",
      "Iteration 12, loss = 1.01452695\n",
      "Iteration 13, loss = 0.99382567\n",
      "Iteration 14, loss = 0.99470170\n",
      "Iteration 15, loss = 1.07544585\n",
      "Iteration 16, loss = 0.99292085\n",
      "Iteration 17, loss = 0.97621940\n",
      "Iteration 18, loss = 1.05390203\n",
      "Iteration 19, loss = 0.97548327\n",
      "Iteration 20, loss = 0.99074087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27635466\n",
      "Iteration 2, loss = 1.14101065\n",
      "Iteration 3, loss = 1.16219802\n",
      "Iteration 9, loss = 0.97381273\n",
      "Iteration 10, loss = 1.02918850\n",
      "Iteration 11, loss = 1.04657241\n",
      "Iteration 12, loss = 1.01452695\n",
      "Iteration 13, loss = 0.99382567\n",
      "Iteration 14, loss = 0.99470170\n",
      "Iteration 15, loss = 1.07544585\n",
      "Iteration 16, loss = 0.99292085\n",
      "Iteration 17, loss = 0.97621940\n",
      "Iteration 18, loss = 1.05390203\n",
      "Iteration 19, loss = 0.97548327\n",
      "Iteration 20, loss = 0.99074087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27635466\n",
      "Iteration 2, loss = 1.14101065\n",
      "Iteration 3, loss = 1.16219802\n",
      "Iteration 4, loss = 1.04045614\n",
      "Iteration 5, loss = 1.00619346\n",
      "Iteration 6, loss = 1.05308627\n",
      "Iteration 7, loss = 1.12221102\n",
      "Iteration 8, loss = 1.04065084\n",
      "Iteration 9, loss = 0.99781776\n",
      "Iteration 10, loss = 0.97879065\n",
      "Iteration 11, loss = 1.00895149\n",
      "Iteration 12, loss = 0.97611345\n",
      "Iteration 13, loss = 0.99646046\n",
      "Iteration 14, loss = 0.98728685\n",
      "Iteration 15, loss = 0.98818666\n",
      "Iteration 16, loss = 1.02566436\n",
      "Iteration 4, loss = 1.04045614\n",
      "Iteration 5, loss = 1.00619346\n",
      "Iteration 6, loss = 1.05308627\n",
      "Iteration 7, loss = 1.12221102\n",
      "Iteration 8, loss = 1.04065084\n",
      "Iteration 9, loss = 0.99781776\n",
      "Iteration 10, loss = 0.97879065\n",
      "Iteration 11, loss = 1.00895149\n",
      "Iteration 12, loss = 0.97611345\n",
      "Iteration 13, loss = 0.99646046\n",
      "Iteration 14, loss = 0.98728685\n",
      "Iteration 15, loss = 0.98818666\n",
      "Iteration 16, loss = 1.02566436\n",
      "Iteration 17, loss = 1.03797107\n",
      "Iteration 18, loss = 1.05250741\n",
      "Iteration 19, loss = 1.11185720\n",
      "Iteration 20, loss = 1.03840345\n",
      "Iteration 21, loss = 1.04854596\n",
      "Iteration 22, loss = 1.01218296\n",
      "Iteration 23, loss = 1.06143046\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29740861\n",
      "Iteration 2, loss = 1.07859727\n",
      "Iteration 3, loss = 1.02532204\n",
      "Iteration 4, loss = 0.98779222\n",
      "Iteration 5, loss = 0.97605538\n",
      "Iteration 6, loss = 1.08224902\n",
      "Iteration 17, loss = 1.03797107\n",
      "Iteration 18, loss = 1.05250741\n",
      "Iteration 19, loss = 1.11185720\n",
      "Iteration 20, loss = 1.03840345\n",
      "Iteration 21, loss = 1.04854596\n",
      "Iteration 22, loss = 1.01218296\n",
      "Iteration 23, loss = 1.06143046\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29740861\n",
      "Iteration 2, loss = 1.07859727\n",
      "Iteration 3, loss = 1.02532204\n",
      "Iteration 4, loss = 0.98779222\n",
      "Iteration 5, loss = 0.97605538\n",
      "Iteration 6, loss = 1.08224902\n",
      "Iteration 7, loss = 1.02597387\n",
      "Iteration 8, loss = 0.96042568\n",
      "Iteration 9, loss = 0.98056532\n",
      "Iteration 10, loss = 0.95794270\n",
      "Iteration 11, loss = 0.97364160\n",
      "Iteration 12, loss = 0.93628555\n",
      "Iteration 13, loss = 0.96025125\n",
      "Iteration 14, loss = 0.93048696\n",
      "Iteration 15, loss = 0.92980956\n",
      "Iteration 16, loss = 0.93084648\n",
      "Iteration 17, loss = 0.92817924\n",
      "Iteration 18, loss = 0.91234537\n",
      "Iteration 19, loss = 1.00817107\n",
      "Iteration 20, loss = 1.03261744\n",
      "Iteration 7, loss = 1.02597387\n",
      "Iteration 8, loss = 0.96042568\n",
      "Iteration 9, loss = 0.98056532\n",
      "Iteration 10, loss = 0.95794270\n",
      "Iteration 11, loss = 0.97364160\n",
      "Iteration 12, loss = 0.93628555\n",
      "Iteration 13, loss = 0.96025125\n",
      "Iteration 14, loss = 0.93048696\n",
      "Iteration 15, loss = 0.92980956\n",
      "Iteration 16, loss = 0.93084648\n",
      "Iteration 17, loss = 0.92817924\n",
      "Iteration 18, loss = 0.91234537\n",
      "Iteration 19, loss = 1.00817107\n",
      "Iteration 20, loss = 1.03261744\n",
      "Iteration 21, loss = 0.94098339\n",
      "Iteration 22, loss = 0.92756835\n",
      "Iteration 23, loss = 0.93300801\n",
      "Iteration 24, loss = 0.91225220\n",
      "Iteration 25, loss = 0.92109622\n",
      "Iteration 26, loss = 0.92433589\n",
      "Iteration 27, loss = 0.92357219\n",
      "Iteration 28, loss = 0.91827321\n",
      "Iteration 29, loss = 0.91605734\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27907223\n",
      "Iteration 2, loss = 1.11971732\n",
      "Iteration 3, loss = 1.04017684\n",
      "Iteration 4, loss = 1.00511439\n",
      "Iteration 5, loss = 1.01055155\n",
      "Iteration 6, loss = 1.05011455\n",
      "Iteration 21, loss = 0.94098339\n",
      "Iteration 22, loss = 0.92756835\n",
      "Iteration 23, loss = 0.93300801\n",
      "Iteration 24, loss = 0.91225220\n",
      "Iteration 25, loss = 0.92109622\n",
      "Iteration 26, loss = 0.92433589\n",
      "Iteration 27, loss = 0.92357219\n",
      "Iteration 28, loss = 0.91827321\n",
      "Iteration 29, loss = 0.91605734\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27907223\n",
      "Iteration 2, loss = 1.11971732\n",
      "Iteration 3, loss = 1.04017684\n",
      "Iteration 4, loss = 1.00511439\n",
      "Iteration 5, loss = 1.01055155\n",
      "Iteration 6, loss = 1.05011455\n",
      "Iteration 7, loss = 0.98398336\n",
      "Iteration 8, loss = 0.97720969\n",
      "Iteration 9, loss = 0.95810845\n",
      "Iteration 10, loss = 1.01166025\n",
      "Iteration 11, loss = 0.98966506\n",
      "Iteration 12, loss = 0.96072793\n",
      "Iteration 13, loss = 1.00120695\n",
      "Iteration 14, loss = 1.04666543\n",
      "Iteration 15, loss = 0.94503346\n",
      "Iteration 16, loss = 0.95847688\n",
      "Iteration 17, loss = 0.97604467\n",
      "Iteration 18, loss = 0.95063725\n",
      "Iteration 19, loss = 0.98911057\n",
      "Iteration 20, loss = 1.03569193\n",
      "Iteration 21, loss = 0.98383476\n",
      "Iteration 7, loss = 0.98398336\n",
      "Iteration 8, loss = 0.97720969\n",
      "Iteration 9, loss = 0.95810845\n",
      "Iteration 10, loss = 1.01166025\n",
      "Iteration 11, loss = 0.98966506\n",
      "Iteration 12, loss = 0.96072793\n",
      "Iteration 13, loss = 1.00120695\n",
      "Iteration 14, loss = 1.04666543\n",
      "Iteration 15, loss = 0.94503346\n",
      "Iteration 16, loss = 0.95847688\n",
      "Iteration 17, loss = 0.97604467\n",
      "Iteration 18, loss = 0.95063725\n",
      "Iteration 19, loss = 0.98911057\n",
      "Iteration 20, loss = 1.03569193\n",
      "Iteration 21, loss = 0.98383476\n",
      "Iteration 22, loss = 0.96974150\n",
      "Iteration 23, loss = 0.97707051\n",
      "Iteration 24, loss = 1.01147016\n",
      "Iteration 25, loss = 0.94897146\n",
      "Iteration 26, loss = 0.97194598\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25049210\n",
      "Iteration 2, loss = 1.31172531\n",
      "Iteration 3, loss = 1.24462960\n",
      "Iteration 4, loss = 1.25865971\n",
      "Iteration 5, loss = 1.24869188\n",
      "Iteration 6, loss = 1.26507956\n",
      "Iteration 7, loss = 1.24666810\n",
      "Iteration 8, loss = 1.24346538\n",
      "Iteration 22, loss = 0.96974150\n",
      "Iteration 23, loss = 0.97707051\n",
      "Iteration 24, loss = 1.01147016\n",
      "Iteration 25, loss = 0.94897146\n",
      "Iteration 26, loss = 0.97194598\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25049210\n",
      "Iteration 2, loss = 1.31172531\n",
      "Iteration 3, loss = 1.24462960\n",
      "Iteration 4, loss = 1.25865971\n",
      "Iteration 5, loss = 1.24869188\n",
      "Iteration 6, loss = 1.26507956\n",
      "Iteration 7, loss = 1.24666810\n",
      "Iteration 8, loss = 1.24346538\n",
      "Iteration 9, loss = 1.24793530\n",
      "Iteration 10, loss = 1.25460298\n",
      "Iteration 11, loss = 1.26093047\n",
      "Iteration 12, loss = 1.24867614\n",
      "Iteration 13, loss = 1.24266187\n",
      "Iteration 14, loss = 1.24573426\n",
      "Iteration 15, loss = 1.24740398\n",
      "Iteration 16, loss = 1.24505832\n",
      "Iteration 17, loss = 1.23958674\n",
      "Iteration 18, loss = 1.24440353\n",
      "Iteration 19, loss = 1.23501902\n",
      "Iteration 20, loss = 1.25509184\n",
      "Iteration 21, loss = 1.24271254\n",
      "Iteration 22, loss = 1.25825986\n",
      "Iteration 23, loss = 1.24680918\n",
      "Iteration 24, loss = 1.24571744\n",
      "Iteration 9, loss = 1.24793530\n",
      "Iteration 10, loss = 1.25460298\n",
      "Iteration 11, loss = 1.26093047\n",
      "Iteration 12, loss = 1.24867614\n",
      "Iteration 13, loss = 1.24266187\n",
      "Iteration 14, loss = 1.24573426\n",
      "Iteration 15, loss = 1.24740398\n",
      "Iteration 16, loss = 1.24505832\n",
      "Iteration 17, loss = 1.23958674\n",
      "Iteration 18, loss = 1.24440353\n",
      "Iteration 19, loss = 1.23501902\n",
      "Iteration 20, loss = 1.25509184\n",
      "Iteration 21, loss = 1.24271254\n",
      "Iteration 22, loss = 1.25825986\n",
      "Iteration 23, loss = 1.24680918\n",
      "Iteration 24, loss = 1.24571744\n",
      "Iteration 25, loss = 1.25060051\n",
      "Iteration 26, loss = 1.24744103\n",
      "Iteration 27, loss = 1.24802862\n",
      "Iteration 28, loss = 1.25385817\n",
      "Iteration 29, loss = 1.24021018\n",
      "Iteration 30, loss = 1.26635686\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24159380\n",
      "Iteration 2, loss = 1.15299959\n",
      "Iteration 3, loss = 1.08317889\n",
      "Iteration 4, loss = 1.06040190\n",
      "Iteration 5, loss = 1.04254791\n",
      "Iteration 6, loss = 1.02105735\n",
      "Iteration 7, loss = 1.01204170\n",
      "Iteration 25, loss = 1.25060051\n",
      "Iteration 26, loss = 1.24744103\n",
      "Iteration 27, loss = 1.24802862\n",
      "Iteration 28, loss = 1.25385817\n",
      "Iteration 29, loss = 1.24021018\n",
      "Iteration 30, loss = 1.26635686\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24159380\n",
      "Iteration 2, loss = 1.15299959\n",
      "Iteration 3, loss = 1.08317889\n",
      "Iteration 4, loss = 1.06040190\n",
      "Iteration 5, loss = 1.04254791\n",
      "Iteration 6, loss = 1.02105735\n",
      "Iteration 7, loss = 1.01204170\n",
      "Iteration 8, loss = 1.05783031\n",
      "Iteration 9, loss = 0.97381273\n",
      "Iteration 10, loss = 1.02918850\n",
      "Iteration 11, loss = 1.04657241\n",
      "Iteration 12, loss = 1.01452695\n",
      "Iteration 13, loss = 0.99382567\n",
      "Iteration 14, loss = 0.99470170\n",
      "Iteration 15, loss = 1.07544585\n",
      "Iteration 16, loss = 0.99292085\n",
      "Iteration 17, loss = 0.97621940\n",
      "Iteration 18, loss = 1.05390203\n",
      "Iteration 19, loss = 0.97548327\n",
      "Iteration 20, loss = 0.99074087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28260275\n",
      "Iteration 2, loss = 1.25245741\n",
      "Iteration 8, loss = 1.05783031\n",
      "Iteration 9, loss = 0.97381273\n",
      "Iteration 10, loss = 1.02918850\n",
      "Iteration 11, loss = 1.04657241\n",
      "Iteration 12, loss = 1.01452695\n",
      "Iteration 13, loss = 0.99382567\n",
      "Iteration 14, loss = 0.99470170\n",
      "Iteration 15, loss = 1.07544585\n",
      "Iteration 16, loss = 0.99292085\n",
      "Iteration 17, loss = 0.97621940\n",
      "Iteration 18, loss = 1.05390203\n",
      "Iteration 19, loss = 0.97548327\n",
      "Iteration 20, loss = 0.99074087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28260275\n",
      "Iteration 2, loss = 1.25245741\n",
      "Iteration 3, loss = 1.24647536\n",
      "Iteration 4, loss = 1.24712100\n",
      "Iteration 5, loss = 1.25208635\n",
      "Iteration 6, loss = 1.25056367\n",
      "Iteration 7, loss = 1.24724045\n",
      "Iteration 8, loss = 1.25377074\n",
      "Iteration 9, loss = 1.24574607\n",
      "Iteration 10, loss = 1.23741578\n",
      "Iteration 1, loss = 1.29037587\n",
      "Iteration 2, loss = 1.11877772\n",
      "Iteration 3, loss = 1.14150391\n",
      "Iteration 4, loss = 1.02617463\n",
      "Iteration 5, loss = 1.25722471\n",
      "Iteration 6, loss = 1.27124666\n",
      "Iteration 3, loss = 1.24647536\n",
      "Iteration 4, loss = 1.24712100\n",
      "Iteration 5, loss = 1.25208635\n",
      "Iteration 6, loss = 1.25056367\n",
      "Iteration 7, loss = 1.24724045\n",
      "Iteration 8, loss = 1.25377074\n",
      "Iteration 9, loss = 1.24574607\n",
      "Iteration 10, loss = 1.23741578\n",
      "Iteration 1, loss = 1.29037587\n",
      "Iteration 2, loss = 1.11877772\n",
      "Iteration 3, loss = 1.14150391\n",
      "Iteration 4, loss = 1.02617463\n",
      "Iteration 5, loss = 1.25722471\n",
      "Iteration 6, loss = 1.27124666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.24322409\n",
      "Iteration 8, loss = 1.25042591\n",
      "Iteration 9, loss = 1.24815240\n",
      "Iteration 10, loss = 1.24753004\n",
      "Iteration 1, loss = 1.29768205\n",
      "Iteration 2, loss = 1.20696040\n",
      "Iteration 3, loss = 1.13416530\n",
      "Iteration 4, loss = 1.11037572\n",
      "Iteration 5, loss = 1.34800199\n",
      "Iteration 6, loss = 1.30014099\n",
      "Iteration 7, loss = 1.26411919\n",
      "Iteration 8, loss = 1.26450918\n",
      "Iteration 7, loss = 1.24322409\n",
      "Iteration 8, loss = 1.25042591\n",
      "Iteration 9, loss = 1.24815240\n",
      "Iteration 10, loss = 1.24753004\n",
      "Iteration 1, loss = 1.29768205\n",
      "Iteration 2, loss = 1.20696040\n",
      "Iteration 3, loss = 1.13416530\n",
      "Iteration 4, loss = 1.11037572\n",
      "Iteration 5, loss = 1.34800199\n",
      "Iteration 6, loss = 1.30014099\n",
      "Iteration 7, loss = 1.26411919\n",
      "Iteration 8, loss = 1.26450918\n",
      "Iteration 9, loss = 1.26006489\n",
      "Iteration 10, loss = 1.27247320\n",
      "Iteration 1, loss = 1.30210635\n",
      "Iteration 2, loss = 1.23211457\n",
      "Iteration 3, loss = 1.17143102\n",
      "Iteration 4, loss = 1.19723682\n",
      "Iteration 5, loss = 1.25818970\n",
      "Iteration 6, loss = 1.26778152\n",
      "Iteration 7, loss = 1.24459317\n",
      "Iteration 8, loss = 1.25581515\n",
      "Iteration 9, loss = 1.25430022\n",
      "Iteration 10, loss = 1.26708969\n",
      "Iteration 1, loss = 1.29366746\n",
      "Iteration 2, loss = 1.19290431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.26006489\n",
      "Iteration 10, loss = 1.27247320\n",
      "Iteration 1, loss = 1.30210635\n",
      "Iteration 2, loss = 1.23211457\n",
      "Iteration 3, loss = 1.17143102\n",
      "Iteration 4, loss = 1.19723682\n",
      "Iteration 5, loss = 1.25818970\n",
      "Iteration 6, loss = 1.26778152\n",
      "Iteration 7, loss = 1.24459317\n",
      "Iteration 8, loss = 1.25581515\n",
      "Iteration 9, loss = 1.25430022\n",
      "Iteration 10, loss = 1.26708969\n",
      "Iteration 1, loss = 1.29366746\n",
      "Iteration 2, loss = 1.19290431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.15262150\n",
      "Iteration 4, loss = 1.16673324\n",
      "Iteration 5, loss = 1.27300579\n",
      "Iteration 6, loss = 1.27807996\n",
      "Iteration 7, loss = 1.26347068\n",
      "Iteration 8, loss = 1.26093116\n",
      "Iteration 9, loss = 1.26023621\n",
      "Iteration 10, loss = 1.28827067\n",
      "Iteration 1, loss = 1.28260275\n",
      "Iteration 2, loss = 1.25245741\n",
      "Iteration 3, loss = 1.24647536\n",
      "Iteration 4, loss = 1.24712100\n",
      "Iteration 5, loss = 1.25208635\n",
      "Iteration 6, loss = 1.25056367\n",
      "Iteration 3, loss = 1.15262150\n",
      "Iteration 4, loss = 1.16673324\n",
      "Iteration 5, loss = 1.27300579\n",
      "Iteration 6, loss = 1.27807996\n",
      "Iteration 7, loss = 1.26347068\n",
      "Iteration 8, loss = 1.26093116\n",
      "Iteration 9, loss = 1.26023621\n",
      "Iteration 10, loss = 1.28827067\n",
      "Iteration 1, loss = 1.28260275\n",
      "Iteration 2, loss = 1.25245741\n",
      "Iteration 3, loss = 1.24647536\n",
      "Iteration 4, loss = 1.24712100\n",
      "Iteration 5, loss = 1.25208635\n",
      "Iteration 6, loss = 1.25056367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.24724045\n",
      "Iteration 8, loss = 1.25377074\n",
      "Iteration 9, loss = 1.24574607\n",
      "Iteration 10, loss = 1.23741578\n",
      "Iteration 11, loss = 1.24276481\n",
      "Iteration 12, loss = 1.26711162\n",
      "Iteration 13, loss = 1.24788281\n",
      "Iteration 14, loss = 1.24940796\n",
      "Iteration 15, loss = 1.24786160\n",
      "Iteration 16, loss = 1.24873778\n",
      "Iteration 17, loss = 1.25694478\n",
      "Iteration 18, loss = 1.25168696\n",
      "Iteration 19, loss = 1.24189822\n",
      "Iteration 20, loss = 1.25215696\n",
      "Iteration 21, loss = 1.25754167\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 7, loss = 1.24724045\n",
      "Iteration 8, loss = 1.25377074\n",
      "Iteration 9, loss = 1.24574607\n",
      "Iteration 10, loss = 1.23741578\n",
      "Iteration 11, loss = 1.24276481\n",
      "Iteration 12, loss = 1.26711162\n",
      "Iteration 13, loss = 1.24788281\n",
      "Iteration 14, loss = 1.24940796\n",
      "Iteration 15, loss = 1.24786160\n",
      "Iteration 16, loss = 1.24873778\n",
      "Iteration 17, loss = 1.25694478\n",
      "Iteration 18, loss = 1.25168696\n",
      "Iteration 19, loss = 1.24189822\n",
      "Iteration 20, loss = 1.25215696\n",
      "Iteration 21, loss = 1.25754167\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29037587\n",
      "Iteration 2, loss = 1.11877772\n",
      "Iteration 3, loss = 1.14150391\n",
      "Iteration 4, loss = 1.02617463\n",
      "Iteration 5, loss = 1.25722471\n",
      "Iteration 6, loss = 1.27124666\n",
      "Iteration 7, loss = 1.24322409\n",
      "Iteration 8, loss = 1.25042591\n",
      "Iteration 9, loss = 1.24815240\n",
      "Iteration 10, loss = 1.24753004\n",
      "Iteration 11, loss = 1.25309269\n",
      "Iteration 12, loss = 1.26595872\n",
      "Iteration 13, loss = 1.24168955\n",
      "Iteration 1, loss = 1.29037587\n",
      "Iteration 2, loss = 1.11877772\n",
      "Iteration 3, loss = 1.14150391\n",
      "Iteration 4, loss = 1.02617463\n",
      "Iteration 5, loss = 1.25722471\n",
      "Iteration 6, loss = 1.27124666\n",
      "Iteration 7, loss = 1.24322409\n",
      "Iteration 8, loss = 1.25042591\n",
      "Iteration 9, loss = 1.24815240\n",
      "Iteration 10, loss = 1.24753004\n",
      "Iteration 11, loss = 1.25309269\n",
      "Iteration 12, loss = 1.26595872\n",
      "Iteration 13, loss = 1.24168955\n",
      "Iteration 14, loss = 1.24697851\n",
      "Iteration 15, loss = 1.24739653\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29768205\n",
      "Iteration 2, loss = 1.20696040\n",
      "Iteration 3, loss = 1.13416530\n",
      "Iteration 4, loss = 1.11037572\n",
      "Iteration 5, loss = 1.34800199\n",
      "Iteration 6, loss = 1.30014099\n",
      "Iteration 7, loss = 1.26411919\n",
      "Iteration 8, loss = 1.26450918\n",
      "Iteration 9, loss = 1.26006489\n",
      "Iteration 10, loss = 1.27247320\n",
      "Iteration 11, loss = 1.26089260\n",
      "Iteration 14, loss = 1.24697851\n",
      "Iteration 15, loss = 1.24739653\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29768205\n",
      "Iteration 2, loss = 1.20696040\n",
      "Iteration 3, loss = 1.13416530\n",
      "Iteration 4, loss = 1.11037572\n",
      "Iteration 5, loss = 1.34800199\n",
      "Iteration 6, loss = 1.30014099\n",
      "Iteration 7, loss = 1.26411919\n",
      "Iteration 8, loss = 1.26450918\n",
      "Iteration 9, loss = 1.26006489\n",
      "Iteration 10, loss = 1.27247320\n",
      "Iteration 11, loss = 1.26089260\n",
      "Iteration 12, loss = 1.28033291\n",
      "Iteration 13, loss = 1.25404176\n",
      "Iteration 14, loss = 1.26562485\n",
      "Iteration 15, loss = 1.26723360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30210635\n",
      "Iteration 2, loss = 1.23211457\n",
      "Iteration 3, loss = 1.17143102\n",
      "Iteration 4, loss = 1.19723682\n",
      "Iteration 5, loss = 1.25818970\n",
      "Iteration 6, loss = 1.26778152\n",
      "Iteration 7, loss = 1.24459317\n",
      "Iteration 8, loss = 1.25581515\n",
      "Iteration 9, loss = 1.25430022\n",
      "Iteration 10, loss = 1.26708969\n",
      "Iteration 12, loss = 1.28033291\n",
      "Iteration 13, loss = 1.25404176\n",
      "Iteration 14, loss = 1.26562485\n",
      "Iteration 15, loss = 1.26723360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30210635\n",
      "Iteration 2, loss = 1.23211457\n",
      "Iteration 3, loss = 1.17143102\n",
      "Iteration 4, loss = 1.19723682\n",
      "Iteration 5, loss = 1.25818970\n",
      "Iteration 6, loss = 1.26778152\n",
      "Iteration 7, loss = 1.24459317\n",
      "Iteration 8, loss = 1.25581515\n",
      "Iteration 9, loss = 1.25430022\n",
      "Iteration 10, loss = 1.26708969\n",
      "Iteration 11, loss = 1.28144212\n",
      "Iteration 12, loss = 1.25441979\n",
      "Iteration 13, loss = 1.24421004\n",
      "Iteration 14, loss = 1.25279009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29366746\n",
      "Iteration 2, loss = 1.19290431\n",
      "Iteration 3, loss = 1.15262150\n",
      "Iteration 4, loss = 1.16673324\n",
      "Iteration 5, loss = 1.27300579\n",
      "Iteration 6, loss = 1.27807996\n",
      "Iteration 7, loss = 1.26347068\n",
      "Iteration 11, loss = 1.28144212\n",
      "Iteration 12, loss = 1.25441979\n",
      "Iteration 13, loss = 1.24421004\n",
      "Iteration 14, loss = 1.25279009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29366746\n",
      "Iteration 2, loss = 1.19290431\n",
      "Iteration 3, loss = 1.15262150\n",
      "Iteration 4, loss = 1.16673324\n",
      "Iteration 5, loss = 1.27300579\n",
      "Iteration 6, loss = 1.27807996\n",
      "Iteration 7, loss = 1.26347068\n",
      "Iteration 8, loss = 1.26093116\n",
      "Iteration 9, loss = 1.26023621\n",
      "Iteration 10, loss = 1.28827067\n",
      "Iteration 11, loss = 1.29096990\n",
      "Iteration 12, loss = 1.27101134\n",
      "Iteration 13, loss = 1.26273211\n",
      "Iteration 14, loss = 1.27011740\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28260275\n",
      "Iteration 2, loss = 1.25245741\n",
      "Iteration 3, loss = 1.24647536\n",
      "Iteration 4, loss = 1.24712100\n",
      "Iteration 5, loss = 1.25208635\n",
      "Iteration 8, loss = 1.26093116\n",
      "Iteration 9, loss = 1.26023621\n",
      "Iteration 10, loss = 1.28827067\n",
      "Iteration 11, loss = 1.29096990\n",
      "Iteration 12, loss = 1.27101134\n",
      "Iteration 13, loss = 1.26273211\n",
      "Iteration 14, loss = 1.27011740\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28260275\n",
      "Iteration 2, loss = 1.25245741\n",
      "Iteration 3, loss = 1.24647536\n",
      "Iteration 4, loss = 1.24712100\n",
      "Iteration 5, loss = 1.25208635\n",
      "Iteration 6, loss = 1.25056367\n",
      "Iteration 7, loss = 1.24724045\n",
      "Iteration 8, loss = 1.25377074\n",
      "Iteration 9, loss = 1.24574607\n",
      "Iteration 10, loss = 1.23741578\n",
      "Iteration 11, loss = 1.24276481\n",
      "Iteration 12, loss = 1.26711162\n",
      "Iteration 13, loss = 1.24788281\n",
      "Iteration 14, loss = 1.24940796\n",
      "Iteration 15, loss = 1.24786160\n",
      "Iteration 16, loss = 1.24873778\n",
      "Iteration 17, loss = 1.25694478\n",
      "Iteration 18, loss = 1.25168696\n",
      "Iteration 19, loss = 1.24189822\n",
      "Iteration 6, loss = 1.25056367\n",
      "Iteration 7, loss = 1.24724045\n",
      "Iteration 8, loss = 1.25377074\n",
      "Iteration 9, loss = 1.24574607\n",
      "Iteration 10, loss = 1.23741578\n",
      "Iteration 11, loss = 1.24276481\n",
      "Iteration 12, loss = 1.26711162\n",
      "Iteration 13, loss = 1.24788281\n",
      "Iteration 14, loss = 1.24940796\n",
      "Iteration 15, loss = 1.24786160\n",
      "Iteration 16, loss = 1.24873778\n",
      "Iteration 17, loss = 1.25694478\n",
      "Iteration 18, loss = 1.25168696\n",
      "Iteration 19, loss = 1.24189822\n",
      "Iteration 20, loss = 1.25215696\n",
      "Iteration 21, loss = 1.25754167\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29037587\n",
      "Iteration 2, loss = 1.11877772\n",
      "Iteration 3, loss = 1.14150391\n",
      "Iteration 4, loss = 1.02617463\n",
      "Iteration 5, loss = 1.25722471\n",
      "Iteration 6, loss = 1.27124666\n",
      "Iteration 7, loss = 1.24322409\n",
      "Iteration 8, loss = 1.25042591\n",
      "Iteration 9, loss = 1.24815240\n",
      "Iteration 10, loss = 1.24753004\n",
      "Iteration 20, loss = 1.25215696\n",
      "Iteration 21, loss = 1.25754167\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29037587\n",
      "Iteration 2, loss = 1.11877772\n",
      "Iteration 3, loss = 1.14150391\n",
      "Iteration 4, loss = 1.02617463\n",
      "Iteration 5, loss = 1.25722471\n",
      "Iteration 6, loss = 1.27124666\n",
      "Iteration 7, loss = 1.24322409\n",
      "Iteration 8, loss = 1.25042591\n",
      "Iteration 9, loss = 1.24815240\n",
      "Iteration 10, loss = 1.24753004\n",
      "Iteration 11, loss = 1.25309269\n",
      "Iteration 12, loss = 1.26595872\n",
      "Iteration 13, loss = 1.24168955\n",
      "Iteration 14, loss = 1.24697851\n",
      "Iteration 15, loss = 1.24739653\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29768205\n",
      "Iteration 2, loss = 1.20696040\n",
      "Iteration 3, loss = 1.13416530\n",
      "Iteration 4, loss = 1.11037572\n",
      "Iteration 5, loss = 1.34800199\n",
      "Iteration 6, loss = 1.30014099\n",
      "Iteration 7, loss = 1.26411919\n",
      "Iteration 8, loss = 1.26450918\n",
      "Iteration 11, loss = 1.25309269\n",
      "Iteration 12, loss = 1.26595872\n",
      "Iteration 13, loss = 1.24168955\n",
      "Iteration 14, loss = 1.24697851\n",
      "Iteration 15, loss = 1.24739653\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29768205\n",
      "Iteration 2, loss = 1.20696040\n",
      "Iteration 3, loss = 1.13416530\n",
      "Iteration 4, loss = 1.11037572\n",
      "Iteration 5, loss = 1.34800199\n",
      "Iteration 6, loss = 1.30014099\n",
      "Iteration 7, loss = 1.26411919\n",
      "Iteration 8, loss = 1.26450918\n",
      "Iteration 9, loss = 1.26006489\n",
      "Iteration 10, loss = 1.27247320\n",
      "Iteration 11, loss = 1.26089260\n",
      "Iteration 12, loss = 1.28033291\n",
      "Iteration 13, loss = 1.25404176\n",
      "Iteration 14, loss = 1.26562485\n",
      "Iteration 15, loss = 1.26723360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30210635\n",
      "Iteration 2, loss = 1.23211457\n",
      "Iteration 3, loss = 1.17143102\n",
      "Iteration 4, loss = 1.19723682\n",
      "Iteration 5, loss = 1.25818970\n",
      "Iteration 6, loss = 1.26778152\n",
      "Iteration 9, loss = 1.26006489\n",
      "Iteration 10, loss = 1.27247320\n",
      "Iteration 11, loss = 1.26089260\n",
      "Iteration 12, loss = 1.28033291\n",
      "Iteration 13, loss = 1.25404176\n",
      "Iteration 14, loss = 1.26562485\n",
      "Iteration 15, loss = 1.26723360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30210635\n",
      "Iteration 2, loss = 1.23211457\n",
      "Iteration 3, loss = 1.17143102\n",
      "Iteration 4, loss = 1.19723682\n",
      "Iteration 5, loss = 1.25818970\n",
      "Iteration 6, loss = 1.26778152\n",
      "Iteration 7, loss = 1.24459317\n",
      "Iteration 8, loss = 1.25581515\n",
      "Iteration 9, loss = 1.25430022\n",
      "Iteration 10, loss = 1.26708969\n",
      "Iteration 11, loss = 1.28144212\n",
      "Iteration 12, loss = 1.25441979\n",
      "Iteration 13, loss = 1.24421004\n",
      "Iteration 14, loss = 1.25279009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29366746\n",
      "Iteration 2, loss = 1.19290431\n",
      "Iteration 3, loss = 1.15262150\n",
      "Iteration 4, loss = 1.16673324\n",
      "Iteration 5, loss = 1.27300579\n",
      "Iteration 7, loss = 1.24459317\n",
      "Iteration 8, loss = 1.25581515\n",
      "Iteration 9, loss = 1.25430022\n",
      "Iteration 10, loss = 1.26708969\n",
      "Iteration 11, loss = 1.28144212\n",
      "Iteration 12, loss = 1.25441979\n",
      "Iteration 13, loss = 1.24421004\n",
      "Iteration 14, loss = 1.25279009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29366746\n",
      "Iteration 2, loss = 1.19290431\n",
      "Iteration 3, loss = 1.15262150\n",
      "Iteration 4, loss = 1.16673324\n",
      "Iteration 5, loss = 1.27300579\n",
      "Iteration 6, loss = 1.27807996\n",
      "Iteration 7, loss = 1.26347068\n",
      "Iteration 8, loss = 1.26093116\n",
      "Iteration 9, loss = 1.26023621\n",
      "Iteration 10, loss = 1.28827067\n",
      "Iteration 11, loss = 1.29096990\n",
      "Iteration 12, loss = 1.27101134\n",
      "Iteration 13, loss = 1.26273211\n",
      "Iteration 14, loss = 1.27011740\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28204002\n",
      "Iteration 2, loss = 1.25442661\n",
      "Iteration 3, loss = 1.25283131\n",
      "Iteration 4, loss = 1.24687688\n",
      "Iteration 6, loss = 1.27807996\n",
      "Iteration 7, loss = 1.26347068\n",
      "Iteration 8, loss = 1.26093116\n",
      "Iteration 9, loss = 1.26023621\n",
      "Iteration 10, loss = 1.28827067\n",
      "Iteration 11, loss = 1.29096990\n",
      "Iteration 12, loss = 1.27101134\n",
      "Iteration 13, loss = 1.26273211\n",
      "Iteration 14, loss = 1.27011740\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28204002\n",
      "Iteration 2, loss = 1.25442661\n",
      "Iteration 3, loss = 1.25283131\n",
      "Iteration 4, loss = 1.24687688\n",
      "Iteration 5, loss = 1.25727827\n",
      "Iteration 6, loss = 1.26006158\n",
      "Iteration 7, loss = 1.25322875\n",
      "Iteration 8, loss = 1.25724756\n",
      "Iteration 9, loss = 1.24625151\n",
      "Iteration 10, loss = 1.24029788\n",
      "Iteration 1, loss = 1.30942553\n",
      "Iteration 2, loss = 1.25680208\n",
      "Iteration 3, loss = 1.26515913\n",
      "Iteration 4, loss = 1.24305591\n",
      "Iteration 5, loss = 1.24033843\n",
      "Iteration 5, loss = 1.25727827\n",
      "Iteration 6, loss = 1.26006158\n",
      "Iteration 7, loss = 1.25322875\n",
      "Iteration 8, loss = 1.25724756\n",
      "Iteration 9, loss = 1.24625151\n",
      "Iteration 10, loss = 1.24029788\n",
      "Iteration 1, loss = 1.30942553\n",
      "Iteration 2, loss = 1.25680208\n",
      "Iteration 3, loss = 1.26515913\n",
      "Iteration 4, loss = 1.24305591\n",
      "Iteration 5, loss = 1.24033843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.26674902\n",
      "Iteration 7, loss = 1.23878945\n",
      "Iteration 8, loss = 1.24952250\n",
      "Iteration 9, loss = 1.24776419\n",
      "Iteration 10, loss = 1.24634133\n",
      "Iteration 1, loss = 1.31575204\n",
      "Iteration 2, loss = 1.26929171\n",
      "Iteration 3, loss = 1.27893912\n",
      "Iteration 4, loss = 1.26582292\n",
      "Iteration 5, loss = 1.26322160\n",
      "Iteration 6, loss = 1.28434415\n",
      "Iteration 7, loss = 1.26186880\n",
      "Iteration 8, loss = 1.26720192\n",
      "Iteration 9, loss = 1.26252955\n",
      "Iteration 6, loss = 1.26674902\n",
      "Iteration 7, loss = 1.23878945\n",
      "Iteration 8, loss = 1.24952250\n",
      "Iteration 9, loss = 1.24776419\n",
      "Iteration 10, loss = 1.24634133\n",
      "Iteration 1, loss = 1.31575204\n",
      "Iteration 2, loss = 1.26929171\n",
      "Iteration 3, loss = 1.27893912\n",
      "Iteration 4, loss = 1.26582292\n",
      "Iteration 5, loss = 1.26322160\n",
      "Iteration 6, loss = 1.28434415\n",
      "Iteration 7, loss = 1.26186880\n",
      "Iteration 8, loss = 1.26720192\n",
      "Iteration 9, loss = 1.26252955\n",
      "Iteration 10, loss = 1.27973481\n",
      "Iteration 1, loss = 1.31169511\n",
      "Iteration 2, loss = 1.26792186\n",
      "Iteration 3, loss = 1.25480756\n",
      "Iteration 4, loss = 1.26976619\n",
      "Iteration 5, loss = 1.25347248\n",
      "Iteration 6, loss = 1.26746366\n",
      "Iteration 7, loss = 1.26532934\n",
      "Iteration 8, loss = 1.25484133\n",
      "Iteration 9, loss = 1.25660281\n",
      "Iteration 10, loss = 1.28042244\n",
      "Iteration 1, loss = 1.31494517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.27973481\n",
      "Iteration 1, loss = 1.31169511\n",
      "Iteration 2, loss = 1.26792186\n",
      "Iteration 3, loss = 1.25480756\n",
      "Iteration 4, loss = 1.26976619\n",
      "Iteration 5, loss = 1.25347248\n",
      "Iteration 6, loss = 1.26746366\n",
      "Iteration 7, loss = 1.26532934\n",
      "Iteration 8, loss = 1.25484133\n",
      "Iteration 9, loss = 1.25660281\n",
      "Iteration 10, loss = 1.28042244\n",
      "Iteration 1, loss = 1.31494517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.27015850\n",
      "Iteration 3, loss = 1.30423287\n",
      "Iteration 4, loss = 1.28834918\n",
      "Iteration 5, loss = 1.26501954\n",
      "Iteration 6, loss = 1.27438978\n",
      "Iteration 7, loss = 1.26072776\n",
      "Iteration 8, loss = 1.26060129\n",
      "Iteration 9, loss = 1.25763076\n",
      "Iteration 10, loss = 1.29551494\n",
      "Iteration 1, loss = 1.28204002\n",
      "Iteration 2, loss = 1.25442661\n",
      "Iteration 3, loss = 1.25283131\n",
      "Iteration 4, loss = 1.24687688\n",
      "Iteration 2, loss = 1.27015850\n",
      "Iteration 3, loss = 1.30423287\n",
      "Iteration 4, loss = 1.28834918\n",
      "Iteration 5, loss = 1.26501954\n",
      "Iteration 6, loss = 1.27438978\n",
      "Iteration 7, loss = 1.26072776\n",
      "Iteration 8, loss = 1.26060129\n",
      "Iteration 9, loss = 1.25763076\n",
      "Iteration 10, loss = 1.29551494\n",
      "Iteration 1, loss = 1.28204002\n",
      "Iteration 2, loss = 1.25442661\n",
      "Iteration 3, loss = 1.25283131\n",
      "Iteration 4, loss = 1.24687688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.25727827\n",
      "Iteration 6, loss = 1.26006158\n",
      "Iteration 7, loss = 1.25322875\n",
      "Iteration 8, loss = 1.25724756\n",
      "Iteration 9, loss = 1.24625151\n",
      "Iteration 10, loss = 1.24029788\n",
      "Iteration 11, loss = 1.24418835\n",
      "Iteration 12, loss = 1.26945623\n",
      "Iteration 13, loss = 1.25716094\n",
      "Iteration 14, loss = 1.25601451\n",
      "Iteration 15, loss = 1.25271179\n",
      "Iteration 16, loss = 1.25482960\n",
      "Iteration 17, loss = 1.25919761\n",
      "Iteration 18, loss = 1.26068621\n",
      "Iteration 19, loss = 1.24687468\n",
      "Iteration 5, loss = 1.25727827\n",
      "Iteration 6, loss = 1.26006158\n",
      "Iteration 7, loss = 1.25322875\n",
      "Iteration 8, loss = 1.25724756\n",
      "Iteration 9, loss = 1.24625151\n",
      "Iteration 10, loss = 1.24029788\n",
      "Iteration 11, loss = 1.24418835\n",
      "Iteration 12, loss = 1.26945623\n",
      "Iteration 13, loss = 1.25716094\n",
      "Iteration 14, loss = 1.25601451\n",
      "Iteration 15, loss = 1.25271179\n",
      "Iteration 16, loss = 1.25482960\n",
      "Iteration 17, loss = 1.25919761\n",
      "Iteration 18, loss = 1.26068621\n",
      "Iteration 19, loss = 1.24687468\n",
      "Iteration 20, loss = 1.25877243\n",
      "Iteration 21, loss = 1.26555410\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30942553\n",
      "Iteration 2, loss = 1.25680208\n",
      "Iteration 3, loss = 1.26515913\n",
      "Iteration 4, loss = 1.24305591\n",
      "Iteration 5, loss = 1.24033843\n",
      "Iteration 6, loss = 1.26674902\n",
      "Iteration 7, loss = 1.23878945\n",
      "Iteration 8, loss = 1.24952250\n",
      "Iteration 9, loss = 1.24776419\n",
      "Iteration 10, loss = 1.24634133\n",
      "Iteration 11, loss = 1.25764092\n",
      "Iteration 12, loss = 1.26667500\n",
      "Iteration 20, loss = 1.25877243\n",
      "Iteration 21, loss = 1.26555410\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30942553\n",
      "Iteration 2, loss = 1.25680208\n",
      "Iteration 3, loss = 1.26515913\n",
      "Iteration 4, loss = 1.24305591\n",
      "Iteration 5, loss = 1.24033843\n",
      "Iteration 6, loss = 1.26674902\n",
      "Iteration 7, loss = 1.23878945\n",
      "Iteration 8, loss = 1.24952250\n",
      "Iteration 9, loss = 1.24776419\n",
      "Iteration 10, loss = 1.24634133\n",
      "Iteration 11, loss = 1.25764092\n",
      "Iteration 12, loss = 1.26667500\n",
      "Iteration 13, loss = 1.24359209\n",
      "Iteration 14, loss = 1.25089802\n",
      "Iteration 15, loss = 1.24534611\n",
      "Iteration 16, loss = 1.25416518\n",
      "Iteration 17, loss = 1.24352436\n",
      "Iteration 18, loss = 1.24135614\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31575204\n",
      "Iteration 2, loss = 1.26929171\n",
      "Iteration 3, loss = 1.27893912\n",
      "Iteration 4, loss = 1.26582292\n",
      "Iteration 5, loss = 1.26322160\n",
      "Iteration 6, loss = 1.28434415\n",
      "Iteration 7, loss = 1.26186880\n",
      "Iteration 8, loss = 1.26720192\n",
      "Iteration 9, loss = 1.26252955\n",
      "Iteration 13, loss = 1.24359209\n",
      "Iteration 14, loss = 1.25089802\n",
      "Iteration 15, loss = 1.24534611\n",
      "Iteration 16, loss = 1.25416518\n",
      "Iteration 17, loss = 1.24352436\n",
      "Iteration 18, loss = 1.24135614\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31575204\n",
      "Iteration 2, loss = 1.26929171\n",
      "Iteration 3, loss = 1.27893912\n",
      "Iteration 4, loss = 1.26582292\n",
      "Iteration 5, loss = 1.26322160\n",
      "Iteration 6, loss = 1.28434415\n",
      "Iteration 7, loss = 1.26186880\n",
      "Iteration 8, loss = 1.26720192\n",
      "Iteration 9, loss = 1.26252955\n",
      "Iteration 10, loss = 1.27973481\n",
      "Iteration 11, loss = 1.26457097\n",
      "Iteration 12, loss = 1.28055026\n",
      "Iteration 13, loss = 1.25083629\n",
      "Iteration 14, loss = 1.26730725\n",
      "Iteration 15, loss = 1.26831389\n",
      "Iteration 16, loss = 1.26031329\n",
      "Iteration 17, loss = 1.25713112\n",
      "Iteration 18, loss = 1.25211418\n",
      "Iteration 19, loss = 1.26049213\n",
      "Iteration 20, loss = 1.27241752\n",
      "Iteration 21, loss = 1.26591149\n",
      "Iteration 22, loss = 1.28721197\n",
      "Iteration 23, loss = 1.28501875\n",
      "Iteration 10, loss = 1.27973481\n",
      "Iteration 11, loss = 1.26457097\n",
      "Iteration 12, loss = 1.28055026\n",
      "Iteration 13, loss = 1.25083629\n",
      "Iteration 14, loss = 1.26730725\n",
      "Iteration 15, loss = 1.26831389\n",
      "Iteration 16, loss = 1.26031329\n",
      "Iteration 17, loss = 1.25713112\n",
      "Iteration 18, loss = 1.25211418\n",
      "Iteration 19, loss = 1.26049213\n",
      "Iteration 20, loss = 1.27241752\n",
      "Iteration 21, loss = 1.26591149\n",
      "Iteration 22, loss = 1.28721197\n",
      "Iteration 23, loss = 1.28501875\n",
      "Iteration 24, loss = 1.26283820\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31169511\n",
      "Iteration 2, loss = 1.26792186\n",
      "Iteration 3, loss = 1.25480756\n",
      "Iteration 4, loss = 1.26976619\n",
      "Iteration 5, loss = 1.25347248\n",
      "Iteration 6, loss = 1.26746366\n",
      "Iteration 7, loss = 1.26532934\n",
      "Iteration 8, loss = 1.25484133\n",
      "Iteration 9, loss = 1.25660281\n",
      "Iteration 10, loss = 1.28042244\n",
      "Iteration 11, loss = 1.29339671\n",
      "Iteration 12, loss = 1.25871115\n",
      "Iteration 24, loss = 1.26283820\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31169511\n",
      "Iteration 2, loss = 1.26792186\n",
      "Iteration 3, loss = 1.25480756\n",
      "Iteration 4, loss = 1.26976619\n",
      "Iteration 5, loss = 1.25347248\n",
      "Iteration 6, loss = 1.26746366\n",
      "Iteration 7, loss = 1.26532934\n",
      "Iteration 8, loss = 1.25484133\n",
      "Iteration 9, loss = 1.25660281\n",
      "Iteration 10, loss = 1.28042244\n",
      "Iteration 11, loss = 1.29339671\n",
      "Iteration 12, loss = 1.25871115\n",
      "Iteration 13, loss = 1.24358634\n",
      "Iteration 14, loss = 1.25314040\n",
      "Iteration 15, loss = 1.25743351\n",
      "Iteration 16, loss = 1.24893690\n",
      "Iteration 17, loss = 1.24658075\n",
      "Iteration 18, loss = 1.24945405\n",
      "Iteration 19, loss = 1.23824365\n",
      "Iteration 20, loss = 1.25559311\n",
      "Iteration 21, loss = 1.25412052\n",
      "Iteration 22, loss = 1.27760531\n",
      "Iteration 23, loss = 1.25512172\n",
      "Iteration 24, loss = 1.25486218\n",
      "Iteration 25, loss = 1.25465449\n",
      "Iteration 26, loss = 1.24792678\n",
      "Iteration 27, loss = 1.25222796\n",
      "Iteration 13, loss = 1.24358634\n",
      "Iteration 14, loss = 1.25314040\n",
      "Iteration 15, loss = 1.25743351\n",
      "Iteration 16, loss = 1.24893690\n",
      "Iteration 17, loss = 1.24658075\n",
      "Iteration 18, loss = 1.24945405\n",
      "Iteration 19, loss = 1.23824365\n",
      "Iteration 20, loss = 1.25559311\n",
      "Iteration 21, loss = 1.25412052\n",
      "Iteration 22, loss = 1.27760531\n",
      "Iteration 23, loss = 1.25512172\n",
      "Iteration 24, loss = 1.25486218\n",
      "Iteration 25, loss = 1.25465449\n",
      "Iteration 26, loss = 1.24792678\n",
      "Iteration 27, loss = 1.25222796\n",
      "Iteration 28, loss = 1.25633637\n",
      "Iteration 29, loss = 1.24385231\n",
      "Iteration 30, loss = 1.27594439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31494517\n",
      "Iteration 2, loss = 1.27015850\n",
      "Iteration 3, loss = 1.30423287\n",
      "Iteration 4, loss = 1.28834918\n",
      "Iteration 5, loss = 1.26501954\n",
      "Iteration 6, loss = 1.27438978\n",
      "Iteration 7, loss = 1.26072776\n",
      "Iteration 8, loss = 1.26060129\n",
      "Iteration 9, loss = 1.25763076\n",
      "Iteration 10, loss = 1.29551494\n",
      "Iteration 28, loss = 1.25633637\n",
      "Iteration 29, loss = 1.24385231\n",
      "Iteration 30, loss = 1.27594439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31494517\n",
      "Iteration 2, loss = 1.27015850\n",
      "Iteration 3, loss = 1.30423287\n",
      "Iteration 4, loss = 1.28834918\n",
      "Iteration 5, loss = 1.26501954\n",
      "Iteration 6, loss = 1.27438978\n",
      "Iteration 7, loss = 1.26072776\n",
      "Iteration 8, loss = 1.26060129\n",
      "Iteration 9, loss = 1.25763076\n",
      "Iteration 10, loss = 1.29551494\n",
      "Iteration 11, loss = 1.30089733\n",
      "Iteration 12, loss = 1.27191200\n",
      "Iteration 13, loss = 1.26307815\n",
      "Iteration 14, loss = 1.26490499\n",
      "Iteration 15, loss = 1.27206891\n",
      "Iteration 16, loss = 1.25740044\n",
      "Iteration 17, loss = 1.26006904\n",
      "Iteration 18, loss = 1.25740866\n",
      "Iteration 19, loss = 1.25728265\n",
      "Iteration 20, loss = 1.27513926\n",
      "Iteration 21, loss = 1.26961590\n",
      "Iteration 22, loss = 1.28384889\n",
      "Iteration 23, loss = 1.27884079\n",
      "Iteration 24, loss = 1.26356324\n",
      "Iteration 25, loss = 1.26279320\n",
      "Iteration 11, loss = 1.30089733\n",
      "Iteration 12, loss = 1.27191200\n",
      "Iteration 13, loss = 1.26307815\n",
      "Iteration 14, loss = 1.26490499\n",
      "Iteration 15, loss = 1.27206891\n",
      "Iteration 16, loss = 1.25740044\n",
      "Iteration 17, loss = 1.26006904\n",
      "Iteration 18, loss = 1.25740866\n",
      "Iteration 19, loss = 1.25728265\n",
      "Iteration 20, loss = 1.27513926\n",
      "Iteration 21, loss = 1.26961590\n",
      "Iteration 22, loss = 1.28384889\n",
      "Iteration 23, loss = 1.27884079\n",
      "Iteration 24, loss = 1.26356324\n",
      "Iteration 25, loss = 1.26279320\n",
      "Iteration 26, loss = 1.25927165\n",
      "Iteration 27, loss = 1.26903158\n",
      "Iteration 28, loss = 1.26865123\n",
      "Iteration 29, loss = 1.25697085\n",
      "Iteration 30, loss = 1.30024866\n",
      "Iteration 31, loss = 1.26450527\n",
      "Iteration 32, loss = 1.26479802\n",
      "Iteration 33, loss = 1.26179277\n",
      "Iteration 34, loss = 1.26818465\n",
      "Iteration 35, loss = 1.27231237\n",
      "Iteration 36, loss = 1.26879046\n",
      "Iteration 37, loss = 1.27270718\n",
      "Iteration 38, loss = 1.26896394\n",
      "Iteration 39, loss = 1.28009324\n",
      "Iteration 40, loss = 1.26794956\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 1.25927165\n",
      "Iteration 27, loss = 1.26903158\n",
      "Iteration 28, loss = 1.26865123\n",
      "Iteration 29, loss = 1.25697085\n",
      "Iteration 30, loss = 1.30024866\n",
      "Iteration 31, loss = 1.26450527\n",
      "Iteration 32, loss = 1.26479802\n",
      "Iteration 33, loss = 1.26179277\n",
      "Iteration 34, loss = 1.26818465\n",
      "Iteration 35, loss = 1.27231237\n",
      "Iteration 36, loss = 1.26879046\n",
      "Iteration 37, loss = 1.27270718\n",
      "Iteration 38, loss = 1.26896394\n",
      "Iteration 39, loss = 1.28009324\n",
      "Iteration 40, loss = 1.26794956\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28204002\n",
      "Iteration 2, loss = 1.25442661\n",
      "Iteration 3, loss = 1.25283131\n",
      "Iteration 4, loss = 1.24687688\n",
      "Iteration 5, loss = 1.25727827\n",
      "Iteration 6, loss = 1.26006158\n",
      "Iteration 7, loss = 1.25322875\n",
      "Iteration 8, loss = 1.25724756\n",
      "Iteration 9, loss = 1.24625151\n",
      "Iteration 10, loss = 1.24029788\n",
      "Iteration 11, loss = 1.24418835\n",
      "Iteration 12, loss = 1.26945623\n",
      "Iteration 13, loss = 1.25716094\n",
      "Iteration 1, loss = 1.28204002\n",
      "Iteration 2, loss = 1.25442661\n",
      "Iteration 3, loss = 1.25283131\n",
      "Iteration 4, loss = 1.24687688\n",
      "Iteration 5, loss = 1.25727827\n",
      "Iteration 6, loss = 1.26006158\n",
      "Iteration 7, loss = 1.25322875\n",
      "Iteration 8, loss = 1.25724756\n",
      "Iteration 9, loss = 1.24625151\n",
      "Iteration 10, loss = 1.24029788\n",
      "Iteration 11, loss = 1.24418835\n",
      "Iteration 12, loss = 1.26945623\n",
      "Iteration 13, loss = 1.25716094\n",
      "Iteration 14, loss = 1.25601451\n",
      "Iteration 15, loss = 1.25271179\n",
      "Iteration 16, loss = 1.25482960\n",
      "Iteration 17, loss = 1.25919761\n",
      "Iteration 18, loss = 1.26068621\n",
      "Iteration 19, loss = 1.24687468\n",
      "Iteration 20, loss = 1.25877243\n",
      "Iteration 21, loss = 1.26555410\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30942553\n",
      "Iteration 2, loss = 1.25680208\n",
      "Iteration 3, loss = 1.26515913\n",
      "Iteration 4, loss = 1.24305591\n",
      "Iteration 5, loss = 1.24033843\n",
      "Iteration 6, loss = 1.26674902\n",
      "Iteration 7, loss = 1.23878945\n",
      "Iteration 8, loss = 1.24952250\n",
      "Iteration 14, loss = 1.25601451\n",
      "Iteration 15, loss = 1.25271179\n",
      "Iteration 16, loss = 1.25482960\n",
      "Iteration 17, loss = 1.25919761\n",
      "Iteration 18, loss = 1.26068621\n",
      "Iteration 19, loss = 1.24687468\n",
      "Iteration 20, loss = 1.25877243\n",
      "Iteration 21, loss = 1.26555410\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30942553\n",
      "Iteration 2, loss = 1.25680208\n",
      "Iteration 3, loss = 1.26515913\n",
      "Iteration 4, loss = 1.24305591\n",
      "Iteration 5, loss = 1.24033843\n",
      "Iteration 6, loss = 1.26674902\n",
      "Iteration 7, loss = 1.23878945\n",
      "Iteration 8, loss = 1.24952250\n",
      "Iteration 9, loss = 1.24776419\n",
      "Iteration 10, loss = 1.24634133\n",
      "Iteration 11, loss = 1.25764092\n",
      "Iteration 12, loss = 1.26667500\n",
      "Iteration 13, loss = 1.24359209\n",
      "Iteration 14, loss = 1.25089802\n",
      "Iteration 15, loss = 1.24534611\n",
      "Iteration 16, loss = 1.25416518\n",
      "Iteration 17, loss = 1.24352436\n",
      "Iteration 18, loss = 1.24135614\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31575204\n",
      "Iteration 2, loss = 1.26929171\n",
      "Iteration 3, loss = 1.27893912\n",
      "Iteration 9, loss = 1.24776419\n",
      "Iteration 10, loss = 1.24634133\n",
      "Iteration 11, loss = 1.25764092\n",
      "Iteration 12, loss = 1.26667500\n",
      "Iteration 13, loss = 1.24359209\n",
      "Iteration 14, loss = 1.25089802\n",
      "Iteration 15, loss = 1.24534611\n",
      "Iteration 16, loss = 1.25416518\n",
      "Iteration 17, loss = 1.24352436\n",
      "Iteration 18, loss = 1.24135614\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31575204\n",
      "Iteration 2, loss = 1.26929171\n",
      "Iteration 3, loss = 1.27893912\n",
      "Iteration 4, loss = 1.26582292\n",
      "Iteration 5, loss = 1.26322160\n",
      "Iteration 6, loss = 1.28434415\n",
      "Iteration 7, loss = 1.26186880\n",
      "Iteration 8, loss = 1.26720192\n",
      "Iteration 9, loss = 1.26252955\n",
      "Iteration 10, loss = 1.27973481\n",
      "Iteration 11, loss = 1.26457097\n",
      "Iteration 12, loss = 1.28055026\n",
      "Iteration 13, loss = 1.25083629\n",
      "Iteration 14, loss = 1.26730725\n",
      "Iteration 15, loss = 1.26831389\n",
      "Iteration 16, loss = 1.26031329\n",
      "Iteration 4, loss = 1.26582292\n",
      "Iteration 5, loss = 1.26322160\n",
      "Iteration 6, loss = 1.28434415\n",
      "Iteration 7, loss = 1.26186880\n",
      "Iteration 8, loss = 1.26720192\n",
      "Iteration 9, loss = 1.26252955\n",
      "Iteration 10, loss = 1.27973481\n",
      "Iteration 11, loss = 1.26457097\n",
      "Iteration 12, loss = 1.28055026\n",
      "Iteration 13, loss = 1.25083629\n",
      "Iteration 14, loss = 1.26730725\n",
      "Iteration 15, loss = 1.26831389\n",
      "Iteration 16, loss = 1.26031329\n",
      "Iteration 17, loss = 1.25713112\n",
      "Iteration 18, loss = 1.25211418\n",
      "Iteration 19, loss = 1.26049213\n",
      "Iteration 20, loss = 1.27241752\n",
      "Iteration 21, loss = 1.26591149\n",
      "Iteration 22, loss = 1.28721197\n",
      "Iteration 23, loss = 1.28501875\n",
      "Iteration 24, loss = 1.26283820\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31169511\n",
      "Iteration 2, loss = 1.26792186\n",
      "Iteration 3, loss = 1.25480756\n",
      "Iteration 4, loss = 1.26976619\n",
      "Iteration 17, loss = 1.25713112\n",
      "Iteration 18, loss = 1.25211418\n",
      "Iteration 19, loss = 1.26049213\n",
      "Iteration 20, loss = 1.27241752\n",
      "Iteration 21, loss = 1.26591149\n",
      "Iteration 22, loss = 1.28721197\n",
      "Iteration 23, loss = 1.28501875\n",
      "Iteration 24, loss = 1.26283820\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31169511\n",
      "Iteration 2, loss = 1.26792186\n",
      "Iteration 3, loss = 1.25480756\n",
      "Iteration 4, loss = 1.26976619\n",
      "Iteration 5, loss = 1.25347248\n",
      "Iteration 6, loss = 1.26746366\n",
      "Iteration 7, loss = 1.26532934\n",
      "Iteration 8, loss = 1.25484133\n",
      "Iteration 9, loss = 1.25660281\n",
      "Iteration 10, loss = 1.28042244\n",
      "Iteration 11, loss = 1.29339671\n",
      "Iteration 12, loss = 1.25871115\n",
      "Iteration 13, loss = 1.24358634\n",
      "Iteration 14, loss = 1.25314040\n",
      "Iteration 15, loss = 1.25743351\n",
      "Iteration 16, loss = 1.24893690\n",
      "Iteration 17, loss = 1.24658075\n",
      "Iteration 18, loss = 1.24945405\n",
      "Iteration 19, loss = 1.23824365\n",
      "Iteration 20, loss = 1.25559311\n",
      "Iteration 5, loss = 1.25347248\n",
      "Iteration 6, loss = 1.26746366\n",
      "Iteration 7, loss = 1.26532934\n",
      "Iteration 8, loss = 1.25484133\n",
      "Iteration 9, loss = 1.25660281\n",
      "Iteration 10, loss = 1.28042244\n",
      "Iteration 11, loss = 1.29339671\n",
      "Iteration 12, loss = 1.25871115\n",
      "Iteration 13, loss = 1.24358634\n",
      "Iteration 14, loss = 1.25314040\n",
      "Iteration 15, loss = 1.25743351\n",
      "Iteration 16, loss = 1.24893690\n",
      "Iteration 17, loss = 1.24658075\n",
      "Iteration 18, loss = 1.24945405\n",
      "Iteration 19, loss = 1.23824365\n",
      "Iteration 20, loss = 1.25559311\n",
      "Iteration 21, loss = 1.25412052\n",
      "Iteration 22, loss = 1.27760531\n",
      "Iteration 23, loss = 1.25512172\n",
      "Iteration 24, loss = 1.25486218\n",
      "Iteration 25, loss = 1.25465449\n",
      "Iteration 26, loss = 1.24792678\n",
      "Iteration 27, loss = 1.25222796\n",
      "Iteration 28, loss = 1.25633637\n",
      "Iteration 29, loss = 1.24385231\n",
      "Iteration 30, loss = 1.27594439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31494517\n",
      "Iteration 2, loss = 1.27015850\n",
      "Iteration 3, loss = 1.30423287\n",
      "Iteration 4, loss = 1.28834918\n",
      "Iteration 5, loss = 1.26501954\n",
      "Iteration 21, loss = 1.25412052\n",
      "Iteration 22, loss = 1.27760531\n",
      "Iteration 23, loss = 1.25512172\n",
      "Iteration 24, loss = 1.25486218\n",
      "Iteration 25, loss = 1.25465449\n",
      "Iteration 26, loss = 1.24792678\n",
      "Iteration 27, loss = 1.25222796\n",
      "Iteration 28, loss = 1.25633637\n",
      "Iteration 29, loss = 1.24385231\n",
      "Iteration 30, loss = 1.27594439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31494517\n",
      "Iteration 2, loss = 1.27015850\n",
      "Iteration 3, loss = 1.30423287\n",
      "Iteration 4, loss = 1.28834918\n",
      "Iteration 5, loss = 1.26501954\n",
      "Iteration 6, loss = 1.27438978\n",
      "Iteration 7, loss = 1.26072776\n",
      "Iteration 8, loss = 1.26060129\n",
      "Iteration 9, loss = 1.25763076\n",
      "Iteration 10, loss = 1.29551494\n",
      "Iteration 11, loss = 1.30089733\n",
      "Iteration 12, loss = 1.27191200\n",
      "Iteration 13, loss = 1.26307815\n",
      "Iteration 14, loss = 1.26490499\n",
      "Iteration 15, loss = 1.27206891\n",
      "Iteration 16, loss = 1.25740044\n",
      "Iteration 17, loss = 1.26006904\n",
      "Iteration 18, loss = 1.25740866\n",
      "Iteration 19, loss = 1.25728265\n",
      "Iteration 6, loss = 1.27438978\n",
      "Iteration 7, loss = 1.26072776\n",
      "Iteration 8, loss = 1.26060129\n",
      "Iteration 9, loss = 1.25763076\n",
      "Iteration 10, loss = 1.29551494\n",
      "Iteration 11, loss = 1.30089733\n",
      "Iteration 12, loss = 1.27191200\n",
      "Iteration 13, loss = 1.26307815\n",
      "Iteration 14, loss = 1.26490499\n",
      "Iteration 15, loss = 1.27206891\n",
      "Iteration 16, loss = 1.25740044\n",
      "Iteration 17, loss = 1.26006904\n",
      "Iteration 18, loss = 1.25740866\n",
      "Iteration 19, loss = 1.25728265\n",
      "Iteration 20, loss = 1.27513926\n",
      "Iteration 21, loss = 1.26961590\n",
      "Iteration 22, loss = 1.28384889\n",
      "Iteration 23, loss = 1.27884079\n",
      "Iteration 24, loss = 1.26356324\n",
      "Iteration 25, loss = 1.26279320\n",
      "Iteration 26, loss = 1.25927165\n",
      "Iteration 27, loss = 1.26903158\n",
      "Iteration 28, loss = 1.26865123\n",
      "Iteration 29, loss = 1.25697085\n",
      "Iteration 30, loss = 1.30024866\n",
      "Iteration 31, loss = 1.26450527\n",
      "Iteration 32, loss = 1.26479802\n",
      "Iteration 33, loss = 1.26179277\n",
      "Iteration 34, loss = 1.26818465\n",
      "Iteration 20, loss = 1.27513926\n",
      "Iteration 21, loss = 1.26961590\n",
      "Iteration 22, loss = 1.28384889\n",
      "Iteration 23, loss = 1.27884079\n",
      "Iteration 24, loss = 1.26356324\n",
      "Iteration 25, loss = 1.26279320\n",
      "Iteration 26, loss = 1.25927165\n",
      "Iteration 27, loss = 1.26903158\n",
      "Iteration 28, loss = 1.26865123\n",
      "Iteration 29, loss = 1.25697085\n",
      "Iteration 30, loss = 1.30024866\n",
      "Iteration 31, loss = 1.26450527\n",
      "Iteration 32, loss = 1.26479802\n",
      "Iteration 33, loss = 1.26179277\n",
      "Iteration 34, loss = 1.26818465\n",
      "Iteration 35, loss = 1.27231237\n",
      "Iteration 36, loss = 1.26879046\n",
      "Iteration 37, loss = 1.27270718\n",
      "Iteration 38, loss = 1.26896394\n",
      "Iteration 39, loss = 1.28009324\n",
      "Iteration 40, loss = 1.26794956\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26326048\n",
      "Iteration 2, loss = 1.11344998\n",
      "Iteration 3, loss = 1.01659609\n",
      "Iteration 4, loss = 0.97617747\n",
      "Iteration 5, loss = 1.02636360\n",
      "Iteration 6, loss = 0.99588596\n",
      "Iteration 7, loss = 0.96722653\n",
      "Iteration 35, loss = 1.27231237\n",
      "Iteration 36, loss = 1.26879046\n",
      "Iteration 37, loss = 1.27270718\n",
      "Iteration 38, loss = 1.26896394\n",
      "Iteration 39, loss = 1.28009324\n",
      "Iteration 40, loss = 1.26794956\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26326048\n",
      "Iteration 2, loss = 1.11344998\n",
      "Iteration 3, loss = 1.01659609\n",
      "Iteration 4, loss = 0.97617747\n",
      "Iteration 5, loss = 1.02636360\n",
      "Iteration 6, loss = 0.99588596\n",
      "Iteration 7, loss = 0.96722653\n",
      "Iteration 8, loss = 0.96143281\n",
      "Iteration 9, loss = 0.94411521\n",
      "Iteration 10, loss = 0.96721848\n",
      "Iteration 1, loss = 1.22992895\n",
      "Iteration 2, loss = 1.08647648\n",
      "Iteration 3, loss = 1.03980657\n",
      "Iteration 4, loss = 0.97645695\n",
      "Iteration 5, loss = 0.98124253\n",
      "Iteration 6, loss = 0.97862446\n",
      "Iteration 7, loss = 0.96632041\n",
      "Iteration 8, loss = 0.92343812\n",
      "Iteration 9, loss = 0.91446602\n",
      "Iteration 10, loss = 0.89827520\n",
      "Iteration 1, loss = 1.25930195\n",
      "Iteration 2, loss = 1.13106766\n",
      "Iteration 8, loss = 0.96143281\n",
      "Iteration 9, loss = 0.94411521\n",
      "Iteration 10, loss = 0.96721848\n",
      "Iteration 1, loss = 1.22992895\n",
      "Iteration 2, loss = 1.08647648\n",
      "Iteration 3, loss = 1.03980657\n",
      "Iteration 4, loss = 0.97645695\n",
      "Iteration 5, loss = 0.98124253\n",
      "Iteration 6, loss = 0.97862446\n",
      "Iteration 7, loss = 0.96632041\n",
      "Iteration 8, loss = 0.92343812\n",
      "Iteration 9, loss = 0.91446602\n",
      "Iteration 10, loss = 0.89827520\n",
      "Iteration 1, loss = 1.25930195\n",
      "Iteration 2, loss = 1.13106766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.07777376\n",
      "Iteration 4, loss = 1.04809078\n",
      "Iteration 5, loss = 0.94956266\n",
      "Iteration 6, loss = 0.97189502\n",
      "Iteration 7, loss = 0.95598699\n",
      "Iteration 8, loss = 0.94596152\n",
      "Iteration 9, loss = 0.94691331\n",
      "Iteration 10, loss = 0.93042415\n",
      "Iteration 1, loss = 1.25940657\n",
      "Iteration 2, loss = 1.15150334\n",
      "Iteration 3, loss = 1.09279648\n",
      "Iteration 4, loss = 1.08842321\n",
      "Iteration 5, loss = 1.00597816\n",
      "Iteration 3, loss = 1.07777376\n",
      "Iteration 4, loss = 1.04809078\n",
      "Iteration 5, loss = 0.94956266\n",
      "Iteration 6, loss = 0.97189502\n",
      "Iteration 7, loss = 0.95598699\n",
      "Iteration 8, loss = 0.94596152\n",
      "Iteration 9, loss = 0.94691331\n",
      "Iteration 10, loss = 0.93042415\n",
      "Iteration 1, loss = 1.25940657\n",
      "Iteration 2, loss = 1.15150334\n",
      "Iteration 3, loss = 1.09279648\n",
      "Iteration 4, loss = 1.08842321\n",
      "Iteration 5, loss = 1.00597816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.98043512\n",
      "Iteration 7, loss = 0.97154661\n",
      "Iteration 8, loss = 0.96857268\n",
      "Iteration 9, loss = 0.97164033\n",
      "Iteration 10, loss = 0.94616284\n",
      "Iteration 1, loss = 1.24927430\n",
      "Iteration 2, loss = 1.07970529\n",
      "Iteration 3, loss = 1.00700149\n",
      "Iteration 4, loss = 0.96531450\n",
      "Iteration 5, loss = 0.94946781\n",
      "Iteration 6, loss = 0.94876006\n",
      "Iteration 6, loss = 0.98043512\n",
      "Iteration 7, loss = 0.97154661\n",
      "Iteration 8, loss = 0.96857268\n",
      "Iteration 9, loss = 0.97164033\n",
      "Iteration 10, loss = 0.94616284\n",
      "Iteration 1, loss = 1.24927430\n",
      "Iteration 2, loss = 1.07970529\n",
      "Iteration 3, loss = 1.00700149\n",
      "Iteration 4, loss = 0.96531450\n",
      "Iteration 5, loss = 0.94946781\n",
      "Iteration 6, loss = 0.94876006\n",
      "Iteration 7, loss = 0.95189394\n",
      "Iteration 8, loss = 0.93450541\n",
      "Iteration 9, loss = 0.92686508\n",
      "Iteration 10, loss = 0.92888901\n",
      "Iteration 1, loss = 1.26326048\n",
      "Iteration 2, loss = 1.11344998\n",
      "Iteration 3, loss = 1.01659609\n",
      "Iteration 4, loss = 0.97617747\n",
      "Iteration 5, loss = 1.02636360\n",
      "Iteration 6, loss = 0.99588596\n",
      "Iteration 7, loss = 0.96722653\n",
      "Iteration 8, loss = 0.96143281\n",
      "Iteration 9, loss = 0.94411521\n",
      "Iteration 10, loss = 0.96721848\n",
      "Iteration 7, loss = 0.95189394\n",
      "Iteration 8, loss = 0.93450541\n",
      "Iteration 9, loss = 0.92686508\n",
      "Iteration 10, loss = 0.92888901\n",
      "Iteration 1, loss = 1.26326048\n",
      "Iteration 2, loss = 1.11344998\n",
      "Iteration 3, loss = 1.01659609\n",
      "Iteration 4, loss = 0.97617747\n",
      "Iteration 5, loss = 1.02636360\n",
      "Iteration 6, loss = 0.99588596\n",
      "Iteration 7, loss = 0.96722653\n",
      "Iteration 8, loss = 0.96143281\n",
      "Iteration 9, loss = 0.94411521\n",
      "Iteration 10, loss = 0.96721848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.00881092\n",
      "Iteration 12, loss = 0.96380640\n",
      "Iteration 13, loss = 0.92744677\n",
      "Iteration 14, loss = 1.00394381\n",
      "Iteration 15, loss = 0.92544813\n",
      "Iteration 16, loss = 0.91184793\n",
      "Iteration 17, loss = 0.92660968\n",
      "Iteration 18, loss = 0.91377040\n",
      "Iteration 19, loss = 0.89616066\n",
      "Iteration 20, loss = 0.90388155\n",
      "Iteration 21, loss = 0.92048591\n",
      "Iteration 22, loss = 0.87983353\n",
      "Iteration 23, loss = 0.89849365\n",
      "Iteration 24, loss = 0.85284406\n",
      "Iteration 11, loss = 1.00881092\n",
      "Iteration 12, loss = 0.96380640\n",
      "Iteration 13, loss = 0.92744677\n",
      "Iteration 14, loss = 1.00394381\n",
      "Iteration 15, loss = 0.92544813\n",
      "Iteration 16, loss = 0.91184793\n",
      "Iteration 17, loss = 0.92660968\n",
      "Iteration 18, loss = 0.91377040\n",
      "Iteration 19, loss = 0.89616066\n",
      "Iteration 20, loss = 0.90388155\n",
      "Iteration 21, loss = 0.92048591\n",
      "Iteration 22, loss = 0.87983353\n",
      "Iteration 23, loss = 0.89849365\n",
      "Iteration 24, loss = 0.85284406\n",
      "Iteration 25, loss = 0.89832599\n",
      "Iteration 26, loss = 0.86489916\n",
      "Iteration 27, loss = 0.87984530\n",
      "Iteration 28, loss = 0.89014658\n",
      "Iteration 29, loss = 0.87369085\n",
      "Iteration 30, loss = 0.90679954\n",
      "Iteration 31, loss = 0.84786184\n",
      "Iteration 32, loss = 0.84850831\n",
      "Iteration 33, loss = 0.83085887\n",
      "Iteration 34, loss = 0.85004862\n",
      "Iteration 35, loss = 0.83813617\n",
      "Iteration 36, loss = 0.82298893\n",
      "Iteration 37, loss = 0.84940051\n",
      "Iteration 38, loss = 0.83543014\n",
      "Iteration 39, loss = 0.78334436\n",
      "Iteration 40, loss = 0.82583279\n",
      "Iteration 25, loss = 0.89832599\n",
      "Iteration 26, loss = 0.86489916\n",
      "Iteration 27, loss = 0.87984530\n",
      "Iteration 28, loss = 0.89014658\n",
      "Iteration 29, loss = 0.87369085\n",
      "Iteration 30, loss = 0.90679954\n",
      "Iteration 31, loss = 0.84786184\n",
      "Iteration 32, loss = 0.84850831\n",
      "Iteration 33, loss = 0.83085887\n",
      "Iteration 34, loss = 0.85004862\n",
      "Iteration 35, loss = 0.83813617\n",
      "Iteration 36, loss = 0.82298893\n",
      "Iteration 37, loss = 0.84940051\n",
      "Iteration 38, loss = 0.83543014\n",
      "Iteration 39, loss = 0.78334436\n",
      "Iteration 40, loss = 0.82583279\n",
      "Iteration 41, loss = 0.82614866\n",
      "Iteration 42, loss = 0.80083497\n",
      "Iteration 43, loss = 0.83415067\n",
      "Iteration 44, loss = 0.82904320\n",
      "Iteration 45, loss = 0.78522200\n",
      "Iteration 46, loss = 0.78842640\n",
      "Iteration 47, loss = 0.79730102\n",
      "Iteration 48, loss = 0.77957988\n",
      "Iteration 49, loss = 0.76603429\n",
      "Iteration 50, loss = 0.78854192\n",
      "Iteration 1, loss = 1.22992895\n",
      "Iteration 2, loss = 1.08647648\n",
      "Iteration 3, loss = 1.03980657\n",
      "Iteration 41, loss = 0.82614866\n",
      "Iteration 42, loss = 0.80083497\n",
      "Iteration 43, loss = 0.83415067\n",
      "Iteration 44, loss = 0.82904320\n",
      "Iteration 45, loss = 0.78522200\n",
      "Iteration 46, loss = 0.78842640\n",
      "Iteration 47, loss = 0.79730102\n",
      "Iteration 48, loss = 0.77957988\n",
      "Iteration 49, loss = 0.76603429\n",
      "Iteration 50, loss = 0.78854192\n",
      "Iteration 1, loss = 1.22992895\n",
      "Iteration 2, loss = 1.08647648\n",
      "Iteration 3, loss = 1.03980657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.97645695\n",
      "Iteration 5, loss = 0.98124253\n",
      "Iteration 6, loss = 0.97862446\n",
      "Iteration 7, loss = 0.96632041\n",
      "Iteration 8, loss = 0.92343812\n",
      "Iteration 9, loss = 0.91446602\n",
      "Iteration 10, loss = 0.89827520\n",
      "Iteration 11, loss = 0.88142502\n",
      "Iteration 12, loss = 0.88636926\n",
      "Iteration 13, loss = 0.90424094\n",
      "Iteration 14, loss = 0.92222989\n",
      "Iteration 15, loss = 0.88688609\n",
      "Iteration 16, loss = 0.85247769\n",
      "Iteration 17, loss = 0.87111773\n",
      "Iteration 4, loss = 0.97645695\n",
      "Iteration 5, loss = 0.98124253\n",
      "Iteration 6, loss = 0.97862446\n",
      "Iteration 7, loss = 0.96632041\n",
      "Iteration 8, loss = 0.92343812\n",
      "Iteration 9, loss = 0.91446602\n",
      "Iteration 10, loss = 0.89827520\n",
      "Iteration 11, loss = 0.88142502\n",
      "Iteration 12, loss = 0.88636926\n",
      "Iteration 13, loss = 0.90424094\n",
      "Iteration 14, loss = 0.92222989\n",
      "Iteration 15, loss = 0.88688609\n",
      "Iteration 16, loss = 0.85247769\n",
      "Iteration 17, loss = 0.87111773\n",
      "Iteration 18, loss = 0.86234409\n",
      "Iteration 19, loss = 0.84927951\n",
      "Iteration 20, loss = 0.86380892\n",
      "Iteration 21, loss = 0.86634573\n",
      "Iteration 22, loss = 0.84433935\n",
      "Iteration 23, loss = 0.82255721\n",
      "Iteration 24, loss = 0.79700082\n",
      "Iteration 25, loss = 0.87916852\n",
      "Iteration 26, loss = 0.82053652\n",
      "Iteration 27, loss = 0.84876009\n",
      "Iteration 28, loss = 0.83612413\n",
      "Iteration 29, loss = 0.83548555\n",
      "Iteration 30, loss = 0.79850885\n",
      "Iteration 31, loss = 0.78826782\n",
      "Iteration 32, loss = 0.76620032\n",
      "Iteration 18, loss = 0.86234409\n",
      "Iteration 19, loss = 0.84927951\n",
      "Iteration 20, loss = 0.86380892\n",
      "Iteration 21, loss = 0.86634573\n",
      "Iteration 22, loss = 0.84433935\n",
      "Iteration 23, loss = 0.82255721\n",
      "Iteration 24, loss = 0.79700082\n",
      "Iteration 25, loss = 0.87916852\n",
      "Iteration 26, loss = 0.82053652\n",
      "Iteration 27, loss = 0.84876009\n",
      "Iteration 28, loss = 0.83612413\n",
      "Iteration 29, loss = 0.83548555\n",
      "Iteration 30, loss = 0.79850885\n",
      "Iteration 31, loss = 0.78826782\n",
      "Iteration 32, loss = 0.76620032\n",
      "Iteration 33, loss = 0.78032079\n",
      "Iteration 34, loss = 0.81406420\n",
      "Iteration 35, loss = 0.75879050\n",
      "Iteration 36, loss = 0.81006664\n",
      "Iteration 37, loss = 0.77016580\n",
      "Iteration 38, loss = 0.77670962\n",
      "Iteration 39, loss = 0.75815989\n",
      "Iteration 40, loss = 0.84023780\n",
      "Iteration 41, loss = 0.77164375\n",
      "Iteration 42, loss = 0.73927052\n",
      "Iteration 43, loss = 0.75310858\n",
      "Iteration 44, loss = 0.73748408\n",
      "Iteration 45, loss = 0.75586729\n",
      "Iteration 46, loss = 0.77335868\n",
      "Iteration 33, loss = 0.78032079\n",
      "Iteration 34, loss = 0.81406420\n",
      "Iteration 35, loss = 0.75879050\n",
      "Iteration 36, loss = 0.81006664\n",
      "Iteration 37, loss = 0.77016580\n",
      "Iteration 38, loss = 0.77670962\n",
      "Iteration 39, loss = 0.75815989\n",
      "Iteration 40, loss = 0.84023780\n",
      "Iteration 41, loss = 0.77164375\n",
      "Iteration 42, loss = 0.73927052\n",
      "Iteration 43, loss = 0.75310858\n",
      "Iteration 44, loss = 0.73748408\n",
      "Iteration 45, loss = 0.75586729\n",
      "Iteration 46, loss = 0.77335868\n",
      "Iteration 47, loss = 0.79662468\n",
      "Iteration 48, loss = 0.74683787\n",
      "Iteration 49, loss = 0.73388612\n",
      "Iteration 50, loss = 0.72195095\n",
      "Iteration 1, loss = 1.25930195\n",
      "Iteration 2, loss = 1.13106766\n",
      "Iteration 3, loss = 1.07777376\n",
      "Iteration 4, loss = 1.04809078\n",
      "Iteration 5, loss = 0.94956266\n",
      "Iteration 6, loss = 0.97189502\n",
      "Iteration 7, loss = 0.95598699\n",
      "Iteration 8, loss = 0.94596152\n",
      "Iteration 9, loss = 0.94691331\n",
      "Iteration 10, loss = 0.93042415\n",
      "Iteration 11, loss = 0.91575943\n",
      "Iteration 47, loss = 0.79662468\n",
      "Iteration 48, loss = 0.74683787\n",
      "Iteration 49, loss = 0.73388612\n",
      "Iteration 50, loss = 0.72195095\n",
      "Iteration 1, loss = 1.25930195\n",
      "Iteration 2, loss = 1.13106766\n",
      "Iteration 3, loss = 1.07777376\n",
      "Iteration 4, loss = 1.04809078\n",
      "Iteration 5, loss = 0.94956266\n",
      "Iteration 6, loss = 0.97189502\n",
      "Iteration 7, loss = 0.95598699\n",
      "Iteration 8, loss = 0.94596152\n",
      "Iteration 9, loss = 0.94691331\n",
      "Iteration 10, loss = 0.93042415\n",
      "Iteration 11, loss = 0.91575943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.91886457\n",
      "Iteration 13, loss = 0.90495771\n",
      "Iteration 14, loss = 0.91770890\n",
      "Iteration 15, loss = 0.90215872\n",
      "Iteration 16, loss = 0.91610993\n",
      "Iteration 17, loss = 0.92604732\n",
      "Iteration 18, loss = 0.90004558\n",
      "Iteration 19, loss = 0.89625541\n",
      "Iteration 20, loss = 0.89418013\n",
      "Iteration 21, loss = 0.94318256\n",
      "Iteration 22, loss = 0.94654403\n",
      "Iteration 23, loss = 0.91149022\n",
      "Iteration 24, loss = 0.90857324\n",
      "Iteration 25, loss = 0.87685199\n",
      "Iteration 26, loss = 0.86040186\n",
      "Iteration 12, loss = 0.91886457\n",
      "Iteration 13, loss = 0.90495771\n",
      "Iteration 14, loss = 0.91770890\n",
      "Iteration 15, loss = 0.90215872\n",
      "Iteration 16, loss = 0.91610993\n",
      "Iteration 17, loss = 0.92604732\n",
      "Iteration 18, loss = 0.90004558\n",
      "Iteration 19, loss = 0.89625541\n",
      "Iteration 20, loss = 0.89418013\n",
      "Iteration 21, loss = 0.94318256\n",
      "Iteration 22, loss = 0.94654403\n",
      "Iteration 23, loss = 0.91149022\n",
      "Iteration 24, loss = 0.90857324\n",
      "Iteration 25, loss = 0.87685199\n",
      "Iteration 26, loss = 0.86040186\n",
      "Iteration 27, loss = 0.91616376\n",
      "Iteration 28, loss = 0.90344264\n",
      "Iteration 29, loss = 0.87411849\n",
      "Iteration 30, loss = 0.88505159\n",
      "Iteration 31, loss = 0.92896505\n",
      "Iteration 32, loss = 0.85184935\n",
      "Iteration 33, loss = 0.89378676\n",
      "Iteration 34, loss = 0.87060226\n",
      "Iteration 35, loss = 0.85855841\n",
      "Iteration 36, loss = 0.90010854\n",
      "Iteration 37, loss = 0.90830134\n",
      "Iteration 38, loss = 0.85938982\n",
      "Iteration 39, loss = 0.81535932\n",
      "Iteration 40, loss = 0.89205584\n",
      "Iteration 41, loss = 0.82790365\n",
      "Iteration 27, loss = 0.91616376\n",
      "Iteration 28, loss = 0.90344264\n",
      "Iteration 29, loss = 0.87411849\n",
      "Iteration 30, loss = 0.88505159\n",
      "Iteration 31, loss = 0.92896505\n",
      "Iteration 32, loss = 0.85184935\n",
      "Iteration 33, loss = 0.89378676\n",
      "Iteration 34, loss = 0.87060226\n",
      "Iteration 35, loss = 0.85855841\n",
      "Iteration 36, loss = 0.90010854\n",
      "Iteration 37, loss = 0.90830134\n",
      "Iteration 38, loss = 0.85938982\n",
      "Iteration 39, loss = 0.81535932\n",
      "Iteration 40, loss = 0.89205584\n",
      "Iteration 41, loss = 0.82790365\n",
      "Iteration 42, loss = 0.84081699\n",
      "Iteration 43, loss = 0.82147430\n",
      "Iteration 44, loss = 0.78784356\n",
      "Iteration 45, loss = 0.81425167\n",
      "Iteration 46, loss = 0.84165407\n",
      "Iteration 47, loss = 0.80474051\n",
      "Iteration 48, loss = 0.77130381\n",
      "Iteration 49, loss = 0.83031570\n",
      "Iteration 50, loss = 0.80255766\n",
      "Iteration 1, loss = 1.25940657\n",
      "Iteration 2, loss = 1.15150334\n",
      "Iteration 3, loss = 1.09279648\n",
      "Iteration 4, loss = 1.08842321\n",
      "Iteration 5, loss = 1.00597816\n",
      "Iteration 42, loss = 0.84081699\n",
      "Iteration 43, loss = 0.82147430\n",
      "Iteration 44, loss = 0.78784356\n",
      "Iteration 45, loss = 0.81425167\n",
      "Iteration 46, loss = 0.84165407\n",
      "Iteration 47, loss = 0.80474051\n",
      "Iteration 48, loss = 0.77130381\n",
      "Iteration 49, loss = 0.83031570\n",
      "Iteration 50, loss = 0.80255766\n",
      "Iteration 1, loss = 1.25940657\n",
      "Iteration 2, loss = 1.15150334\n",
      "Iteration 3, loss = 1.09279648\n",
      "Iteration 4, loss = 1.08842321\n",
      "Iteration 5, loss = 1.00597816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.98043512\n",
      "Iteration 7, loss = 0.97154661\n",
      "Iteration 8, loss = 0.96857268\n",
      "Iteration 9, loss = 0.97164033\n",
      "Iteration 10, loss = 0.94616284\n",
      "Iteration 11, loss = 0.94896084\n",
      "Iteration 12, loss = 0.96369275\n",
      "Iteration 13, loss = 0.98273117\n",
      "Iteration 14, loss = 0.94601995\n",
      "Iteration 15, loss = 0.94137751\n",
      "Iteration 16, loss = 0.92699002\n",
      "Iteration 17, loss = 0.92519352\n",
      "Iteration 18, loss = 0.92021310\n",
      "Iteration 6, loss = 0.98043512\n",
      "Iteration 7, loss = 0.97154661\n",
      "Iteration 8, loss = 0.96857268\n",
      "Iteration 9, loss = 0.97164033\n",
      "Iteration 10, loss = 0.94616284\n",
      "Iteration 11, loss = 0.94896084\n",
      "Iteration 12, loss = 0.96369275\n",
      "Iteration 13, loss = 0.98273117\n",
      "Iteration 14, loss = 0.94601995\n",
      "Iteration 15, loss = 0.94137751\n",
      "Iteration 16, loss = 0.92699002\n",
      "Iteration 17, loss = 0.92519352\n",
      "Iteration 18, loss = 0.92021310\n",
      "Iteration 19, loss = 0.90629439\n",
      "Iteration 20, loss = 0.87915617\n",
      "Iteration 21, loss = 0.94686085\n",
      "Iteration 22, loss = 0.91959224\n",
      "Iteration 23, loss = 0.90074915\n",
      "Iteration 24, loss = 0.86494518\n",
      "Iteration 25, loss = 0.85288930\n",
      "Iteration 26, loss = 0.86838473\n",
      "Iteration 27, loss = 0.88524988\n",
      "Iteration 28, loss = 0.88026318\n",
      "Iteration 29, loss = 0.85941887\n",
      "Iteration 30, loss = 0.86608849\n",
      "Iteration 31, loss = 0.88276049\n",
      "Iteration 32, loss = 0.88338296\n",
      "Iteration 33, loss = 0.88203063\n",
      "Iteration 34, loss = 0.87234359\n",
      "Iteration 19, loss = 0.90629439\n",
      "Iteration 20, loss = 0.87915617\n",
      "Iteration 21, loss = 0.94686085\n",
      "Iteration 22, loss = 0.91959224\n",
      "Iteration 23, loss = 0.90074915\n",
      "Iteration 24, loss = 0.86494518\n",
      "Iteration 25, loss = 0.85288930\n",
      "Iteration 26, loss = 0.86838473\n",
      "Iteration 27, loss = 0.88524988\n",
      "Iteration 28, loss = 0.88026318\n",
      "Iteration 29, loss = 0.85941887\n",
      "Iteration 30, loss = 0.86608849\n",
      "Iteration 31, loss = 0.88276049\n",
      "Iteration 32, loss = 0.88338296\n",
      "Iteration 33, loss = 0.88203063\n",
      "Iteration 34, loss = 0.87234359\n",
      "Iteration 35, loss = 0.84480690\n",
      "Iteration 36, loss = 0.83650756\n",
      "Iteration 37, loss = 0.82459325\n",
      "Iteration 38, loss = 0.82350192\n",
      "Iteration 39, loss = 0.83636933\n",
      "Iteration 40, loss = 0.83918113\n",
      "Iteration 41, loss = 0.81857356\n",
      "Iteration 42, loss = 0.83095501\n",
      "Iteration 43, loss = 0.82606111\n",
      "Iteration 44, loss = 0.77755829\n",
      "Iteration 45, loss = 0.81845212\n",
      "Iteration 46, loss = 0.82767516\n",
      "Iteration 47, loss = 0.83273288\n",
      "Iteration 48, loss = 0.82817373\n",
      "Iteration 49, loss = 0.77419906\n",
      "Iteration 35, loss = 0.84480690\n",
      "Iteration 36, loss = 0.83650756\n",
      "Iteration 37, loss = 0.82459325\n",
      "Iteration 38, loss = 0.82350192\n",
      "Iteration 39, loss = 0.83636933\n",
      "Iteration 40, loss = 0.83918113\n",
      "Iteration 41, loss = 0.81857356\n",
      "Iteration 42, loss = 0.83095501\n",
      "Iteration 43, loss = 0.82606111\n",
      "Iteration 44, loss = 0.77755829\n",
      "Iteration 45, loss = 0.81845212\n",
      "Iteration 46, loss = 0.82767516\n",
      "Iteration 47, loss = 0.83273288\n",
      "Iteration 48, loss = 0.82817373\n",
      "Iteration 49, loss = 0.77419906\n",
      "Iteration 50, loss = 0.78390865\n",
      "Iteration 1, loss = 1.24927430\n",
      "Iteration 2, loss = 1.07970529\n",
      "Iteration 3, loss = 1.00700149\n",
      "Iteration 4, loss = 0.96531450\n",
      "Iteration 5, loss = 0.94946781\n",
      "Iteration 6, loss = 0.94876006\n",
      "Iteration 7, loss = 0.95189394\n",
      "Iteration 8, loss = 0.93450541\n",
      "Iteration 9, loss = 0.92686508\n",
      "Iteration 10, loss = 0.92888901\n",
      "Iteration 11, loss = 0.93864994\n",
      "Iteration 50, loss = 0.78390865\n",
      "Iteration 1, loss = 1.24927430\n",
      "Iteration 2, loss = 1.07970529\n",
      "Iteration 3, loss = 1.00700149\n",
      "Iteration 4, loss = 0.96531450\n",
      "Iteration 5, loss = 0.94946781\n",
      "Iteration 6, loss = 0.94876006\n",
      "Iteration 7, loss = 0.95189394\n",
      "Iteration 8, loss = 0.93450541\n",
      "Iteration 9, loss = 0.92686508\n",
      "Iteration 10, loss = 0.92888901\n",
      "Iteration 11, loss = 0.93864994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.92733107\n",
      "Iteration 13, loss = 0.89855829\n",
      "Iteration 14, loss = 0.90641789\n",
      "Iteration 15, loss = 0.88455022\n",
      "Iteration 16, loss = 0.94070594\n",
      "Iteration 17, loss = 0.88585787\n",
      "Iteration 18, loss = 0.90406345\n",
      "Iteration 19, loss = 0.86723640\n",
      "Iteration 20, loss = 0.91015852\n",
      "Iteration 21, loss = 0.95451427\n",
      "Iteration 22, loss = 0.93870441\n",
      "Iteration 23, loss = 0.89204269\n",
      "Iteration 24, loss = 0.85900683\n",
      "Iteration 25, loss = 0.86854977\n",
      "Iteration 26, loss = 0.84162955\n",
      "Iteration 27, loss = 0.86235377\n",
      "Iteration 28, loss = 0.82364713\n",
      "Iteration 12, loss = 0.92733107\n",
      "Iteration 13, loss = 0.89855829\n",
      "Iteration 14, loss = 0.90641789\n",
      "Iteration 15, loss = 0.88455022\n",
      "Iteration 16, loss = 0.94070594\n",
      "Iteration 17, loss = 0.88585787\n",
      "Iteration 18, loss = 0.90406345\n",
      "Iteration 19, loss = 0.86723640\n",
      "Iteration 20, loss = 0.91015852\n",
      "Iteration 21, loss = 0.95451427\n",
      "Iteration 22, loss = 0.93870441\n",
      "Iteration 23, loss = 0.89204269\n",
      "Iteration 24, loss = 0.85900683\n",
      "Iteration 25, loss = 0.86854977\n",
      "Iteration 26, loss = 0.84162955\n",
      "Iteration 27, loss = 0.86235377\n",
      "Iteration 28, loss = 0.82364713\n",
      "Iteration 29, loss = 0.84235281\n",
      "Iteration 30, loss = 0.86558652\n",
      "Iteration 31, loss = 0.88019491\n",
      "Iteration 32, loss = 0.87287684\n",
      "Iteration 33, loss = 0.85546115\n",
      "Iteration 34, loss = 0.82787367\n",
      "Iteration 35, loss = 0.83039954\n",
      "Iteration 36, loss = 0.85441670\n",
      "Iteration 37, loss = 0.86172879\n",
      "Iteration 38, loss = 0.84997921\n",
      "Iteration 39, loss = 0.84393175\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26326048\n",
      "Iteration 2, loss = 1.11344998\n",
      "Iteration 3, loss = 1.01659609\n",
      "Iteration 29, loss = 0.84235281\n",
      "Iteration 30, loss = 0.86558652\n",
      "Iteration 31, loss = 0.88019491\n",
      "Iteration 32, loss = 0.87287684\n",
      "Iteration 33, loss = 0.85546115\n",
      "Iteration 34, loss = 0.82787367\n",
      "Iteration 35, loss = 0.83039954\n",
      "Iteration 36, loss = 0.85441670\n",
      "Iteration 37, loss = 0.86172879\n",
      "Iteration 38, loss = 0.84997921\n",
      "Iteration 39, loss = 0.84393175\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26326048\n",
      "Iteration 2, loss = 1.11344998\n",
      "Iteration 3, loss = 1.01659609\n",
      "Iteration 4, loss = 0.97617747\n",
      "Iteration 5, loss = 1.02636360\n",
      "Iteration 6, loss = 0.99588596\n",
      "Iteration 7, loss = 0.96722653\n",
      "Iteration 8, loss = 0.96143281\n",
      "Iteration 9, loss = 0.94411521\n",
      "Iteration 10, loss = 0.96721848\n",
      "Iteration 11, loss = 1.00881092\n",
      "Iteration 12, loss = 0.96380640\n",
      "Iteration 13, loss = 0.92744677\n",
      "Iteration 14, loss = 1.00394381\n",
      "Iteration 15, loss = 0.92544813\n",
      "Iteration 16, loss = 0.91184793\n",
      "Iteration 17, loss = 0.92660968\n",
      "Iteration 18, loss = 0.91377040\n",
      "Iteration 4, loss = 0.97617747\n",
      "Iteration 5, loss = 1.02636360\n",
      "Iteration 6, loss = 0.99588596\n",
      "Iteration 7, loss = 0.96722653\n",
      "Iteration 8, loss = 0.96143281\n",
      "Iteration 9, loss = 0.94411521\n",
      "Iteration 10, loss = 0.96721848\n",
      "Iteration 11, loss = 1.00881092\n",
      "Iteration 12, loss = 0.96380640\n",
      "Iteration 13, loss = 0.92744677\n",
      "Iteration 14, loss = 1.00394381\n",
      "Iteration 15, loss = 0.92544813\n",
      "Iteration 16, loss = 0.91184793\n",
      "Iteration 17, loss = 0.92660968\n",
      "Iteration 18, loss = 0.91377040\n",
      "Iteration 19, loss = 0.89616066\n",
      "Iteration 20, loss = 0.90388155\n",
      "Iteration 21, loss = 0.92048591\n",
      "Iteration 22, loss = 0.87983353\n",
      "Iteration 23, loss = 0.89849365\n",
      "Iteration 24, loss = 0.85284406\n",
      "Iteration 25, loss = 0.89832599\n",
      "Iteration 26, loss = 0.86489916\n",
      "Iteration 27, loss = 0.87984530\n",
      "Iteration 28, loss = 0.89014658\n",
      "Iteration 29, loss = 0.87369085\n",
      "Iteration 30, loss = 0.90679954\n",
      "Iteration 31, loss = 0.84786184\n",
      "Iteration 32, loss = 0.84850831\n",
      "Iteration 33, loss = 0.83085887\n",
      "Iteration 19, loss = 0.89616066\n",
      "Iteration 20, loss = 0.90388155\n",
      "Iteration 21, loss = 0.92048591\n",
      "Iteration 22, loss = 0.87983353\n",
      "Iteration 23, loss = 0.89849365\n",
      "Iteration 24, loss = 0.85284406\n",
      "Iteration 25, loss = 0.89832599\n",
      "Iteration 26, loss = 0.86489916\n",
      "Iteration 27, loss = 0.87984530\n",
      "Iteration 28, loss = 0.89014658\n",
      "Iteration 29, loss = 0.87369085\n",
      "Iteration 30, loss = 0.90679954\n",
      "Iteration 31, loss = 0.84786184\n",
      "Iteration 32, loss = 0.84850831\n",
      "Iteration 33, loss = 0.83085887\n",
      "Iteration 34, loss = 0.85004862\n",
      "Iteration 35, loss = 0.83813617\n",
      "Iteration 36, loss = 0.82298893\n",
      "Iteration 37, loss = 0.84940051\n",
      "Iteration 38, loss = 0.83543014\n",
      "Iteration 39, loss = 0.78334436\n",
      "Iteration 40, loss = 0.82583279\n",
      "Iteration 41, loss = 0.82614866\n",
      "Iteration 42, loss = 0.80083497\n",
      "Iteration 43, loss = 0.83415067\n",
      "Iteration 44, loss = 0.82904320\n",
      "Iteration 45, loss = 0.78522200\n",
      "Iteration 46, loss = 0.78842640\n",
      "Iteration 47, loss = 0.79730102\n",
      "Iteration 48, loss = 0.77957988\n",
      "Iteration 49, loss = 0.76603429\n",
      "Iteration 34, loss = 0.85004862\n",
      "Iteration 35, loss = 0.83813617\n",
      "Iteration 36, loss = 0.82298893\n",
      "Iteration 37, loss = 0.84940051\n",
      "Iteration 38, loss = 0.83543014\n",
      "Iteration 39, loss = 0.78334436\n",
      "Iteration 40, loss = 0.82583279\n",
      "Iteration 41, loss = 0.82614866\n",
      "Iteration 42, loss = 0.80083497\n",
      "Iteration 43, loss = 0.83415067\n",
      "Iteration 44, loss = 0.82904320\n",
      "Iteration 45, loss = 0.78522200\n",
      "Iteration 46, loss = 0.78842640\n",
      "Iteration 47, loss = 0.79730102\n",
      "Iteration 48, loss = 0.77957988\n",
      "Iteration 49, loss = 0.76603429\n",
      "Iteration 50, loss = 0.78854192\n",
      "Iteration 51, loss = 0.80788517\n",
      "Iteration 52, loss = 0.79321887\n",
      "Iteration 53, loss = 0.80354624\n",
      "Iteration 54, loss = 0.76601204\n",
      "Iteration 55, loss = 0.78979629\n",
      "Iteration 56, loss = 0.75339460\n",
      "Iteration 57, loss = 0.76828058\n",
      "Iteration 58, loss = 0.74095457\n",
      "Iteration 59, loss = 0.79094966\n",
      "Iteration 60, loss = 0.84734484\n",
      "Iteration 61, loss = 0.74226025\n",
      "Iteration 62, loss = 0.76177531\n",
      "Iteration 63, loss = 0.73801574\n",
      "Iteration 64, loss = 0.79509925\n",
      "Iteration 50, loss = 0.78854192\n",
      "Iteration 51, loss = 0.80788517\n",
      "Iteration 52, loss = 0.79321887\n",
      "Iteration 53, loss = 0.80354624\n",
      "Iteration 54, loss = 0.76601204\n",
      "Iteration 55, loss = 0.78979629\n",
      "Iteration 56, loss = 0.75339460\n",
      "Iteration 57, loss = 0.76828058\n",
      "Iteration 58, loss = 0.74095457\n",
      "Iteration 59, loss = 0.79094966\n",
      "Iteration 60, loss = 0.84734484\n",
      "Iteration 61, loss = 0.74226025\n",
      "Iteration 62, loss = 0.76177531\n",
      "Iteration 63, loss = 0.73801574\n",
      "Iteration 64, loss = 0.79509925\n",
      "Iteration 65, loss = 0.72866306\n",
      "Iteration 66, loss = 0.72611988\n",
      "Iteration 67, loss = 0.72340817\n",
      "Iteration 68, loss = 0.73519743\n",
      "Iteration 69, loss = 0.77233154\n",
      "Iteration 70, loss = 0.71191985\n",
      "Iteration 71, loss = 0.71118061\n",
      "Iteration 72, loss = 0.75875937\n",
      "Iteration 73, loss = 0.71791246\n",
      "Iteration 74, loss = 0.81275266\n",
      "Iteration 75, loss = 0.75392759\n",
      "Iteration 76, loss = 0.75094225\n",
      "Iteration 77, loss = 0.79216872\n",
      "Iteration 78, loss = 0.72705892\n",
      "Iteration 65, loss = 0.72866306\n",
      "Iteration 66, loss = 0.72611988\n",
      "Iteration 67, loss = 0.72340817\n",
      "Iteration 68, loss = 0.73519743\n",
      "Iteration 69, loss = 0.77233154\n",
      "Iteration 70, loss = 0.71191985\n",
      "Iteration 71, loss = 0.71118061\n",
      "Iteration 72, loss = 0.75875937\n",
      "Iteration 73, loss = 0.71791246\n",
      "Iteration 74, loss = 0.81275266\n",
      "Iteration 75, loss = 0.75392759\n",
      "Iteration 76, loss = 0.75094225\n",
      "Iteration 77, loss = 0.79216872\n",
      "Iteration 78, loss = 0.72705892\n",
      "Iteration 79, loss = 0.71907121\n",
      "Iteration 80, loss = 0.70195483\n",
      "Iteration 81, loss = 0.68090685\n",
      "Iteration 82, loss = 0.75016144\n",
      "Iteration 83, loss = 0.75019753\n",
      "Iteration 84, loss = 0.68366761\n",
      "Iteration 85, loss = 0.72120755\n",
      "Iteration 86, loss = 0.72955971\n",
      "Iteration 87, loss = 0.70274506\n",
      "Iteration 88, loss = 0.69237913\n",
      "Iteration 89, loss = 0.68567434\n",
      "Iteration 90, loss = 0.68787908\n",
      "Iteration 91, loss = 0.72151140\n",
      "Iteration 92, loss = 0.71311442\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22992895\n",
      "Iteration 79, loss = 0.71907121\n",
      "Iteration 80, loss = 0.70195483\n",
      "Iteration 81, loss = 0.68090685\n",
      "Iteration 82, loss = 0.75016144\n",
      "Iteration 83, loss = 0.75019753\n",
      "Iteration 84, loss = 0.68366761\n",
      "Iteration 85, loss = 0.72120755\n",
      "Iteration 86, loss = 0.72955971\n",
      "Iteration 87, loss = 0.70274506\n",
      "Iteration 88, loss = 0.69237913\n",
      "Iteration 89, loss = 0.68567434\n",
      "Iteration 90, loss = 0.68787908\n",
      "Iteration 91, loss = 0.72151140\n",
      "Iteration 92, loss = 0.71311442\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22992895\n",
      "Iteration 2, loss = 1.08647648\n",
      "Iteration 3, loss = 1.03980657\n",
      "Iteration 4, loss = 0.97645695\n",
      "Iteration 5, loss = 0.98124253\n",
      "Iteration 6, loss = 0.97862446\n",
      "Iteration 7, loss = 0.96632041\n",
      "Iteration 8, loss = 0.92343812\n",
      "Iteration 9, loss = 0.91446602\n",
      "Iteration 10, loss = 0.89827520\n",
      "Iteration 11, loss = 0.88142502\n",
      "Iteration 12, loss = 0.88636926\n",
      "Iteration 13, loss = 0.90424094\n",
      "Iteration 14, loss = 0.92222989\n",
      "Iteration 15, loss = 0.88688609\n",
      "Iteration 2, loss = 1.08647648\n",
      "Iteration 3, loss = 1.03980657\n",
      "Iteration 4, loss = 0.97645695\n",
      "Iteration 5, loss = 0.98124253\n",
      "Iteration 6, loss = 0.97862446\n",
      "Iteration 7, loss = 0.96632041\n",
      "Iteration 8, loss = 0.92343812\n",
      "Iteration 9, loss = 0.91446602\n",
      "Iteration 10, loss = 0.89827520\n",
      "Iteration 11, loss = 0.88142502\n",
      "Iteration 12, loss = 0.88636926\n",
      "Iteration 13, loss = 0.90424094\n",
      "Iteration 14, loss = 0.92222989\n",
      "Iteration 15, loss = 0.88688609\n",
      "Iteration 16, loss = 0.85247769\n",
      "Iteration 17, loss = 0.87111773\n",
      "Iteration 18, loss = 0.86234409\n",
      "Iteration 19, loss = 0.84927951\n",
      "Iteration 20, loss = 0.86380892\n",
      "Iteration 21, loss = 0.86634573\n",
      "Iteration 22, loss = 0.84433935\n",
      "Iteration 23, loss = 0.82255721\n",
      "Iteration 24, loss = 0.79700082\n",
      "Iteration 25, loss = 0.87916852\n",
      "Iteration 26, loss = 0.82053652\n",
      "Iteration 27, loss = 0.84876009\n",
      "Iteration 28, loss = 0.83612413\n",
      "Iteration 29, loss = 0.83548555\n",
      "Iteration 30, loss = 0.79850885\n",
      "Iteration 16, loss = 0.85247769\n",
      "Iteration 17, loss = 0.87111773\n",
      "Iteration 18, loss = 0.86234409\n",
      "Iteration 19, loss = 0.84927951\n",
      "Iteration 20, loss = 0.86380892\n",
      "Iteration 21, loss = 0.86634573\n",
      "Iteration 22, loss = 0.84433935\n",
      "Iteration 23, loss = 0.82255721\n",
      "Iteration 24, loss = 0.79700082\n",
      "Iteration 25, loss = 0.87916852\n",
      "Iteration 26, loss = 0.82053652\n",
      "Iteration 27, loss = 0.84876009\n",
      "Iteration 28, loss = 0.83612413\n",
      "Iteration 29, loss = 0.83548555\n",
      "Iteration 30, loss = 0.79850885\n",
      "Iteration 31, loss = 0.78826782\n",
      "Iteration 32, loss = 0.76620032\n",
      "Iteration 33, loss = 0.78032079\n",
      "Iteration 34, loss = 0.81406420\n",
      "Iteration 35, loss = 0.75879050\n",
      "Iteration 36, loss = 0.81006664\n",
      "Iteration 37, loss = 0.77016580\n",
      "Iteration 38, loss = 0.77670962\n",
      "Iteration 39, loss = 0.75815989\n",
      "Iteration 40, loss = 0.84023780\n",
      "Iteration 41, loss = 0.77164375\n",
      "Iteration 42, loss = 0.73927052\n",
      "Iteration 43, loss = 0.75310858\n",
      "Iteration 44, loss = 0.73748408\n",
      "Iteration 45, loss = 0.75586729\n",
      "Iteration 31, loss = 0.78826782\n",
      "Iteration 32, loss = 0.76620032\n",
      "Iteration 33, loss = 0.78032079\n",
      "Iteration 34, loss = 0.81406420\n",
      "Iteration 35, loss = 0.75879050\n",
      "Iteration 36, loss = 0.81006664\n",
      "Iteration 37, loss = 0.77016580\n",
      "Iteration 38, loss = 0.77670962\n",
      "Iteration 39, loss = 0.75815989\n",
      "Iteration 40, loss = 0.84023780\n",
      "Iteration 41, loss = 0.77164375\n",
      "Iteration 42, loss = 0.73927052\n",
      "Iteration 43, loss = 0.75310858\n",
      "Iteration 44, loss = 0.73748408\n",
      "Iteration 45, loss = 0.75586729\n",
      "Iteration 46, loss = 0.77335868\n",
      "Iteration 47, loss = 0.79662468\n",
      "Iteration 48, loss = 0.74683787\n",
      "Iteration 49, loss = 0.73388612\n",
      "Iteration 50, loss = 0.72195095\n",
      "Iteration 51, loss = 0.72267111\n",
      "Iteration 52, loss = 0.77252492\n",
      "Iteration 53, loss = 0.73990232\n",
      "Iteration 54, loss = 0.69534082\n",
      "Iteration 55, loss = 0.75254668\n",
      "Iteration 56, loss = 0.70424685\n",
      "Iteration 57, loss = 0.69073966\n",
      "Iteration 58, loss = 0.69098973\n",
      "Iteration 59, loss = 0.71109361\n",
      "Iteration 60, loss = 0.73263136\n",
      "Iteration 46, loss = 0.77335868\n",
      "Iteration 47, loss = 0.79662468\n",
      "Iteration 48, loss = 0.74683787\n",
      "Iteration 49, loss = 0.73388612\n",
      "Iteration 50, loss = 0.72195095\n",
      "Iteration 51, loss = 0.72267111\n",
      "Iteration 52, loss = 0.77252492\n",
      "Iteration 53, loss = 0.73990232\n",
      "Iteration 54, loss = 0.69534082\n",
      "Iteration 55, loss = 0.75254668\n",
      "Iteration 56, loss = 0.70424685\n",
      "Iteration 57, loss = 0.69073966\n",
      "Iteration 58, loss = 0.69098973\n",
      "Iteration 59, loss = 0.71109361\n",
      "Iteration 60, loss = 0.73263136\n",
      "Iteration 61, loss = 0.69078941\n",
      "Iteration 62, loss = 0.69020602\n",
      "Iteration 63, loss = 0.71143086\n",
      "Iteration 64, loss = 0.67154554\n",
      "Iteration 65, loss = 0.66652495\n",
      "Iteration 66, loss = 0.68730859\n",
      "Iteration 67, loss = 0.75081899\n",
      "Iteration 68, loss = 0.66065361\n",
      "Iteration 69, loss = 0.68496303\n",
      "Iteration 70, loss = 0.68220662\n",
      "Iteration 71, loss = 0.63902022\n",
      "Iteration 72, loss = 0.66366853\n",
      "Iteration 73, loss = 0.64664970\n",
      "Iteration 74, loss = 0.71639990\n",
      "Iteration 75, loss = 0.66250485\n",
      "Iteration 76, loss = 0.69127124\n",
      "Iteration 61, loss = 0.69078941\n",
      "Iteration 62, loss = 0.69020602\n",
      "Iteration 63, loss = 0.71143086\n",
      "Iteration 64, loss = 0.67154554\n",
      "Iteration 65, loss = 0.66652495\n",
      "Iteration 66, loss = 0.68730859\n",
      "Iteration 67, loss = 0.75081899\n",
      "Iteration 68, loss = 0.66065361\n",
      "Iteration 69, loss = 0.68496303\n",
      "Iteration 70, loss = 0.68220662\n",
      "Iteration 71, loss = 0.63902022\n",
      "Iteration 72, loss = 0.66366853\n",
      "Iteration 73, loss = 0.64664970\n",
      "Iteration 74, loss = 0.71639990\n",
      "Iteration 75, loss = 0.66250485\n",
      "Iteration 76, loss = 0.69127124\n",
      "Iteration 77, loss = 0.66727425\n",
      "Iteration 78, loss = 0.62441241\n",
      "Iteration 79, loss = 0.68956436\n",
      "Iteration 80, loss = 0.67132209\n",
      "Iteration 81, loss = 0.65301014\n",
      "Iteration 82, loss = 0.64628169\n",
      "Iteration 83, loss = 0.64052427\n",
      "Iteration 84, loss = 0.64956408\n",
      "Iteration 85, loss = 0.66248756\n",
      "Iteration 86, loss = 0.60770602\n",
      "Iteration 87, loss = 0.74737425\n",
      "Iteration 88, loss = 0.66891535\n",
      "Iteration 89, loss = 0.62640329\n",
      "Iteration 90, loss = 0.63283287\n",
      "Iteration 91, loss = 0.62093863\n",
      "Iteration 77, loss = 0.66727425\n",
      "Iteration 78, loss = 0.62441241\n",
      "Iteration 79, loss = 0.68956436\n",
      "Iteration 80, loss = 0.67132209\n",
      "Iteration 81, loss = 0.65301014\n",
      "Iteration 82, loss = 0.64628169\n",
      "Iteration 83, loss = 0.64052427\n",
      "Iteration 84, loss = 0.64956408\n",
      "Iteration 85, loss = 0.66248756\n",
      "Iteration 86, loss = 0.60770602\n",
      "Iteration 87, loss = 0.74737425\n",
      "Iteration 88, loss = 0.66891535\n",
      "Iteration 89, loss = 0.62640329\n",
      "Iteration 90, loss = 0.63283287\n",
      "Iteration 91, loss = 0.62093863\n",
      "Iteration 92, loss = 0.66933405\n",
      "Iteration 93, loss = 0.68923163\n",
      "Iteration 94, loss = 0.66740490\n",
      "Iteration 95, loss = 0.60581720\n",
      "Iteration 96, loss = 0.65895184\n",
      "Iteration 97, loss = 0.65238684\n",
      "Iteration 98, loss = 0.60021364\n",
      "Iteration 99, loss = 0.59810808\n",
      "Iteration 100, loss = 0.63256426\n",
      "Iteration 1, loss = 1.25930195\n",
      "Iteration 2, loss = 1.13106766\n",
      "Iteration 3, loss = 1.07777376\n",
      "Iteration 4, loss = 1.04809078\n",
      "Iteration 5, loss = 0.94956266\n",
      "Iteration 6, loss = 0.97189502\n",
      "Iteration 92, loss = 0.66933405\n",
      "Iteration 93, loss = 0.68923163\n",
      "Iteration 94, loss = 0.66740490\n",
      "Iteration 95, loss = 0.60581720\n",
      "Iteration 96, loss = 0.65895184\n",
      "Iteration 97, loss = 0.65238684\n",
      "Iteration 98, loss = 0.60021364\n",
      "Iteration 99, loss = 0.59810808\n",
      "Iteration 100, loss = 0.63256426\n",
      "Iteration 1, loss = 1.25930195\n",
      "Iteration 2, loss = 1.13106766\n",
      "Iteration 3, loss = 1.07777376\n",
      "Iteration 4, loss = 1.04809078\n",
      "Iteration 5, loss = 0.94956266\n",
      "Iteration 6, loss = 0.97189502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.95598699\n",
      "Iteration 8, loss = 0.94596152\n",
      "Iteration 9, loss = 0.94691331\n",
      "Iteration 10, loss = 0.93042415\n",
      "Iteration 11, loss = 0.91575943\n",
      "Iteration 12, loss = 0.91886457\n",
      "Iteration 13, loss = 0.90495771\n",
      "Iteration 14, loss = 0.91770890\n",
      "Iteration 15, loss = 0.90215872\n",
      "Iteration 16, loss = 0.91610993\n",
      "Iteration 17, loss = 0.92604732\n",
      "Iteration 18, loss = 0.90004558\n",
      "Iteration 19, loss = 0.89625541\n",
      "Iteration 7, loss = 0.95598699\n",
      "Iteration 8, loss = 0.94596152\n",
      "Iteration 9, loss = 0.94691331\n",
      "Iteration 10, loss = 0.93042415\n",
      "Iteration 11, loss = 0.91575943\n",
      "Iteration 12, loss = 0.91886457\n",
      "Iteration 13, loss = 0.90495771\n",
      "Iteration 14, loss = 0.91770890\n",
      "Iteration 15, loss = 0.90215872\n",
      "Iteration 16, loss = 0.91610993\n",
      "Iteration 17, loss = 0.92604732\n",
      "Iteration 18, loss = 0.90004558\n",
      "Iteration 19, loss = 0.89625541\n",
      "Iteration 20, loss = 0.89418013\n",
      "Iteration 21, loss = 0.94318256\n",
      "Iteration 22, loss = 0.94654403\n",
      "Iteration 23, loss = 0.91149022\n",
      "Iteration 24, loss = 0.90857324\n",
      "Iteration 25, loss = 0.87685199\n",
      "Iteration 26, loss = 0.86040186\n",
      "Iteration 27, loss = 0.91616376\n",
      "Iteration 28, loss = 0.90344264\n",
      "Iteration 29, loss = 0.87411849\n",
      "Iteration 20, loss = 0.89418013\n",
      "Iteration 21, loss = 0.94318256\n",
      "Iteration 22, loss = 0.94654403\n",
      "Iteration 23, loss = 0.91149022\n",
      "Iteration 24, loss = 0.90857324\n",
      "Iteration 25, loss = 0.87685199\n",
      "Iteration 26, loss = 0.86040186\n",
      "Iteration 27, loss = 0.91616376\n",
      "Iteration 28, loss = 0.90344264\n",
      "Iteration 29, loss = 0.87411849\n",
      "Iteration 30, loss = 0.88505159\n",
      "Iteration 31, loss = 0.92896505\n",
      "Iteration 32, loss = 0.85184935\n",
      "Iteration 33, loss = 0.89378676\n",
      "Iteration 34, loss = 0.87060226\n",
      "Iteration 35, loss = 0.85855841\n",
      "Iteration 36, loss = 0.90010854\n",
      "Iteration 37, loss = 0.90830134\n",
      "Iteration 38, loss = 0.85938982\n",
      "Iteration 39, loss = 0.81535932\n",
      "Iteration 40, loss = 0.89205584\n",
      "Iteration 41, loss = 0.82790365\n",
      "Iteration 42, loss = 0.84081699\n",
      "Iteration 43, loss = 0.82147430\n",
      "Iteration 44, loss = 0.78784356\n",
      "Iteration 45, loss = 0.81425167\n",
      "Iteration 46, loss = 0.84165407\n",
      "Iteration 30, loss = 0.88505159\n",
      "Iteration 31, loss = 0.92896505\n",
      "Iteration 32, loss = 0.85184935\n",
      "Iteration 33, loss = 0.89378676\n",
      "Iteration 34, loss = 0.87060226\n",
      "Iteration 35, loss = 0.85855841\n",
      "Iteration 36, loss = 0.90010854\n",
      "Iteration 37, loss = 0.90830134\n",
      "Iteration 38, loss = 0.85938982\n",
      "Iteration 39, loss = 0.81535932\n",
      "Iteration 40, loss = 0.89205584\n",
      "Iteration 41, loss = 0.82790365\n",
      "Iteration 42, loss = 0.84081699\n",
      "Iteration 43, loss = 0.82147430\n",
      "Iteration 44, loss = 0.78784356\n",
      "Iteration 45, loss = 0.81425167\n",
      "Iteration 46, loss = 0.84165407\n",
      "Iteration 47, loss = 0.80474051\n",
      "Iteration 48, loss = 0.77130381\n",
      "Iteration 49, loss = 0.83031570\n",
      "Iteration 50, loss = 0.80255766\n",
      "Iteration 51, loss = 0.83689273\n",
      "Iteration 52, loss = 0.84566390\n",
      "Iteration 53, loss = 0.82904602\n",
      "Iteration 54, loss = 0.82141915\n",
      "Iteration 55, loss = 0.76698558\n",
      "Iteration 56, loss = 0.81050222\n",
      "Iteration 57, loss = 0.78753518\n",
      "Iteration 58, loss = 0.77406860\n",
      "Iteration 59, loss = 0.80329435\n",
      "Iteration 60, loss = 0.76819203\n",
      "Iteration 61, loss = 0.78957779\n",
      "Iteration 47, loss = 0.80474051\n",
      "Iteration 48, loss = 0.77130381\n",
      "Iteration 49, loss = 0.83031570\n",
      "Iteration 50, loss = 0.80255766\n",
      "Iteration 51, loss = 0.83689273\n",
      "Iteration 52, loss = 0.84566390\n",
      "Iteration 53, loss = 0.82904602\n",
      "Iteration 54, loss = 0.82141915\n",
      "Iteration 55, loss = 0.76698558\n",
      "Iteration 56, loss = 0.81050222\n",
      "Iteration 57, loss = 0.78753518\n",
      "Iteration 58, loss = 0.77406860\n",
      "Iteration 59, loss = 0.80329435\n",
      "Iteration 60, loss = 0.76819203\n",
      "Iteration 61, loss = 0.78957779\n",
      "Iteration 62, loss = 0.79835464\n",
      "Iteration 63, loss = 0.77586020\n",
      "Iteration 64, loss = 0.82166743\n",
      "Iteration 65, loss = 0.86473891\n",
      "Iteration 66, loss = 0.79678383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25940657\n",
      "Iteration 2, loss = 1.15150334\n",
      "Iteration 3, loss = 1.09279648\n",
      "Iteration 4, loss = 1.08842321\n",
      "Iteration 5, loss = 1.00597816\n",
      "Iteration 6, loss = 0.98043512\n",
      "Iteration 7, loss = 0.97154661\n",
      "Iteration 62, loss = 0.79835464\n",
      "Iteration 63, loss = 0.77586020\n",
      "Iteration 64, loss = 0.82166743\n",
      "Iteration 65, loss = 0.86473891\n",
      "Iteration 66, loss = 0.79678383\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25940657\n",
      "Iteration 2, loss = 1.15150334\n",
      "Iteration 3, loss = 1.09279648\n",
      "Iteration 4, loss = 1.08842321\n",
      "Iteration 5, loss = 1.00597816\n",
      "Iteration 6, loss = 0.98043512\n",
      "Iteration 7, loss = 0.97154661\n",
      "Iteration 8, loss = 0.96857268\n",
      "Iteration 9, loss = 0.97164033\n",
      "Iteration 10, loss = 0.94616284\n",
      "Iteration 11, loss = 0.94896084\n",
      "Iteration 12, loss = 0.96369275\n",
      "Iteration 13, loss = 0.98273117\n",
      "Iteration 14, loss = 0.94601995\n",
      "Iteration 15, loss = 0.94137751\n",
      "Iteration 16, loss = 0.92699002\n",
      "Iteration 17, loss = 0.92519352\n",
      "Iteration 18, loss = 0.92021310\n",
      "Iteration 19, loss = 0.90629439\n",
      "Iteration 20, loss = 0.87915617\n",
      "Iteration 21, loss = 0.94686085\n",
      "Iteration 22, loss = 0.91959224\n",
      "Iteration 23, loss = 0.90074915\n",
      "Iteration 8, loss = 0.96857268\n",
      "Iteration 9, loss = 0.97164033\n",
      "Iteration 10, loss = 0.94616284\n",
      "Iteration 11, loss = 0.94896084\n",
      "Iteration 12, loss = 0.96369275\n",
      "Iteration 13, loss = 0.98273117\n",
      "Iteration 14, loss = 0.94601995\n",
      "Iteration 15, loss = 0.94137751\n",
      "Iteration 16, loss = 0.92699002\n",
      "Iteration 17, loss = 0.92519352\n",
      "Iteration 18, loss = 0.92021310\n",
      "Iteration 19, loss = 0.90629439\n",
      "Iteration 20, loss = 0.87915617\n",
      "Iteration 21, loss = 0.94686085\n",
      "Iteration 22, loss = 0.91959224\n",
      "Iteration 23, loss = 0.90074915\n",
      "Iteration 24, loss = 0.86494518\n",
      "Iteration 25, loss = 0.85288930\n",
      "Iteration 26, loss = 0.86838473\n",
      "Iteration 27, loss = 0.88524988\n",
      "Iteration 28, loss = 0.88026318\n",
      "Iteration 29, loss = 0.85941887\n",
      "Iteration 30, loss = 0.86608849\n",
      "Iteration 31, loss = 0.88276049\n",
      "Iteration 32, loss = 0.88338296\n",
      "Iteration 33, loss = 0.88203063\n",
      "Iteration 34, loss = 0.87234359\n",
      "Iteration 35, loss = 0.84480690\n",
      "Iteration 36, loss = 0.83650756\n",
      "Iteration 37, loss = 0.82459325\n",
      "Iteration 38, loss = 0.82350192\n",
      "Iteration 24, loss = 0.86494518\n",
      "Iteration 25, loss = 0.85288930\n",
      "Iteration 26, loss = 0.86838473\n",
      "Iteration 27, loss = 0.88524988\n",
      "Iteration 28, loss = 0.88026318\n",
      "Iteration 29, loss = 0.85941887\n",
      "Iteration 30, loss = 0.86608849\n",
      "Iteration 31, loss = 0.88276049\n",
      "Iteration 32, loss = 0.88338296\n",
      "Iteration 33, loss = 0.88203063\n",
      "Iteration 34, loss = 0.87234359\n",
      "Iteration 35, loss = 0.84480690\n",
      "Iteration 36, loss = 0.83650756\n",
      "Iteration 37, loss = 0.82459325\n",
      "Iteration 38, loss = 0.82350192\n",
      "Iteration 39, loss = 0.83636933\n",
      "Iteration 40, loss = 0.83918113\n",
      "Iteration 41, loss = 0.81857356\n",
      "Iteration 42, loss = 0.83095501\n",
      "Iteration 43, loss = 0.82606111\n",
      "Iteration 44, loss = 0.77755829\n",
      "Iteration 45, loss = 0.81845212\n",
      "Iteration 46, loss = 0.82767516\n",
      "Iteration 47, loss = 0.83273288\n",
      "Iteration 48, loss = 0.82817373\n",
      "Iteration 49, loss = 0.77419906\n",
      "Iteration 50, loss = 0.78390865\n",
      "Iteration 51, loss = 0.79704382\n",
      "Iteration 52, loss = 0.81909139\n",
      "Iteration 53, loss = 0.82392230\n",
      "Iteration 54, loss = 0.79196054\n",
      "Iteration 39, loss = 0.83636933\n",
      "Iteration 40, loss = 0.83918113\n",
      "Iteration 41, loss = 0.81857356\n",
      "Iteration 42, loss = 0.83095501\n",
      "Iteration 43, loss = 0.82606111\n",
      "Iteration 44, loss = 0.77755829\n",
      "Iteration 45, loss = 0.81845212\n",
      "Iteration 46, loss = 0.82767516\n",
      "Iteration 47, loss = 0.83273288\n",
      "Iteration 48, loss = 0.82817373\n",
      "Iteration 49, loss = 0.77419906\n",
      "Iteration 50, loss = 0.78390865\n",
      "Iteration 51, loss = 0.79704382\n",
      "Iteration 52, loss = 0.81909139\n",
      "Iteration 53, loss = 0.82392230\n",
      "Iteration 54, loss = 0.79196054\n",
      "Iteration 55, loss = 0.76539816\n",
      "Iteration 56, loss = 0.75099556\n",
      "Iteration 57, loss = 0.75108794\n",
      "Iteration 58, loss = 0.73763112\n",
      "Iteration 59, loss = 0.77610111\n",
      "Iteration 60, loss = 0.70453143\n",
      "Iteration 61, loss = 0.70277955\n",
      "Iteration 62, loss = 0.76165034\n",
      "Iteration 63, loss = 0.77031917\n",
      "Iteration 64, loss = 0.75682794\n",
      "Iteration 65, loss = 0.73654227\n",
      "Iteration 66, loss = 0.74358771\n",
      "Iteration 67, loss = 0.74874701\n",
      "Iteration 68, loss = 0.73199363\n",
      "Iteration 69, loss = 0.71794918\n",
      "Iteration 70, loss = 0.72683873\n",
      "Iteration 55, loss = 0.76539816\n",
      "Iteration 56, loss = 0.75099556\n",
      "Iteration 57, loss = 0.75108794\n",
      "Iteration 58, loss = 0.73763112\n",
      "Iteration 59, loss = 0.77610111\n",
      "Iteration 60, loss = 0.70453143\n",
      "Iteration 61, loss = 0.70277955\n",
      "Iteration 62, loss = 0.76165034\n",
      "Iteration 63, loss = 0.77031917\n",
      "Iteration 64, loss = 0.75682794\n",
      "Iteration 65, loss = 0.73654227\n",
      "Iteration 66, loss = 0.74358771\n",
      "Iteration 67, loss = 0.74874701\n",
      "Iteration 68, loss = 0.73199363\n",
      "Iteration 69, loss = 0.71794918\n",
      "Iteration 70, loss = 0.72683873\n",
      "Iteration 71, loss = 0.75243039\n",
      "Iteration 72, loss = 0.73534263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24927430\n",
      "Iteration 2, loss = 1.07970529\n",
      "Iteration 3, loss = 1.00700149\n",
      "Iteration 4, loss = 0.96531450\n",
      "Iteration 5, loss = 0.94946781\n",
      "Iteration 6, loss = 0.94876006\n",
      "Iteration 7, loss = 0.95189394\n",
      "Iteration 8, loss = 0.93450541\n",
      "Iteration 9, loss = 0.92686508\n",
      "Iteration 71, loss = 0.75243039\n",
      "Iteration 72, loss = 0.73534263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24927430\n",
      "Iteration 2, loss = 1.07970529\n",
      "Iteration 3, loss = 1.00700149\n",
      "Iteration 4, loss = 0.96531450\n",
      "Iteration 5, loss = 0.94946781\n",
      "Iteration 6, loss = 0.94876006\n",
      "Iteration 7, loss = 0.95189394\n",
      "Iteration 8, loss = 0.93450541\n",
      "Iteration 9, loss = 0.92686508\n",
      "Iteration 10, loss = 0.92888901\n",
      "Iteration 11, loss = 0.93864994\n",
      "Iteration 12, loss = 0.92733107\n",
      "Iteration 13, loss = 0.89855829\n",
      "Iteration 14, loss = 0.90641789\n",
      "Iteration 15, loss = 0.88455022\n",
      "Iteration 16, loss = 0.94070594\n",
      "Iteration 17, loss = 0.88585787\n",
      "Iteration 18, loss = 0.90406345\n",
      "Iteration 19, loss = 0.86723640\n",
      "Iteration 20, loss = 0.91015852\n",
      "Iteration 21, loss = 0.95451427\n",
      "Iteration 22, loss = 0.93870441\n",
      "Iteration 23, loss = 0.89204269\n",
      "Iteration 24, loss = 0.85900683\n",
      "Iteration 10, loss = 0.92888901\n",
      "Iteration 11, loss = 0.93864994\n",
      "Iteration 12, loss = 0.92733107\n",
      "Iteration 13, loss = 0.89855829\n",
      "Iteration 14, loss = 0.90641789\n",
      "Iteration 15, loss = 0.88455022\n",
      "Iteration 16, loss = 0.94070594\n",
      "Iteration 17, loss = 0.88585787\n",
      "Iteration 18, loss = 0.90406345\n",
      "Iteration 19, loss = 0.86723640\n",
      "Iteration 20, loss = 0.91015852\n",
      "Iteration 21, loss = 0.95451427\n",
      "Iteration 22, loss = 0.93870441\n",
      "Iteration 23, loss = 0.89204269\n",
      "Iteration 24, loss = 0.85900683\n",
      "Iteration 25, loss = 0.86854977\n",
      "Iteration 26, loss = 0.84162955\n",
      "Iteration 27, loss = 0.86235377\n",
      "Iteration 28, loss = 0.82364713\n",
      "Iteration 29, loss = 0.84235281\n",
      "Iteration 30, loss = 0.86558652\n",
      "Iteration 31, loss = 0.88019491\n",
      "Iteration 32, loss = 0.87287684\n",
      "Iteration 33, loss = 0.85546115\n",
      "Iteration 34, loss = 0.82787367\n",
      "Iteration 35, loss = 0.83039954\n",
      "Iteration 36, loss = 0.85441670\n",
      "Iteration 37, loss = 0.86172879\n",
      "Iteration 38, loss = 0.84997921\n",
      "Iteration 39, loss = 0.84393175\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 0.86854977\n",
      "Iteration 26, loss = 0.84162955\n",
      "Iteration 27, loss = 0.86235377\n",
      "Iteration 28, loss = 0.82364713\n",
      "Iteration 29, loss = 0.84235281\n",
      "Iteration 30, loss = 0.86558652\n",
      "Iteration 31, loss = 0.88019491\n",
      "Iteration 32, loss = 0.87287684\n",
      "Iteration 33, loss = 0.85546115\n",
      "Iteration 34, loss = 0.82787367\n",
      "Iteration 35, loss = 0.83039954\n",
      "Iteration 36, loss = 0.85441670\n",
      "Iteration 37, loss = 0.86172879\n",
      "Iteration 38, loss = 0.84997921\n",
      "Iteration 39, loss = 0.84393175\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30758985\n",
      "Iteration 2, loss = 1.23773641\n",
      "Iteration 3, loss = 1.24825053\n",
      "Iteration 4, loss = 1.24454859\n",
      "Iteration 5, loss = 1.24245748\n",
      "Iteration 6, loss = 1.24898288\n",
      "Iteration 7, loss = 1.23535779\n",
      "Iteration 8, loss = 1.16229840\n",
      "Iteration 9, loss = 1.04885592\n",
      "Iteration 10, loss = 1.04458530\n",
      "Iteration 1, loss = 1.22759328\n",
      "Iteration 1, loss = 1.30758985\n",
      "Iteration 2, loss = 1.23773641\n",
      "Iteration 3, loss = 1.24825053\n",
      "Iteration 4, loss = 1.24454859\n",
      "Iteration 5, loss = 1.24245748\n",
      "Iteration 6, loss = 1.24898288\n",
      "Iteration 7, loss = 1.23535779\n",
      "Iteration 8, loss = 1.16229840\n",
      "Iteration 9, loss = 1.04885592\n",
      "Iteration 10, loss = 1.04458530\n",
      "Iteration 1, loss = 1.22759328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.12262338\n",
      "Iteration 3, loss = 1.05605808\n",
      "Iteration 4, loss = 1.06460676\n",
      "Iteration 5, loss = 1.03817258\n",
      "Iteration 6, loss = 0.95606570\n",
      "Iteration 7, loss = 0.96058810\n",
      "Iteration 8, loss = 0.94320812\n",
      "Iteration 9, loss = 0.93630873\n",
      "Iteration 10, loss = 0.94975719\n",
      "Iteration 1, loss = 1.23000771\n",
      "Iteration 2, loss = 1.11769848\n",
      "Iteration 2, loss = 1.12262338\n",
      "Iteration 3, loss = 1.05605808\n",
      "Iteration 4, loss = 1.06460676\n",
      "Iteration 5, loss = 1.03817258\n",
      "Iteration 6, loss = 0.95606570\n",
      "Iteration 7, loss = 0.96058810\n",
      "Iteration 8, loss = 0.94320812\n",
      "Iteration 9, loss = 0.93630873\n",
      "Iteration 10, loss = 0.94975719\n",
      "Iteration 1, loss = 1.23000771\n",
      "Iteration 2, loss = 1.11769848\n",
      "Iteration 3, loss = 1.12658652\n",
      "Iteration 4, loss = 1.13131230\n",
      "Iteration 5, loss = 0.97370883\n",
      "Iteration 6, loss = 0.97532727\n",
      "Iteration 7, loss = 1.00041827\n",
      "Iteration 8, loss = 0.98225769\n",
      "Iteration 9, loss = 0.97970588\n",
      "Iteration 10, loss = 0.98897914\n",
      "Iteration 1, loss = 1.25473976\n",
      "Iteration 2, loss = 1.18656494\n",
      "Iteration 3, loss = 1.13303956\n",
      "Iteration 4, loss = 1.10292815\n",
      "Iteration 5, loss = 1.12494103\n",
      "Iteration 3, loss = 1.12658652\n",
      "Iteration 4, loss = 1.13131230\n",
      "Iteration 5, loss = 0.97370883\n",
      "Iteration 6, loss = 0.97532727\n",
      "Iteration 7, loss = 1.00041827\n",
      "Iteration 8, loss = 0.98225769\n",
      "Iteration 9, loss = 0.97970588\n",
      "Iteration 10, loss = 0.98897914\n",
      "Iteration 1, loss = 1.25473976\n",
      "Iteration 2, loss = 1.18656494\n",
      "Iteration 3, loss = 1.13303956\n",
      "Iteration 4, loss = 1.10292815\n",
      "Iteration 5, loss = 1.12494103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.99650501\n",
      "Iteration 7, loss = 1.06739021\n",
      "Iteration 8, loss = 1.09920276\n",
      "Iteration 9, loss = 1.05601820\n",
      "Iteration 10, loss = 1.03384015\n",
      "Iteration 1, loss = 1.26273023\n",
      "Iteration 2, loss = 1.14814581\n",
      "Iteration 3, loss = 1.05989200\n",
      "Iteration 4, loss = 1.01157261\n",
      "Iteration 5, loss = 0.98512227\n",
      "Iteration 6, loss = 0.97704184\n",
      "Iteration 7, loss = 1.03915771\n",
      "Iteration 8, loss = 1.00029869\n",
      "Iteration 9, loss = 0.98906773\n",
      "Iteration 6, loss = 0.99650501\n",
      "Iteration 7, loss = 1.06739021\n",
      "Iteration 8, loss = 1.09920276\n",
      "Iteration 9, loss = 1.05601820\n",
      "Iteration 10, loss = 1.03384015\n",
      "Iteration 1, loss = 1.26273023\n",
      "Iteration 2, loss = 1.14814581\n",
      "Iteration 3, loss = 1.05989200\n",
      "Iteration 4, loss = 1.01157261\n",
      "Iteration 5, loss = 0.98512227\n",
      "Iteration 6, loss = 0.97704184\n",
      "Iteration 7, loss = 1.03915771\n",
      "Iteration 8, loss = 1.00029869\n",
      "Iteration 9, loss = 0.98906773\n",
      "Iteration 10, loss = 0.96383564\n",
      "Iteration 1, loss = 1.30758985\n",
      "Iteration 2, loss = 1.23773641\n",
      "Iteration 3, loss = 1.24825053\n",
      "Iteration 4, loss = 1.24454859\n",
      "Iteration 5, loss = 1.24245748\n",
      "Iteration 6, loss = 1.24898288\n",
      "Iteration 7, loss = 1.23535779\n",
      "Iteration 8, loss = 1.16229840\n",
      "Iteration 9, loss = 1.04885592\n",
      "Iteration 10, loss = 1.04458530\n",
      "Iteration 11, loss = 1.02249156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.96383564\n",
      "Iteration 1, loss = 1.30758985\n",
      "Iteration 2, loss = 1.23773641\n",
      "Iteration 3, loss = 1.24825053\n",
      "Iteration 4, loss = 1.24454859\n",
      "Iteration 5, loss = 1.24245748\n",
      "Iteration 6, loss = 1.24898288\n",
      "Iteration 7, loss = 1.23535779\n",
      "Iteration 8, loss = 1.16229840\n",
      "Iteration 9, loss = 1.04885592\n",
      "Iteration 10, loss = 1.04458530\n",
      "Iteration 11, loss = 1.02249156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 1.02143904\n",
      "Iteration 13, loss = 0.98607367\n",
      "Iteration 14, loss = 1.11714011\n",
      "Iteration 15, loss = 1.24487612\n",
      "Iteration 16, loss = 1.24761129\n",
      "Iteration 17, loss = 1.14241051\n",
      "Iteration 18, loss = 1.03903053\n",
      "Iteration 19, loss = 1.17535309\n",
      "Iteration 20, loss = 1.08922595\n",
      "Iteration 21, loss = 1.00163072\n",
      "Iteration 22, loss = 0.99270714\n",
      "Iteration 23, loss = 0.98844071\n",
      "Iteration 24, loss = 0.96499724\n",
      "Iteration 25, loss = 0.95733022\n",
      "Iteration 26, loss = 0.97097689\n",
      "Iteration 27, loss = 0.97232017\n",
      "Iteration 28, loss = 0.97314600\n",
      "Iteration 12, loss = 1.02143904\n",
      "Iteration 13, loss = 0.98607367\n",
      "Iteration 14, loss = 1.11714011\n",
      "Iteration 15, loss = 1.24487612\n",
      "Iteration 16, loss = 1.24761129\n",
      "Iteration 17, loss = 1.14241051\n",
      "Iteration 18, loss = 1.03903053\n",
      "Iteration 19, loss = 1.17535309\n",
      "Iteration 20, loss = 1.08922595\n",
      "Iteration 21, loss = 1.00163072\n",
      "Iteration 22, loss = 0.99270714\n",
      "Iteration 23, loss = 0.98844071\n",
      "Iteration 24, loss = 0.96499724\n",
      "Iteration 25, loss = 0.95733022\n",
      "Iteration 26, loss = 0.97097689\n",
      "Iteration 27, loss = 0.97232017\n",
      "Iteration 28, loss = 0.97314600\n",
      "Iteration 29, loss = 0.97044100\n",
      "Iteration 30, loss = 0.96303173\n",
      "Iteration 31, loss = 0.96889949\n",
      "Iteration 32, loss = 0.95795781\n",
      "Iteration 33, loss = 0.99073753\n",
      "Iteration 34, loss = 0.97088572\n",
      "Iteration 35, loss = 0.94290789\n",
      "Iteration 36, loss = 0.96543647\n",
      "Iteration 37, loss = 0.95981645\n",
      "Iteration 38, loss = 0.97297472\n",
      "Iteration 39, loss = 0.95266206\n",
      "Iteration 40, loss = 0.96701155\n",
      "Iteration 41, loss = 0.95140097\n",
      "Iteration 42, loss = 0.94188617\n",
      "Iteration 29, loss = 0.97044100\n",
      "Iteration 30, loss = 0.96303173\n",
      "Iteration 31, loss = 0.96889949\n",
      "Iteration 32, loss = 0.95795781\n",
      "Iteration 33, loss = 0.99073753\n",
      "Iteration 34, loss = 0.97088572\n",
      "Iteration 35, loss = 0.94290789\n",
      "Iteration 36, loss = 0.96543647\n",
      "Iteration 37, loss = 0.95981645\n",
      "Iteration 38, loss = 0.97297472\n",
      "Iteration 39, loss = 0.95266206\n",
      "Iteration 40, loss = 0.96701155\n",
      "Iteration 41, loss = 0.95140097\n",
      "Iteration 42, loss = 0.94188617\n",
      "Iteration 43, loss = 0.93657673\n",
      "Iteration 44, loss = 0.94501459\n",
      "Iteration 45, loss = 0.95373595\n",
      "Iteration 46, loss = 0.94114794\n",
      "Iteration 47, loss = 0.95352752\n",
      "Iteration 48, loss = 0.93873870\n",
      "Iteration 49, loss = 0.94437728\n",
      "Iteration 50, loss = 0.95452405\n",
      "Iteration 1, loss = 1.22759328\n",
      "Iteration 2, loss = 1.12262338\n",
      "Iteration 3, loss = 1.05605808\n",
      "Iteration 4, loss = 1.06460676\n",
      "Iteration 5, loss = 1.03817258\n",
      "Iteration 43, loss = 0.93657673\n",
      "Iteration 44, loss = 0.94501459\n",
      "Iteration 45, loss = 0.95373595\n",
      "Iteration 46, loss = 0.94114794\n",
      "Iteration 47, loss = 0.95352752\n",
      "Iteration 48, loss = 0.93873870\n",
      "Iteration 49, loss = 0.94437728\n",
      "Iteration 50, loss = 0.95452405\n",
      "Iteration 1, loss = 1.22759328\n",
      "Iteration 2, loss = 1.12262338\n",
      "Iteration 3, loss = 1.05605808\n",
      "Iteration 4, loss = 1.06460676\n",
      "Iteration 5, loss = 1.03817258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.95606570\n",
      "Iteration 7, loss = 0.96058810\n",
      "Iteration 8, loss = 0.94320812\n",
      "Iteration 9, loss = 0.93630873\n",
      "Iteration 10, loss = 0.94975719\n",
      "Iteration 11, loss = 0.90321722\n",
      "Iteration 12, loss = 0.92319997\n",
      "Iteration 13, loss = 0.89080635\n",
      "Iteration 14, loss = 1.05638884\n",
      "Iteration 15, loss = 1.09087683\n",
      "Iteration 16, loss = 0.95154880\n",
      "Iteration 17, loss = 0.95081083\n",
      "Iteration 18, loss = 0.95359632\n",
      "Iteration 6, loss = 0.95606570\n",
      "Iteration 7, loss = 0.96058810\n",
      "Iteration 8, loss = 0.94320812\n",
      "Iteration 9, loss = 0.93630873\n",
      "Iteration 10, loss = 0.94975719\n",
      "Iteration 11, loss = 0.90321722\n",
      "Iteration 12, loss = 0.92319997\n",
      "Iteration 13, loss = 0.89080635\n",
      "Iteration 14, loss = 1.05638884\n",
      "Iteration 15, loss = 1.09087683\n",
      "Iteration 16, loss = 0.95154880\n",
      "Iteration 17, loss = 0.95081083\n",
      "Iteration 18, loss = 0.95359632\n",
      "Iteration 19, loss = 0.96271158\n",
      "Iteration 20, loss = 0.98315866\n",
      "Iteration 21, loss = 0.97527597\n",
      "Iteration 22, loss = 0.93125492\n",
      "Iteration 23, loss = 0.92482455\n",
      "Iteration 24, loss = 0.93407731\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23000771\n",
      "Iteration 2, loss = 1.11769848\n",
      "Iteration 3, loss = 1.12658652\n",
      "Iteration 4, loss = 1.13131230\n",
      "Iteration 5, loss = 0.97370883\n",
      "Iteration 6, loss = 0.97532727\n",
      "Iteration 19, loss = 0.96271158\n",
      "Iteration 20, loss = 0.98315866\n",
      "Iteration 21, loss = 0.97527597\n",
      "Iteration 22, loss = 0.93125492\n",
      "Iteration 23, loss = 0.92482455\n",
      "Iteration 24, loss = 0.93407731\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23000771\n",
      "Iteration 2, loss = 1.11769848\n",
      "Iteration 3, loss = 1.12658652\n",
      "Iteration 4, loss = 1.13131230\n",
      "Iteration 5, loss = 0.97370883\n",
      "Iteration 6, loss = 0.97532727\n",
      "Iteration 7, loss = 1.00041827\n",
      "Iteration 8, loss = 0.98225769\n",
      "Iteration 9, loss = 0.97970588\n",
      "Iteration 10, loss = 0.98897914\n",
      "Iteration 11, loss = 0.94722670\n",
      "Iteration 12, loss = 0.95461460\n",
      "Iteration 13, loss = 0.93685087\n",
      "Iteration 14, loss = 0.95340796\n",
      "Iteration 15, loss = 0.95967765\n",
      "Iteration 16, loss = 0.94307047\n",
      "Iteration 17, loss = 0.96804456\n",
      "Iteration 18, loss = 1.00658406\n",
      "Iteration 19, loss = 0.97762307\n",
      "Iteration 20, loss = 0.97514692\n",
      "Iteration 21, loss = 0.96225661\n",
      "Iteration 7, loss = 1.00041827\n",
      "Iteration 8, loss = 0.98225769\n",
      "Iteration 9, loss = 0.97970588\n",
      "Iteration 10, loss = 0.98897914\n",
      "Iteration 11, loss = 0.94722670\n",
      "Iteration 12, loss = 0.95461460\n",
      "Iteration 13, loss = 0.93685087\n",
      "Iteration 14, loss = 0.95340796\n",
      "Iteration 15, loss = 0.95967765\n",
      "Iteration 16, loss = 0.94307047\n",
      "Iteration 17, loss = 0.96804456\n",
      "Iteration 18, loss = 1.00658406\n",
      "Iteration 19, loss = 0.97762307\n",
      "Iteration 20, loss = 0.97514692\n",
      "Iteration 21, loss = 0.96225661\n",
      "Iteration 22, loss = 0.96921771\n",
      "Iteration 23, loss = 0.99296877\n",
      "Iteration 24, loss = 1.00102527\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25473976\n",
      "Iteration 2, loss = 1.18656494\n",
      "Iteration 3, loss = 1.13303956\n",
      "Iteration 4, loss = 1.10292815\n",
      "Iteration 5, loss = 1.12494103\n",
      "Iteration 6, loss = 0.99650501\n",
      "Iteration 7, loss = 1.06739021\n",
      "Iteration 8, loss = 1.09920276\n",
      "Iteration 9, loss = 1.05601820\n",
      "Iteration 10, loss = 1.03384015\n",
      "Iteration 22, loss = 0.96921771\n",
      "Iteration 23, loss = 0.99296877\n",
      "Iteration 24, loss = 1.00102527\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25473976\n",
      "Iteration 2, loss = 1.18656494\n",
      "Iteration 3, loss = 1.13303956\n",
      "Iteration 4, loss = 1.10292815\n",
      "Iteration 5, loss = 1.12494103\n",
      "Iteration 6, loss = 0.99650501\n",
      "Iteration 7, loss = 1.06739021\n",
      "Iteration 8, loss = 1.09920276\n",
      "Iteration 9, loss = 1.05601820\n",
      "Iteration 10, loss = 1.03384015\n",
      "Iteration 11, loss = 1.04356786\n",
      "Iteration 12, loss = 1.03153114\n",
      "Iteration 13, loss = 1.01073870\n",
      "Iteration 14, loss = 1.00881572\n",
      "Iteration 15, loss = 1.00766504\n",
      "Iteration 16, loss = 0.99469953\n",
      "Iteration 17, loss = 1.01749893\n",
      "Iteration 18, loss = 0.97904641\n",
      "Iteration 19, loss = 1.00462958\n",
      "Iteration 20, loss = 0.96924088\n",
      "Iteration 21, loss = 1.05373975\n",
      "Iteration 22, loss = 0.99417750\n",
      "Iteration 23, loss = 1.00663362\n",
      "Iteration 24, loss = 1.00154892\n",
      "Iteration 11, loss = 1.04356786\n",
      "Iteration 12, loss = 1.03153114\n",
      "Iteration 13, loss = 1.01073870\n",
      "Iteration 14, loss = 1.00881572\n",
      "Iteration 15, loss = 1.00766504\n",
      "Iteration 16, loss = 0.99469953\n",
      "Iteration 17, loss = 1.01749893\n",
      "Iteration 18, loss = 0.97904641\n",
      "Iteration 19, loss = 1.00462958\n",
      "Iteration 20, loss = 0.96924088\n",
      "Iteration 21, loss = 1.05373975\n",
      "Iteration 22, loss = 0.99417750\n",
      "Iteration 23, loss = 1.00663362\n",
      "Iteration 24, loss = 1.00154892\n",
      "Iteration 25, loss = 0.92749339\n",
      "Iteration 26, loss = 0.98526979\n",
      "Iteration 27, loss = 0.99666068\n",
      "Iteration 28, loss = 0.93759984\n",
      "Iteration 29, loss = 0.90961973\n",
      "Iteration 30, loss = 0.92703647\n",
      "Iteration 31, loss = 0.98463112\n",
      "Iteration 32, loss = 0.94682863\n",
      "Iteration 33, loss = 0.95447618\n",
      "Iteration 34, loss = 0.96677587\n",
      "Iteration 35, loss = 0.97434308\n",
      "Iteration 36, loss = 0.93397013\n",
      "Iteration 37, loss = 0.98909907\n",
      "Iteration 38, loss = 0.90826574\n",
      "Iteration 39, loss = 0.94172645\n",
      "Iteration 40, loss = 0.92323558\n",
      "Iteration 25, loss = 0.92749339\n",
      "Iteration 26, loss = 0.98526979\n",
      "Iteration 27, loss = 0.99666068\n",
      "Iteration 28, loss = 0.93759984\n",
      "Iteration 29, loss = 0.90961973\n",
      "Iteration 30, loss = 0.92703647\n",
      "Iteration 31, loss = 0.98463112\n",
      "Iteration 32, loss = 0.94682863\n",
      "Iteration 33, loss = 0.95447618\n",
      "Iteration 34, loss = 0.96677587\n",
      "Iteration 35, loss = 0.97434308\n",
      "Iteration 36, loss = 0.93397013\n",
      "Iteration 37, loss = 0.98909907\n",
      "Iteration 38, loss = 0.90826574\n",
      "Iteration 39, loss = 0.94172645\n",
      "Iteration 40, loss = 0.92323558\n",
      "Iteration 41, loss = 0.94789266\n",
      "Iteration 42, loss = 0.92130405\n",
      "Iteration 43, loss = 0.91428193\n",
      "Iteration 44, loss = 0.91402168\n",
      "Iteration 45, loss = 0.90610130\n",
      "Iteration 46, loss = 0.93211616\n",
      "Iteration 47, loss = 0.88894868\n",
      "Iteration 48, loss = 0.95076186\n",
      "Iteration 49, loss = 0.99365232\n",
      "Iteration 50, loss = 1.02660435\n",
      "Iteration 1, loss = 1.26273023\n",
      "Iteration 2, loss = 1.14814581\n",
      "Iteration 3, loss = 1.05989200\n",
      "Iteration 41, loss = 0.94789266\n",
      "Iteration 42, loss = 0.92130405\n",
      "Iteration 43, loss = 0.91428193\n",
      "Iteration 44, loss = 0.91402168\n",
      "Iteration 45, loss = 0.90610130\n",
      "Iteration 46, loss = 0.93211616\n",
      "Iteration 47, loss = 0.88894868\n",
      "Iteration 48, loss = 0.95076186\n",
      "Iteration 49, loss = 0.99365232\n",
      "Iteration 50, loss = 1.02660435\n",
      "Iteration 1, loss = 1.26273023\n",
      "Iteration 2, loss = 1.14814581\n",
      "Iteration 3, loss = 1.05989200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.01157261\n",
      "Iteration 5, loss = 0.98512227\n",
      "Iteration 6, loss = 0.97704184\n",
      "Iteration 7, loss = 1.03915771\n",
      "Iteration 8, loss = 1.00029869\n",
      "Iteration 9, loss = 0.98906773\n",
      "Iteration 10, loss = 0.96383564\n",
      "Iteration 11, loss = 0.99762703\n",
      "Iteration 12, loss = 0.99593636\n",
      "Iteration 13, loss = 0.94988499\n",
      "Iteration 14, loss = 0.95881977\n",
      "Iteration 15, loss = 0.96759912\n",
      "Iteration 16, loss = 1.00071364\n",
      "Iteration 4, loss = 1.01157261\n",
      "Iteration 5, loss = 0.98512227\n",
      "Iteration 6, loss = 0.97704184\n",
      "Iteration 7, loss = 1.03915771\n",
      "Iteration 8, loss = 1.00029869\n",
      "Iteration 9, loss = 0.98906773\n",
      "Iteration 10, loss = 0.96383564\n",
      "Iteration 11, loss = 0.99762703\n",
      "Iteration 12, loss = 0.99593636\n",
      "Iteration 13, loss = 0.94988499\n",
      "Iteration 14, loss = 0.95881977\n",
      "Iteration 15, loss = 0.96759912\n",
      "Iteration 16, loss = 1.00071364\n",
      "Iteration 17, loss = 1.00354613\n",
      "Iteration 18, loss = 1.03520672\n",
      "Iteration 19, loss = 1.00234510\n",
      "Iteration 20, loss = 0.99887266\n",
      "Iteration 21, loss = 1.04518080\n",
      "Iteration 22, loss = 0.97482789\n",
      "Iteration 23, loss = 0.98525980\n",
      "Iteration 24, loss = 0.94467630\n",
      "Iteration 25, loss = 0.97072900\n",
      "Iteration 26, loss = 0.94332910\n",
      "Iteration 27, loss = 0.95694051\n",
      "Iteration 28, loss = 0.95777830\n",
      "Iteration 29, loss = 0.90776258\n",
      "Iteration 30, loss = 0.93243451\n",
      "Iteration 31, loss = 0.93231840\n",
      "Iteration 17, loss = 1.00354613\n",
      "Iteration 18, loss = 1.03520672\n",
      "Iteration 19, loss = 1.00234510\n",
      "Iteration 20, loss = 0.99887266\n",
      "Iteration 21, loss = 1.04518080\n",
      "Iteration 22, loss = 0.97482789\n",
      "Iteration 23, loss = 0.98525980\n",
      "Iteration 24, loss = 0.94467630\n",
      "Iteration 25, loss = 0.97072900\n",
      "Iteration 26, loss = 0.94332910\n",
      "Iteration 27, loss = 0.95694051\n",
      "Iteration 28, loss = 0.95777830\n",
      "Iteration 29, loss = 0.90776258\n",
      "Iteration 30, loss = 0.93243451\n",
      "Iteration 31, loss = 0.93231840\n",
      "Iteration 32, loss = 0.91683615\n",
      "Iteration 33, loss = 0.93422941\n",
      "Iteration 34, loss = 0.92816850\n",
      "Iteration 35, loss = 0.93872176\n",
      "Iteration 36, loss = 1.00498510\n",
      "Iteration 37, loss = 0.95628170\n",
      "Iteration 38, loss = 0.90615263\n",
      "Iteration 39, loss = 0.95228202\n",
      "Iteration 40, loss = 0.90268358\n",
      "Iteration 41, loss = 0.93521596\n",
      "Iteration 42, loss = 0.88550349\n",
      "Iteration 43, loss = 0.91873611\n",
      "Iteration 44, loss = 0.93072572\n",
      "Iteration 45, loss = 0.92714686\n",
      "Iteration 46, loss = 1.05344959\n",
      "Iteration 47, loss = 0.96770392\n",
      "Iteration 32, loss = 0.91683615\n",
      "Iteration 33, loss = 0.93422941\n",
      "Iteration 34, loss = 0.92816850\n",
      "Iteration 35, loss = 0.93872176\n",
      "Iteration 36, loss = 1.00498510\n",
      "Iteration 37, loss = 0.95628170\n",
      "Iteration 38, loss = 0.90615263\n",
      "Iteration 39, loss = 0.95228202\n",
      "Iteration 40, loss = 0.90268358\n",
      "Iteration 41, loss = 0.93521596\n",
      "Iteration 42, loss = 0.88550349\n",
      "Iteration 43, loss = 0.91873611\n",
      "Iteration 44, loss = 0.93072572\n",
      "Iteration 45, loss = 0.92714686\n",
      "Iteration 46, loss = 1.05344959\n",
      "Iteration 47, loss = 0.96770392\n",
      "Iteration 48, loss = 0.91231990\n",
      "Iteration 49, loss = 0.95649746\n",
      "Iteration 50, loss = 0.88415621\n",
      "Iteration 1, loss = 1.30758985\n",
      "Iteration 2, loss = 1.23773641\n",
      "Iteration 3, loss = 1.24825053\n",
      "Iteration 4, loss = 1.24454859\n",
      "Iteration 5, loss = 1.24245748\n",
      "Iteration 6, loss = 1.24898288\n",
      "Iteration 7, loss = 1.23535779\n",
      "Iteration 8, loss = 1.16229840\n",
      "Iteration 9, loss = 1.04885592\n",
      "Iteration 10, loss = 1.04458530\n",
      "Iteration 11, loss = 1.02249156\n",
      "Iteration 12, loss = 1.02143904\n",
      "Iteration 48, loss = 0.91231990\n",
      "Iteration 49, loss = 0.95649746\n",
      "Iteration 50, loss = 0.88415621\n",
      "Iteration 1, loss = 1.30758985\n",
      "Iteration 2, loss = 1.23773641\n",
      "Iteration 3, loss = 1.24825053\n",
      "Iteration 4, loss = 1.24454859\n",
      "Iteration 5, loss = 1.24245748\n",
      "Iteration 6, loss = 1.24898288\n",
      "Iteration 7, loss = 1.23535779\n",
      "Iteration 8, loss = 1.16229840\n",
      "Iteration 9, loss = 1.04885592\n",
      "Iteration 10, loss = 1.04458530\n",
      "Iteration 11, loss = 1.02249156\n",
      "Iteration 12, loss = 1.02143904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.98607367\n",
      "Iteration 14, loss = 1.11714011\n",
      "Iteration 15, loss = 1.24487612\n",
      "Iteration 16, loss = 1.24761129\n",
      "Iteration 17, loss = 1.14241051\n",
      "Iteration 18, loss = 1.03903053\n",
      "Iteration 19, loss = 1.17535309\n",
      "Iteration 20, loss = 1.08922595\n",
      "Iteration 21, loss = 1.00163072\n",
      "Iteration 22, loss = 0.99270714\n",
      "Iteration 23, loss = 0.98844071\n",
      "Iteration 24, loss = 0.96499724\n",
      "Iteration 25, loss = 0.95733022\n",
      "Iteration 26, loss = 0.97097689\n",
      "Iteration 27, loss = 0.97232017\n",
      "Iteration 13, loss = 0.98607367\n",
      "Iteration 14, loss = 1.11714011\n",
      "Iteration 15, loss = 1.24487612\n",
      "Iteration 16, loss = 1.24761129\n",
      "Iteration 17, loss = 1.14241051\n",
      "Iteration 18, loss = 1.03903053\n",
      "Iteration 19, loss = 1.17535309\n",
      "Iteration 20, loss = 1.08922595\n",
      "Iteration 21, loss = 1.00163072\n",
      "Iteration 22, loss = 0.99270714\n",
      "Iteration 23, loss = 0.98844071\n",
      "Iteration 24, loss = 0.96499724\n",
      "Iteration 25, loss = 0.95733022\n",
      "Iteration 26, loss = 0.97097689\n",
      "Iteration 27, loss = 0.97232017\n",
      "Iteration 28, loss = 0.97314600\n",
      "Iteration 29, loss = 0.97044100\n",
      "Iteration 30, loss = 0.96303173\n",
      "Iteration 31, loss = 0.96889949\n",
      "Iteration 32, loss = 0.95795781\n",
      "Iteration 33, loss = 0.99073753\n",
      "Iteration 34, loss = 0.97088572\n",
      "Iteration 35, loss = 0.94290789\n",
      "Iteration 36, loss = 0.96543647\n",
      "Iteration 37, loss = 0.95981645\n",
      "Iteration 38, loss = 0.97297472\n",
      "Iteration 39, loss = 0.95266206\n",
      "Iteration 40, loss = 0.96701155\n",
      "Iteration 41, loss = 0.95140097\n",
      "Iteration 42, loss = 0.94188617\n",
      "Iteration 43, loss = 0.93657673\n",
      "Iteration 28, loss = 0.97314600\n",
      "Iteration 29, loss = 0.97044100\n",
      "Iteration 30, loss = 0.96303173\n",
      "Iteration 31, loss = 0.96889949\n",
      "Iteration 32, loss = 0.95795781\n",
      "Iteration 33, loss = 0.99073753\n",
      "Iteration 34, loss = 0.97088572\n",
      "Iteration 35, loss = 0.94290789\n",
      "Iteration 36, loss = 0.96543647\n",
      "Iteration 37, loss = 0.95981645\n",
      "Iteration 38, loss = 0.97297472\n",
      "Iteration 39, loss = 0.95266206\n",
      "Iteration 40, loss = 0.96701155\n",
      "Iteration 41, loss = 0.95140097\n",
      "Iteration 42, loss = 0.94188617\n",
      "Iteration 43, loss = 0.93657673\n",
      "Iteration 44, loss = 0.94501459\n",
      "Iteration 45, loss = 0.95373595\n",
      "Iteration 46, loss = 0.94114794\n",
      "Iteration 47, loss = 0.95352752\n",
      "Iteration 48, loss = 0.93873870\n",
      "Iteration 49, loss = 0.94437728\n",
      "Iteration 50, loss = 0.95452405\n",
      "Iteration 51, loss = 0.94783180\n",
      "Iteration 52, loss = 0.94825406\n",
      "Iteration 53, loss = 0.96116553\n",
      "Iteration 54, loss = 0.95160252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22759328\n",
      "Iteration 2, loss = 1.12262338\n",
      "Iteration 3, loss = 1.05605808\n",
      "Iteration 44, loss = 0.94501459\n",
      "Iteration 45, loss = 0.95373595\n",
      "Iteration 46, loss = 0.94114794\n",
      "Iteration 47, loss = 0.95352752\n",
      "Iteration 48, loss = 0.93873870\n",
      "Iteration 49, loss = 0.94437728\n",
      "Iteration 50, loss = 0.95452405\n",
      "Iteration 51, loss = 0.94783180\n",
      "Iteration 52, loss = 0.94825406\n",
      "Iteration 53, loss = 0.96116553\n",
      "Iteration 54, loss = 0.95160252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22759328\n",
      "Iteration 2, loss = 1.12262338\n",
      "Iteration 3, loss = 1.05605808\n",
      "Iteration 4, loss = 1.06460676\n",
      "Iteration 5, loss = 1.03817258\n",
      "Iteration 6, loss = 0.95606570\n",
      "Iteration 7, loss = 0.96058810\n",
      "Iteration 8, loss = 0.94320812\n",
      "Iteration 9, loss = 0.93630873\n",
      "Iteration 10, loss = 0.94975719\n",
      "Iteration 11, loss = 0.90321722\n",
      "Iteration 12, loss = 0.92319997\n",
      "Iteration 13, loss = 0.89080635\n",
      "Iteration 14, loss = 1.05638884\n",
      "Iteration 15, loss = 1.09087683\n",
      "Iteration 16, loss = 0.95154880\n",
      "Iteration 17, loss = 0.95081083\n",
      "Iteration 4, loss = 1.06460676\n",
      "Iteration 5, loss = 1.03817258\n",
      "Iteration 6, loss = 0.95606570\n",
      "Iteration 7, loss = 0.96058810\n",
      "Iteration 8, loss = 0.94320812\n",
      "Iteration 9, loss = 0.93630873\n",
      "Iteration 10, loss = 0.94975719\n",
      "Iteration 11, loss = 0.90321722\n",
      "Iteration 12, loss = 0.92319997\n",
      "Iteration 13, loss = 0.89080635\n",
      "Iteration 14, loss = 1.05638884\n",
      "Iteration 15, loss = 1.09087683\n",
      "Iteration 16, loss = 0.95154880\n",
      "Iteration 17, loss = 0.95081083\n",
      "Iteration 18, loss = 0.95359632\n",
      "Iteration 19, loss = 0.96271158\n",
      "Iteration 20, loss = 0.98315866\n",
      "Iteration 21, loss = 0.97527597\n",
      "Iteration 22, loss = 0.93125492\n",
      "Iteration 23, loss = 0.92482455\n",
      "Iteration 24, loss = 0.93407731\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23000771\n",
      "Iteration 2, loss = 1.11769848\n",
      "Iteration 3, loss = 1.12658652\n",
      "Iteration 4, loss = 1.13131230\n",
      "Iteration 5, loss = 0.97370883\n",
      "Iteration 6, loss = 0.97532727\n",
      "Iteration 7, loss = 1.00041827\n",
      "Iteration 18, loss = 0.95359632\n",
      "Iteration 19, loss = 0.96271158\n",
      "Iteration 20, loss = 0.98315866\n",
      "Iteration 21, loss = 0.97527597\n",
      "Iteration 22, loss = 0.93125492\n",
      "Iteration 23, loss = 0.92482455\n",
      "Iteration 24, loss = 0.93407731\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23000771\n",
      "Iteration 2, loss = 1.11769848\n",
      "Iteration 3, loss = 1.12658652\n",
      "Iteration 4, loss = 1.13131230\n",
      "Iteration 5, loss = 0.97370883\n",
      "Iteration 6, loss = 0.97532727\n",
      "Iteration 7, loss = 1.00041827\n",
      "Iteration 8, loss = 0.98225769\n",
      "Iteration 9, loss = 0.97970588\n",
      "Iteration 10, loss = 0.98897914\n",
      "Iteration 11, loss = 0.94722670\n",
      "Iteration 12, loss = 0.95461460\n",
      "Iteration 13, loss = 0.93685087\n",
      "Iteration 14, loss = 0.95340796\n",
      "Iteration 15, loss = 0.95967765\n",
      "Iteration 16, loss = 0.94307047\n",
      "Iteration 17, loss = 0.96804456\n",
      "Iteration 18, loss = 1.00658406\n",
      "Iteration 19, loss = 0.97762307\n",
      "Iteration 20, loss = 0.97514692\n",
      "Iteration 8, loss = 0.98225769\n",
      "Iteration 9, loss = 0.97970588\n",
      "Iteration 10, loss = 0.98897914\n",
      "Iteration 11, loss = 0.94722670\n",
      "Iteration 12, loss = 0.95461460\n",
      "Iteration 13, loss = 0.93685087\n",
      "Iteration 14, loss = 0.95340796\n",
      "Iteration 15, loss = 0.95967765\n",
      "Iteration 16, loss = 0.94307047\n",
      "Iteration 17, loss = 0.96804456\n",
      "Iteration 18, loss = 1.00658406\n",
      "Iteration 19, loss = 0.97762307\n",
      "Iteration 20, loss = 0.97514692\n",
      "Iteration 21, loss = 0.96225661\n",
      "Iteration 22, loss = 0.96921771\n",
      "Iteration 23, loss = 0.99296877\n",
      "Iteration 24, loss = 1.00102527\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25473976\n",
      "Iteration 2, loss = 1.18656494\n",
      "Iteration 3, loss = 1.13303956\n",
      "Iteration 4, loss = 1.10292815\n",
      "Iteration 5, loss = 1.12494103\n",
      "Iteration 6, loss = 0.99650501\n",
      "Iteration 7, loss = 1.06739021\n",
      "Iteration 8, loss = 1.09920276\n",
      "Iteration 9, loss = 1.05601820\n",
      "Iteration 10, loss = 1.03384015\n",
      "Iteration 21, loss = 0.96225661\n",
      "Iteration 22, loss = 0.96921771\n",
      "Iteration 23, loss = 0.99296877\n",
      "Iteration 24, loss = 1.00102527\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25473976\n",
      "Iteration 2, loss = 1.18656494\n",
      "Iteration 3, loss = 1.13303956\n",
      "Iteration 4, loss = 1.10292815\n",
      "Iteration 5, loss = 1.12494103\n",
      "Iteration 6, loss = 0.99650501\n",
      "Iteration 7, loss = 1.06739021\n",
      "Iteration 8, loss = 1.09920276\n",
      "Iteration 9, loss = 1.05601820\n",
      "Iteration 10, loss = 1.03384015\n",
      "Iteration 11, loss = 1.04356786\n",
      "Iteration 12, loss = 1.03153114\n",
      "Iteration 13, loss = 1.01073870\n",
      "Iteration 14, loss = 1.00881572\n",
      "Iteration 15, loss = 1.00766504\n",
      "Iteration 16, loss = 0.99469953\n",
      "Iteration 17, loss = 1.01749893\n",
      "Iteration 18, loss = 0.97904641\n",
      "Iteration 19, loss = 1.00462958\n",
      "Iteration 20, loss = 0.96924088\n",
      "Iteration 21, loss = 1.05373975\n",
      "Iteration 22, loss = 0.99417750\n",
      "Iteration 23, loss = 1.00663362\n",
      "Iteration 24, loss = 1.00154892\n",
      "Iteration 25, loss = 0.92749339\n",
      "Iteration 11, loss = 1.04356786\n",
      "Iteration 12, loss = 1.03153114\n",
      "Iteration 13, loss = 1.01073870\n",
      "Iteration 14, loss = 1.00881572\n",
      "Iteration 15, loss = 1.00766504\n",
      "Iteration 16, loss = 0.99469953\n",
      "Iteration 17, loss = 1.01749893\n",
      "Iteration 18, loss = 0.97904641\n",
      "Iteration 19, loss = 1.00462958\n",
      "Iteration 20, loss = 0.96924088\n",
      "Iteration 21, loss = 1.05373975\n",
      "Iteration 22, loss = 0.99417750\n",
      "Iteration 23, loss = 1.00663362\n",
      "Iteration 24, loss = 1.00154892\n",
      "Iteration 25, loss = 0.92749339\n",
      "Iteration 26, loss = 0.98526979\n",
      "Iteration 27, loss = 0.99666068\n",
      "Iteration 28, loss = 0.93759984\n",
      "Iteration 29, loss = 0.90961973\n",
      "Iteration 30, loss = 0.92703647\n",
      "Iteration 31, loss = 0.98463112\n",
      "Iteration 32, loss = 0.94682863\n",
      "Iteration 33, loss = 0.95447618\n",
      "Iteration 34, loss = 0.96677587\n",
      "Iteration 35, loss = 0.97434308\n",
      "Iteration 36, loss = 0.93397013\n",
      "Iteration 37, loss = 0.98909907\n",
      "Iteration 38, loss = 0.90826574\n",
      "Iteration 39, loss = 0.94172645\n",
      "Iteration 40, loss = 0.92323558\n",
      "Iteration 26, loss = 0.98526979\n",
      "Iteration 27, loss = 0.99666068\n",
      "Iteration 28, loss = 0.93759984\n",
      "Iteration 29, loss = 0.90961973\n",
      "Iteration 30, loss = 0.92703647\n",
      "Iteration 31, loss = 0.98463112\n",
      "Iteration 32, loss = 0.94682863\n",
      "Iteration 33, loss = 0.95447618\n",
      "Iteration 34, loss = 0.96677587\n",
      "Iteration 35, loss = 0.97434308\n",
      "Iteration 36, loss = 0.93397013\n",
      "Iteration 37, loss = 0.98909907\n",
      "Iteration 38, loss = 0.90826574\n",
      "Iteration 39, loss = 0.94172645\n",
      "Iteration 40, loss = 0.92323558\n",
      "Iteration 41, loss = 0.94789266\n",
      "Iteration 42, loss = 0.92130405\n",
      "Iteration 43, loss = 0.91428193\n",
      "Iteration 44, loss = 0.91402168\n",
      "Iteration 45, loss = 0.90610130\n",
      "Iteration 46, loss = 0.93211616\n",
      "Iteration 47, loss = 0.88894868\n",
      "Iteration 48, loss = 0.95076186\n",
      "Iteration 49, loss = 0.99365232\n",
      "Iteration 50, loss = 1.02660435\n",
      "Iteration 51, loss = 0.95817431\n",
      "Iteration 52, loss = 0.98713576\n",
      "Iteration 53, loss = 0.95742822\n",
      "Iteration 54, loss = 0.95959120\n",
      "Iteration 55, loss = 0.94054103\n",
      "Iteration 56, loss = 0.96035571\n",
      "Iteration 41, loss = 0.94789266\n",
      "Iteration 42, loss = 0.92130405\n",
      "Iteration 43, loss = 0.91428193\n",
      "Iteration 44, loss = 0.91402168\n",
      "Iteration 45, loss = 0.90610130\n",
      "Iteration 46, loss = 0.93211616\n",
      "Iteration 47, loss = 0.88894868\n",
      "Iteration 48, loss = 0.95076186\n",
      "Iteration 49, loss = 0.99365232\n",
      "Iteration 50, loss = 1.02660435\n",
      "Iteration 51, loss = 0.95817431\n",
      "Iteration 52, loss = 0.98713576\n",
      "Iteration 53, loss = 0.95742822\n",
      "Iteration 54, loss = 0.95959120\n",
      "Iteration 55, loss = 0.94054103\n",
      "Iteration 56, loss = 0.96035571\n",
      "Iteration 57, loss = 0.94630855\n",
      "Iteration 58, loss = 0.95724602\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26273023\n",
      "Iteration 2, loss = 1.14814581\n",
      "Iteration 3, loss = 1.05989200\n",
      "Iteration 4, loss = 1.01157261\n",
      "Iteration 5, loss = 0.98512227\n",
      "Iteration 6, loss = 0.97704184\n",
      "Iteration 7, loss = 1.03915771\n",
      "Iteration 8, loss = 1.00029869\n",
      "Iteration 9, loss = 0.98906773\n",
      "Iteration 10, loss = 0.96383564\n",
      "Iteration 57, loss = 0.94630855\n",
      "Iteration 58, loss = 0.95724602\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26273023\n",
      "Iteration 2, loss = 1.14814581\n",
      "Iteration 3, loss = 1.05989200\n",
      "Iteration 4, loss = 1.01157261\n",
      "Iteration 5, loss = 0.98512227\n",
      "Iteration 6, loss = 0.97704184\n",
      "Iteration 7, loss = 1.03915771\n",
      "Iteration 8, loss = 1.00029869\n",
      "Iteration 9, loss = 0.98906773\n",
      "Iteration 10, loss = 0.96383564\n",
      "Iteration 11, loss = 0.99762703\n",
      "Iteration 12, loss = 0.99593636\n",
      "Iteration 13, loss = 0.94988499\n",
      "Iteration 14, loss = 0.95881977\n",
      "Iteration 15, loss = 0.96759912\n",
      "Iteration 16, loss = 1.00071364\n",
      "Iteration 17, loss = 1.00354613\n",
      "Iteration 18, loss = 1.03520672\n",
      "Iteration 19, loss = 1.00234510\n",
      "Iteration 20, loss = 0.99887266\n",
      "Iteration 21, loss = 1.04518080\n",
      "Iteration 22, loss = 0.97482789\n",
      "Iteration 23, loss = 0.98525980\n",
      "Iteration 11, loss = 0.99762703\n",
      "Iteration 12, loss = 0.99593636\n",
      "Iteration 13, loss = 0.94988499\n",
      "Iteration 14, loss = 0.95881977\n",
      "Iteration 15, loss = 0.96759912\n",
      "Iteration 16, loss = 1.00071364\n",
      "Iteration 17, loss = 1.00354613\n",
      "Iteration 18, loss = 1.03520672\n",
      "Iteration 19, loss = 1.00234510\n",
      "Iteration 20, loss = 0.99887266\n",
      "Iteration 21, loss = 1.04518080\n",
      "Iteration 22, loss = 0.97482789\n",
      "Iteration 23, loss = 0.98525980\n",
      "Iteration 24, loss = 0.94467630\n",
      "Iteration 25, loss = 0.97072900\n",
      "Iteration 26, loss = 0.94332910\n",
      "Iteration 27, loss = 0.95694051\n",
      "Iteration 28, loss = 0.95777830\n",
      "Iteration 29, loss = 0.90776258\n",
      "Iteration 30, loss = 0.93243451\n",
      "Iteration 31, loss = 0.93231840\n",
      "Iteration 32, loss = 0.91683615\n",
      "Iteration 33, loss = 0.93422941\n",
      "Iteration 34, loss = 0.92816850\n",
      "Iteration 35, loss = 0.93872176\n",
      "Iteration 36, loss = 1.00498510\n",
      "Iteration 37, loss = 0.95628170\n",
      "Iteration 38, loss = 0.90615263\n",
      "Iteration 24, loss = 0.94467630\n",
      "Iteration 25, loss = 0.97072900\n",
      "Iteration 26, loss = 0.94332910\n",
      "Iteration 27, loss = 0.95694051\n",
      "Iteration 28, loss = 0.95777830\n",
      "Iteration 29, loss = 0.90776258\n",
      "Iteration 30, loss = 0.93243451\n",
      "Iteration 31, loss = 0.93231840\n",
      "Iteration 32, loss = 0.91683615\n",
      "Iteration 33, loss = 0.93422941\n",
      "Iteration 34, loss = 0.92816850\n",
      "Iteration 35, loss = 0.93872176\n",
      "Iteration 36, loss = 1.00498510\n",
      "Iteration 37, loss = 0.95628170\n",
      "Iteration 38, loss = 0.90615263\n",
      "Iteration 39, loss = 0.95228202\n",
      "Iteration 40, loss = 0.90268358\n",
      "Iteration 41, loss = 0.93521596\n",
      "Iteration 42, loss = 0.88550349\n",
      "Iteration 43, loss = 0.91873611\n",
      "Iteration 44, loss = 0.93072572\n",
      "Iteration 45, loss = 0.92714686\n",
      "Iteration 46, loss = 1.05344959\n",
      "Iteration 47, loss = 0.96770392\n",
      "Iteration 48, loss = 0.91231990\n",
      "Iteration 49, loss = 0.95649746\n",
      "Iteration 50, loss = 0.88415621\n",
      "Iteration 51, loss = 0.87997772\n",
      "Iteration 52, loss = 0.87038941\n",
      "Iteration 39, loss = 0.95228202\n",
      "Iteration 40, loss = 0.90268358\n",
      "Iteration 41, loss = 0.93521596\n",
      "Iteration 42, loss = 0.88550349\n",
      "Iteration 43, loss = 0.91873611\n",
      "Iteration 44, loss = 0.93072572\n",
      "Iteration 45, loss = 0.92714686\n",
      "Iteration 46, loss = 1.05344959\n",
      "Iteration 47, loss = 0.96770392\n",
      "Iteration 48, loss = 0.91231990\n",
      "Iteration 49, loss = 0.95649746\n",
      "Iteration 50, loss = 0.88415621\n",
      "Iteration 51, loss = 0.87997772\n",
      "Iteration 52, loss = 0.87038941\n",
      "Iteration 53, loss = 0.87325500\n",
      "Iteration 54, loss = 0.89101291\n",
      "Iteration 55, loss = 0.87000026\n",
      "Iteration 56, loss = 0.89281678\n",
      "Iteration 57, loss = 0.99780201\n",
      "Iteration 58, loss = 0.88316648\n",
      "Iteration 59, loss = 0.88169299\n",
      "Iteration 60, loss = 0.90827423\n",
      "Iteration 61, loss = 0.90858104\n",
      "Iteration 62, loss = 0.85995097\n",
      "Iteration 63, loss = 0.89487680\n",
      "Iteration 64, loss = 0.87658397\n",
      "Iteration 65, loss = 0.85651630\n",
      "Iteration 66, loss = 0.85296896\n",
      "Iteration 67, loss = 0.86534526\n",
      "Iteration 53, loss = 0.87325500\n",
      "Iteration 54, loss = 0.89101291\n",
      "Iteration 55, loss = 0.87000026\n",
      "Iteration 56, loss = 0.89281678\n",
      "Iteration 57, loss = 0.99780201\n",
      "Iteration 58, loss = 0.88316648\n",
      "Iteration 59, loss = 0.88169299\n",
      "Iteration 60, loss = 0.90827423\n",
      "Iteration 61, loss = 0.90858104\n",
      "Iteration 62, loss = 0.85995097\n",
      "Iteration 63, loss = 0.89487680\n",
      "Iteration 64, loss = 0.87658397\n",
      "Iteration 65, loss = 0.85651630\n",
      "Iteration 66, loss = 0.85296896\n",
      "Iteration 67, loss = 0.86534526\n",
      "Iteration 68, loss = 0.86591932\n",
      "Iteration 69, loss = 0.83221466\n",
      "Iteration 70, loss = 0.84076540\n",
      "Iteration 71, loss = 0.87308255\n",
      "Iteration 72, loss = 0.87536218\n",
      "Iteration 73, loss = 0.93689260\n",
      "Iteration 74, loss = 0.88040149\n",
      "Iteration 75, loss = 0.89769712\n",
      "Iteration 76, loss = 0.87944373\n",
      "Iteration 77, loss = 0.88603454\n",
      "Iteration 78, loss = 0.88183781\n",
      "Iteration 79, loss = 0.91162850\n",
      "Iteration 68, loss = 0.86591932\n",
      "Iteration 69, loss = 0.83221466\n",
      "Iteration 70, loss = 0.84076540\n",
      "Iteration 71, loss = 0.87308255\n",
      "Iteration 72, loss = 0.87536218\n",
      "Iteration 73, loss = 0.93689260\n",
      "Iteration 74, loss = 0.88040149\n",
      "Iteration 75, loss = 0.89769712\n",
      "Iteration 76, loss = 0.87944373\n",
      "Iteration 77, loss = 0.88603454\n",
      "Iteration 78, loss = 0.88183781\n",
      "Iteration 79, loss = 0.91162850\n",
      "Iteration 80, loss = 0.95121179\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31037008\n",
      "Iteration 2, loss = 1.24055363\n",
      "Iteration 3, loss = 1.25474209\n",
      "Iteration 4, loss = 1.24972599\n",
      "Iteration 5, loss = 1.24533075\n",
      "Iteration 6, loss = 1.25583368\n",
      "Iteration 7, loss = 1.25406202\n",
      "Iteration 8, loss = 1.25261276\n",
      "Iteration 9, loss = 1.24402752\n",
      "Iteration 10, loss = 1.25726390\n",
      "Iteration 1, loss = 1.28786459\n",
      "Iteration 2, loss = 1.23259441\n",
      "Iteration 80, loss = 0.95121179\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31037008\n",
      "Iteration 2, loss = 1.24055363\n",
      "Iteration 3, loss = 1.25474209\n",
      "Iteration 4, loss = 1.24972599\n",
      "Iteration 5, loss = 1.24533075\n",
      "Iteration 6, loss = 1.25583368\n",
      "Iteration 7, loss = 1.25406202\n",
      "Iteration 8, loss = 1.25261276\n",
      "Iteration 9, loss = 1.24402752\n",
      "Iteration 10, loss = 1.25726390\n",
      "Iteration 1, loss = 1.28786459\n",
      "Iteration 2, loss = 1.23259441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.24626109\n",
      "Iteration 4, loss = 1.25033803\n",
      "Iteration 5, loss = 1.25091523\n",
      "Iteration 6, loss = 1.25474582\n",
      "Iteration 7, loss = 1.25626751\n",
      "Iteration 8, loss = 1.24898260\n",
      "Iteration 9, loss = 1.24403392\n",
      "Iteration 10, loss = 1.23863868\n",
      "Iteration 1, loss = 1.27977317\n",
      "Iteration 2, loss = 1.25693577\n",
      "Iteration 3, loss = 1.26206578\n",
      "Iteration 4, loss = 1.26343886\n",
      "Iteration 5, loss = 1.25709423\n",
      "Iteration 6, loss = 1.26483255\n",
      "Iteration 3, loss = 1.24626109\n",
      "Iteration 4, loss = 1.25033803\n",
      "Iteration 5, loss = 1.25091523\n",
      "Iteration 6, loss = 1.25474582\n",
      "Iteration 7, loss = 1.25626751\n",
      "Iteration 8, loss = 1.24898260\n",
      "Iteration 9, loss = 1.24403392\n",
      "Iteration 10, loss = 1.23863868\n",
      "Iteration 1, loss = 1.27977317\n",
      "Iteration 2, loss = 1.25693577\n",
      "Iteration 3, loss = 1.26206578\n",
      "Iteration 4, loss = 1.26343886\n",
      "Iteration 5, loss = 1.25709423\n",
      "Iteration 6, loss = 1.26483255\n",
      "Iteration 7, loss = 1.25764221\n",
      "Iteration 8, loss = 1.25681462\n",
      "Iteration 9, loss = 1.26161459\n",
      "Iteration 10, loss = 1.25725085\n",
      "Iteration 1, loss = 1.27356623\n",
      "Iteration 2, loss = 1.24784033\n",
      "Iteration 3, loss = 1.26569653\n",
      "Iteration 4, loss = 1.26245117\n",
      "Iteration 5, loss = 1.25570420\n",
      "Iteration 6, loss = 1.26273310\n",
      "Iteration 7, loss = 1.24769728\n",
      "Iteration 8, loss = 1.25534674\n",
      "Iteration 7, loss = 1.25764221\n",
      "Iteration 8, loss = 1.25681462\n",
      "Iteration 9, loss = 1.26161459\n",
      "Iteration 10, loss = 1.25725085\n",
      "Iteration 1, loss = 1.27356623\n",
      "Iteration 2, loss = 1.24784033\n",
      "Iteration 3, loss = 1.26569653\n",
      "Iteration 4, loss = 1.26245117\n",
      "Iteration 5, loss = 1.25570420\n",
      "Iteration 6, loss = 1.26273310\n",
      "Iteration 7, loss = 1.24769728\n",
      "Iteration 8, loss = 1.25534674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.24210703\n",
      "Iteration 10, loss = 1.24481858\n",
      "Iteration 1, loss = 1.25893346\n",
      "Iteration 2, loss = 1.13753278\n",
      "Iteration 3, loss = 1.17300402\n",
      "Iteration 4, loss = 1.12622422\n",
      "Iteration 5, loss = 1.05998171\n",
      "Iteration 6, loss = 1.04745708\n",
      "Iteration 7, loss = 1.06798405\n",
      "Iteration 8, loss = 1.02961025\n",
      "Iteration 9, loss = 1.00481189\n",
      "Iteration 10, loss = 0.99474897\n",
      "Iteration 1, loss = 1.31037008\n",
      "Iteration 2, loss = 1.24055363\n",
      "Iteration 9, loss = 1.24210703\n",
      "Iteration 10, loss = 1.24481858\n",
      "Iteration 1, loss = 1.25893346\n",
      "Iteration 2, loss = 1.13753278\n",
      "Iteration 3, loss = 1.17300402\n",
      "Iteration 4, loss = 1.12622422\n",
      "Iteration 5, loss = 1.05998171\n",
      "Iteration 6, loss = 1.04745708\n",
      "Iteration 7, loss = 1.06798405\n",
      "Iteration 8, loss = 1.02961025\n",
      "Iteration 9, loss = 1.00481189\n",
      "Iteration 10, loss = 0.99474897\n",
      "Iteration 1, loss = 1.31037008\n",
      "Iteration 2, loss = 1.24055363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.25474209\n",
      "Iteration 4, loss = 1.24972599\n",
      "Iteration 5, loss = 1.24533075\n",
      "Iteration 6, loss = 1.25583368\n",
      "Iteration 7, loss = 1.25406202\n",
      "Iteration 8, loss = 1.25261276\n",
      "Iteration 9, loss = 1.24402752\n",
      "Iteration 10, loss = 1.25726390\n",
      "Iteration 11, loss = 1.24682552\n",
      "Iteration 12, loss = 1.24444186\n",
      "Iteration 13, loss = 1.24045275\n",
      "Iteration 14, loss = 1.24970193\n",
      "Iteration 15, loss = 1.24447751\n",
      "Iteration 16, loss = 1.25655856\n",
      "Iteration 3, loss = 1.25474209\n",
      "Iteration 4, loss = 1.24972599\n",
      "Iteration 5, loss = 1.24533075\n",
      "Iteration 6, loss = 1.25583368\n",
      "Iteration 7, loss = 1.25406202\n",
      "Iteration 8, loss = 1.25261276\n",
      "Iteration 9, loss = 1.24402752\n",
      "Iteration 10, loss = 1.25726390\n",
      "Iteration 11, loss = 1.24682552\n",
      "Iteration 12, loss = 1.24444186\n",
      "Iteration 13, loss = 1.24045275\n",
      "Iteration 14, loss = 1.24970193\n",
      "Iteration 15, loss = 1.24447751\n",
      "Iteration 16, loss = 1.25655856\n",
      "Iteration 17, loss = 1.24544882\n",
      "Iteration 18, loss = 1.24788846\n",
      "Iteration 19, loss = 1.24686816\n",
      "Iteration 20, loss = 1.23438272\n",
      "Iteration 21, loss = 1.25285161\n",
      "Iteration 22, loss = 1.24590827\n",
      "Iteration 23, loss = 1.25063857\n",
      "Iteration 24, loss = 1.24214343\n",
      "Iteration 25, loss = 1.24878394\n",
      "Iteration 26, loss = 1.24281778\n",
      "Iteration 27, loss = 1.24095132\n",
      "Iteration 28, loss = 1.25611446\n",
      "Iteration 29, loss = 1.24463060\n",
      "Iteration 30, loss = 1.24598332\n",
      "Iteration 31, loss = 1.24208231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 1.24544882\n",
      "Iteration 18, loss = 1.24788846\n",
      "Iteration 19, loss = 1.24686816\n",
      "Iteration 20, loss = 1.23438272\n",
      "Iteration 21, loss = 1.25285161\n",
      "Iteration 22, loss = 1.24590827\n",
      "Iteration 23, loss = 1.25063857\n",
      "Iteration 24, loss = 1.24214343\n",
      "Iteration 25, loss = 1.24878394\n",
      "Iteration 26, loss = 1.24281778\n",
      "Iteration 27, loss = 1.24095132\n",
      "Iteration 28, loss = 1.25611446\n",
      "Iteration 29, loss = 1.24463060\n",
      "Iteration 30, loss = 1.24598332\n",
      "Iteration 31, loss = 1.24208231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28786459\n",
      "Iteration 2, loss = 1.23259441\n",
      "Iteration 3, loss = 1.24626109\n",
      "Iteration 4, loss = 1.25033803\n",
      "Iteration 5, loss = 1.25091523\n",
      "Iteration 6, loss = 1.25474582\n",
      "Iteration 7, loss = 1.25626751\n",
      "Iteration 8, loss = 1.24898260\n",
      "Iteration 9, loss = 1.24403392\n",
      "Iteration 10, loss = 1.23863868\n",
      "Iteration 11, loss = 1.23876487\n",
      "Iteration 12, loss = 1.23518101\n",
      "Iteration 13, loss = 1.23684493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27977317\n",
      "Iteration 1, loss = 1.28786459\n",
      "Iteration 2, loss = 1.23259441\n",
      "Iteration 3, loss = 1.24626109\n",
      "Iteration 4, loss = 1.25033803\n",
      "Iteration 5, loss = 1.25091523\n",
      "Iteration 6, loss = 1.25474582\n",
      "Iteration 7, loss = 1.25626751\n",
      "Iteration 8, loss = 1.24898260\n",
      "Iteration 9, loss = 1.24403392\n",
      "Iteration 10, loss = 1.23863868\n",
      "Iteration 11, loss = 1.23876487\n",
      "Iteration 12, loss = 1.23518101\n",
      "Iteration 13, loss = 1.23684493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27977317\n",
      "Iteration 2, loss = 1.25693577\n",
      "Iteration 3, loss = 1.26206578\n",
      "Iteration 4, loss = 1.26343886\n",
      "Iteration 5, loss = 1.25709423\n",
      "Iteration 6, loss = 1.26483255\n",
      "Iteration 7, loss = 1.25764221\n",
      "Iteration 8, loss = 1.25681462\n",
      "Iteration 9, loss = 1.26161459\n",
      "Iteration 10, loss = 1.25725085\n",
      "Iteration 11, loss = 1.25664823\n",
      "Iteration 12, loss = 1.25236934\n",
      "Iteration 13, loss = 1.25351582\n",
      "Iteration 14, loss = 1.25819632\n",
      "Iteration 2, loss = 1.25693577\n",
      "Iteration 3, loss = 1.26206578\n",
      "Iteration 4, loss = 1.26343886\n",
      "Iteration 5, loss = 1.25709423\n",
      "Iteration 6, loss = 1.26483255\n",
      "Iteration 7, loss = 1.25764221\n",
      "Iteration 8, loss = 1.25681462\n",
      "Iteration 9, loss = 1.26161459\n",
      "Iteration 10, loss = 1.25725085\n",
      "Iteration 11, loss = 1.25664823\n",
      "Iteration 12, loss = 1.25236934\n",
      "Iteration 13, loss = 1.25351582\n",
      "Iteration 14, loss = 1.25819632\n",
      "Iteration 15, loss = 1.26695709\n",
      "Iteration 16, loss = 1.26231392\n",
      "Iteration 17, loss = 1.25707242\n",
      "Iteration 18, loss = 1.26124637\n",
      "Iteration 19, loss = 1.25367142\n",
      "Iteration 20, loss = 1.25368618\n",
      "Iteration 21, loss = 1.26456739\n",
      "Iteration 22, loss = 1.25707389\n",
      "Iteration 23, loss = 1.27196615\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27356623\n",
      "Iteration 2, loss = 1.24784033\n",
      "Iteration 3, loss = 1.26569653\n",
      "Iteration 4, loss = 1.26245117\n",
      "Iteration 5, loss = 1.25570420\n",
      "Iteration 15, loss = 1.26695709\n",
      "Iteration 16, loss = 1.26231392\n",
      "Iteration 17, loss = 1.25707242\n",
      "Iteration 18, loss = 1.26124637\n",
      "Iteration 19, loss = 1.25367142\n",
      "Iteration 20, loss = 1.25368618\n",
      "Iteration 21, loss = 1.26456739\n",
      "Iteration 22, loss = 1.25707389\n",
      "Iteration 23, loss = 1.27196615\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27356623\n",
      "Iteration 2, loss = 1.24784033\n",
      "Iteration 3, loss = 1.26569653\n",
      "Iteration 4, loss = 1.26245117\n",
      "Iteration 5, loss = 1.25570420\n",
      "Iteration 6, loss = 1.26273310\n",
      "Iteration 7, loss = 1.24769728\n",
      "Iteration 8, loss = 1.25534674\n",
      "Iteration 9, loss = 1.24210703\n",
      "Iteration 10, loss = 1.24481858\n",
      "Iteration 11, loss = 1.26357900\n",
      "Iteration 12, loss = 1.25710535\n",
      "Iteration 13, loss = 1.24687184\n",
      "Iteration 14, loss = 1.24764366\n",
      "Iteration 15, loss = 1.24506697\n",
      "Iteration 16, loss = 1.25561695\n",
      "Iteration 17, loss = 1.24753778\n",
      "Iteration 18, loss = 1.24177469\n",
      "Iteration 6, loss = 1.26273310\n",
      "Iteration 7, loss = 1.24769728\n",
      "Iteration 8, loss = 1.25534674\n",
      "Iteration 9, loss = 1.24210703\n",
      "Iteration 10, loss = 1.24481858\n",
      "Iteration 11, loss = 1.26357900\n",
      "Iteration 12, loss = 1.25710535\n",
      "Iteration 13, loss = 1.24687184\n",
      "Iteration 14, loss = 1.24764366\n",
      "Iteration 15, loss = 1.24506697\n",
      "Iteration 16, loss = 1.25561695\n",
      "Iteration 17, loss = 1.24753778\n",
      "Iteration 18, loss = 1.24177469\n",
      "Iteration 19, loss = 1.25175847\n",
      "Iteration 20, loss = 1.25415803\n",
      "Iteration 21, loss = 1.24492004\n",
      "Iteration 22, loss = 1.25451970\n",
      "Iteration 23, loss = 1.26480214\n",
      "Iteration 24, loss = 1.25769611\n",
      "Iteration 25, loss = 1.24420481\n",
      "Iteration 26, loss = 1.26040489\n",
      "Iteration 27, loss = 1.25221194\n",
      "Iteration 28, loss = 1.25038272\n",
      "Iteration 29, loss = 1.24441952\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25893346\n",
      "Iteration 2, loss = 1.13753278\n",
      "Iteration 3, loss = 1.17300402\n",
      "Iteration 4, loss = 1.12622422\n",
      "Iteration 19, loss = 1.25175847\n",
      "Iteration 20, loss = 1.25415803\n",
      "Iteration 21, loss = 1.24492004\n",
      "Iteration 22, loss = 1.25451970\n",
      "Iteration 23, loss = 1.26480214\n",
      "Iteration 24, loss = 1.25769611\n",
      "Iteration 25, loss = 1.24420481\n",
      "Iteration 26, loss = 1.26040489\n",
      "Iteration 27, loss = 1.25221194\n",
      "Iteration 28, loss = 1.25038272\n",
      "Iteration 29, loss = 1.24441952\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25893346\n",
      "Iteration 2, loss = 1.13753278\n",
      "Iteration 3, loss = 1.17300402\n",
      "Iteration 4, loss = 1.12622422\n",
      "Iteration 5, loss = 1.05998171\n",
      "Iteration 6, loss = 1.04745708\n",
      "Iteration 7, loss = 1.06798405\n",
      "Iteration 8, loss = 1.02961025\n",
      "Iteration 9, loss = 1.00481189\n",
      "Iteration 10, loss = 0.99474897\n",
      "Iteration 11, loss = 1.00840743\n",
      "Iteration 12, loss = 0.99526655\n",
      "Iteration 13, loss = 0.98861585\n",
      "Iteration 14, loss = 0.99299906\n",
      "Iteration 15, loss = 0.98294709\n",
      "Iteration 16, loss = 1.01805062\n",
      "Iteration 17, loss = 0.98461889\n",
      "Iteration 18, loss = 1.01016824\n",
      "Iteration 19, loss = 1.05102688\n",
      "Iteration 5, loss = 1.05998171\n",
      "Iteration 6, loss = 1.04745708\n",
      "Iteration 7, loss = 1.06798405\n",
      "Iteration 8, loss = 1.02961025\n",
      "Iteration 9, loss = 1.00481189\n",
      "Iteration 10, loss = 0.99474897\n",
      "Iteration 11, loss = 1.00840743\n",
      "Iteration 12, loss = 0.99526655\n",
      "Iteration 13, loss = 0.98861585\n",
      "Iteration 14, loss = 0.99299906\n",
      "Iteration 15, loss = 0.98294709\n",
      "Iteration 16, loss = 1.01805062\n",
      "Iteration 17, loss = 0.98461889\n",
      "Iteration 18, loss = 1.01016824\n",
      "Iteration 19, loss = 1.05102688\n",
      "Iteration 20, loss = 1.15068653\n",
      "Iteration 21, loss = 1.05615117\n",
      "Iteration 22, loss = 1.03309481\n",
      "Iteration 23, loss = 1.08940481\n",
      "Iteration 24, loss = 1.07615383\n",
      "Iteration 25, loss = 1.02464048\n",
      "Iteration 26, loss = 0.99501639\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31037008\n",
      "Iteration 2, loss = 1.24055363\n",
      "Iteration 3, loss = 1.25474209\n",
      "Iteration 4, loss = 1.24972599\n",
      "Iteration 5, loss = 1.24533075\n",
      "Iteration 6, loss = 1.25583368\n",
      "Iteration 20, loss = 1.15068653\n",
      "Iteration 21, loss = 1.05615117\n",
      "Iteration 22, loss = 1.03309481\n",
      "Iteration 23, loss = 1.08940481\n",
      "Iteration 24, loss = 1.07615383\n",
      "Iteration 25, loss = 1.02464048\n",
      "Iteration 26, loss = 0.99501639\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31037008\n",
      "Iteration 2, loss = 1.24055363\n",
      "Iteration 3, loss = 1.25474209\n",
      "Iteration 4, loss = 1.24972599\n",
      "Iteration 5, loss = 1.24533075\n",
      "Iteration 6, loss = 1.25583368\n",
      "Iteration 7, loss = 1.25406202\n",
      "Iteration 8, loss = 1.25261276\n",
      "Iteration 9, loss = 1.24402752\n",
      "Iteration 10, loss = 1.25726390\n",
      "Iteration 11, loss = 1.24682552\n",
      "Iteration 12, loss = 1.24444186\n",
      "Iteration 13, loss = 1.24045275\n",
      "Iteration 14, loss = 1.24970193\n",
      "Iteration 15, loss = 1.24447751\n",
      "Iteration 16, loss = 1.25655856\n",
      "Iteration 17, loss = 1.24544882\n",
      "Iteration 18, loss = 1.24788846\n",
      "Iteration 19, loss = 1.24686816\n",
      "Iteration 20, loss = 1.23438272\n",
      "Iteration 21, loss = 1.25285161\n",
      "Iteration 7, loss = 1.25406202\n",
      "Iteration 8, loss = 1.25261276\n",
      "Iteration 9, loss = 1.24402752\n",
      "Iteration 10, loss = 1.25726390\n",
      "Iteration 11, loss = 1.24682552\n",
      "Iteration 12, loss = 1.24444186\n",
      "Iteration 13, loss = 1.24045275\n",
      "Iteration 14, loss = 1.24970193\n",
      "Iteration 15, loss = 1.24447751\n",
      "Iteration 16, loss = 1.25655856\n",
      "Iteration 17, loss = 1.24544882\n",
      "Iteration 18, loss = 1.24788846\n",
      "Iteration 19, loss = 1.24686816\n",
      "Iteration 20, loss = 1.23438272\n",
      "Iteration 21, loss = 1.25285161\n",
      "Iteration 22, loss = 1.24590827\n",
      "Iteration 23, loss = 1.25063857\n",
      "Iteration 24, loss = 1.24214343\n",
      "Iteration 25, loss = 1.24878394\n",
      "Iteration 26, loss = 1.24281778\n",
      "Iteration 27, loss = 1.24095132\n",
      "Iteration 28, loss = 1.25611446\n",
      "Iteration 29, loss = 1.24463060\n",
      "Iteration 30, loss = 1.24598332\n",
      "Iteration 31, loss = 1.24208231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28786459\n",
      "Iteration 2, loss = 1.23259441\n",
      "Iteration 3, loss = 1.24626109\n",
      "Iteration 22, loss = 1.24590827\n",
      "Iteration 23, loss = 1.25063857\n",
      "Iteration 24, loss = 1.24214343\n",
      "Iteration 25, loss = 1.24878394\n",
      "Iteration 26, loss = 1.24281778\n",
      "Iteration 27, loss = 1.24095132\n",
      "Iteration 28, loss = 1.25611446\n",
      "Iteration 29, loss = 1.24463060\n",
      "Iteration 30, loss = 1.24598332\n",
      "Iteration 31, loss = 1.24208231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28786459\n",
      "Iteration 2, loss = 1.23259441\n",
      "Iteration 3, loss = 1.24626109\n",
      "Iteration 4, loss = 1.25033803\n",
      "Iteration 5, loss = 1.25091523\n",
      "Iteration 6, loss = 1.25474582\n",
      "Iteration 7, loss = 1.25626751\n",
      "Iteration 8, loss = 1.24898260\n",
      "Iteration 9, loss = 1.24403392\n",
      "Iteration 10, loss = 1.23863868\n",
      "Iteration 11, loss = 1.23876487\n",
      "Iteration 12, loss = 1.23518101\n",
      "Iteration 13, loss = 1.23684493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27977317\n",
      "Iteration 2, loss = 1.25693577\n",
      "Iteration 3, loss = 1.26206578\n",
      "Iteration 4, loss = 1.26343886\n",
      "Iteration 4, loss = 1.25033803\n",
      "Iteration 5, loss = 1.25091523\n",
      "Iteration 6, loss = 1.25474582\n",
      "Iteration 7, loss = 1.25626751\n",
      "Iteration 8, loss = 1.24898260\n",
      "Iteration 9, loss = 1.24403392\n",
      "Iteration 10, loss = 1.23863868\n",
      "Iteration 11, loss = 1.23876487\n",
      "Iteration 12, loss = 1.23518101\n",
      "Iteration 13, loss = 1.23684493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27977317\n",
      "Iteration 2, loss = 1.25693577\n",
      "Iteration 3, loss = 1.26206578\n",
      "Iteration 4, loss = 1.26343886\n",
      "Iteration 5, loss = 1.25709423\n",
      "Iteration 6, loss = 1.26483255\n",
      "Iteration 7, loss = 1.25764221\n",
      "Iteration 8, loss = 1.25681462\n",
      "Iteration 9, loss = 1.26161459\n",
      "Iteration 10, loss = 1.25725085\n",
      "Iteration 11, loss = 1.25664823\n",
      "Iteration 12, loss = 1.25236934\n",
      "Iteration 13, loss = 1.25351582\n",
      "Iteration 14, loss = 1.25819632\n",
      "Iteration 15, loss = 1.26695709\n",
      "Iteration 16, loss = 1.26231392\n",
      "Iteration 17, loss = 1.25707242\n",
      "Iteration 18, loss = 1.26124637\n",
      "Iteration 19, loss = 1.25367142\n",
      "Iteration 5, loss = 1.25709423\n",
      "Iteration 6, loss = 1.26483255\n",
      "Iteration 7, loss = 1.25764221\n",
      "Iteration 8, loss = 1.25681462\n",
      "Iteration 9, loss = 1.26161459\n",
      "Iteration 10, loss = 1.25725085\n",
      "Iteration 11, loss = 1.25664823\n",
      "Iteration 12, loss = 1.25236934\n",
      "Iteration 13, loss = 1.25351582\n",
      "Iteration 14, loss = 1.25819632\n",
      "Iteration 15, loss = 1.26695709\n",
      "Iteration 16, loss = 1.26231392\n",
      "Iteration 17, loss = 1.25707242\n",
      "Iteration 18, loss = 1.26124637\n",
      "Iteration 19, loss = 1.25367142\n",
      "Iteration 20, loss = 1.25368618\n",
      "Iteration 21, loss = 1.26456739\n",
      "Iteration 22, loss = 1.25707389\n",
      "Iteration 23, loss = 1.27196615\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27356623\n",
      "Iteration 2, loss = 1.24784033\n",
      "Iteration 3, loss = 1.26569653\n",
      "Iteration 4, loss = 1.26245117\n",
      "Iteration 5, loss = 1.25570420\n",
      "Iteration 6, loss = 1.26273310\n",
      "Iteration 7, loss = 1.24769728\n",
      "Iteration 8, loss = 1.25534674\n",
      "Iteration 9, loss = 1.24210703\n",
      "Iteration 20, loss = 1.25368618\n",
      "Iteration 21, loss = 1.26456739\n",
      "Iteration 22, loss = 1.25707389\n",
      "Iteration 23, loss = 1.27196615\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27356623\n",
      "Iteration 2, loss = 1.24784033\n",
      "Iteration 3, loss = 1.26569653\n",
      "Iteration 4, loss = 1.26245117\n",
      "Iteration 5, loss = 1.25570420\n",
      "Iteration 6, loss = 1.26273310\n",
      "Iteration 7, loss = 1.24769728\n",
      "Iteration 8, loss = 1.25534674\n",
      "Iteration 9, loss = 1.24210703\n",
      "Iteration 10, loss = 1.24481858\n",
      "Iteration 11, loss = 1.26357900\n",
      "Iteration 12, loss = 1.25710535\n",
      "Iteration 13, loss = 1.24687184\n",
      "Iteration 14, loss = 1.24764366\n",
      "Iteration 15, loss = 1.24506697\n",
      "Iteration 16, loss = 1.25561695\n",
      "Iteration 17, loss = 1.24753778\n",
      "Iteration 18, loss = 1.24177469\n",
      "Iteration 19, loss = 1.25175847\n",
      "Iteration 20, loss = 1.25415803\n",
      "Iteration 21, loss = 1.24492004\n",
      "Iteration 22, loss = 1.25451970\n",
      "Iteration 23, loss = 1.26480214\n",
      "Iteration 24, loss = 1.25769611\n",
      "Iteration 10, loss = 1.24481858\n",
      "Iteration 11, loss = 1.26357900\n",
      "Iteration 12, loss = 1.25710535\n",
      "Iteration 13, loss = 1.24687184\n",
      "Iteration 14, loss = 1.24764366\n",
      "Iteration 15, loss = 1.24506697\n",
      "Iteration 16, loss = 1.25561695\n",
      "Iteration 17, loss = 1.24753778\n",
      "Iteration 18, loss = 1.24177469\n",
      "Iteration 19, loss = 1.25175847\n",
      "Iteration 20, loss = 1.25415803\n",
      "Iteration 21, loss = 1.24492004\n",
      "Iteration 22, loss = 1.25451970\n",
      "Iteration 23, loss = 1.26480214\n",
      "Iteration 24, loss = 1.25769611\n",
      "Iteration 25, loss = 1.24420481\n",
      "Iteration 26, loss = 1.26040489\n",
      "Iteration 27, loss = 1.25221194\n",
      "Iteration 28, loss = 1.25038272\n",
      "Iteration 29, loss = 1.24441952\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25893346\n",
      "Iteration 2, loss = 1.13753278\n",
      "Iteration 3, loss = 1.17300402\n",
      "Iteration 4, loss = 1.12622422\n",
      "Iteration 5, loss = 1.05998171\n",
      "Iteration 6, loss = 1.04745708\n",
      "Iteration 7, loss = 1.06798405\n",
      "Iteration 8, loss = 1.02961025\n",
      "Iteration 25, loss = 1.24420481\n",
      "Iteration 26, loss = 1.26040489\n",
      "Iteration 27, loss = 1.25221194\n",
      "Iteration 28, loss = 1.25038272\n",
      "Iteration 29, loss = 1.24441952\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25893346\n",
      "Iteration 2, loss = 1.13753278\n",
      "Iteration 3, loss = 1.17300402\n",
      "Iteration 4, loss = 1.12622422\n",
      "Iteration 5, loss = 1.05998171\n",
      "Iteration 6, loss = 1.04745708\n",
      "Iteration 7, loss = 1.06798405\n",
      "Iteration 8, loss = 1.02961025\n",
      "Iteration 9, loss = 1.00481189\n",
      "Iteration 10, loss = 0.99474897\n",
      "Iteration 11, loss = 1.00840743\n",
      "Iteration 12, loss = 0.99526655\n",
      "Iteration 13, loss = 0.98861585\n",
      "Iteration 14, loss = 0.99299906\n",
      "Iteration 15, loss = 0.98294709\n",
      "Iteration 16, loss = 1.01805062\n",
      "Iteration 17, loss = 0.98461889\n",
      "Iteration 18, loss = 1.01016824\n",
      "Iteration 19, loss = 1.05102688\n",
      "Iteration 20, loss = 1.15068653\n",
      "Iteration 21, loss = 1.05615117\n",
      "Iteration 22, loss = 1.03309481\n",
      "Iteration 23, loss = 1.08940481\n",
      "Iteration 9, loss = 1.00481189\n",
      "Iteration 10, loss = 0.99474897\n",
      "Iteration 11, loss = 1.00840743\n",
      "Iteration 12, loss = 0.99526655\n",
      "Iteration 13, loss = 0.98861585\n",
      "Iteration 14, loss = 0.99299906\n",
      "Iteration 15, loss = 0.98294709\n",
      "Iteration 16, loss = 1.01805062\n",
      "Iteration 17, loss = 0.98461889\n",
      "Iteration 18, loss = 1.01016824\n",
      "Iteration 19, loss = 1.05102688\n",
      "Iteration 20, loss = 1.15068653\n",
      "Iteration 21, loss = 1.05615117\n",
      "Iteration 22, loss = 1.03309481\n",
      "Iteration 23, loss = 1.08940481\n",
      "Iteration 24, loss = 1.07615383\n",
      "Iteration 25, loss = 1.02464048\n",
      "Iteration 26, loss = 0.99501639\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30571688\n",
      "Iteration 2, loss = 1.24627740\n",
      "Iteration 3, loss = 1.26146898\n",
      "Iteration 4, loss = 1.25574453\n",
      "Iteration 5, loss = 1.25230259\n",
      "Iteration 6, loss = 1.25962670\n",
      "Iteration 7, loss = 1.25976491\n",
      "Iteration 8, loss = 1.25877958\n",
      "Iteration 9, loss = 1.24774553\n",
      "Iteration 10, loss = 1.26788251\n",
      "Iteration 24, loss = 1.07615383\n",
      "Iteration 25, loss = 1.02464048\n",
      "Iteration 26, loss = 0.99501639\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30571688\n",
      "Iteration 2, loss = 1.24627740\n",
      "Iteration 3, loss = 1.26146898\n",
      "Iteration 4, loss = 1.25574453\n",
      "Iteration 5, loss = 1.25230259\n",
      "Iteration 6, loss = 1.25962670\n",
      "Iteration 7, loss = 1.25976491\n",
      "Iteration 8, loss = 1.25877958\n",
      "Iteration 9, loss = 1.24774553\n",
      "Iteration 10, loss = 1.26788251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.28398080\n",
      "Iteration 2, loss = 1.23429054\n",
      "Iteration 3, loss = 1.25340974\n",
      "Iteration 4, loss = 1.25837755\n",
      "Iteration 5, loss = 1.25886173\n",
      "Iteration 6, loss = 1.26774571\n",
      "Iteration 7, loss = 1.26089876\n",
      "Iteration 8, loss = 1.25644437\n",
      "Iteration 9, loss = 1.24870894\n",
      "Iteration 10, loss = 1.24526667\n",
      "Iteration 1, loss = 1.28040865\n",
      "Iteration 2, loss = 1.26181688\n",
      "Iteration 3, loss = 1.26901261\n",
      "Iteration 1, loss = 1.28398080\n",
      "Iteration 2, loss = 1.23429054\n",
      "Iteration 3, loss = 1.25340974\n",
      "Iteration 4, loss = 1.25837755\n",
      "Iteration 5, loss = 1.25886173\n",
      "Iteration 6, loss = 1.26774571\n",
      "Iteration 7, loss = 1.26089876\n",
      "Iteration 8, loss = 1.25644437\n",
      "Iteration 9, loss = 1.24870894\n",
      "Iteration 10, loss = 1.24526667\n",
      "Iteration 1, loss = 1.28040865\n",
      "Iteration 2, loss = 1.26181688\n",
      "Iteration 3, loss = 1.26901261\n",
      "Iteration 4, loss = 1.27187694\n",
      "Iteration 5, loss = 1.26001155\n",
      "Iteration 6, loss = 1.27064905\n",
      "Iteration 7, loss = 1.25950171\n",
      "Iteration 8, loss = 1.26480219\n",
      "Iteration 9, loss = 1.26745801\n",
      "Iteration 10, loss = 1.26148371\n",
      "Iteration 1, loss = 1.27384896\n",
      "Iteration 2, loss = 1.25814771\n",
      "Iteration 3, loss = 1.27732333\n",
      "Iteration 4, loss = 1.27136832\n",
      "Iteration 5, loss = 1.25473834\n",
      "Iteration 6, loss = 1.26144132\n",
      "Iteration 7, loss = 1.24896106\n",
      "Iteration 4, loss = 1.27187694\n",
      "Iteration 5, loss = 1.26001155\n",
      "Iteration 6, loss = 1.27064905\n",
      "Iteration 7, loss = 1.25950171\n",
      "Iteration 8, loss = 1.26480219\n",
      "Iteration 9, loss = 1.26745801\n",
      "Iteration 10, loss = 1.26148371\n",
      "Iteration 1, loss = 1.27384896\n",
      "Iteration 2, loss = 1.25814771\n",
      "Iteration 3, loss = 1.27732333\n",
      "Iteration 4, loss = 1.27136832\n",
      "Iteration 5, loss = 1.25473834\n",
      "Iteration 6, loss = 1.26144132\n",
      "Iteration 7, loss = 1.24896106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.26064898\n",
      "Iteration 9, loss = 1.24465167\n",
      "Iteration 10, loss = 1.24534751\n",
      "Iteration 1, loss = 1.27260776\n",
      "Iteration 2, loss = 1.22424306\n",
      "Iteration 3, loss = 1.24904402\n",
      "Iteration 4, loss = 1.23748382\n",
      "Iteration 5, loss = 1.28832387\n",
      "Iteration 6, loss = 1.27005478\n",
      "Iteration 7, loss = 1.27415333\n",
      "Iteration 8, loss = 1.27919697\n",
      "Iteration 9, loss = 1.25655278\n",
      "Iteration 10, loss = 1.26260393\n",
      "Iteration 8, loss = 1.26064898\n",
      "Iteration 9, loss = 1.24465167\n",
      "Iteration 10, loss = 1.24534751\n",
      "Iteration 1, loss = 1.27260776\n",
      "Iteration 2, loss = 1.22424306\n",
      "Iteration 3, loss = 1.24904402\n",
      "Iteration 4, loss = 1.23748382\n",
      "Iteration 5, loss = 1.28832387\n",
      "Iteration 6, loss = 1.27005478\n",
      "Iteration 7, loss = 1.27415333\n",
      "Iteration 8, loss = 1.27919697\n",
      "Iteration 9, loss = 1.25655278\n",
      "Iteration 10, loss = 1.26260393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.30571688\n",
      "Iteration 2, loss = 1.24627740\n",
      "Iteration 3, loss = 1.26146898\n",
      "Iteration 4, loss = 1.25574453\n",
      "Iteration 5, loss = 1.25230259\n",
      "Iteration 6, loss = 1.25962670\n",
      "Iteration 7, loss = 1.25976491\n",
      "Iteration 8, loss = 1.25877958\n",
      "Iteration 9, loss = 1.24774553\n",
      "Iteration 10, loss = 1.26788251\n",
      "Iteration 11, loss = 1.25145739\n",
      "Iteration 12, loss = 1.24766092\n",
      "Iteration 13, loss = 1.24103451\n",
      "Iteration 14, loss = 1.25102517\n",
      "Iteration 1, loss = 1.30571688\n",
      "Iteration 2, loss = 1.24627740\n",
      "Iteration 3, loss = 1.26146898\n",
      "Iteration 4, loss = 1.25574453\n",
      "Iteration 5, loss = 1.25230259\n",
      "Iteration 6, loss = 1.25962670\n",
      "Iteration 7, loss = 1.25976491\n",
      "Iteration 8, loss = 1.25877958\n",
      "Iteration 9, loss = 1.24774553\n",
      "Iteration 10, loss = 1.26788251\n",
      "Iteration 11, loss = 1.25145739\n",
      "Iteration 12, loss = 1.24766092\n",
      "Iteration 13, loss = 1.24103451\n",
      "Iteration 14, loss = 1.25102517\n",
      "Iteration 15, loss = 1.24432673\n",
      "Iteration 16, loss = 1.26727681\n",
      "Iteration 17, loss = 1.25278657\n",
      "Iteration 18, loss = 1.25188063\n",
      "Iteration 19, loss = 1.25380880\n",
      "Iteration 20, loss = 1.23825350\n",
      "Iteration 21, loss = 1.25912723\n",
      "Iteration 22, loss = 1.25248779\n",
      "Iteration 23, loss = 1.25768557\n",
      "Iteration 24, loss = 1.24545942\n",
      "Iteration 25, loss = 1.25251333\n",
      "Iteration 26, loss = 1.24323585\n",
      "Iteration 27, loss = 1.24485831\n",
      "Iteration 28, loss = 1.26288167\n",
      "Iteration 29, loss = 1.24975914\n",
      "Iteration 30, loss = 1.24834995\n",
      "Iteration 15, loss = 1.24432673\n",
      "Iteration 16, loss = 1.26727681\n",
      "Iteration 17, loss = 1.25278657\n",
      "Iteration 18, loss = 1.25188063\n",
      "Iteration 19, loss = 1.25380880\n",
      "Iteration 20, loss = 1.23825350\n",
      "Iteration 21, loss = 1.25912723\n",
      "Iteration 22, loss = 1.25248779\n",
      "Iteration 23, loss = 1.25768557\n",
      "Iteration 24, loss = 1.24545942\n",
      "Iteration 25, loss = 1.25251333\n",
      "Iteration 26, loss = 1.24323585\n",
      "Iteration 27, loss = 1.24485831\n",
      "Iteration 28, loss = 1.26288167\n",
      "Iteration 29, loss = 1.24975914\n",
      "Iteration 30, loss = 1.24834995\n",
      "Iteration 31, loss = 1.24582911\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28398080\n",
      "Iteration 2, loss = 1.23429054\n",
      "Iteration 3, loss = 1.25340974\n",
      "Iteration 4, loss = 1.25837755\n",
      "Iteration 5, loss = 1.25886173\n",
      "Iteration 6, loss = 1.26774571\n",
      "Iteration 7, loss = 1.26089876\n",
      "Iteration 8, loss = 1.25644437\n",
      "Iteration 9, loss = 1.24870894\n",
      "Iteration 10, loss = 1.24526667\n",
      "Iteration 11, loss = 1.24231509\n",
      "Iteration 12, loss = 1.23691877\n",
      "Iteration 31, loss = 1.24582911\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28398080\n",
      "Iteration 2, loss = 1.23429054\n",
      "Iteration 3, loss = 1.25340974\n",
      "Iteration 4, loss = 1.25837755\n",
      "Iteration 5, loss = 1.25886173\n",
      "Iteration 6, loss = 1.26774571\n",
      "Iteration 7, loss = 1.26089876\n",
      "Iteration 8, loss = 1.25644437\n",
      "Iteration 9, loss = 1.24870894\n",
      "Iteration 10, loss = 1.24526667\n",
      "Iteration 11, loss = 1.24231509\n",
      "Iteration 12, loss = 1.23691877\n",
      "Iteration 13, loss = 1.23681247\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28040865\n",
      "Iteration 2, loss = 1.26181688\n",
      "Iteration 3, loss = 1.26901261\n",
      "Iteration 4, loss = 1.27187694\n",
      "Iteration 5, loss = 1.26001155\n",
      "Iteration 6, loss = 1.27064905\n",
      "Iteration 7, loss = 1.25950171\n",
      "Iteration 8, loss = 1.26480219\n",
      "Iteration 9, loss = 1.26745801\n",
      "Iteration 10, loss = 1.26148371\n",
      "Iteration 11, loss = 1.25925609\n",
      "Iteration 12, loss = 1.25415341\n",
      "Iteration 13, loss = 1.25569674\n",
      "Iteration 13, loss = 1.23681247\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28040865\n",
      "Iteration 2, loss = 1.26181688\n",
      "Iteration 3, loss = 1.26901261\n",
      "Iteration 4, loss = 1.27187694\n",
      "Iteration 5, loss = 1.26001155\n",
      "Iteration 6, loss = 1.27064905\n",
      "Iteration 7, loss = 1.25950171\n",
      "Iteration 8, loss = 1.26480219\n",
      "Iteration 9, loss = 1.26745801\n",
      "Iteration 10, loss = 1.26148371\n",
      "Iteration 11, loss = 1.25925609\n",
      "Iteration 12, loss = 1.25415341\n",
      "Iteration 13, loss = 1.25569674\n",
      "Iteration 14, loss = 1.25955121\n",
      "Iteration 15, loss = 1.27601319\n",
      "Iteration 16, loss = 1.26075006\n",
      "Iteration 17, loss = 1.26487804\n",
      "Iteration 18, loss = 1.26146305\n",
      "Iteration 19, loss = 1.26152838\n",
      "Iteration 20, loss = 1.25513227\n",
      "Iteration 21, loss = 1.26392135\n",
      "Iteration 22, loss = 1.25530718\n",
      "Iteration 23, loss = 1.28184536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27384896\n",
      "Iteration 2, loss = 1.25814771\n",
      "Iteration 3, loss = 1.27732333\n",
      "Iteration 14, loss = 1.25955121\n",
      "Iteration 15, loss = 1.27601319\n",
      "Iteration 16, loss = 1.26075006\n",
      "Iteration 17, loss = 1.26487804\n",
      "Iteration 18, loss = 1.26146305\n",
      "Iteration 19, loss = 1.26152838\n",
      "Iteration 20, loss = 1.25513227\n",
      "Iteration 21, loss = 1.26392135\n",
      "Iteration 22, loss = 1.25530718\n",
      "Iteration 23, loss = 1.28184536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27384896\n",
      "Iteration 2, loss = 1.25814771\n",
      "Iteration 3, loss = 1.27732333\n",
      "Iteration 4, loss = 1.27136832\n",
      "Iteration 5, loss = 1.25473834\n",
      "Iteration 6, loss = 1.26144132\n",
      "Iteration 7, loss = 1.24896106\n",
      "Iteration 8, loss = 1.26064898\n",
      "Iteration 9, loss = 1.24465167\n",
      "Iteration 10, loss = 1.24534751\n",
      "Iteration 11, loss = 1.26286729\n",
      "Iteration 12, loss = 1.26138865\n",
      "Iteration 13, loss = 1.24973704\n",
      "Iteration 14, loss = 1.25106796\n",
      "Iteration 15, loss = 1.24797062\n",
      "Iteration 4, loss = 1.27136832\n",
      "Iteration 5, loss = 1.25473834\n",
      "Iteration 6, loss = 1.26144132\n",
      "Iteration 7, loss = 1.24896106\n",
      "Iteration 8, loss = 1.26064898\n",
      "Iteration 9, loss = 1.24465167\n",
      "Iteration 10, loss = 1.24534751\n",
      "Iteration 11, loss = 1.26286729\n",
      "Iteration 12, loss = 1.26138865\n",
      "Iteration 13, loss = 1.24973704\n",
      "Iteration 14, loss = 1.25106796\n",
      "Iteration 15, loss = 1.24797062\n",
      "Iteration 16, loss = 1.25396947\n",
      "Iteration 17, loss = 1.25378429\n",
      "Iteration 18, loss = 1.23998091\n",
      "Iteration 19, loss = 1.25516843\n",
      "Iteration 20, loss = 1.25791027\n",
      "Iteration 21, loss = 1.24672520\n",
      "Iteration 22, loss = 1.25432075\n",
      "Iteration 23, loss = 1.27233563\n",
      "Iteration 24, loss = 1.26046029\n",
      "Iteration 25, loss = 1.24309827\n",
      "Iteration 26, loss = 1.25842059\n",
      "Iteration 27, loss = 1.25602941\n",
      "Iteration 28, loss = 1.25287013\n",
      "Iteration 29, loss = 1.24465600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27260776\n",
      "Iteration 16, loss = 1.25396947\n",
      "Iteration 17, loss = 1.25378429\n",
      "Iteration 18, loss = 1.23998091\n",
      "Iteration 19, loss = 1.25516843\n",
      "Iteration 20, loss = 1.25791027\n",
      "Iteration 21, loss = 1.24672520\n",
      "Iteration 22, loss = 1.25432075\n",
      "Iteration 23, loss = 1.27233563\n",
      "Iteration 24, loss = 1.26046029\n",
      "Iteration 25, loss = 1.24309827\n",
      "Iteration 26, loss = 1.25842059\n",
      "Iteration 27, loss = 1.25602941\n",
      "Iteration 28, loss = 1.25287013\n",
      "Iteration 29, loss = 1.24465600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27260776\n",
      "Iteration 2, loss = 1.22424306\n",
      "Iteration 3, loss = 1.24904402\n",
      "Iteration 4, loss = 1.23748382\n",
      "Iteration 5, loss = 1.28832387\n",
      "Iteration 6, loss = 1.27005478\n",
      "Iteration 7, loss = 1.27415333\n",
      "Iteration 8, loss = 1.27919697\n",
      "Iteration 9, loss = 1.25655278\n",
      "Iteration 10, loss = 1.26260393\n",
      "Iteration 11, loss = 1.28557465\n",
      "Iteration 12, loss = 1.27959046\n",
      "Iteration 13, loss = 1.26984770\n",
      "Iteration 2, loss = 1.22424306\n",
      "Iteration 3, loss = 1.24904402\n",
      "Iteration 4, loss = 1.23748382\n",
      "Iteration 5, loss = 1.28832387\n",
      "Iteration 6, loss = 1.27005478\n",
      "Iteration 7, loss = 1.27415333\n",
      "Iteration 8, loss = 1.27919697\n",
      "Iteration 9, loss = 1.25655278\n",
      "Iteration 10, loss = 1.26260393\n",
      "Iteration 11, loss = 1.28557465\n",
      "Iteration 12, loss = 1.27959046\n",
      "Iteration 13, loss = 1.26984770\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30571688\n",
      "Iteration 2, loss = 1.24627740\n",
      "Iteration 3, loss = 1.26146898\n",
      "Iteration 4, loss = 1.25574453\n",
      "Iteration 5, loss = 1.25230259\n",
      "Iteration 6, loss = 1.25962670\n",
      "Iteration 7, loss = 1.25976491\n",
      "Iteration 8, loss = 1.25877958\n",
      "Iteration 9, loss = 1.24774553\n",
      "Iteration 10, loss = 1.26788251\n",
      "Iteration 11, loss = 1.25145739\n",
      "Iteration 12, loss = 1.24766092\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30571688\n",
      "Iteration 2, loss = 1.24627740\n",
      "Iteration 3, loss = 1.26146898\n",
      "Iteration 4, loss = 1.25574453\n",
      "Iteration 5, loss = 1.25230259\n",
      "Iteration 6, loss = 1.25962670\n",
      "Iteration 7, loss = 1.25976491\n",
      "Iteration 8, loss = 1.25877958\n",
      "Iteration 9, loss = 1.24774553\n",
      "Iteration 10, loss = 1.26788251\n",
      "Iteration 11, loss = 1.25145739\n",
      "Iteration 12, loss = 1.24766092\n",
      "Iteration 13, loss = 1.24103451\n",
      "Iteration 14, loss = 1.25102517\n",
      "Iteration 15, loss = 1.24432673\n",
      "Iteration 16, loss = 1.26727681\n",
      "Iteration 17, loss = 1.25278657\n",
      "Iteration 18, loss = 1.25188063\n",
      "Iteration 19, loss = 1.25380880\n",
      "Iteration 20, loss = 1.23825350\n",
      "Iteration 21, loss = 1.25912723\n",
      "Iteration 22, loss = 1.25248779\n",
      "Iteration 23, loss = 1.25768557\n",
      "Iteration 24, loss = 1.24545942\n",
      "Iteration 25, loss = 1.25251333\n",
      "Iteration 26, loss = 1.24323585\n",
      "Iteration 27, loss = 1.24485831\n",
      "Iteration 13, loss = 1.24103451\n",
      "Iteration 14, loss = 1.25102517\n",
      "Iteration 15, loss = 1.24432673\n",
      "Iteration 16, loss = 1.26727681\n",
      "Iteration 17, loss = 1.25278657\n",
      "Iteration 18, loss = 1.25188063\n",
      "Iteration 19, loss = 1.25380880\n",
      "Iteration 20, loss = 1.23825350\n",
      "Iteration 21, loss = 1.25912723\n",
      "Iteration 22, loss = 1.25248779\n",
      "Iteration 23, loss = 1.25768557\n",
      "Iteration 24, loss = 1.24545942\n",
      "Iteration 25, loss = 1.25251333\n",
      "Iteration 26, loss = 1.24323585\n",
      "Iteration 27, loss = 1.24485831\n",
      "Iteration 28, loss = 1.26288167\n",
      "Iteration 29, loss = 1.24975914\n",
      "Iteration 30, loss = 1.24834995\n",
      "Iteration 31, loss = 1.24582911\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28398080\n",
      "Iteration 2, loss = 1.23429054\n",
      "Iteration 3, loss = 1.25340974\n",
      "Iteration 4, loss = 1.25837755\n",
      "Iteration 5, loss = 1.25886173\n",
      "Iteration 6, loss = 1.26774571\n",
      "Iteration 7, loss = 1.26089876\n",
      "Iteration 8, loss = 1.25644437\n",
      "Iteration 9, loss = 1.24870894\n",
      "Iteration 10, loss = 1.24526667\n",
      "Iteration 11, loss = 1.24231509\n",
      "Iteration 28, loss = 1.26288167\n",
      "Iteration 29, loss = 1.24975914\n",
      "Iteration 30, loss = 1.24834995\n",
      "Iteration 31, loss = 1.24582911\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28398080\n",
      "Iteration 2, loss = 1.23429054\n",
      "Iteration 3, loss = 1.25340974\n",
      "Iteration 4, loss = 1.25837755\n",
      "Iteration 5, loss = 1.25886173\n",
      "Iteration 6, loss = 1.26774571\n",
      "Iteration 7, loss = 1.26089876\n",
      "Iteration 8, loss = 1.25644437\n",
      "Iteration 9, loss = 1.24870894\n",
      "Iteration 10, loss = 1.24526667\n",
      "Iteration 11, loss = 1.24231509\n",
      "Iteration 12, loss = 1.23691877\n",
      "Iteration 13, loss = 1.23681247\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28040865\n",
      "Iteration 2, loss = 1.26181688\n",
      "Iteration 3, loss = 1.26901261\n",
      "Iteration 4, loss = 1.27187694\n",
      "Iteration 5, loss = 1.26001155\n",
      "Iteration 6, loss = 1.27064905\n",
      "Iteration 7, loss = 1.25950171\n",
      "Iteration 8, loss = 1.26480219\n",
      "Iteration 9, loss = 1.26745801\n",
      "Iteration 10, loss = 1.26148371\n",
      "Iteration 11, loss = 1.25925609\n",
      "Iteration 12, loss = 1.25415341\n",
      "Iteration 12, loss = 1.23691877\n",
      "Iteration 13, loss = 1.23681247\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28040865\n",
      "Iteration 2, loss = 1.26181688\n",
      "Iteration 3, loss = 1.26901261\n",
      "Iteration 4, loss = 1.27187694\n",
      "Iteration 5, loss = 1.26001155\n",
      "Iteration 6, loss = 1.27064905\n",
      "Iteration 7, loss = 1.25950171\n",
      "Iteration 8, loss = 1.26480219\n",
      "Iteration 9, loss = 1.26745801\n",
      "Iteration 10, loss = 1.26148371\n",
      "Iteration 11, loss = 1.25925609\n",
      "Iteration 12, loss = 1.25415341\n",
      "Iteration 13, loss = 1.25569674\n",
      "Iteration 14, loss = 1.25955121\n",
      "Iteration 15, loss = 1.27601319\n",
      "Iteration 16, loss = 1.26075006\n",
      "Iteration 17, loss = 1.26487804\n",
      "Iteration 18, loss = 1.26146305\n",
      "Iteration 19, loss = 1.26152838\n",
      "Iteration 20, loss = 1.25513227\n",
      "Iteration 21, loss = 1.26392135\n",
      "Iteration 22, loss = 1.25530718\n",
      "Iteration 23, loss = 1.28184536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27384896\n",
      "Iteration 2, loss = 1.25814771\n",
      "Iteration 3, loss = 1.27732333\n",
      "Iteration 13, loss = 1.25569674\n",
      "Iteration 14, loss = 1.25955121\n",
      "Iteration 15, loss = 1.27601319\n",
      "Iteration 16, loss = 1.26075006\n",
      "Iteration 17, loss = 1.26487804\n",
      "Iteration 18, loss = 1.26146305\n",
      "Iteration 19, loss = 1.26152838\n",
      "Iteration 20, loss = 1.25513227\n",
      "Iteration 21, loss = 1.26392135\n",
      "Iteration 22, loss = 1.25530718\n",
      "Iteration 23, loss = 1.28184536\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27384896\n",
      "Iteration 2, loss = 1.25814771\n",
      "Iteration 3, loss = 1.27732333\n",
      "Iteration 4, loss = 1.27136832\n",
      "Iteration 5, loss = 1.25473834\n",
      "Iteration 6, loss = 1.26144132\n",
      "Iteration 7, loss = 1.24896106\n",
      "Iteration 8, loss = 1.26064898\n",
      "Iteration 9, loss = 1.24465167\n",
      "Iteration 10, loss = 1.24534751\n",
      "Iteration 11, loss = 1.26286729\n",
      "Iteration 12, loss = 1.26138865\n",
      "Iteration 13, loss = 1.24973704\n",
      "Iteration 14, loss = 1.25106796\n",
      "Iteration 15, loss = 1.24797062\n",
      "Iteration 16, loss = 1.25396947\n",
      "Iteration 17, loss = 1.25378429\n",
      "Iteration 18, loss = 1.23998091\n",
      "Iteration 4, loss = 1.27136832\n",
      "Iteration 5, loss = 1.25473834\n",
      "Iteration 6, loss = 1.26144132\n",
      "Iteration 7, loss = 1.24896106\n",
      "Iteration 8, loss = 1.26064898\n",
      "Iteration 9, loss = 1.24465167\n",
      "Iteration 10, loss = 1.24534751\n",
      "Iteration 11, loss = 1.26286729\n",
      "Iteration 12, loss = 1.26138865\n",
      "Iteration 13, loss = 1.24973704\n",
      "Iteration 14, loss = 1.25106796\n",
      "Iteration 15, loss = 1.24797062\n",
      "Iteration 16, loss = 1.25396947\n",
      "Iteration 17, loss = 1.25378429\n",
      "Iteration 18, loss = 1.23998091\n",
      "Iteration 19, loss = 1.25516843\n",
      "Iteration 20, loss = 1.25791027\n",
      "Iteration 21, loss = 1.24672520\n",
      "Iteration 22, loss = 1.25432075\n",
      "Iteration 23, loss = 1.27233563\n",
      "Iteration 24, loss = 1.26046029\n",
      "Iteration 25, loss = 1.24309827\n",
      "Iteration 26, loss = 1.25842059\n",
      "Iteration 27, loss = 1.25602941\n",
      "Iteration 28, loss = 1.25287013\n",
      "Iteration 29, loss = 1.24465600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27260776\n",
      "Iteration 2, loss = 1.22424306\n",
      "Iteration 3, loss = 1.24904402\n",
      "Iteration 19, loss = 1.25516843\n",
      "Iteration 20, loss = 1.25791027\n",
      "Iteration 21, loss = 1.24672520\n",
      "Iteration 22, loss = 1.25432075\n",
      "Iteration 23, loss = 1.27233563\n",
      "Iteration 24, loss = 1.26046029\n",
      "Iteration 25, loss = 1.24309827\n",
      "Iteration 26, loss = 1.25842059\n",
      "Iteration 27, loss = 1.25602941\n",
      "Iteration 28, loss = 1.25287013\n",
      "Iteration 29, loss = 1.24465600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27260776\n",
      "Iteration 2, loss = 1.22424306\n",
      "Iteration 3, loss = 1.24904402\n",
      "Iteration 4, loss = 1.23748382\n",
      "Iteration 5, loss = 1.28832387\n",
      "Iteration 6, loss = 1.27005478\n",
      "Iteration 7, loss = 1.27415333\n",
      "Iteration 8, loss = 1.27919697\n",
      "Iteration 9, loss = 1.25655278\n",
      "Iteration 10, loss = 1.26260393\n",
      "Iteration 11, loss = 1.28557465\n",
      "Iteration 12, loss = 1.27959046\n",
      "Iteration 13, loss = 1.26984770\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16893895\n",
      "Iteration 2, loss = 1.02332004\n",
      "Iteration 3, loss = 1.09407233\n",
      "Iteration 4, loss = 1.00951187\n",
      "Iteration 4, loss = 1.23748382\n",
      "Iteration 5, loss = 1.28832387\n",
      "Iteration 6, loss = 1.27005478\n",
      "Iteration 7, loss = 1.27415333\n",
      "Iteration 8, loss = 1.27919697\n",
      "Iteration 9, loss = 1.25655278\n",
      "Iteration 10, loss = 1.26260393\n",
      "Iteration 11, loss = 1.28557465\n",
      "Iteration 12, loss = 1.27959046\n",
      "Iteration 13, loss = 1.26984770\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16893895\n",
      "Iteration 2, loss = 1.02332004\n",
      "Iteration 3, loss = 1.09407233\n",
      "Iteration 4, loss = 1.00951187\n",
      "Iteration 5, loss = 0.98929198\n",
      "Iteration 6, loss = 0.97096347\n",
      "Iteration 7, loss = 0.98288161\n",
      "Iteration 8, loss = 0.97316433\n",
      "Iteration 9, loss = 0.94958777\n",
      "Iteration 10, loss = 0.94326479\n",
      "Iteration 1, loss = 1.12973774\n",
      "Iteration 2, loss = 0.98304198\n",
      "Iteration 3, loss = 0.93108350\n",
      "Iteration 4, loss = 0.93850632\n",
      "Iteration 5, loss = 0.91889813\n",
      "Iteration 6, loss = 0.89238323\n",
      "Iteration 7, loss = 0.90985407\n",
      "Iteration 5, loss = 0.98929198\n",
      "Iteration 6, loss = 0.97096347\n",
      "Iteration 7, loss = 0.98288161\n",
      "Iteration 8, loss = 0.97316433\n",
      "Iteration 9, loss = 0.94958777\n",
      "Iteration 10, loss = 0.94326479\n",
      "Iteration 1, loss = 1.12973774\n",
      "Iteration 2, loss = 0.98304198\n",
      "Iteration 3, loss = 0.93108350\n",
      "Iteration 4, loss = 0.93850632\n",
      "Iteration 5, loss = 0.91889813\n",
      "Iteration 6, loss = 0.89238323\n",
      "Iteration 7, loss = 0.90985407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.92599377\n",
      "Iteration 9, loss = 0.92994811\n",
      "Iteration 10, loss = 0.91438471\n",
      "Iteration 1, loss = 1.15928287\n",
      "Iteration 2, loss = 0.99804327\n",
      "Iteration 3, loss = 0.99139856\n",
      "Iteration 4, loss = 0.96341003\n",
      "Iteration 5, loss = 0.93500060\n",
      "Iteration 6, loss = 0.95010664\n",
      "Iteration 7, loss = 0.91619896\n",
      "Iteration 8, loss = 0.94006729\n",
      "Iteration 9, loss = 0.93902528\n",
      "Iteration 10, loss = 0.96392479\n",
      "Iteration 8, loss = 0.92599377\n",
      "Iteration 9, loss = 0.92994811\n",
      "Iteration 10, loss = 0.91438471\n",
      "Iteration 1, loss = 1.15928287\n",
      "Iteration 2, loss = 0.99804327\n",
      "Iteration 3, loss = 0.99139856\n",
      "Iteration 4, loss = 0.96341003\n",
      "Iteration 5, loss = 0.93500060\n",
      "Iteration 6, loss = 0.95010664\n",
      "Iteration 7, loss = 0.91619896\n",
      "Iteration 8, loss = 0.94006729\n",
      "Iteration 9, loss = 0.93902528\n",
      "Iteration 10, loss = 0.96392479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.20408773\n",
      "Iteration 2, loss = 1.03240977\n",
      "Iteration 3, loss = 1.02047944\n",
      "Iteration 4, loss = 0.99138450\n",
      "Iteration 5, loss = 0.96212958\n",
      "Iteration 6, loss = 0.98072389\n",
      "Iteration 7, loss = 0.94571476\n",
      "Iteration 8, loss = 0.93257381\n",
      "Iteration 9, loss = 0.90988489\n",
      "Iteration 10, loss = 0.97609611\n",
      "Iteration 1, loss = 1.23628093\n",
      "Iteration 2, loss = 1.06539175\n",
      "Iteration 3, loss = 1.01337135\n",
      "Iteration 1, loss = 1.20408773\n",
      "Iteration 2, loss = 1.03240977\n",
      "Iteration 3, loss = 1.02047944\n",
      "Iteration 4, loss = 0.99138450\n",
      "Iteration 5, loss = 0.96212958\n",
      "Iteration 6, loss = 0.98072389\n",
      "Iteration 7, loss = 0.94571476\n",
      "Iteration 8, loss = 0.93257381\n",
      "Iteration 9, loss = 0.90988489\n",
      "Iteration 10, loss = 0.97609611\n",
      "Iteration 1, loss = 1.23628093\n",
      "Iteration 2, loss = 1.06539175\n",
      "Iteration 3, loss = 1.01337135\n",
      "Iteration 4, loss = 0.96090391\n",
      "Iteration 5, loss = 0.94854385\n",
      "Iteration 6, loss = 0.95528209\n",
      "Iteration 7, loss = 0.93809513\n",
      "Iteration 8, loss = 0.94206918\n",
      "Iteration 9, loss = 0.91040215\n",
      "Iteration 10, loss = 0.94677065\n",
      "Iteration 1, loss = 1.16893895\n",
      "Iteration 2, loss = 1.02332004\n",
      "Iteration 3, loss = 1.09407233\n",
      "Iteration 4, loss = 1.00951187\n",
      "Iteration 5, loss = 0.98929198\n",
      "Iteration 4, loss = 0.96090391\n",
      "Iteration 5, loss = 0.94854385\n",
      "Iteration 6, loss = 0.95528209\n",
      "Iteration 7, loss = 0.93809513\n",
      "Iteration 8, loss = 0.94206918\n",
      "Iteration 9, loss = 0.91040215\n",
      "Iteration 10, loss = 0.94677065\n",
      "Iteration 1, loss = 1.16893895\n",
      "Iteration 2, loss = 1.02332004\n",
      "Iteration 3, loss = 1.09407233\n",
      "Iteration 4, loss = 1.00951187\n",
      "Iteration 5, loss = 0.98929198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.97096347\n",
      "Iteration 7, loss = 0.98288161\n",
      "Iteration 8, loss = 0.97316433\n",
      "Iteration 9, loss = 0.94958777\n",
      "Iteration 10, loss = 0.94326479\n",
      "Iteration 11, loss = 0.96144835\n",
      "Iteration 12, loss = 0.93008034\n",
      "Iteration 13, loss = 0.92302895\n",
      "Iteration 14, loss = 0.94301439\n",
      "Iteration 15, loss = 1.00864075\n",
      "Iteration 16, loss = 0.96217545\n",
      "Iteration 17, loss = 0.95090977\n",
      "Iteration 18, loss = 0.91468052\n",
      "Iteration 6, loss = 0.97096347\n",
      "Iteration 7, loss = 0.98288161\n",
      "Iteration 8, loss = 0.97316433\n",
      "Iteration 9, loss = 0.94958777\n",
      "Iteration 10, loss = 0.94326479\n",
      "Iteration 11, loss = 0.96144835\n",
      "Iteration 12, loss = 0.93008034\n",
      "Iteration 13, loss = 0.92302895\n",
      "Iteration 14, loss = 0.94301439\n",
      "Iteration 15, loss = 1.00864075\n",
      "Iteration 16, loss = 0.96217545\n",
      "Iteration 17, loss = 0.95090977\n",
      "Iteration 18, loss = 0.91468052\n",
      "Iteration 19, loss = 0.91252656\n",
      "Iteration 20, loss = 0.89018605\n",
      "Iteration 21, loss = 0.88854418\n",
      "Iteration 22, loss = 0.91731075\n",
      "Iteration 23, loss = 0.88339434\n",
      "Iteration 24, loss = 0.88058545\n",
      "Iteration 25, loss = 0.88572572\n",
      "Iteration 26, loss = 0.85127375\n",
      "Iteration 27, loss = 0.84643075\n",
      "Iteration 28, loss = 0.86746413\n",
      "Iteration 29, loss = 0.85808599\n",
      "Iteration 30, loss = 0.89485908\n",
      "Iteration 31, loss = 0.86682325\n",
      "Iteration 32, loss = 0.84691999\n",
      "Iteration 33, loss = 0.81861089\n",
      "Iteration 19, loss = 0.91252656\n",
      "Iteration 20, loss = 0.89018605\n",
      "Iteration 21, loss = 0.88854418\n",
      "Iteration 22, loss = 0.91731075\n",
      "Iteration 23, loss = 0.88339434\n",
      "Iteration 24, loss = 0.88058545\n",
      "Iteration 25, loss = 0.88572572\n",
      "Iteration 26, loss = 0.85127375\n",
      "Iteration 27, loss = 0.84643075\n",
      "Iteration 28, loss = 0.86746413\n",
      "Iteration 29, loss = 0.85808599\n",
      "Iteration 30, loss = 0.89485908\n",
      "Iteration 31, loss = 0.86682325\n",
      "Iteration 32, loss = 0.84691999\n",
      "Iteration 33, loss = 0.81861089\n",
      "Iteration 34, loss = 0.80355617\n",
      "Iteration 35, loss = 0.87285143\n",
      "Iteration 36, loss = 0.83371103\n",
      "Iteration 37, loss = 0.82788484\n",
      "Iteration 38, loss = 0.78408536\n",
      "Iteration 39, loss = 0.79728548\n",
      "Iteration 40, loss = 0.78831690\n",
      "Iteration 41, loss = 0.77083813\n",
      "Iteration 42, loss = 0.78443743\n",
      "Iteration 43, loss = 0.81358020\n",
      "Iteration 44, loss = 0.77545819\n",
      "Iteration 45, loss = 0.75948923\n",
      "Iteration 46, loss = 0.79854030\n",
      "Iteration 47, loss = 0.82268429\n",
      "Iteration 48, loss = 0.80987194\n",
      "Iteration 34, loss = 0.80355617\n",
      "Iteration 35, loss = 0.87285143\n",
      "Iteration 36, loss = 0.83371103\n",
      "Iteration 37, loss = 0.82788484\n",
      "Iteration 38, loss = 0.78408536\n",
      "Iteration 39, loss = 0.79728548\n",
      "Iteration 40, loss = 0.78831690\n",
      "Iteration 41, loss = 0.77083813\n",
      "Iteration 42, loss = 0.78443743\n",
      "Iteration 43, loss = 0.81358020\n",
      "Iteration 44, loss = 0.77545819\n",
      "Iteration 45, loss = 0.75948923\n",
      "Iteration 46, loss = 0.79854030\n",
      "Iteration 47, loss = 0.82268429\n",
      "Iteration 48, loss = 0.80987194\n",
      "Iteration 49, loss = 0.77588976\n",
      "Iteration 50, loss = 0.77960941\n",
      "Iteration 1, loss = 1.12973774\n",
      "Iteration 2, loss = 0.98304198\n",
      "Iteration 3, loss = 0.93108350\n",
      "Iteration 4, loss = 0.93850632\n",
      "Iteration 5, loss = 0.91889813\n",
      "Iteration 6, loss = 0.89238323\n",
      "Iteration 7, loss = 0.90985407\n",
      "Iteration 8, loss = 0.92599377\n",
      "Iteration 9, loss = 0.92994811\n",
      "Iteration 49, loss = 0.77588976\n",
      "Iteration 50, loss = 0.77960941\n",
      "Iteration 1, loss = 1.12973774\n",
      "Iteration 2, loss = 0.98304198\n",
      "Iteration 3, loss = 0.93108350\n",
      "Iteration 4, loss = 0.93850632\n",
      "Iteration 5, loss = 0.91889813\n",
      "Iteration 6, loss = 0.89238323\n",
      "Iteration 7, loss = 0.90985407\n",
      "Iteration 8, loss = 0.92599377\n",
      "Iteration 9, loss = 0.92994811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.91438471\n",
      "Iteration 11, loss = 0.89738983\n",
      "Iteration 12, loss = 0.87397124\n",
      "Iteration 13, loss = 0.87226282\n",
      "Iteration 14, loss = 0.88429578\n",
      "Iteration 15, loss = 0.94249240\n",
      "Iteration 16, loss = 0.86531714\n",
      "Iteration 17, loss = 0.88062133\n",
      "Iteration 18, loss = 0.90781503\n",
      "Iteration 19, loss = 0.87989247\n",
      "Iteration 20, loss = 0.82113170\n",
      "Iteration 21, loss = 0.83992940\n",
      "Iteration 22, loss = 0.86960722\n",
      "Iteration 23, loss = 0.83073195\n",
      "Iteration 10, loss = 0.91438471\n",
      "Iteration 11, loss = 0.89738983\n",
      "Iteration 12, loss = 0.87397124\n",
      "Iteration 13, loss = 0.87226282\n",
      "Iteration 14, loss = 0.88429578\n",
      "Iteration 15, loss = 0.94249240\n",
      "Iteration 16, loss = 0.86531714\n",
      "Iteration 17, loss = 0.88062133\n",
      "Iteration 18, loss = 0.90781503\n",
      "Iteration 19, loss = 0.87989247\n",
      "Iteration 20, loss = 0.82113170\n",
      "Iteration 21, loss = 0.83992940\n",
      "Iteration 22, loss = 0.86960722\n",
      "Iteration 23, loss = 0.83073195\n",
      "Iteration 24, loss = 0.83239629\n",
      "Iteration 25, loss = 0.83500466\n",
      "Iteration 26, loss = 0.79802407\n",
      "Iteration 27, loss = 0.84141229\n",
      "Iteration 28, loss = 0.83853064\n",
      "Iteration 29, loss = 0.79902204\n",
      "Iteration 30, loss = 0.79242545\n",
      "Iteration 31, loss = 0.81811653\n",
      "Iteration 32, loss = 0.79048537\n",
      "Iteration 33, loss = 0.75191176\n",
      "Iteration 34, loss = 0.79583491\n",
      "Iteration 35, loss = 0.76710703\n",
      "Iteration 36, loss = 0.79329646\n",
      "Iteration 37, loss = 0.79823639\n",
      "Iteration 38, loss = 0.77306506\n",
      "Iteration 24, loss = 0.83239629\n",
      "Iteration 25, loss = 0.83500466\n",
      "Iteration 26, loss = 0.79802407\n",
      "Iteration 27, loss = 0.84141229\n",
      "Iteration 28, loss = 0.83853064\n",
      "Iteration 29, loss = 0.79902204\n",
      "Iteration 30, loss = 0.79242545\n",
      "Iteration 31, loss = 0.81811653\n",
      "Iteration 32, loss = 0.79048537\n",
      "Iteration 33, loss = 0.75191176\n",
      "Iteration 34, loss = 0.79583491\n",
      "Iteration 35, loss = 0.76710703\n",
      "Iteration 36, loss = 0.79329646\n",
      "Iteration 37, loss = 0.79823639\n",
      "Iteration 38, loss = 0.77306506\n",
      "Iteration 39, loss = 0.77313184\n",
      "Iteration 40, loss = 0.74883984\n",
      "Iteration 41, loss = 0.77647701\n",
      "Iteration 42, loss = 0.74335316\n",
      "Iteration 43, loss = 0.72794348\n",
      "Iteration 44, loss = 0.72324702\n",
      "Iteration 45, loss = 0.75024864\n",
      "Iteration 46, loss = 0.72911051\n",
      "Iteration 47, loss = 0.76112847\n",
      "Iteration 48, loss = 0.73282680\n",
      "Iteration 49, loss = 0.72869924\n",
      "Iteration 50, loss = 0.74163082\n",
      "Iteration 1, loss = 1.15928287\n",
      "Iteration 39, loss = 0.77313184\n",
      "Iteration 40, loss = 0.74883984\n",
      "Iteration 41, loss = 0.77647701\n",
      "Iteration 42, loss = 0.74335316\n",
      "Iteration 43, loss = 0.72794348\n",
      "Iteration 44, loss = 0.72324702\n",
      "Iteration 45, loss = 0.75024864\n",
      "Iteration 46, loss = 0.72911051\n",
      "Iteration 47, loss = 0.76112847\n",
      "Iteration 48, loss = 0.73282680\n",
      "Iteration 49, loss = 0.72869924\n",
      "Iteration 50, loss = 0.74163082\n",
      "Iteration 1, loss = 1.15928287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.99804327\n",
      "Iteration 3, loss = 0.99139856\n",
      "Iteration 4, loss = 0.96341003\n",
      "Iteration 5, loss = 0.93500060\n",
      "Iteration 6, loss = 0.95010664\n",
      "Iteration 7, loss = 0.91619896\n",
      "Iteration 8, loss = 0.94006729\n",
      "Iteration 9, loss = 0.93902528\n",
      "Iteration 10, loss = 0.96392479\n",
      "Iteration 11, loss = 0.92308291\n",
      "Iteration 12, loss = 0.93242109\n",
      "Iteration 13, loss = 0.91957291\n",
      "Iteration 14, loss = 0.89296569\n",
      "Iteration 15, loss = 0.95646375\n",
      "Iteration 2, loss = 0.99804327\n",
      "Iteration 3, loss = 0.99139856\n",
      "Iteration 4, loss = 0.96341003\n",
      "Iteration 5, loss = 0.93500060\n",
      "Iteration 6, loss = 0.95010664\n",
      "Iteration 7, loss = 0.91619896\n",
      "Iteration 8, loss = 0.94006729\n",
      "Iteration 9, loss = 0.93902528\n",
      "Iteration 10, loss = 0.96392479\n",
      "Iteration 11, loss = 0.92308291\n",
      "Iteration 12, loss = 0.93242109\n",
      "Iteration 13, loss = 0.91957291\n",
      "Iteration 14, loss = 0.89296569\n",
      "Iteration 15, loss = 0.95646375\n",
      "Iteration 16, loss = 0.88729142\n",
      "Iteration 17, loss = 0.88336424\n",
      "Iteration 18, loss = 0.92318346\n",
      "Iteration 19, loss = 0.87698573\n",
      "Iteration 20, loss = 0.84002874\n",
      "Iteration 21, loss = 0.87447992\n",
      "Iteration 22, loss = 0.90509841\n",
      "Iteration 23, loss = 0.86126981\n",
      "Iteration 24, loss = 0.85331485\n",
      "Iteration 25, loss = 0.85449439\n",
      "Iteration 26, loss = 0.83380957\n",
      "Iteration 27, loss = 0.83670183\n",
      "Iteration 28, loss = 0.83396774\n",
      "Iteration 29, loss = 0.82790494\n",
      "Iteration 16, loss = 0.88729142\n",
      "Iteration 17, loss = 0.88336424\n",
      "Iteration 18, loss = 0.92318346\n",
      "Iteration 19, loss = 0.87698573\n",
      "Iteration 20, loss = 0.84002874\n",
      "Iteration 21, loss = 0.87447992\n",
      "Iteration 22, loss = 0.90509841\n",
      "Iteration 23, loss = 0.86126981\n",
      "Iteration 24, loss = 0.85331485\n",
      "Iteration 25, loss = 0.85449439\n",
      "Iteration 26, loss = 0.83380957\n",
      "Iteration 27, loss = 0.83670183\n",
      "Iteration 28, loss = 0.83396774\n",
      "Iteration 29, loss = 0.82790494\n",
      "Iteration 30, loss = 0.86331161\n",
      "Iteration 31, loss = 0.86043559\n",
      "Iteration 32, loss = 0.80871254\n",
      "Iteration 33, loss = 0.80645456\n",
      "Iteration 34, loss = 0.82181489\n",
      "Iteration 35, loss = 0.81585201\n",
      "Iteration 36, loss = 0.85646872\n",
      "Iteration 37, loss = 0.84109935\n",
      "Iteration 38, loss = 0.79671566\n",
      "Iteration 39, loss = 0.77352879\n",
      "Iteration 40, loss = 0.80529924\n",
      "Iteration 41, loss = 0.79994726\n",
      "Iteration 42, loss = 0.79169020\n",
      "Iteration 43, loss = 0.77057363\n",
      "Iteration 30, loss = 0.86331161\n",
      "Iteration 31, loss = 0.86043559\n",
      "Iteration 32, loss = 0.80871254\n",
      "Iteration 33, loss = 0.80645456\n",
      "Iteration 34, loss = 0.82181489\n",
      "Iteration 35, loss = 0.81585201\n",
      "Iteration 36, loss = 0.85646872\n",
      "Iteration 37, loss = 0.84109935\n",
      "Iteration 38, loss = 0.79671566\n",
      "Iteration 39, loss = 0.77352879\n",
      "Iteration 40, loss = 0.80529924\n",
      "Iteration 41, loss = 0.79994726\n",
      "Iteration 42, loss = 0.79169020\n",
      "Iteration 43, loss = 0.77057363\n",
      "Iteration 44, loss = 0.81172570\n",
      "Iteration 45, loss = 0.78750636\n",
      "Iteration 46, loss = 0.76975792\n",
      "Iteration 47, loss = 0.76460290\n",
      "Iteration 48, loss = 0.73795471\n",
      "Iteration 49, loss = 0.75750243\n",
      "Iteration 50, loss = 0.77039462\n",
      "Iteration 1, loss = 1.20408773\n",
      "Iteration 2, loss = 1.03240977\n",
      "Iteration 3, loss = 1.02047944\n",
      "Iteration 4, loss = 0.99138450\n",
      "Iteration 5, loss = 0.96212958\n",
      "Iteration 6, loss = 0.98072389\n",
      "Iteration 7, loss = 0.94571476\n",
      "Iteration 44, loss = 0.81172570\n",
      "Iteration 45, loss = 0.78750636\n",
      "Iteration 46, loss = 0.76975792\n",
      "Iteration 47, loss = 0.76460290\n",
      "Iteration 48, loss = 0.73795471\n",
      "Iteration 49, loss = 0.75750243\n",
      "Iteration 50, loss = 0.77039462\n",
      "Iteration 1, loss = 1.20408773\n",
      "Iteration 2, loss = 1.03240977\n",
      "Iteration 3, loss = 1.02047944\n",
      "Iteration 4, loss = 0.99138450\n",
      "Iteration 5, loss = 0.96212958\n",
      "Iteration 6, loss = 0.98072389\n",
      "Iteration 7, loss = 0.94571476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.93257381\n",
      "Iteration 9, loss = 0.90988489\n",
      "Iteration 10, loss = 0.97609611\n",
      "Iteration 11, loss = 0.98071991\n",
      "Iteration 12, loss = 0.95082207\n",
      "Iteration 13, loss = 0.94059856\n",
      "Iteration 14, loss = 0.91606733\n",
      "Iteration 15, loss = 0.89903964\n",
      "Iteration 16, loss = 0.89159337\n",
      "Iteration 17, loss = 0.89442114\n",
      "Iteration 18, loss = 0.91310099\n",
      "Iteration 19, loss = 0.88618009\n",
      "Iteration 20, loss = 0.89627994\n",
      "Iteration 8, loss = 0.93257381\n",
      "Iteration 9, loss = 0.90988489\n",
      "Iteration 10, loss = 0.97609611\n",
      "Iteration 11, loss = 0.98071991\n",
      "Iteration 12, loss = 0.95082207\n",
      "Iteration 13, loss = 0.94059856\n",
      "Iteration 14, loss = 0.91606733\n",
      "Iteration 15, loss = 0.89903964\n",
      "Iteration 16, loss = 0.89159337\n",
      "Iteration 17, loss = 0.89442114\n",
      "Iteration 18, loss = 0.91310099\n",
      "Iteration 19, loss = 0.88618009\n",
      "Iteration 20, loss = 0.89627994\n",
      "Iteration 21, loss = 0.88089883\n",
      "Iteration 22, loss = 0.87288278\n",
      "Iteration 23, loss = 0.86445586\n",
      "Iteration 24, loss = 0.86209179\n",
      "Iteration 25, loss = 0.89173735\n",
      "Iteration 26, loss = 0.87353572\n",
      "Iteration 27, loss = 0.83265055\n",
      "Iteration 28, loss = 0.87569900\n",
      "Iteration 29, loss = 0.90845091\n",
      "Iteration 30, loss = 0.82405363\n",
      "Iteration 31, loss = 0.85949420\n",
      "Iteration 32, loss = 0.86658243\n",
      "Iteration 33, loss = 0.87026922\n",
      "Iteration 34, loss = 0.82038028\n",
      "Iteration 35, loss = 0.79745150\n",
      "Iteration 36, loss = 0.80908748\n",
      "Iteration 21, loss = 0.88089883\n",
      "Iteration 22, loss = 0.87288278\n",
      "Iteration 23, loss = 0.86445586\n",
      "Iteration 24, loss = 0.86209179\n",
      "Iteration 25, loss = 0.89173735\n",
      "Iteration 26, loss = 0.87353572\n",
      "Iteration 27, loss = 0.83265055\n",
      "Iteration 28, loss = 0.87569900\n",
      "Iteration 29, loss = 0.90845091\n",
      "Iteration 30, loss = 0.82405363\n",
      "Iteration 31, loss = 0.85949420\n",
      "Iteration 32, loss = 0.86658243\n",
      "Iteration 33, loss = 0.87026922\n",
      "Iteration 34, loss = 0.82038028\n",
      "Iteration 35, loss = 0.79745150\n",
      "Iteration 36, loss = 0.80908748\n",
      "Iteration 37, loss = 0.83691119\n",
      "Iteration 38, loss = 0.82434782\n",
      "Iteration 39, loss = 0.77524467\n",
      "Iteration 40, loss = 0.76610776\n",
      "Iteration 41, loss = 0.77221597\n",
      "Iteration 42, loss = 0.75742588\n",
      "Iteration 43, loss = 0.73969634\n",
      "Iteration 44, loss = 0.80868890\n",
      "Iteration 45, loss = 0.74445641\n",
      "Iteration 46, loss = 0.72874137\n",
      "Iteration 47, loss = 0.73126122\n",
      "Iteration 48, loss = 0.78534786\n",
      "Iteration 49, loss = 0.80740706\n",
      "Iteration 50, loss = 0.78941521\n",
      "Iteration 1, loss = 1.23628093\n",
      "Iteration 37, loss = 0.83691119\n",
      "Iteration 38, loss = 0.82434782\n",
      "Iteration 39, loss = 0.77524467\n",
      "Iteration 40, loss = 0.76610776\n",
      "Iteration 41, loss = 0.77221597\n",
      "Iteration 42, loss = 0.75742588\n",
      "Iteration 43, loss = 0.73969634\n",
      "Iteration 44, loss = 0.80868890\n",
      "Iteration 45, loss = 0.74445641\n",
      "Iteration 46, loss = 0.72874137\n",
      "Iteration 47, loss = 0.73126122\n",
      "Iteration 48, loss = 0.78534786\n",
      "Iteration 49, loss = 0.80740706\n",
      "Iteration 50, loss = 0.78941521\n",
      "Iteration 1, loss = 1.23628093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.06539175\n",
      "Iteration 3, loss = 1.01337135\n",
      "Iteration 4, loss = 0.96090391\n",
      "Iteration 5, loss = 0.94854385\n",
      "Iteration 6, loss = 0.95528209\n",
      "Iteration 7, loss = 0.93809513\n",
      "Iteration 8, loss = 0.94206918\n",
      "Iteration 9, loss = 0.91040215\n",
      "Iteration 10, loss = 0.94677065\n",
      "Iteration 11, loss = 0.92274935\n",
      "Iteration 12, loss = 0.94106159\n",
      "Iteration 13, loss = 0.92466374\n",
      "Iteration 14, loss = 0.91324759\n",
      "Iteration 2, loss = 1.06539175\n",
      "Iteration 3, loss = 1.01337135\n",
      "Iteration 4, loss = 0.96090391\n",
      "Iteration 5, loss = 0.94854385\n",
      "Iteration 6, loss = 0.95528209\n",
      "Iteration 7, loss = 0.93809513\n",
      "Iteration 8, loss = 0.94206918\n",
      "Iteration 9, loss = 0.91040215\n",
      "Iteration 10, loss = 0.94677065\n",
      "Iteration 11, loss = 0.92274935\n",
      "Iteration 12, loss = 0.94106159\n",
      "Iteration 13, loss = 0.92466374\n",
      "Iteration 14, loss = 0.91324759\n",
      "Iteration 15, loss = 0.90251982\n",
      "Iteration 16, loss = 0.87656781\n",
      "Iteration 17, loss = 0.87739163\n",
      "Iteration 18, loss = 0.89178239\n",
      "Iteration 19, loss = 0.91847931\n",
      "Iteration 20, loss = 0.88409246\n",
      "Iteration 21, loss = 0.91911903\n",
      "Iteration 22, loss = 0.87886237\n",
      "Iteration 23, loss = 0.87024336\n",
      "Iteration 24, loss = 0.88640851\n",
      "Iteration 25, loss = 0.86773633\n",
      "Iteration 26, loss = 0.85215621\n",
      "Iteration 27, loss = 0.83277581\n",
      "Iteration 28, loss = 0.88756543\n",
      "Iteration 15, loss = 0.90251982\n",
      "Iteration 16, loss = 0.87656781\n",
      "Iteration 17, loss = 0.87739163\n",
      "Iteration 18, loss = 0.89178239\n",
      "Iteration 19, loss = 0.91847931\n",
      "Iteration 20, loss = 0.88409246\n",
      "Iteration 21, loss = 0.91911903\n",
      "Iteration 22, loss = 0.87886237\n",
      "Iteration 23, loss = 0.87024336\n",
      "Iteration 24, loss = 0.88640851\n",
      "Iteration 25, loss = 0.86773633\n",
      "Iteration 26, loss = 0.85215621\n",
      "Iteration 27, loss = 0.83277581\n",
      "Iteration 28, loss = 0.88756543\n",
      "Iteration 29, loss = 0.88281727\n",
      "Iteration 30, loss = 0.84284700\n",
      "Iteration 31, loss = 0.84548133\n",
      "Iteration 32, loss = 0.81738824\n",
      "Iteration 33, loss = 0.83098152\n",
      "Iteration 34, loss = 0.80027021\n",
      "Iteration 35, loss = 0.78219155\n",
      "Iteration 36, loss = 0.80316257\n",
      "Iteration 37, loss = 0.80010590\n",
      "Iteration 38, loss = 0.89060568\n",
      "Iteration 39, loss = 0.83674832\n",
      "Iteration 40, loss = 0.88684786\n",
      "Iteration 41, loss = 0.83640238\n",
      "Iteration 42, loss = 0.86624014\n",
      "Iteration 29, loss = 0.88281727\n",
      "Iteration 30, loss = 0.84284700\n",
      "Iteration 31, loss = 0.84548133\n",
      "Iteration 32, loss = 0.81738824\n",
      "Iteration 33, loss = 0.83098152\n",
      "Iteration 34, loss = 0.80027021\n",
      "Iteration 35, loss = 0.78219155\n",
      "Iteration 36, loss = 0.80316257\n",
      "Iteration 37, loss = 0.80010590\n",
      "Iteration 38, loss = 0.89060568\n",
      "Iteration 39, loss = 0.83674832\n",
      "Iteration 40, loss = 0.88684786\n",
      "Iteration 41, loss = 0.83640238\n",
      "Iteration 42, loss = 0.86624014\n",
      "Iteration 43, loss = 0.86160499\n",
      "Iteration 44, loss = 0.83090491\n",
      "Iteration 45, loss = 0.82271693\n",
      "Iteration 46, loss = 0.80971168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16893895\n",
      "Iteration 2, loss = 1.02332004\n",
      "Iteration 3, loss = 1.09407233\n",
      "Iteration 4, loss = 1.00951187\n",
      "Iteration 5, loss = 0.98929198\n",
      "Iteration 6, loss = 0.97096347\n",
      "Iteration 7, loss = 0.98288161\n",
      "Iteration 8, loss = 0.97316433\n",
      "Iteration 9, loss = 0.94958777\n",
      "Iteration 10, loss = 0.94326479\n",
      "Iteration 11, loss = 0.96144835\n",
      "Iteration 43, loss = 0.86160499\n",
      "Iteration 44, loss = 0.83090491\n",
      "Iteration 45, loss = 0.82271693\n",
      "Iteration 46, loss = 0.80971168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16893895\n",
      "Iteration 2, loss = 1.02332004\n",
      "Iteration 3, loss = 1.09407233\n",
      "Iteration 4, loss = 1.00951187\n",
      "Iteration 5, loss = 0.98929198\n",
      "Iteration 6, loss = 0.97096347\n",
      "Iteration 7, loss = 0.98288161\n",
      "Iteration 8, loss = 0.97316433\n",
      "Iteration 9, loss = 0.94958777\n",
      "Iteration 10, loss = 0.94326479\n",
      "Iteration 11, loss = 0.96144835\n",
      "Iteration 12, loss = 0.93008034\n",
      "Iteration 13, loss = 0.92302895\n",
      "Iteration 14, loss = 0.94301439\n",
      "Iteration 15, loss = 1.00864075\n",
      "Iteration 16, loss = 0.96217545\n",
      "Iteration 17, loss = 0.95090977\n",
      "Iteration 18, loss = 0.91468052\n",
      "Iteration 19, loss = 0.91252656\n",
      "Iteration 20, loss = 0.89018605\n",
      "Iteration 21, loss = 0.88854418\n",
      "Iteration 22, loss = 0.91731075\n",
      "Iteration 23, loss = 0.88339434\n",
      "Iteration 24, loss = 0.88058545\n",
      "Iteration 25, loss = 0.88572572\n",
      "Iteration 26, loss = 0.85127375\n",
      "Iteration 12, loss = 0.93008034\n",
      "Iteration 13, loss = 0.92302895\n",
      "Iteration 14, loss = 0.94301439\n",
      "Iteration 15, loss = 1.00864075\n",
      "Iteration 16, loss = 0.96217545\n",
      "Iteration 17, loss = 0.95090977\n",
      "Iteration 18, loss = 0.91468052\n",
      "Iteration 19, loss = 0.91252656\n",
      "Iteration 20, loss = 0.89018605\n",
      "Iteration 21, loss = 0.88854418\n",
      "Iteration 22, loss = 0.91731075\n",
      "Iteration 23, loss = 0.88339434\n",
      "Iteration 24, loss = 0.88058545\n",
      "Iteration 25, loss = 0.88572572\n",
      "Iteration 26, loss = 0.85127375\n",
      "Iteration 27, loss = 0.84643075\n",
      "Iteration 28, loss = 0.86746413\n",
      "Iteration 29, loss = 0.85808599\n",
      "Iteration 30, loss = 0.89485908\n",
      "Iteration 31, loss = 0.86682325\n",
      "Iteration 32, loss = 0.84691999\n",
      "Iteration 33, loss = 0.81861089\n",
      "Iteration 34, loss = 0.80355617\n",
      "Iteration 35, loss = 0.87285143\n",
      "Iteration 36, loss = 0.83371103\n",
      "Iteration 37, loss = 0.82788484\n",
      "Iteration 38, loss = 0.78408536\n",
      "Iteration 39, loss = 0.79728548\n",
      "Iteration 40, loss = 0.78831690\n",
      "Iteration 41, loss = 0.77083813\n",
      "Iteration 27, loss = 0.84643075\n",
      "Iteration 28, loss = 0.86746413\n",
      "Iteration 29, loss = 0.85808599\n",
      "Iteration 30, loss = 0.89485908\n",
      "Iteration 31, loss = 0.86682325\n",
      "Iteration 32, loss = 0.84691999\n",
      "Iteration 33, loss = 0.81861089\n",
      "Iteration 34, loss = 0.80355617\n",
      "Iteration 35, loss = 0.87285143\n",
      "Iteration 36, loss = 0.83371103\n",
      "Iteration 37, loss = 0.82788484\n",
      "Iteration 38, loss = 0.78408536\n",
      "Iteration 39, loss = 0.79728548\n",
      "Iteration 40, loss = 0.78831690\n",
      "Iteration 41, loss = 0.77083813\n",
      "Iteration 42, loss = 0.78443743\n",
      "Iteration 43, loss = 0.81358020\n",
      "Iteration 44, loss = 0.77545819\n",
      "Iteration 45, loss = 0.75948923\n",
      "Iteration 46, loss = 0.79854030\n",
      "Iteration 47, loss = 0.82268429\n",
      "Iteration 48, loss = 0.80987194\n",
      "Iteration 49, loss = 0.77588976\n",
      "Iteration 50, loss = 0.77960941\n",
      "Iteration 51, loss = 0.77948727\n",
      "Iteration 52, loss = 0.80723862\n",
      "Iteration 53, loss = 0.78258604\n",
      "Iteration 54, loss = 0.78527565\n",
      "Iteration 55, loss = 0.75977088\n",
      "Iteration 56, loss = 0.81422324\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.12973774\n",
      "Iteration 42, loss = 0.78443743\n",
      "Iteration 43, loss = 0.81358020\n",
      "Iteration 44, loss = 0.77545819\n",
      "Iteration 45, loss = 0.75948923\n",
      "Iteration 46, loss = 0.79854030\n",
      "Iteration 47, loss = 0.82268429\n",
      "Iteration 48, loss = 0.80987194\n",
      "Iteration 49, loss = 0.77588976\n",
      "Iteration 50, loss = 0.77960941\n",
      "Iteration 51, loss = 0.77948727\n",
      "Iteration 52, loss = 0.80723862\n",
      "Iteration 53, loss = 0.78258604\n",
      "Iteration 54, loss = 0.78527565\n",
      "Iteration 55, loss = 0.75977088\n",
      "Iteration 56, loss = 0.81422324\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.12973774\n",
      "Iteration 2, loss = 0.98304198\n",
      "Iteration 3, loss = 0.93108350\n",
      "Iteration 4, loss = 0.93850632\n",
      "Iteration 5, loss = 0.91889813\n",
      "Iteration 6, loss = 0.89238323\n",
      "Iteration 7, loss = 0.90985407\n",
      "Iteration 8, loss = 0.92599377\n",
      "Iteration 9, loss = 0.92994811\n",
      "Iteration 10, loss = 0.91438471\n",
      "Iteration 11, loss = 0.89738983\n",
      "Iteration 12, loss = 0.87397124\n",
      "Iteration 13, loss = 0.87226282\n",
      "Iteration 14, loss = 0.88429578\n",
      "Iteration 2, loss = 0.98304198\n",
      "Iteration 3, loss = 0.93108350\n",
      "Iteration 4, loss = 0.93850632\n",
      "Iteration 5, loss = 0.91889813\n",
      "Iteration 6, loss = 0.89238323\n",
      "Iteration 7, loss = 0.90985407\n",
      "Iteration 8, loss = 0.92599377\n",
      "Iteration 9, loss = 0.92994811\n",
      "Iteration 10, loss = 0.91438471\n",
      "Iteration 11, loss = 0.89738983\n",
      "Iteration 12, loss = 0.87397124\n",
      "Iteration 13, loss = 0.87226282\n",
      "Iteration 14, loss = 0.88429578\n",
      "Iteration 15, loss = 0.94249240\n",
      "Iteration 16, loss = 0.86531714\n",
      "Iteration 17, loss = 0.88062133\n",
      "Iteration 18, loss = 0.90781503\n",
      "Iteration 19, loss = 0.87989247\n",
      "Iteration 20, loss = 0.82113170\n",
      "Iteration 21, loss = 0.83992940\n",
      "Iteration 22, loss = 0.86960722\n",
      "Iteration 23, loss = 0.83073195\n",
      "Iteration 24, loss = 0.83239629\n",
      "Iteration 25, loss = 0.83500466\n",
      "Iteration 26, loss = 0.79802407\n",
      "Iteration 27, loss = 0.84141229\n",
      "Iteration 28, loss = 0.83853064\n",
      "Iteration 29, loss = 0.79902204\n",
      "Iteration 15, loss = 0.94249240\n",
      "Iteration 16, loss = 0.86531714\n",
      "Iteration 17, loss = 0.88062133\n",
      "Iteration 18, loss = 0.90781503\n",
      "Iteration 19, loss = 0.87989247\n",
      "Iteration 20, loss = 0.82113170\n",
      "Iteration 21, loss = 0.83992940\n",
      "Iteration 22, loss = 0.86960722\n",
      "Iteration 23, loss = 0.83073195\n",
      "Iteration 24, loss = 0.83239629\n",
      "Iteration 25, loss = 0.83500466\n",
      "Iteration 26, loss = 0.79802407\n",
      "Iteration 27, loss = 0.84141229\n",
      "Iteration 28, loss = 0.83853064\n",
      "Iteration 29, loss = 0.79902204\n",
      "Iteration 30, loss = 0.79242545\n",
      "Iteration 31, loss = 0.81811653\n",
      "Iteration 32, loss = 0.79048537\n",
      "Iteration 33, loss = 0.75191176\n",
      "Iteration 34, loss = 0.79583491\n",
      "Iteration 35, loss = 0.76710703\n",
      "Iteration 36, loss = 0.79329646\n",
      "Iteration 37, loss = 0.79823639\n",
      "Iteration 38, loss = 0.77306506\n",
      "Iteration 39, loss = 0.77313184\n",
      "Iteration 40, loss = 0.74883984\n",
      "Iteration 41, loss = 0.77647701\n",
      "Iteration 42, loss = 0.74335316\n",
      "Iteration 43, loss = 0.72794348\n",
      "Iteration 44, loss = 0.72324702\n",
      "Iteration 30, loss = 0.79242545\n",
      "Iteration 31, loss = 0.81811653\n",
      "Iteration 32, loss = 0.79048537\n",
      "Iteration 33, loss = 0.75191176\n",
      "Iteration 34, loss = 0.79583491\n",
      "Iteration 35, loss = 0.76710703\n",
      "Iteration 36, loss = 0.79329646\n",
      "Iteration 37, loss = 0.79823639\n",
      "Iteration 38, loss = 0.77306506\n",
      "Iteration 39, loss = 0.77313184\n",
      "Iteration 40, loss = 0.74883984\n",
      "Iteration 41, loss = 0.77647701\n",
      "Iteration 42, loss = 0.74335316\n",
      "Iteration 43, loss = 0.72794348\n",
      "Iteration 44, loss = 0.72324702\n",
      "Iteration 45, loss = 0.75024864\n",
      "Iteration 46, loss = 0.72911051\n",
      "Iteration 47, loss = 0.76112847\n",
      "Iteration 48, loss = 0.73282680\n",
      "Iteration 49, loss = 0.72869924\n",
      "Iteration 50, loss = 0.74163082\n",
      "Iteration 51, loss = 0.75297032\n",
      "Iteration 52, loss = 0.72705949\n",
      "Iteration 53, loss = 0.69795855\n",
      "Iteration 54, loss = 0.70879265\n",
      "Iteration 55, loss = 0.68222004\n",
      "Iteration 56, loss = 0.69236826\n",
      "Iteration 57, loss = 0.72412293\n",
      "Iteration 58, loss = 0.70975165\n",
      "Iteration 59, loss = 0.67737221\n",
      "Iteration 45, loss = 0.75024864\n",
      "Iteration 46, loss = 0.72911051\n",
      "Iteration 47, loss = 0.76112847\n",
      "Iteration 48, loss = 0.73282680\n",
      "Iteration 49, loss = 0.72869924\n",
      "Iteration 50, loss = 0.74163082\n",
      "Iteration 51, loss = 0.75297032\n",
      "Iteration 52, loss = 0.72705949\n",
      "Iteration 53, loss = 0.69795855\n",
      "Iteration 54, loss = 0.70879265\n",
      "Iteration 55, loss = 0.68222004\n",
      "Iteration 56, loss = 0.69236826\n",
      "Iteration 57, loss = 0.72412293\n",
      "Iteration 58, loss = 0.70975165\n",
      "Iteration 59, loss = 0.67737221\n",
      "Iteration 60, loss = 0.69919031\n",
      "Iteration 61, loss = 0.70450091\n",
      "Iteration 62, loss = 0.72687931\n",
      "Iteration 63, loss = 0.73021171\n",
      "Iteration 64, loss = 0.70734447\n",
      "Iteration 65, loss = 0.75764046\n",
      "Iteration 66, loss = 0.72370058\n",
      "Iteration 67, loss = 0.67295616\n",
      "Iteration 68, loss = 0.71710102\n",
      "Iteration 69, loss = 0.68608401\n",
      "Iteration 70, loss = 0.68088059\n",
      "Iteration 71, loss = 0.70615738\n",
      "Iteration 72, loss = 0.72459470\n",
      "Iteration 73, loss = 0.68233216\n",
      "Iteration 74, loss = 0.70726484\n",
      "Iteration 60, loss = 0.69919031\n",
      "Iteration 61, loss = 0.70450091\n",
      "Iteration 62, loss = 0.72687931\n",
      "Iteration 63, loss = 0.73021171\n",
      "Iteration 64, loss = 0.70734447\n",
      "Iteration 65, loss = 0.75764046\n",
      "Iteration 66, loss = 0.72370058\n",
      "Iteration 67, loss = 0.67295616\n",
      "Iteration 68, loss = 0.71710102\n",
      "Iteration 69, loss = 0.68608401\n",
      "Iteration 70, loss = 0.68088059\n",
      "Iteration 71, loss = 0.70615738\n",
      "Iteration 72, loss = 0.72459470\n",
      "Iteration 73, loss = 0.68233216\n",
      "Iteration 74, loss = 0.70726484\n",
      "Iteration 75, loss = 0.71269424\n",
      "Iteration 76, loss = 0.67548027\n",
      "Iteration 77, loss = 0.71109372\n",
      "Iteration 78, loss = 0.71454100\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15928287\n",
      "Iteration 2, loss = 0.99804327\n",
      "Iteration 3, loss = 0.99139856\n",
      "Iteration 4, loss = 0.96341003\n",
      "Iteration 5, loss = 0.93500060\n",
      "Iteration 6, loss = 0.95010664\n",
      "Iteration 7, loss = 0.91619896\n",
      "Iteration 8, loss = 0.94006729\n",
      "Iteration 75, loss = 0.71269424\n",
      "Iteration 76, loss = 0.67548027\n",
      "Iteration 77, loss = 0.71109372\n",
      "Iteration 78, loss = 0.71454100\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15928287\n",
      "Iteration 2, loss = 0.99804327\n",
      "Iteration 3, loss = 0.99139856\n",
      "Iteration 4, loss = 0.96341003\n",
      "Iteration 5, loss = 0.93500060\n",
      "Iteration 6, loss = 0.95010664\n",
      "Iteration 7, loss = 0.91619896\n",
      "Iteration 8, loss = 0.94006729\n",
      "Iteration 9, loss = 0.93902528\n",
      "Iteration 10, loss = 0.96392479\n",
      "Iteration 11, loss = 0.92308291\n",
      "Iteration 12, loss = 0.93242109\n",
      "Iteration 13, loss = 0.91957291\n",
      "Iteration 14, loss = 0.89296569\n",
      "Iteration 15, loss = 0.95646375\n",
      "Iteration 16, loss = 0.88729142\n",
      "Iteration 17, loss = 0.88336424\n",
      "Iteration 18, loss = 0.92318346\n",
      "Iteration 19, loss = 0.87698573\n",
      "Iteration 20, loss = 0.84002874\n",
      "Iteration 21, loss = 0.87447992\n",
      "Iteration 22, loss = 0.90509841\n",
      "Iteration 23, loss = 0.86126981\n",
      "Iteration 9, loss = 0.93902528\n",
      "Iteration 10, loss = 0.96392479\n",
      "Iteration 11, loss = 0.92308291\n",
      "Iteration 12, loss = 0.93242109\n",
      "Iteration 13, loss = 0.91957291\n",
      "Iteration 14, loss = 0.89296569\n",
      "Iteration 15, loss = 0.95646375\n",
      "Iteration 16, loss = 0.88729142\n",
      "Iteration 17, loss = 0.88336424\n",
      "Iteration 18, loss = 0.92318346\n",
      "Iteration 19, loss = 0.87698573\n",
      "Iteration 20, loss = 0.84002874\n",
      "Iteration 21, loss = 0.87447992\n",
      "Iteration 22, loss = 0.90509841\n",
      "Iteration 23, loss = 0.86126981\n",
      "Iteration 24, loss = 0.85331485\n",
      "Iteration 25, loss = 0.85449439\n",
      "Iteration 26, loss = 0.83380957\n",
      "Iteration 27, loss = 0.83670183\n",
      "Iteration 28, loss = 0.83396774\n",
      "Iteration 29, loss = 0.82790494\n",
      "Iteration 30, loss = 0.86331161\n",
      "Iteration 31, loss = 0.86043559\n",
      "Iteration 32, loss = 0.80871254\n",
      "Iteration 33, loss = 0.80645456\n",
      "Iteration 34, loss = 0.82181489\n",
      "Iteration 35, loss = 0.81585201\n",
      "Iteration 36, loss = 0.85646872\n",
      "Iteration 37, loss = 0.84109935\n",
      "Iteration 38, loss = 0.79671566\n",
      "Iteration 24, loss = 0.85331485\n",
      "Iteration 25, loss = 0.85449439\n",
      "Iteration 26, loss = 0.83380957\n",
      "Iteration 27, loss = 0.83670183\n",
      "Iteration 28, loss = 0.83396774\n",
      "Iteration 29, loss = 0.82790494\n",
      "Iteration 30, loss = 0.86331161\n",
      "Iteration 31, loss = 0.86043559\n",
      "Iteration 32, loss = 0.80871254\n",
      "Iteration 33, loss = 0.80645456\n",
      "Iteration 34, loss = 0.82181489\n",
      "Iteration 35, loss = 0.81585201\n",
      "Iteration 36, loss = 0.85646872\n",
      "Iteration 37, loss = 0.84109935\n",
      "Iteration 38, loss = 0.79671566\n",
      "Iteration 39, loss = 0.77352879\n",
      "Iteration 40, loss = 0.80529924\n",
      "Iteration 41, loss = 0.79994726\n",
      "Iteration 42, loss = 0.79169020\n",
      "Iteration 43, loss = 0.77057363\n",
      "Iteration 44, loss = 0.81172570\n",
      "Iteration 45, loss = 0.78750636\n",
      "Iteration 46, loss = 0.76975792\n",
      "Iteration 47, loss = 0.76460290\n",
      "Iteration 48, loss = 0.73795471\n",
      "Iteration 49, loss = 0.75750243\n",
      "Iteration 50, loss = 0.77039462\n",
      "Iteration 51, loss = 0.75380838\n",
      "Iteration 52, loss = 0.73501297\n",
      "Iteration 39, loss = 0.77352879\n",
      "Iteration 40, loss = 0.80529924\n",
      "Iteration 41, loss = 0.79994726\n",
      "Iteration 42, loss = 0.79169020\n",
      "Iteration 43, loss = 0.77057363\n",
      "Iteration 44, loss = 0.81172570\n",
      "Iteration 45, loss = 0.78750636\n",
      "Iteration 46, loss = 0.76975792\n",
      "Iteration 47, loss = 0.76460290\n",
      "Iteration 48, loss = 0.73795471\n",
      "Iteration 49, loss = 0.75750243\n",
      "Iteration 50, loss = 0.77039462\n",
      "Iteration 51, loss = 0.75380838\n",
      "Iteration 52, loss = 0.73501297\n",
      "Iteration 53, loss = 0.72060853\n",
      "Iteration 54, loss = 0.71633080\n",
      "Iteration 55, loss = 0.71864268\n",
      "Iteration 56, loss = 0.73182571\n",
      "Iteration 57, loss = 0.79215139\n",
      "Iteration 58, loss = 0.78560522\n",
      "Iteration 59, loss = 0.78520154\n",
      "Iteration 60, loss = 0.74322941\n",
      "Iteration 61, loss = 0.77407605\n",
      "Iteration 62, loss = 0.78894439\n",
      "Iteration 63, loss = 0.78095400\n",
      "Iteration 64, loss = 0.75619034\n",
      "Iteration 65, loss = 0.80050780\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20408773\n",
      "Iteration 2, loss = 1.03240977\n",
      "Iteration 53, loss = 0.72060853\n",
      "Iteration 54, loss = 0.71633080\n",
      "Iteration 55, loss = 0.71864268\n",
      "Iteration 56, loss = 0.73182571\n",
      "Iteration 57, loss = 0.79215139\n",
      "Iteration 58, loss = 0.78560522\n",
      "Iteration 59, loss = 0.78520154\n",
      "Iteration 60, loss = 0.74322941\n",
      "Iteration 61, loss = 0.77407605\n",
      "Iteration 62, loss = 0.78894439\n",
      "Iteration 63, loss = 0.78095400\n",
      "Iteration 64, loss = 0.75619034\n",
      "Iteration 65, loss = 0.80050780\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20408773\n",
      "Iteration 2, loss = 1.03240977\n",
      "Iteration 3, loss = 1.02047944\n",
      "Iteration 4, loss = 0.99138450\n",
      "Iteration 5, loss = 0.96212958\n",
      "Iteration 6, loss = 0.98072389\n",
      "Iteration 7, loss = 0.94571476\n",
      "Iteration 8, loss = 0.93257381\n",
      "Iteration 9, loss = 0.90988489\n",
      "Iteration 10, loss = 0.97609611\n",
      "Iteration 11, loss = 0.98071991\n",
      "Iteration 12, loss = 0.95082207\n",
      "Iteration 13, loss = 0.94059856\n",
      "Iteration 14, loss = 0.91606733\n",
      "Iteration 15, loss = 0.89903964\n",
      "Iteration 16, loss = 0.89159337\n",
      "Iteration 3, loss = 1.02047944\n",
      "Iteration 4, loss = 0.99138450\n",
      "Iteration 5, loss = 0.96212958\n",
      "Iteration 6, loss = 0.98072389\n",
      "Iteration 7, loss = 0.94571476\n",
      "Iteration 8, loss = 0.93257381\n",
      "Iteration 9, loss = 0.90988489\n",
      "Iteration 10, loss = 0.97609611\n",
      "Iteration 11, loss = 0.98071991\n",
      "Iteration 12, loss = 0.95082207\n",
      "Iteration 13, loss = 0.94059856\n",
      "Iteration 14, loss = 0.91606733\n",
      "Iteration 15, loss = 0.89903964\n",
      "Iteration 16, loss = 0.89159337\n",
      "Iteration 17, loss = 0.89442114\n",
      "Iteration 18, loss = 0.91310099\n",
      "Iteration 19, loss = 0.88618009\n",
      "Iteration 20, loss = 0.89627994\n",
      "Iteration 21, loss = 0.88089883\n",
      "Iteration 22, loss = 0.87288278\n",
      "Iteration 23, loss = 0.86445586\n",
      "Iteration 24, loss = 0.86209179\n",
      "Iteration 25, loss = 0.89173735\n",
      "Iteration 26, loss = 0.87353572\n",
      "Iteration 27, loss = 0.83265055\n",
      "Iteration 28, loss = 0.87569900\n",
      "Iteration 29, loss = 0.90845091\n",
      "Iteration 30, loss = 0.82405363\n",
      "Iteration 17, loss = 0.89442114\n",
      "Iteration 18, loss = 0.91310099\n",
      "Iteration 19, loss = 0.88618009\n",
      "Iteration 20, loss = 0.89627994\n",
      "Iteration 21, loss = 0.88089883\n",
      "Iteration 22, loss = 0.87288278\n",
      "Iteration 23, loss = 0.86445586\n",
      "Iteration 24, loss = 0.86209179\n",
      "Iteration 25, loss = 0.89173735\n",
      "Iteration 26, loss = 0.87353572\n",
      "Iteration 27, loss = 0.83265055\n",
      "Iteration 28, loss = 0.87569900\n",
      "Iteration 29, loss = 0.90845091\n",
      "Iteration 30, loss = 0.82405363\n",
      "Iteration 31, loss = 0.85949420\n",
      "Iteration 32, loss = 0.86658243\n",
      "Iteration 33, loss = 0.87026922\n",
      "Iteration 34, loss = 0.82038028\n",
      "Iteration 35, loss = 0.79745150\n",
      "Iteration 36, loss = 0.80908748\n",
      "Iteration 37, loss = 0.83691119\n",
      "Iteration 38, loss = 0.82434782\n",
      "Iteration 39, loss = 0.77524467\n",
      "Iteration 40, loss = 0.76610776\n",
      "Iteration 41, loss = 0.77221597\n",
      "Iteration 42, loss = 0.75742588\n",
      "Iteration 43, loss = 0.73969634\n",
      "Iteration 44, loss = 0.80868890\n",
      "Iteration 45, loss = 0.74445641\n",
      "Iteration 31, loss = 0.85949420\n",
      "Iteration 32, loss = 0.86658243\n",
      "Iteration 33, loss = 0.87026922\n",
      "Iteration 34, loss = 0.82038028\n",
      "Iteration 35, loss = 0.79745150\n",
      "Iteration 36, loss = 0.80908748\n",
      "Iteration 37, loss = 0.83691119\n",
      "Iteration 38, loss = 0.82434782\n",
      "Iteration 39, loss = 0.77524467\n",
      "Iteration 40, loss = 0.76610776\n",
      "Iteration 41, loss = 0.77221597\n",
      "Iteration 42, loss = 0.75742588\n",
      "Iteration 43, loss = 0.73969634\n",
      "Iteration 44, loss = 0.80868890\n",
      "Iteration 45, loss = 0.74445641\n",
      "Iteration 46, loss = 0.72874137\n",
      "Iteration 47, loss = 0.73126122\n",
      "Iteration 48, loss = 0.78534786\n",
      "Iteration 49, loss = 0.80740706\n",
      "Iteration 50, loss = 0.78941521\n",
      "Iteration 51, loss = 0.75912410\n",
      "Iteration 52, loss = 0.78936412\n",
      "Iteration 53, loss = 0.77922555\n",
      "Iteration 54, loss = 0.75648325\n",
      "Iteration 55, loss = 0.79181236\n",
      "Iteration 56, loss = 0.75394015\n",
      "Iteration 57, loss = 0.81997910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23628093\n",
      "Iteration 2, loss = 1.06539175\n",
      "Iteration 46, loss = 0.72874137\n",
      "Iteration 47, loss = 0.73126122\n",
      "Iteration 48, loss = 0.78534786\n",
      "Iteration 49, loss = 0.80740706\n",
      "Iteration 50, loss = 0.78941521\n",
      "Iteration 51, loss = 0.75912410\n",
      "Iteration 52, loss = 0.78936412\n",
      "Iteration 53, loss = 0.77922555\n",
      "Iteration 54, loss = 0.75648325\n",
      "Iteration 55, loss = 0.79181236\n",
      "Iteration 56, loss = 0.75394015\n",
      "Iteration 57, loss = 0.81997910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23628093\n",
      "Iteration 2, loss = 1.06539175\n",
      "Iteration 3, loss = 1.01337135\n",
      "Iteration 4, loss = 0.96090391\n",
      "Iteration 5, loss = 0.94854385\n",
      "Iteration 6, loss = 0.95528209\n",
      "Iteration 7, loss = 0.93809513\n",
      "Iteration 8, loss = 0.94206918\n",
      "Iteration 9, loss = 0.91040215\n",
      "Iteration 10, loss = 0.94677065\n",
      "Iteration 11, loss = 0.92274935\n",
      "Iteration 12, loss = 0.94106159\n",
      "Iteration 13, loss = 0.92466374\n",
      "Iteration 14, loss = 0.91324759\n",
      "Iteration 15, loss = 0.90251982\n",
      "Iteration 3, loss = 1.01337135\n",
      "Iteration 4, loss = 0.96090391\n",
      "Iteration 5, loss = 0.94854385\n",
      "Iteration 6, loss = 0.95528209\n",
      "Iteration 7, loss = 0.93809513\n",
      "Iteration 8, loss = 0.94206918\n",
      "Iteration 9, loss = 0.91040215\n",
      "Iteration 10, loss = 0.94677065\n",
      "Iteration 11, loss = 0.92274935\n",
      "Iteration 12, loss = 0.94106159\n",
      "Iteration 13, loss = 0.92466374\n",
      "Iteration 14, loss = 0.91324759\n",
      "Iteration 15, loss = 0.90251982\n",
      "Iteration 16, loss = 0.87656781\n",
      "Iteration 17, loss = 0.87739163\n",
      "Iteration 18, loss = 0.89178239\n",
      "Iteration 19, loss = 0.91847931\n",
      "Iteration 20, loss = 0.88409246\n",
      "Iteration 21, loss = 0.91911903\n",
      "Iteration 22, loss = 0.87886237\n",
      "Iteration 23, loss = 0.87024336\n",
      "Iteration 24, loss = 0.88640851\n",
      "Iteration 25, loss = 0.86773633\n",
      "Iteration 26, loss = 0.85215621\n",
      "Iteration 27, loss = 0.83277581\n",
      "Iteration 28, loss = 0.88756543\n",
      "Iteration 29, loss = 0.88281727\n",
      "Iteration 30, loss = 0.84284700\n",
      "Iteration 16, loss = 0.87656781\n",
      "Iteration 17, loss = 0.87739163\n",
      "Iteration 18, loss = 0.89178239\n",
      "Iteration 19, loss = 0.91847931\n",
      "Iteration 20, loss = 0.88409246\n",
      "Iteration 21, loss = 0.91911903\n",
      "Iteration 22, loss = 0.87886237\n",
      "Iteration 23, loss = 0.87024336\n",
      "Iteration 24, loss = 0.88640851\n",
      "Iteration 25, loss = 0.86773633\n",
      "Iteration 26, loss = 0.85215621\n",
      "Iteration 27, loss = 0.83277581\n",
      "Iteration 28, loss = 0.88756543\n",
      "Iteration 29, loss = 0.88281727\n",
      "Iteration 30, loss = 0.84284700\n",
      "Iteration 31, loss = 0.84548133\n",
      "Iteration 32, loss = 0.81738824\n",
      "Iteration 33, loss = 0.83098152\n",
      "Iteration 34, loss = 0.80027021\n",
      "Iteration 35, loss = 0.78219155\n",
      "Iteration 36, loss = 0.80316257\n",
      "Iteration 37, loss = 0.80010590\n",
      "Iteration 38, loss = 0.89060568\n",
      "Iteration 39, loss = 0.83674832\n",
      "Iteration 40, loss = 0.88684786\n",
      "Iteration 41, loss = 0.83640238\n",
      "Iteration 31, loss = 0.84548133\n",
      "Iteration 32, loss = 0.81738824\n",
      "Iteration 33, loss = 0.83098152\n",
      "Iteration 34, loss = 0.80027021\n",
      "Iteration 35, loss = 0.78219155\n",
      "Iteration 36, loss = 0.80316257\n",
      "Iteration 37, loss = 0.80010590\n",
      "Iteration 38, loss = 0.89060568\n",
      "Iteration 39, loss = 0.83674832\n",
      "Iteration 40, loss = 0.88684786\n",
      "Iteration 41, loss = 0.83640238\n",
      "Iteration 42, loss = 0.86624014\n",
      "Iteration 43, loss = 0.86160499\n",
      "Iteration 44, loss = 0.83090491\n",
      "Iteration 45, loss = 0.82271693\n",
      "Iteration 46, loss = 0.80971168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15762681\n",
      "Iteration 2, loss = 1.07198232\n",
      "Iteration 3, loss = 1.10020197\n",
      "Iteration 4, loss = 1.02109159\n",
      "Iteration 5, loss = 0.99797878\n",
      "Iteration 6, loss = 1.06154217\n",
      "Iteration 7, loss = 1.00365726\n",
      "Iteration 42, loss = 0.86624014\n",
      "Iteration 43, loss = 0.86160499\n",
      "Iteration 44, loss = 0.83090491\n",
      "Iteration 45, loss = 0.82271693\n",
      "Iteration 46, loss = 0.80971168\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15762681\n",
      "Iteration 2, loss = 1.07198232\n",
      "Iteration 3, loss = 1.10020197\n",
      "Iteration 4, loss = 1.02109159\n",
      "Iteration 5, loss = 0.99797878\n",
      "Iteration 6, loss = 1.06154217\n",
      "Iteration 7, loss = 1.00365726\n",
      "Iteration 8, loss = 1.00705361\n",
      "Iteration 9, loss = 1.00252538\n",
      "Iteration 10, loss = 0.97121980\n",
      "Iteration 1, loss = 1.11263502\n",
      "Iteration 2, loss = 1.01776860\n",
      "Iteration 3, loss = 0.96347644\n",
      "Iteration 4, loss = 1.00080867\n",
      "Iteration 5, loss = 0.93009550\n",
      "Iteration 6, loss = 0.92940146\n",
      "Iteration 7, loss = 0.89049169\n",
      "Iteration 8, loss = 1.04225791\n",
      "Iteration 9, loss = 0.98094381\n",
      "Iteration 10, loss = 0.95286250\n",
      "Iteration 8, loss = 1.00705361\n",
      "Iteration 9, loss = 1.00252538\n",
      "Iteration 10, loss = 0.97121980\n",
      "Iteration 1, loss = 1.11263502\n",
      "Iteration 2, loss = 1.01776860\n",
      "Iteration 3, loss = 0.96347644\n",
      "Iteration 4, loss = 1.00080867\n",
      "Iteration 5, loss = 0.93009550\n",
      "Iteration 6, loss = 0.92940146\n",
      "Iteration 7, loss = 0.89049169\n",
      "Iteration 8, loss = 1.04225791\n",
      "Iteration 9, loss = 0.98094381\n",
      "Iteration 10, loss = 0.95286250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.14295345\n",
      "Iteration 2, loss = 1.01279097\n",
      "Iteration 3, loss = 1.03292638\n",
      "Iteration 4, loss = 1.03040512\n",
      "Iteration 5, loss = 0.98149467\n",
      "Iteration 6, loss = 0.97031401\n",
      "Iteration 7, loss = 0.95697268\n",
      "Iteration 8, loss = 1.01168063\n",
      "Iteration 9, loss = 0.99779276\n",
      "Iteration 10, loss = 0.97879989\n",
      "Iteration 1, loss = 1.18194085\n",
      "Iteration 1, loss = 1.14295345\n",
      "Iteration 2, loss = 1.01279097\n",
      "Iteration 3, loss = 1.03292638\n",
      "Iteration 4, loss = 1.03040512\n",
      "Iteration 5, loss = 0.98149467\n",
      "Iteration 6, loss = 0.97031401\n",
      "Iteration 7, loss = 0.95697268\n",
      "Iteration 8, loss = 1.01168063\n",
      "Iteration 9, loss = 0.99779276\n",
      "Iteration 10, loss = 0.97879989\n",
      "Iteration 1, loss = 1.18194085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.06150217\n",
      "Iteration 3, loss = 1.07683230\n",
      "Iteration 4, loss = 1.03251810\n",
      "Iteration 5, loss = 1.07515634\n",
      "Iteration 6, loss = 1.00776031\n",
      "Iteration 7, loss = 0.97162225\n",
      "Iteration 8, loss = 1.00401624\n",
      "Iteration 9, loss = 0.99169001\n",
      "Iteration 10, loss = 1.01457682\n",
      "Iteration 1, loss = 1.22288311\n",
      "Iteration 2, loss = 1.06150217\n",
      "Iteration 3, loss = 1.07683230\n",
      "Iteration 4, loss = 1.03251810\n",
      "Iteration 5, loss = 1.07515634\n",
      "Iteration 6, loss = 1.00776031\n",
      "Iteration 7, loss = 0.97162225\n",
      "Iteration 8, loss = 1.00401624\n",
      "Iteration 9, loss = 0.99169001\n",
      "Iteration 10, loss = 1.01457682\n",
      "Iteration 1, loss = 1.22288311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.08620206\n",
      "Iteration 3, loss = 1.06578616\n",
      "Iteration 4, loss = 0.98916616\n",
      "Iteration 5, loss = 1.00866454\n",
      "Iteration 6, loss = 1.01091462\n",
      "Iteration 7, loss = 0.97723490\n",
      "Iteration 8, loss = 1.01275811\n",
      "Iteration 9, loss = 0.96917364\n",
      "Iteration 10, loss = 0.94425765\n",
      "Iteration 1, loss = 1.15762681\n",
      "Iteration 2, loss = 1.07198232\n",
      "Iteration 3, loss = 1.10020197\n",
      "Iteration 4, loss = 1.02109159\n",
      "Iteration 2, loss = 1.08620206\n",
      "Iteration 3, loss = 1.06578616\n",
      "Iteration 4, loss = 0.98916616\n",
      "Iteration 5, loss = 1.00866454\n",
      "Iteration 6, loss = 1.01091462\n",
      "Iteration 7, loss = 0.97723490\n",
      "Iteration 8, loss = 1.01275811\n",
      "Iteration 9, loss = 0.96917364\n",
      "Iteration 10, loss = 0.94425765\n",
      "Iteration 1, loss = 1.15762681\n",
      "Iteration 2, loss = 1.07198232\n",
      "Iteration 3, loss = 1.10020197\n",
      "Iteration 4, loss = 1.02109159\n",
      "Iteration 5, loss = 0.99797878\n",
      "Iteration 6, loss = 1.06154217\n",
      "Iteration 7, loss = 1.00365726\n",
      "Iteration 8, loss = 1.00705361\n",
      "Iteration 9, loss = 1.00252538\n",
      "Iteration 10, loss = 0.97121980\n",
      "Iteration 11, loss = 1.02454139\n",
      "Iteration 12, loss = 0.98412263\n",
      "Iteration 13, loss = 0.95417504\n",
      "Iteration 14, loss = 0.94374449\n",
      "Iteration 15, loss = 1.00787381\n",
      "Iteration 16, loss = 1.19925126\n",
      "Iteration 17, loss = 1.25883872\n",
      "Iteration 18, loss = 1.22403253\n",
      "Iteration 5, loss = 0.99797878\n",
      "Iteration 6, loss = 1.06154217\n",
      "Iteration 7, loss = 1.00365726\n",
      "Iteration 8, loss = 1.00705361\n",
      "Iteration 9, loss = 1.00252538\n",
      "Iteration 10, loss = 0.97121980\n",
      "Iteration 11, loss = 1.02454139\n",
      "Iteration 12, loss = 0.98412263\n",
      "Iteration 13, loss = 0.95417504\n",
      "Iteration 14, loss = 0.94374449\n",
      "Iteration 15, loss = 1.00787381\n",
      "Iteration 16, loss = 1.19925126\n",
      "Iteration 17, loss = 1.25883872\n",
      "Iteration 18, loss = 1.22403253\n",
      "Iteration 19, loss = 1.03469028\n",
      "Iteration 20, loss = 1.02598804\n",
      "Iteration 21, loss = 0.97572260\n",
      "Iteration 22, loss = 1.21203834\n",
      "Iteration 23, loss = 1.07700787\n",
      "Iteration 24, loss = 1.14176666\n",
      "Iteration 25, loss = 1.02538649\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11263502\n",
      "Iteration 2, loss = 1.01776860\n",
      "Iteration 3, loss = 0.96347644\n",
      "Iteration 4, loss = 1.00080867\n",
      "Iteration 5, loss = 0.93009550\n",
      "Iteration 6, loss = 0.92940146\n",
      "Iteration 7, loss = 0.89049169\n",
      "Iteration 19, loss = 1.03469028\n",
      "Iteration 20, loss = 1.02598804\n",
      "Iteration 21, loss = 0.97572260\n",
      "Iteration 22, loss = 1.21203834\n",
      "Iteration 23, loss = 1.07700787\n",
      "Iteration 24, loss = 1.14176666\n",
      "Iteration 25, loss = 1.02538649\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11263502\n",
      "Iteration 2, loss = 1.01776860\n",
      "Iteration 3, loss = 0.96347644\n",
      "Iteration 4, loss = 1.00080867\n",
      "Iteration 5, loss = 0.93009550\n",
      "Iteration 6, loss = 0.92940146\n",
      "Iteration 7, loss = 0.89049169\n",
      "Iteration 8, loss = 1.04225791\n",
      "Iteration 9, loss = 0.98094381\n",
      "Iteration 10, loss = 0.95286250\n",
      "Iteration 11, loss = 0.97964980\n",
      "Iteration 12, loss = 1.00625934\n",
      "Iteration 13, loss = 0.91231134\n",
      "Iteration 14, loss = 0.91883089\n",
      "Iteration 15, loss = 1.04081226\n",
      "Iteration 16, loss = 0.93593735\n",
      "Iteration 17, loss = 0.97003430\n",
      "Iteration 18, loss = 0.98767950\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14295345\n",
      "Iteration 2, loss = 1.01279097\n",
      "Iteration 3, loss = 1.03292638\n",
      "Iteration 8, loss = 1.04225791\n",
      "Iteration 9, loss = 0.98094381\n",
      "Iteration 10, loss = 0.95286250\n",
      "Iteration 11, loss = 0.97964980\n",
      "Iteration 12, loss = 1.00625934\n",
      "Iteration 13, loss = 0.91231134\n",
      "Iteration 14, loss = 0.91883089\n",
      "Iteration 15, loss = 1.04081226\n",
      "Iteration 16, loss = 0.93593735\n",
      "Iteration 17, loss = 0.97003430\n",
      "Iteration 18, loss = 0.98767950\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14295345\n",
      "Iteration 2, loss = 1.01279097\n",
      "Iteration 3, loss = 1.03292638\n",
      "Iteration 4, loss = 1.03040512\n",
      "Iteration 5, loss = 0.98149467\n",
      "Iteration 6, loss = 0.97031401\n",
      "Iteration 7, loss = 0.95697268\n",
      "Iteration 8, loss = 1.01168063\n",
      "Iteration 9, loss = 0.99779276\n",
      "Iteration 10, loss = 0.97879989\n",
      "Iteration 11, loss = 0.96652116\n",
      "Iteration 12, loss = 0.96545303\n",
      "Iteration 13, loss = 0.97597169\n",
      "Iteration 14, loss = 0.90973147\n",
      "Iteration 15, loss = 0.99053144\n",
      "Iteration 16, loss = 1.01354169\n",
      "Iteration 4, loss = 1.03040512\n",
      "Iteration 5, loss = 0.98149467\n",
      "Iteration 6, loss = 0.97031401\n",
      "Iteration 7, loss = 0.95697268\n",
      "Iteration 8, loss = 1.01168063\n",
      "Iteration 9, loss = 0.99779276\n",
      "Iteration 10, loss = 0.97879989\n",
      "Iteration 11, loss = 0.96652116\n",
      "Iteration 12, loss = 0.96545303\n",
      "Iteration 13, loss = 0.97597169\n",
      "Iteration 14, loss = 0.90973147\n",
      "Iteration 15, loss = 0.99053144\n",
      "Iteration 16, loss = 1.01354169\n",
      "Iteration 17, loss = 0.94403906\n",
      "Iteration 18, loss = 1.00787057\n",
      "Iteration 19, loss = 0.94791556\n",
      "Iteration 20, loss = 0.93365180\n",
      "Iteration 21, loss = 0.99813105\n",
      "Iteration 22, loss = 0.99648867\n",
      "Iteration 23, loss = 0.97496456\n",
      "Iteration 24, loss = 0.93388578\n",
      "Iteration 25, loss = 0.93566317\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18194085\n",
      "Iteration 2, loss = 1.06150217\n",
      "Iteration 3, loss = 1.07683230\n",
      "Iteration 4, loss = 1.03251810\n",
      "Iteration 5, loss = 1.07515634\n",
      "Iteration 17, loss = 0.94403906\n",
      "Iteration 18, loss = 1.00787057\n",
      "Iteration 19, loss = 0.94791556\n",
      "Iteration 20, loss = 0.93365180\n",
      "Iteration 21, loss = 0.99813105\n",
      "Iteration 22, loss = 0.99648867\n",
      "Iteration 23, loss = 0.97496456\n",
      "Iteration 24, loss = 0.93388578\n",
      "Iteration 25, loss = 0.93566317\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18194085\n",
      "Iteration 2, loss = 1.06150217\n",
      "Iteration 3, loss = 1.07683230\n",
      "Iteration 4, loss = 1.03251810\n",
      "Iteration 5, loss = 1.07515634\n",
      "Iteration 6, loss = 1.00776031\n",
      "Iteration 7, loss = 0.97162225\n",
      "Iteration 8, loss = 1.00401624\n",
      "Iteration 9, loss = 0.99169001\n",
      "Iteration 10, loss = 1.01457682\n",
      "Iteration 11, loss = 0.98199186\n",
      "Iteration 12, loss = 0.98519624\n",
      "Iteration 13, loss = 0.99882391\n",
      "Iteration 14, loss = 0.97483233\n",
      "Iteration 15, loss = 0.97592751\n",
      "Iteration 16, loss = 0.96865600\n",
      "Iteration 17, loss = 0.93577857\n",
      "Iteration 18, loss = 0.98559976\n",
      "Iteration 19, loss = 1.01809244\n",
      "Iteration 20, loss = 0.93257013\n",
      "Iteration 6, loss = 1.00776031\n",
      "Iteration 7, loss = 0.97162225\n",
      "Iteration 8, loss = 1.00401624\n",
      "Iteration 9, loss = 0.99169001\n",
      "Iteration 10, loss = 1.01457682\n",
      "Iteration 11, loss = 0.98199186\n",
      "Iteration 12, loss = 0.98519624\n",
      "Iteration 13, loss = 0.99882391\n",
      "Iteration 14, loss = 0.97483233\n",
      "Iteration 15, loss = 0.97592751\n",
      "Iteration 16, loss = 0.96865600\n",
      "Iteration 17, loss = 0.93577857\n",
      "Iteration 18, loss = 0.98559976\n",
      "Iteration 19, loss = 1.01809244\n",
      "Iteration 20, loss = 0.93257013\n",
      "Iteration 21, loss = 0.94199085\n",
      "Iteration 22, loss = 0.92504094\n",
      "Iteration 23, loss = 0.95626785\n",
      "Iteration 24, loss = 0.97310316\n",
      "Iteration 25, loss = 0.97930630\n",
      "Iteration 26, loss = 0.92159375\n",
      "Iteration 27, loss = 0.94115306\n",
      "Iteration 28, loss = 0.93918012\n",
      "Iteration 29, loss = 0.97024802\n",
      "Iteration 30, loss = 0.91382758\n",
      "Iteration 31, loss = 0.91158796\n",
      "Iteration 32, loss = 0.90296499\n",
      "Iteration 33, loss = 0.92965348\n",
      "Iteration 34, loss = 0.94005142\n",
      "Iteration 35, loss = 0.89923942\n",
      "Iteration 21, loss = 0.94199085\n",
      "Iteration 22, loss = 0.92504094\n",
      "Iteration 23, loss = 0.95626785\n",
      "Iteration 24, loss = 0.97310316\n",
      "Iteration 25, loss = 0.97930630\n",
      "Iteration 26, loss = 0.92159375\n",
      "Iteration 27, loss = 0.94115306\n",
      "Iteration 28, loss = 0.93918012\n",
      "Iteration 29, loss = 0.97024802\n",
      "Iteration 30, loss = 0.91382758\n",
      "Iteration 31, loss = 0.91158796\n",
      "Iteration 32, loss = 0.90296499\n",
      "Iteration 33, loss = 0.92965348\n",
      "Iteration 34, loss = 0.94005142\n",
      "Iteration 35, loss = 0.89923942\n",
      "Iteration 36, loss = 0.98221226\n",
      "Iteration 37, loss = 0.97266296\n",
      "Iteration 38, loss = 1.00442513\n",
      "Iteration 39, loss = 1.04676262\n",
      "Iteration 40, loss = 0.99690518\n",
      "Iteration 41, loss = 0.96088291\n",
      "Iteration 42, loss = 0.91164824\n",
      "Iteration 43, loss = 0.94573729\n",
      "Iteration 44, loss = 0.95397838\n",
      "Iteration 45, loss = 0.93680478\n",
      "Iteration 46, loss = 0.94195304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22288311\n",
      "Iteration 2, loss = 1.08620206\n",
      "Iteration 3, loss = 1.06578616\n",
      "Iteration 36, loss = 0.98221226\n",
      "Iteration 37, loss = 0.97266296\n",
      "Iteration 38, loss = 1.00442513\n",
      "Iteration 39, loss = 1.04676262\n",
      "Iteration 40, loss = 0.99690518\n",
      "Iteration 41, loss = 0.96088291\n",
      "Iteration 42, loss = 0.91164824\n",
      "Iteration 43, loss = 0.94573729\n",
      "Iteration 44, loss = 0.95397838\n",
      "Iteration 45, loss = 0.93680478\n",
      "Iteration 46, loss = 0.94195304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22288311\n",
      "Iteration 2, loss = 1.08620206\n",
      "Iteration 3, loss = 1.06578616\n",
      "Iteration 4, loss = 0.98916616\n",
      "Iteration 5, loss = 1.00866454\n",
      "Iteration 6, loss = 1.01091462\n",
      "Iteration 7, loss = 0.97723490\n",
      "Iteration 8, loss = 1.01275811\n",
      "Iteration 9, loss = 0.96917364\n",
      "Iteration 10, loss = 0.94425765\n",
      "Iteration 11, loss = 0.97225869\n",
      "Iteration 12, loss = 0.99460191\n",
      "Iteration 13, loss = 0.94156848\n",
      "Iteration 14, loss = 0.99644411\n",
      "Iteration 15, loss = 0.95733847\n",
      "Iteration 16, loss = 0.93355054\n",
      "Iteration 17, loss = 0.92281154\n",
      "Iteration 4, loss = 0.98916616\n",
      "Iteration 5, loss = 1.00866454\n",
      "Iteration 6, loss = 1.01091462\n",
      "Iteration 7, loss = 0.97723490\n",
      "Iteration 8, loss = 1.01275811\n",
      "Iteration 9, loss = 0.96917364\n",
      "Iteration 10, loss = 0.94425765\n",
      "Iteration 11, loss = 0.97225869\n",
      "Iteration 12, loss = 0.99460191\n",
      "Iteration 13, loss = 0.94156848\n",
      "Iteration 14, loss = 0.99644411\n",
      "Iteration 15, loss = 0.95733847\n",
      "Iteration 16, loss = 0.93355054\n",
      "Iteration 17, loss = 0.92281154\n",
      "Iteration 18, loss = 0.95958907\n",
      "Iteration 19, loss = 0.93896137\n",
      "Iteration 20, loss = 0.91124935\n",
      "Iteration 21, loss = 0.96997306\n",
      "Iteration 22, loss = 0.94953947\n",
      "Iteration 23, loss = 0.93450272\n",
      "Iteration 24, loss = 0.93398364\n",
      "Iteration 25, loss = 0.91335297\n",
      "Iteration 26, loss = 0.90806570\n",
      "Iteration 27, loss = 0.91352733\n",
      "Iteration 28, loss = 0.96505239\n",
      "Iteration 29, loss = 0.91332086\n",
      "Iteration 30, loss = 0.93904835\n",
      "Iteration 31, loss = 0.98015837\n",
      "Iteration 32, loss = 0.92655038\n",
      "Iteration 18, loss = 0.95958907\n",
      "Iteration 19, loss = 0.93896137\n",
      "Iteration 20, loss = 0.91124935\n",
      "Iteration 21, loss = 0.96997306\n",
      "Iteration 22, loss = 0.94953947\n",
      "Iteration 23, loss = 0.93450272\n",
      "Iteration 24, loss = 0.93398364\n",
      "Iteration 25, loss = 0.91335297\n",
      "Iteration 26, loss = 0.90806570\n",
      "Iteration 27, loss = 0.91352733\n",
      "Iteration 28, loss = 0.96505239\n",
      "Iteration 29, loss = 0.91332086\n",
      "Iteration 30, loss = 0.93904835\n",
      "Iteration 31, loss = 0.98015837\n",
      "Iteration 32, loss = 0.92655038\n",
      "Iteration 33, loss = 0.92504990\n",
      "Iteration 34, loss = 0.88494321\n",
      "Iteration 35, loss = 0.91483986\n",
      "Iteration 36, loss = 0.93431964\n",
      "Iteration 37, loss = 0.86296211\n",
      "Iteration 38, loss = 0.94156579\n",
      "Iteration 39, loss = 0.90206762\n",
      "Iteration 40, loss = 0.89985649\n",
      "Iteration 41, loss = 0.90513040\n",
      "Iteration 42, loss = 0.99475787\n",
      "Iteration 43, loss = 0.95612567\n",
      "Iteration 44, loss = 0.94874361\n",
      "Iteration 45, loss = 0.96251934\n",
      "Iteration 46, loss = 0.95712897\n",
      "Iteration 47, loss = 0.94674759\n",
      "Iteration 48, loss = 0.90422197\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.92504990\n",
      "Iteration 34, loss = 0.88494321\n",
      "Iteration 35, loss = 0.91483986\n",
      "Iteration 36, loss = 0.93431964\n",
      "Iteration 37, loss = 0.86296211\n",
      "Iteration 38, loss = 0.94156579\n",
      "Iteration 39, loss = 0.90206762\n",
      "Iteration 40, loss = 0.89985649\n",
      "Iteration 41, loss = 0.90513040\n",
      "Iteration 42, loss = 0.99475787\n",
      "Iteration 43, loss = 0.95612567\n",
      "Iteration 44, loss = 0.94874361\n",
      "Iteration 45, loss = 0.96251934\n",
      "Iteration 46, loss = 0.95712897\n",
      "Iteration 47, loss = 0.94674759\n",
      "Iteration 48, loss = 0.90422197\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15762681\n",
      "Iteration 2, loss = 1.07198232\n",
      "Iteration 3, loss = 1.10020197\n",
      "Iteration 4, loss = 1.02109159\n",
      "Iteration 5, loss = 0.99797878\n",
      "Iteration 6, loss = 1.06154217\n",
      "Iteration 7, loss = 1.00365726\n",
      "Iteration 8, loss = 1.00705361\n",
      "Iteration 9, loss = 1.00252538\n",
      "Iteration 10, loss = 0.97121980\n",
      "Iteration 11, loss = 1.02454139\n",
      "Iteration 12, loss = 0.98412263\n",
      "Iteration 13, loss = 0.95417504\n",
      "Iteration 1, loss = 1.15762681\n",
      "Iteration 2, loss = 1.07198232\n",
      "Iteration 3, loss = 1.10020197\n",
      "Iteration 4, loss = 1.02109159\n",
      "Iteration 5, loss = 0.99797878\n",
      "Iteration 6, loss = 1.06154217\n",
      "Iteration 7, loss = 1.00365726\n",
      "Iteration 8, loss = 1.00705361\n",
      "Iteration 9, loss = 1.00252538\n",
      "Iteration 10, loss = 0.97121980\n",
      "Iteration 11, loss = 1.02454139\n",
      "Iteration 12, loss = 0.98412263\n",
      "Iteration 13, loss = 0.95417504\n",
      "Iteration 14, loss = 0.94374449\n",
      "Iteration 15, loss = 1.00787381\n",
      "Iteration 16, loss = 1.19925126\n",
      "Iteration 17, loss = 1.25883872\n",
      "Iteration 18, loss = 1.22403253\n",
      "Iteration 19, loss = 1.03469028\n",
      "Iteration 20, loss = 1.02598804\n",
      "Iteration 21, loss = 0.97572260\n",
      "Iteration 22, loss = 1.21203834\n",
      "Iteration 23, loss = 1.07700787\n",
      "Iteration 24, loss = 1.14176666\n",
      "Iteration 25, loss = 1.02538649\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11263502\n",
      "Iteration 2, loss = 1.01776860\n",
      "Iteration 3, loss = 0.96347644\n",
      "Iteration 14, loss = 0.94374449\n",
      "Iteration 15, loss = 1.00787381\n",
      "Iteration 16, loss = 1.19925126\n",
      "Iteration 17, loss = 1.25883872\n",
      "Iteration 18, loss = 1.22403253\n",
      "Iteration 19, loss = 1.03469028\n",
      "Iteration 20, loss = 1.02598804\n",
      "Iteration 21, loss = 0.97572260\n",
      "Iteration 22, loss = 1.21203834\n",
      "Iteration 23, loss = 1.07700787\n",
      "Iteration 24, loss = 1.14176666\n",
      "Iteration 25, loss = 1.02538649\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11263502\n",
      "Iteration 2, loss = 1.01776860\n",
      "Iteration 3, loss = 0.96347644\n",
      "Iteration 4, loss = 1.00080867\n",
      "Iteration 5, loss = 0.93009550\n",
      "Iteration 6, loss = 0.92940146\n",
      "Iteration 7, loss = 0.89049169\n",
      "Iteration 8, loss = 1.04225791\n",
      "Iteration 9, loss = 0.98094381\n",
      "Iteration 10, loss = 0.95286250\n",
      "Iteration 11, loss = 0.97964980\n",
      "Iteration 12, loss = 1.00625934\n",
      "Iteration 13, loss = 0.91231134\n",
      "Iteration 14, loss = 0.91883089\n",
      "Iteration 15, loss = 1.04081226\n",
      "Iteration 16, loss = 0.93593735\n",
      "Iteration 4, loss = 1.00080867\n",
      "Iteration 5, loss = 0.93009550\n",
      "Iteration 6, loss = 0.92940146\n",
      "Iteration 7, loss = 0.89049169\n",
      "Iteration 8, loss = 1.04225791\n",
      "Iteration 9, loss = 0.98094381\n",
      "Iteration 10, loss = 0.95286250\n",
      "Iteration 11, loss = 0.97964980\n",
      "Iteration 12, loss = 1.00625934\n",
      "Iteration 13, loss = 0.91231134\n",
      "Iteration 14, loss = 0.91883089\n",
      "Iteration 15, loss = 1.04081226\n",
      "Iteration 16, loss = 0.93593735\n",
      "Iteration 17, loss = 0.97003430\n",
      "Iteration 18, loss = 0.98767950\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14295345\n",
      "Iteration 2, loss = 1.01279097\n",
      "Iteration 3, loss = 1.03292638\n",
      "Iteration 4, loss = 1.03040512\n",
      "Iteration 5, loss = 0.98149467\n",
      "Iteration 6, loss = 0.97031401\n",
      "Iteration 7, loss = 0.95697268\n",
      "Iteration 8, loss = 1.01168063\n",
      "Iteration 9, loss = 0.99779276\n",
      "Iteration 10, loss = 0.97879989\n",
      "Iteration 11, loss = 0.96652116\n",
      "Iteration 17, loss = 0.97003430\n",
      "Iteration 18, loss = 0.98767950\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14295345\n",
      "Iteration 2, loss = 1.01279097\n",
      "Iteration 3, loss = 1.03292638\n",
      "Iteration 4, loss = 1.03040512\n",
      "Iteration 5, loss = 0.98149467\n",
      "Iteration 6, loss = 0.97031401\n",
      "Iteration 7, loss = 0.95697268\n",
      "Iteration 8, loss = 1.01168063\n",
      "Iteration 9, loss = 0.99779276\n",
      "Iteration 10, loss = 0.97879989\n",
      "Iteration 11, loss = 0.96652116\n",
      "Iteration 12, loss = 0.96545303\n",
      "Iteration 13, loss = 0.97597169\n",
      "Iteration 14, loss = 0.90973147\n",
      "Iteration 15, loss = 0.99053144\n",
      "Iteration 16, loss = 1.01354169\n",
      "Iteration 17, loss = 0.94403906\n",
      "Iteration 18, loss = 1.00787057\n",
      "Iteration 19, loss = 0.94791556\n",
      "Iteration 20, loss = 0.93365180\n",
      "Iteration 21, loss = 0.99813105\n",
      "Iteration 22, loss = 0.99648867\n",
      "Iteration 23, loss = 0.97496456\n",
      "Iteration 24, loss = 0.93388578\n",
      "Iteration 25, loss = 0.93566317\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 12, loss = 0.96545303\n",
      "Iteration 13, loss = 0.97597169\n",
      "Iteration 14, loss = 0.90973147\n",
      "Iteration 15, loss = 0.99053144\n",
      "Iteration 16, loss = 1.01354169\n",
      "Iteration 17, loss = 0.94403906\n",
      "Iteration 18, loss = 1.00787057\n",
      "Iteration 19, loss = 0.94791556\n",
      "Iteration 20, loss = 0.93365180\n",
      "Iteration 21, loss = 0.99813105\n",
      "Iteration 22, loss = 0.99648867\n",
      "Iteration 23, loss = 0.97496456\n",
      "Iteration 24, loss = 0.93388578\n",
      "Iteration 25, loss = 0.93566317\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18194085\n",
      "Iteration 2, loss = 1.06150217\n",
      "Iteration 3, loss = 1.07683230\n",
      "Iteration 4, loss = 1.03251810\n",
      "Iteration 5, loss = 1.07515634\n",
      "Iteration 6, loss = 1.00776031\n",
      "Iteration 7, loss = 0.97162225\n",
      "Iteration 8, loss = 1.00401624\n",
      "Iteration 9, loss = 0.99169001\n",
      "Iteration 10, loss = 1.01457682\n",
      "Iteration 11, loss = 0.98199186\n",
      "Iteration 12, loss = 0.98519624\n",
      "Iteration 13, loss = 0.99882391\n",
      "Iteration 14, loss = 0.97483233\n",
      "Iteration 1, loss = 1.18194085\n",
      "Iteration 2, loss = 1.06150217\n",
      "Iteration 3, loss = 1.07683230\n",
      "Iteration 4, loss = 1.03251810\n",
      "Iteration 5, loss = 1.07515634\n",
      "Iteration 6, loss = 1.00776031\n",
      "Iteration 7, loss = 0.97162225\n",
      "Iteration 8, loss = 1.00401624\n",
      "Iteration 9, loss = 0.99169001\n",
      "Iteration 10, loss = 1.01457682\n",
      "Iteration 11, loss = 0.98199186\n",
      "Iteration 12, loss = 0.98519624\n",
      "Iteration 13, loss = 0.99882391\n",
      "Iteration 14, loss = 0.97483233\n",
      "Iteration 15, loss = 0.97592751\n",
      "Iteration 16, loss = 0.96865600\n",
      "Iteration 17, loss = 0.93577857\n",
      "Iteration 18, loss = 0.98559976\n",
      "Iteration 19, loss = 1.01809244\n",
      "Iteration 20, loss = 0.93257013\n",
      "Iteration 21, loss = 0.94199085\n",
      "Iteration 22, loss = 0.92504094\n",
      "Iteration 23, loss = 0.95626785\n",
      "Iteration 24, loss = 0.97310316\n",
      "Iteration 25, loss = 0.97930630\n",
      "Iteration 26, loss = 0.92159375\n",
      "Iteration 27, loss = 0.94115306\n",
      "Iteration 28, loss = 0.93918012\n",
      "Iteration 29, loss = 0.97024802\n",
      "Iteration 15, loss = 0.97592751\n",
      "Iteration 16, loss = 0.96865600\n",
      "Iteration 17, loss = 0.93577857\n",
      "Iteration 18, loss = 0.98559976\n",
      "Iteration 19, loss = 1.01809244\n",
      "Iteration 20, loss = 0.93257013\n",
      "Iteration 21, loss = 0.94199085\n",
      "Iteration 22, loss = 0.92504094\n",
      "Iteration 23, loss = 0.95626785\n",
      "Iteration 24, loss = 0.97310316\n",
      "Iteration 25, loss = 0.97930630\n",
      "Iteration 26, loss = 0.92159375\n",
      "Iteration 27, loss = 0.94115306\n",
      "Iteration 28, loss = 0.93918012\n",
      "Iteration 29, loss = 0.97024802\n",
      "Iteration 30, loss = 0.91382758\n",
      "Iteration 31, loss = 0.91158796\n",
      "Iteration 32, loss = 0.90296499\n",
      "Iteration 33, loss = 0.92965348\n",
      "Iteration 34, loss = 0.94005142\n",
      "Iteration 35, loss = 0.89923942\n",
      "Iteration 36, loss = 0.98221226\n",
      "Iteration 37, loss = 0.97266296\n",
      "Iteration 38, loss = 1.00442513\n",
      "Iteration 39, loss = 1.04676262\n",
      "Iteration 40, loss = 0.99690518\n",
      "Iteration 41, loss = 0.96088291\n",
      "Iteration 42, loss = 0.91164824\n",
      "Iteration 43, loss = 0.94573729\n",
      "Iteration 44, loss = 0.95397838\n",
      "Iteration 45, loss = 0.93680478\n",
      "Iteration 30, loss = 0.91382758\n",
      "Iteration 31, loss = 0.91158796\n",
      "Iteration 32, loss = 0.90296499\n",
      "Iteration 33, loss = 0.92965348\n",
      "Iteration 34, loss = 0.94005142\n",
      "Iteration 35, loss = 0.89923942\n",
      "Iteration 36, loss = 0.98221226\n",
      "Iteration 37, loss = 0.97266296\n",
      "Iteration 38, loss = 1.00442513\n",
      "Iteration 39, loss = 1.04676262\n",
      "Iteration 40, loss = 0.99690518\n",
      "Iteration 41, loss = 0.96088291\n",
      "Iteration 42, loss = 0.91164824\n",
      "Iteration 43, loss = 0.94573729\n",
      "Iteration 44, loss = 0.95397838\n",
      "Iteration 45, loss = 0.93680478\n",
      "Iteration 46, loss = 0.94195304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22288311\n",
      "Iteration 2, loss = 1.08620206\n",
      "Iteration 3, loss = 1.06578616\n",
      "Iteration 4, loss = 0.98916616\n",
      "Iteration 5, loss = 1.00866454\n",
      "Iteration 6, loss = 1.01091462\n",
      "Iteration 7, loss = 0.97723490\n",
      "Iteration 8, loss = 1.01275811\n",
      "Iteration 9, loss = 0.96917364\n",
      "Iteration 10, loss = 0.94425765\n",
      "Iteration 46, loss = 0.94195304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22288311\n",
      "Iteration 2, loss = 1.08620206\n",
      "Iteration 3, loss = 1.06578616\n",
      "Iteration 4, loss = 0.98916616\n",
      "Iteration 5, loss = 1.00866454\n",
      "Iteration 6, loss = 1.01091462\n",
      "Iteration 7, loss = 0.97723490\n",
      "Iteration 8, loss = 1.01275811\n",
      "Iteration 9, loss = 0.96917364\n",
      "Iteration 10, loss = 0.94425765\n",
      "Iteration 11, loss = 0.97225869\n",
      "Iteration 12, loss = 0.99460191\n",
      "Iteration 13, loss = 0.94156848\n",
      "Iteration 14, loss = 0.99644411\n",
      "Iteration 15, loss = 0.95733847\n",
      "Iteration 16, loss = 0.93355054\n",
      "Iteration 17, loss = 0.92281154\n",
      "Iteration 18, loss = 0.95958907\n",
      "Iteration 19, loss = 0.93896137\n",
      "Iteration 20, loss = 0.91124935\n",
      "Iteration 21, loss = 0.96997306\n",
      "Iteration 22, loss = 0.94953947\n",
      "Iteration 23, loss = 0.93450272\n",
      "Iteration 24, loss = 0.93398364\n",
      "Iteration 25, loss = 0.91335297\n",
      "Iteration 26, loss = 0.90806570\n",
      "Iteration 11, loss = 0.97225869\n",
      "Iteration 12, loss = 0.99460191\n",
      "Iteration 13, loss = 0.94156848\n",
      "Iteration 14, loss = 0.99644411\n",
      "Iteration 15, loss = 0.95733847\n",
      "Iteration 16, loss = 0.93355054\n",
      "Iteration 17, loss = 0.92281154\n",
      "Iteration 18, loss = 0.95958907\n",
      "Iteration 19, loss = 0.93896137\n",
      "Iteration 20, loss = 0.91124935\n",
      "Iteration 21, loss = 0.96997306\n",
      "Iteration 22, loss = 0.94953947\n",
      "Iteration 23, loss = 0.93450272\n",
      "Iteration 24, loss = 0.93398364\n",
      "Iteration 25, loss = 0.91335297\n",
      "Iteration 26, loss = 0.90806570\n",
      "Iteration 27, loss = 0.91352733\n",
      "Iteration 28, loss = 0.96505239\n",
      "Iteration 29, loss = 0.91332086\n",
      "Iteration 30, loss = 0.93904835\n",
      "Iteration 31, loss = 0.98015837\n",
      "Iteration 32, loss = 0.92655038\n",
      "Iteration 33, loss = 0.92504990\n",
      "Iteration 34, loss = 0.88494321\n",
      "Iteration 35, loss = 0.91483986\n",
      "Iteration 36, loss = 0.93431964\n",
      "Iteration 37, loss = 0.86296211\n",
      "Iteration 38, loss = 0.94156579\n",
      "Iteration 39, loss = 0.90206762\n",
      "Iteration 40, loss = 0.89985649\n",
      "Iteration 41, loss = 0.90513040\n",
      "Iteration 27, loss = 0.91352733\n",
      "Iteration 28, loss = 0.96505239\n",
      "Iteration 29, loss = 0.91332086\n",
      "Iteration 30, loss = 0.93904835\n",
      "Iteration 31, loss = 0.98015837\n",
      "Iteration 32, loss = 0.92655038\n",
      "Iteration 33, loss = 0.92504990\n",
      "Iteration 34, loss = 0.88494321\n",
      "Iteration 35, loss = 0.91483986\n",
      "Iteration 36, loss = 0.93431964\n",
      "Iteration 37, loss = 0.86296211\n",
      "Iteration 38, loss = 0.94156579\n",
      "Iteration 39, loss = 0.90206762\n",
      "Iteration 40, loss = 0.89985649\n",
      "Iteration 41, loss = 0.90513040\n",
      "Iteration 42, loss = 0.99475787\n",
      "Iteration 43, loss = 0.95612567\n",
      "Iteration 44, loss = 0.94874361\n",
      "Iteration 45, loss = 0.96251934\n",
      "Iteration 46, loss = 0.95712897\n",
      "Iteration 47, loss = 0.94674759\n",
      "Iteration 48, loss = 0.90422197\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17947800\n",
      "Iteration 2, loss = 1.15325071\n",
      "Iteration 3, loss = 1.13955982\n",
      "Iteration 4, loss = 1.24816499\n",
      "Iteration 5, loss = 1.25518792\n",
      "Iteration 6, loss = 1.25333161\n",
      "Iteration 42, loss = 0.99475787\n",
      "Iteration 43, loss = 0.95612567\n",
      "Iteration 44, loss = 0.94874361\n",
      "Iteration 45, loss = 0.96251934\n",
      "Iteration 46, loss = 0.95712897\n",
      "Iteration 47, loss = 0.94674759\n",
      "Iteration 48, loss = 0.90422197\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17947800\n",
      "Iteration 2, loss = 1.15325071\n",
      "Iteration 3, loss = 1.13955982\n",
      "Iteration 4, loss = 1.24816499\n",
      "Iteration 5, loss = 1.25518792\n",
      "Iteration 6, loss = 1.25333161\n",
      "Iteration 7, loss = 1.24283930\n",
      "Iteration 8, loss = 1.26719625\n",
      "Iteration 9, loss = 1.25286056\n",
      "Iteration 10, loss = 1.25385581\n",
      "Iteration 1, loss = 1.14946084\n",
      "Iteration 2, loss = 1.04822968\n",
      "Iteration 3, loss = 1.00266921\n",
      "Iteration 4, loss = 1.06624857\n",
      "Iteration 5, loss = 1.00000169\n",
      "Iteration 6, loss = 1.01114447\n",
      "Iteration 7, loss = 1.00058632\n",
      "Iteration 8, loss = 1.25793556\n",
      "Iteration 9, loss = 1.24883289\n",
      "Iteration 7, loss = 1.24283930\n",
      "Iteration 8, loss = 1.26719625\n",
      "Iteration 9, loss = 1.25286056\n",
      "Iteration 10, loss = 1.25385581\n",
      "Iteration 1, loss = 1.14946084\n",
      "Iteration 2, loss = 1.04822968\n",
      "Iteration 3, loss = 1.00266921\n",
      "Iteration 4, loss = 1.06624857\n",
      "Iteration 5, loss = 1.00000169\n",
      "Iteration 6, loss = 1.01114447\n",
      "Iteration 7, loss = 1.00058632\n",
      "Iteration 8, loss = 1.25793556\n",
      "Iteration 9, loss = 1.24883289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25055700\n",
      "Iteration 1, loss = 1.15671182\n",
      "Iteration 2, loss = 1.11380726\n",
      "Iteration 3, loss = 1.08006235\n",
      "Iteration 4, loss = 1.10713157\n",
      "Iteration 5, loss = 1.03130975\n",
      "Iteration 6, loss = 0.98350946\n",
      "Iteration 7, loss = 0.96495650\n",
      "Iteration 8, loss = 1.05531894\n",
      "Iteration 9, loss = 1.03299968\n",
      "Iteration 10, loss = 1.03363063\n",
      "Iteration 10, loss = 1.25055700\n",
      "Iteration 1, loss = 1.15671182\n",
      "Iteration 2, loss = 1.11380726\n",
      "Iteration 3, loss = 1.08006235\n",
      "Iteration 4, loss = 1.10713157\n",
      "Iteration 5, loss = 1.03130975\n",
      "Iteration 6, loss = 0.98350946\n",
      "Iteration 7, loss = 0.96495650\n",
      "Iteration 8, loss = 1.05531894\n",
      "Iteration 9, loss = 1.03299968\n",
      "Iteration 10, loss = 1.03363063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.19729456\n",
      "Iteration 2, loss = 1.08396373\n",
      "Iteration 3, loss = 1.08675731\n",
      "Iteration 4, loss = 1.05970563\n",
      "Iteration 5, loss = 1.08477022\n",
      "Iteration 6, loss = 1.11920541\n",
      "Iteration 7, loss = 1.12133640\n",
      "Iteration 8, loss = 1.09543197\n",
      "Iteration 9, loss = 1.05197242\n",
      "Iteration 10, loss = 1.06720426\n",
      "Iteration 1, loss = 1.22289815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.19729456\n",
      "Iteration 2, loss = 1.08396373\n",
      "Iteration 3, loss = 1.08675731\n",
      "Iteration 4, loss = 1.05970563\n",
      "Iteration 5, loss = 1.08477022\n",
      "Iteration 6, loss = 1.11920541\n",
      "Iteration 7, loss = 1.12133640\n",
      "Iteration 8, loss = 1.09543197\n",
      "Iteration 9, loss = 1.05197242\n",
      "Iteration 10, loss = 1.06720426\n",
      "Iteration 1, loss = 1.22289815\n",
      "Iteration 2, loss = 1.15595407\n",
      "Iteration 3, loss = 1.11956743\n",
      "Iteration 4, loss = 1.03278354\n",
      "Iteration 5, loss = 1.04034729\n",
      "Iteration 6, loss = 1.06767682\n",
      "Iteration 7, loss = 1.25365323\n",
      "Iteration 8, loss = 1.15869326\n",
      "Iteration 9, loss = 1.07905243\n",
      "Iteration 10, loss = 1.04650975\n",
      "Iteration 1, loss = 1.17947800\n",
      "Iteration 2, loss = 1.15325071\n",
      "Iteration 3, loss = 1.13955982\n",
      "Iteration 4, loss = 1.24816499\n",
      "Iteration 2, loss = 1.15595407\n",
      "Iteration 3, loss = 1.11956743\n",
      "Iteration 4, loss = 1.03278354\n",
      "Iteration 5, loss = 1.04034729\n",
      "Iteration 6, loss = 1.06767682\n",
      "Iteration 7, loss = 1.25365323\n",
      "Iteration 8, loss = 1.15869326\n",
      "Iteration 9, loss = 1.07905243\n",
      "Iteration 10, loss = 1.04650975\n",
      "Iteration 1, loss = 1.17947800\n",
      "Iteration 2, loss = 1.15325071\n",
      "Iteration 3, loss = 1.13955982\n",
      "Iteration 4, loss = 1.24816499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.25518792\n",
      "Iteration 6, loss = 1.25333161\n",
      "Iteration 7, loss = 1.24283930\n",
      "Iteration 8, loss = 1.26719625\n",
      "Iteration 9, loss = 1.25286056\n",
      "Iteration 10, loss = 1.25385581\n",
      "Iteration 11, loss = 1.24317547\n",
      "Iteration 12, loss = 1.25524440\n",
      "Iteration 13, loss = 1.23940178\n",
      "Iteration 14, loss = 1.25194158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14946084\n",
      "Iteration 2, loss = 1.04822968\n",
      "Iteration 5, loss = 1.25518792\n",
      "Iteration 6, loss = 1.25333161\n",
      "Iteration 7, loss = 1.24283930\n",
      "Iteration 8, loss = 1.26719625\n",
      "Iteration 9, loss = 1.25286056\n",
      "Iteration 10, loss = 1.25385581\n",
      "Iteration 11, loss = 1.24317547\n",
      "Iteration 12, loss = 1.25524440\n",
      "Iteration 13, loss = 1.23940178\n",
      "Iteration 14, loss = 1.25194158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14946084\n",
      "Iteration 2, loss = 1.04822968\n",
      "Iteration 3, loss = 1.00266921\n",
      "Iteration 4, loss = 1.06624857\n",
      "Iteration 5, loss = 1.00000169\n",
      "Iteration 6, loss = 1.01114447\n",
      "Iteration 7, loss = 1.00058632\n",
      "Iteration 8, loss = 1.25793556\n",
      "Iteration 9, loss = 1.24883289\n",
      "Iteration 10, loss = 1.25055700\n",
      "Iteration 11, loss = 1.24927323\n",
      "Iteration 12, loss = 1.26175466\n",
      "Iteration 13, loss = 1.24655138\n",
      "Iteration 14, loss = 1.24952534\n",
      "Iteration 15, loss = 1.25989779\n",
      "Iteration 16, loss = 1.27682401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15671182\n",
      "Iteration 3, loss = 1.00266921\n",
      "Iteration 4, loss = 1.06624857\n",
      "Iteration 5, loss = 1.00000169\n",
      "Iteration 6, loss = 1.01114447\n",
      "Iteration 7, loss = 1.00058632\n",
      "Iteration 8, loss = 1.25793556\n",
      "Iteration 9, loss = 1.24883289\n",
      "Iteration 10, loss = 1.25055700\n",
      "Iteration 11, loss = 1.24927323\n",
      "Iteration 12, loss = 1.26175466\n",
      "Iteration 13, loss = 1.24655138\n",
      "Iteration 14, loss = 1.24952534\n",
      "Iteration 15, loss = 1.25989779\n",
      "Iteration 16, loss = 1.27682401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15671182\n",
      "Iteration 2, loss = 1.11380726\n",
      "Iteration 3, loss = 1.08006235\n",
      "Iteration 4, loss = 1.10713157\n",
      "Iteration 5, loss = 1.03130975\n",
      "Iteration 6, loss = 0.98350946\n",
      "Iteration 7, loss = 0.96495650\n",
      "Iteration 8, loss = 1.05531894\n",
      "Iteration 9, loss = 1.03299968\n",
      "Iteration 10, loss = 1.03363063\n",
      "Iteration 11, loss = 1.14689244\n",
      "Iteration 12, loss = 1.01462702\n",
      "Iteration 13, loss = 0.99307090\n",
      "Iteration 14, loss = 0.97543153\n",
      "Iteration 2, loss = 1.11380726\n",
      "Iteration 3, loss = 1.08006235\n",
      "Iteration 4, loss = 1.10713157\n",
      "Iteration 5, loss = 1.03130975\n",
      "Iteration 6, loss = 0.98350946\n",
      "Iteration 7, loss = 0.96495650\n",
      "Iteration 8, loss = 1.05531894\n",
      "Iteration 9, loss = 1.03299968\n",
      "Iteration 10, loss = 1.03363063\n",
      "Iteration 11, loss = 1.14689244\n",
      "Iteration 12, loss = 1.01462702\n",
      "Iteration 13, loss = 0.99307090\n",
      "Iteration 14, loss = 0.97543153\n",
      "Iteration 15, loss = 0.99596794\n",
      "Iteration 16, loss = 1.00495595\n",
      "Iteration 17, loss = 0.99280389\n",
      "Iteration 18, loss = 1.11469832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19729456\n",
      "Iteration 2, loss = 1.08396373\n",
      "Iteration 3, loss = 1.08675731\n",
      "Iteration 4, loss = 1.05970563\n",
      "Iteration 5, loss = 1.08477022\n",
      "Iteration 6, loss = 1.11920541\n",
      "Iteration 7, loss = 1.12133640\n",
      "Iteration 8, loss = 1.09543197\n",
      "Iteration 9, loss = 1.05197242\n",
      "Iteration 15, loss = 0.99596794\n",
      "Iteration 16, loss = 1.00495595\n",
      "Iteration 17, loss = 0.99280389\n",
      "Iteration 18, loss = 1.11469832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19729456\n",
      "Iteration 2, loss = 1.08396373\n",
      "Iteration 3, loss = 1.08675731\n",
      "Iteration 4, loss = 1.05970563\n",
      "Iteration 5, loss = 1.08477022\n",
      "Iteration 6, loss = 1.11920541\n",
      "Iteration 7, loss = 1.12133640\n",
      "Iteration 8, loss = 1.09543197\n",
      "Iteration 9, loss = 1.05197242\n",
      "Iteration 10, loss = 1.06720426\n",
      "Iteration 11, loss = 1.07970072\n",
      "Iteration 12, loss = 1.03678600\n",
      "Iteration 13, loss = 1.06733152\n",
      "Iteration 14, loss = 1.02676011\n",
      "Iteration 15, loss = 1.02070949\n",
      "Iteration 16, loss = 0.99590955\n",
      "Iteration 17, loss = 0.98343639\n",
      "Iteration 18, loss = 1.02924876\n",
      "Iteration 19, loss = 1.06536425\n",
      "Iteration 20, loss = 1.04445110\n",
      "Iteration 21, loss = 1.08835477\n",
      "Iteration 22, loss = 1.07284002\n",
      "Iteration 23, loss = 1.03945293\n",
      "Iteration 24, loss = 1.05116419\n",
      "Iteration 10, loss = 1.06720426\n",
      "Iteration 11, loss = 1.07970072\n",
      "Iteration 12, loss = 1.03678600\n",
      "Iteration 13, loss = 1.06733152\n",
      "Iteration 14, loss = 1.02676011\n",
      "Iteration 15, loss = 1.02070949\n",
      "Iteration 16, loss = 0.99590955\n",
      "Iteration 17, loss = 0.98343639\n",
      "Iteration 18, loss = 1.02924876\n",
      "Iteration 19, loss = 1.06536425\n",
      "Iteration 20, loss = 1.04445110\n",
      "Iteration 21, loss = 1.08835477\n",
      "Iteration 22, loss = 1.07284002\n",
      "Iteration 23, loss = 1.03945293\n",
      "Iteration 24, loss = 1.05116419\n",
      "Iteration 25, loss = 0.99947671\n",
      "Iteration 26, loss = 1.04703007\n",
      "Iteration 27, loss = 0.99959442\n",
      "Iteration 28, loss = 1.02286495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22289815\n",
      "Iteration 2, loss = 1.15595407\n",
      "Iteration 3, loss = 1.11956743\n",
      "Iteration 4, loss = 1.03278354\n",
      "Iteration 5, loss = 1.04034729\n",
      "Iteration 6, loss = 1.06767682\n",
      "Iteration 7, loss = 1.25365323\n",
      "Iteration 8, loss = 1.15869326\n",
      "Iteration 9, loss = 1.07905243\n",
      "Iteration 10, loss = 1.04650975\n",
      "Iteration 25, loss = 0.99947671\n",
      "Iteration 26, loss = 1.04703007\n",
      "Iteration 27, loss = 0.99959442\n",
      "Iteration 28, loss = 1.02286495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22289815\n",
      "Iteration 2, loss = 1.15595407\n",
      "Iteration 3, loss = 1.11956743\n",
      "Iteration 4, loss = 1.03278354\n",
      "Iteration 5, loss = 1.04034729\n",
      "Iteration 6, loss = 1.06767682\n",
      "Iteration 7, loss = 1.25365323\n",
      "Iteration 8, loss = 1.15869326\n",
      "Iteration 9, loss = 1.07905243\n",
      "Iteration 10, loss = 1.04650975\n",
      "Iteration 11, loss = 1.03287556\n",
      "Iteration 12, loss = 1.00760898\n",
      "Iteration 13, loss = 1.06452796\n",
      "Iteration 14, loss = 1.05740294\n",
      "Iteration 15, loss = 1.02199255\n",
      "Iteration 16, loss = 1.03207705\n",
      "Iteration 17, loss = 1.02831075\n",
      "Iteration 18, loss = 1.04997916\n",
      "Iteration 19, loss = 1.01749737\n",
      "Iteration 20, loss = 0.97992215\n",
      "Iteration 21, loss = 1.01202309\n",
      "Iteration 22, loss = 0.99883750\n",
      "Iteration 23, loss = 1.04465697\n",
      "Iteration 24, loss = 1.00572786\n",
      "Iteration 25, loss = 1.04132975\n",
      "Iteration 11, loss = 1.03287556\n",
      "Iteration 12, loss = 1.00760898\n",
      "Iteration 13, loss = 1.06452796\n",
      "Iteration 14, loss = 1.05740294\n",
      "Iteration 15, loss = 1.02199255\n",
      "Iteration 16, loss = 1.03207705\n",
      "Iteration 17, loss = 1.02831075\n",
      "Iteration 18, loss = 1.04997916\n",
      "Iteration 19, loss = 1.01749737\n",
      "Iteration 20, loss = 0.97992215\n",
      "Iteration 21, loss = 1.01202309\n",
      "Iteration 22, loss = 0.99883750\n",
      "Iteration 23, loss = 1.04465697\n",
      "Iteration 24, loss = 1.00572786\n",
      "Iteration 25, loss = 1.04132975\n",
      "Iteration 26, loss = 1.00917707\n",
      "Iteration 27, loss = 0.98867857\n",
      "Iteration 28, loss = 1.04880269\n",
      "Iteration 29, loss = 1.22467801\n",
      "Iteration 30, loss = 1.08169002\n",
      "Iteration 31, loss = 1.08446253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17947800\n",
      "Iteration 2, loss = 1.15325071\n",
      "Iteration 3, loss = 1.13955982\n",
      "Iteration 4, loss = 1.24816499\n",
      "Iteration 5, loss = 1.25518792\n",
      "Iteration 6, loss = 1.25333161\n",
      "Iteration 7, loss = 1.24283930\n",
      "Iteration 8, loss = 1.26719625\n",
      "Iteration 26, loss = 1.00917707\n",
      "Iteration 27, loss = 0.98867857\n",
      "Iteration 28, loss = 1.04880269\n",
      "Iteration 29, loss = 1.22467801\n",
      "Iteration 30, loss = 1.08169002\n",
      "Iteration 31, loss = 1.08446253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17947800\n",
      "Iteration 2, loss = 1.15325071\n",
      "Iteration 3, loss = 1.13955982\n",
      "Iteration 4, loss = 1.24816499\n",
      "Iteration 5, loss = 1.25518792\n",
      "Iteration 6, loss = 1.25333161\n",
      "Iteration 7, loss = 1.24283930\n",
      "Iteration 8, loss = 1.26719625\n",
      "Iteration 9, loss = 1.25286056\n",
      "Iteration 10, loss = 1.25385581\n",
      "Iteration 11, loss = 1.24317547\n",
      "Iteration 12, loss = 1.25524440\n",
      "Iteration 13, loss = 1.23940178\n",
      "Iteration 14, loss = 1.25194158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14946084\n",
      "Iteration 2, loss = 1.04822968\n",
      "Iteration 3, loss = 1.00266921\n",
      "Iteration 4, loss = 1.06624857\n",
      "Iteration 5, loss = 1.00000169\n",
      "Iteration 6, loss = 1.01114447\n",
      "Iteration 7, loss = 1.00058632\n",
      "Iteration 8, loss = 1.25793556\n",
      "Iteration 9, loss = 1.25286056\n",
      "Iteration 10, loss = 1.25385581\n",
      "Iteration 11, loss = 1.24317547\n",
      "Iteration 12, loss = 1.25524440\n",
      "Iteration 13, loss = 1.23940178\n",
      "Iteration 14, loss = 1.25194158\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.14946084\n",
      "Iteration 2, loss = 1.04822968\n",
      "Iteration 3, loss = 1.00266921\n",
      "Iteration 4, loss = 1.06624857\n",
      "Iteration 5, loss = 1.00000169\n",
      "Iteration 6, loss = 1.01114447\n",
      "Iteration 7, loss = 1.00058632\n",
      "Iteration 8, loss = 1.25793556\n",
      "Iteration 9, loss = 1.24883289\n",
      "Iteration 10, loss = 1.25055700\n",
      "Iteration 11, loss = 1.24927323\n",
      "Iteration 12, loss = 1.26175466\n",
      "Iteration 13, loss = 1.24655138\n",
      "Iteration 14, loss = 1.24952534\n",
      "Iteration 15, loss = 1.25989779\n",
      "Iteration 16, loss = 1.27682401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15671182\n",
      "Iteration 2, loss = 1.11380726\n",
      "Iteration 3, loss = 1.08006235\n",
      "Iteration 4, loss = 1.10713157\n",
      "Iteration 5, loss = 1.03130975\n",
      "Iteration 9, loss = 1.24883289\n",
      "Iteration 10, loss = 1.25055700\n",
      "Iteration 11, loss = 1.24927323\n",
      "Iteration 12, loss = 1.26175466\n",
      "Iteration 13, loss = 1.24655138\n",
      "Iteration 14, loss = 1.24952534\n",
      "Iteration 15, loss = 1.25989779\n",
      "Iteration 16, loss = 1.27682401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15671182\n",
      "Iteration 2, loss = 1.11380726\n",
      "Iteration 3, loss = 1.08006235\n",
      "Iteration 4, loss = 1.10713157\n",
      "Iteration 5, loss = 1.03130975\n",
      "Iteration 6, loss = 0.98350946\n",
      "Iteration 7, loss = 0.96495650\n",
      "Iteration 8, loss = 1.05531894\n",
      "Iteration 9, loss = 1.03299968\n",
      "Iteration 10, loss = 1.03363063\n",
      "Iteration 11, loss = 1.14689244\n",
      "Iteration 12, loss = 1.01462702\n",
      "Iteration 13, loss = 0.99307090\n",
      "Iteration 14, loss = 0.97543153\n",
      "Iteration 15, loss = 0.99596794\n",
      "Iteration 16, loss = 1.00495595\n",
      "Iteration 17, loss = 0.99280389\n",
      "Iteration 18, loss = 1.11469832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19729456\n",
      "Iteration 6, loss = 0.98350946\n",
      "Iteration 7, loss = 0.96495650\n",
      "Iteration 8, loss = 1.05531894\n",
      "Iteration 9, loss = 1.03299968\n",
      "Iteration 10, loss = 1.03363063\n",
      "Iteration 11, loss = 1.14689244\n",
      "Iteration 12, loss = 1.01462702\n",
      "Iteration 13, loss = 0.99307090\n",
      "Iteration 14, loss = 0.97543153\n",
      "Iteration 15, loss = 0.99596794\n",
      "Iteration 16, loss = 1.00495595\n",
      "Iteration 17, loss = 0.99280389\n",
      "Iteration 18, loss = 1.11469832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19729456\n",
      "Iteration 2, loss = 1.08396373\n",
      "Iteration 3, loss = 1.08675731\n",
      "Iteration 4, loss = 1.05970563\n",
      "Iteration 5, loss = 1.08477022\n",
      "Iteration 6, loss = 1.11920541\n",
      "Iteration 7, loss = 1.12133640\n",
      "Iteration 8, loss = 1.09543197\n",
      "Iteration 9, loss = 1.05197242\n",
      "Iteration 10, loss = 1.06720426\n",
      "Iteration 11, loss = 1.07970072\n",
      "Iteration 12, loss = 1.03678600\n",
      "Iteration 13, loss = 1.06733152\n",
      "Iteration 14, loss = 1.02676011\n",
      "Iteration 15, loss = 1.02070949\n",
      "Iteration 2, loss = 1.08396373\n",
      "Iteration 3, loss = 1.08675731\n",
      "Iteration 4, loss = 1.05970563\n",
      "Iteration 5, loss = 1.08477022\n",
      "Iteration 6, loss = 1.11920541\n",
      "Iteration 7, loss = 1.12133640\n",
      "Iteration 8, loss = 1.09543197\n",
      "Iteration 9, loss = 1.05197242\n",
      "Iteration 10, loss = 1.06720426\n",
      "Iteration 11, loss = 1.07970072\n",
      "Iteration 12, loss = 1.03678600\n",
      "Iteration 13, loss = 1.06733152\n",
      "Iteration 14, loss = 1.02676011\n",
      "Iteration 15, loss = 1.02070949\n",
      "Iteration 16, loss = 0.99590955\n",
      "Iteration 17, loss = 0.98343639\n",
      "Iteration 18, loss = 1.02924876\n",
      "Iteration 19, loss = 1.06536425\n",
      "Iteration 20, loss = 1.04445110\n",
      "Iteration 21, loss = 1.08835477\n",
      "Iteration 22, loss = 1.07284002\n",
      "Iteration 23, loss = 1.03945293\n",
      "Iteration 24, loss = 1.05116419\n",
      "Iteration 25, loss = 0.99947671\n",
      "Iteration 26, loss = 1.04703007\n",
      "Iteration 27, loss = 0.99959442\n",
      "Iteration 28, loss = 1.02286495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22289815\n",
      "Iteration 16, loss = 0.99590955\n",
      "Iteration 17, loss = 0.98343639\n",
      "Iteration 18, loss = 1.02924876\n",
      "Iteration 19, loss = 1.06536425\n",
      "Iteration 20, loss = 1.04445110\n",
      "Iteration 21, loss = 1.08835477\n",
      "Iteration 22, loss = 1.07284002\n",
      "Iteration 23, loss = 1.03945293\n",
      "Iteration 24, loss = 1.05116419\n",
      "Iteration 25, loss = 0.99947671\n",
      "Iteration 26, loss = 1.04703007\n",
      "Iteration 27, loss = 0.99959442\n",
      "Iteration 28, loss = 1.02286495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22289815\n",
      "Iteration 2, loss = 1.15595407\n",
      "Iteration 3, loss = 1.11956743\n",
      "Iteration 4, loss = 1.03278354\n",
      "Iteration 5, loss = 1.04034729\n",
      "Iteration 6, loss = 1.06767682\n",
      "Iteration 7, loss = 1.25365323\n",
      "Iteration 8, loss = 1.15869326\n",
      "Iteration 9, loss = 1.07905243\n",
      "Iteration 10, loss = 1.04650975\n",
      "Iteration 11, loss = 1.03287556\n",
      "Iteration 12, loss = 1.00760898\n",
      "Iteration 13, loss = 1.06452796\n",
      "Iteration 2, loss = 1.15595407\n",
      "Iteration 3, loss = 1.11956743\n",
      "Iteration 4, loss = 1.03278354\n",
      "Iteration 5, loss = 1.04034729\n",
      "Iteration 6, loss = 1.06767682\n",
      "Iteration 7, loss = 1.25365323\n",
      "Iteration 8, loss = 1.15869326\n",
      "Iteration 9, loss = 1.07905243\n",
      "Iteration 10, loss = 1.04650975\n",
      "Iteration 11, loss = 1.03287556\n",
      "Iteration 12, loss = 1.00760898\n",
      "Iteration 13, loss = 1.06452796\n",
      "Iteration 14, loss = 1.05740294\n",
      "Iteration 15, loss = 1.02199255\n",
      "Iteration 16, loss = 1.03207705\n",
      "Iteration 17, loss = 1.02831075\n",
      "Iteration 18, loss = 1.04997916\n",
      "Iteration 19, loss = 1.01749737\n",
      "Iteration 20, loss = 0.97992215\n",
      "Iteration 21, loss = 1.01202309\n",
      "Iteration 22, loss = 0.99883750\n",
      "Iteration 23, loss = 1.04465697\n",
      "Iteration 24, loss = 1.00572786\n",
      "Iteration 25, loss = 1.04132975\n",
      "Iteration 26, loss = 1.00917707\n",
      "Iteration 27, loss = 0.98867857\n",
      "Iteration 28, loss = 1.04880269\n",
      "Iteration 14, loss = 1.05740294\n",
      "Iteration 15, loss = 1.02199255\n",
      "Iteration 16, loss = 1.03207705\n",
      "Iteration 17, loss = 1.02831075\n",
      "Iteration 18, loss = 1.04997916\n",
      "Iteration 19, loss = 1.01749737\n",
      "Iteration 20, loss = 0.97992215\n",
      "Iteration 21, loss = 1.01202309\n",
      "Iteration 22, loss = 0.99883750\n",
      "Iteration 23, loss = 1.04465697\n",
      "Iteration 24, loss = 1.00572786\n",
      "Iteration 25, loss = 1.04132975\n",
      "Iteration 26, loss = 1.00917707\n",
      "Iteration 27, loss = 0.98867857\n",
      "Iteration 28, loss = 1.04880269\n",
      "Iteration 29, loss = 1.22467801\n",
      "Iteration 30, loss = 1.08169002\n",
      "Iteration 31, loss = 1.08446253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26420190\n",
      "Iteration 2, loss = 1.16744510\n",
      "Iteration 3, loss = 1.11104519\n",
      "Iteration 4, loss = 1.25664341\n",
      "Iteration 5, loss = 1.22320974\n",
      "Iteration 6, loss = 1.25926769\n",
      "Iteration 7, loss = 1.25145675\n",
      "Iteration 8, loss = 1.28105073\n",
      "Iteration 9, loss = 1.26662093\n",
      "Iteration 29, loss = 1.22467801\n",
      "Iteration 30, loss = 1.08169002\n",
      "Iteration 31, loss = 1.08446253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26420190\n",
      "Iteration 2, loss = 1.16744510\n",
      "Iteration 3, loss = 1.11104519\n",
      "Iteration 4, loss = 1.25664341\n",
      "Iteration 5, loss = 1.22320974\n",
      "Iteration 6, loss = 1.25926769\n",
      "Iteration 7, loss = 1.25145675\n",
      "Iteration 8, loss = 1.28105073\n",
      "Iteration 9, loss = 1.26662093\n",
      "Iteration 10, loss = 1.26381929\n",
      "Iteration 1, loss = 1.11565058\n",
      "Iteration 2, loss = 1.11496195\n",
      "Iteration 3, loss = 1.07962958\n",
      "Iteration 4, loss = 1.13810711\n",
      "Iteration 5, loss = 1.03546167\n",
      "Iteration 6, loss = 1.06477224\n",
      "Iteration 7, loss = 1.16621837\n",
      "Iteration 8, loss = 1.27615638\n",
      "Iteration 9, loss = 1.25157512\n",
      "Iteration 10, loss = 1.25228835\n",
      "Iteration 1, loss = 1.25809251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.26381929\n",
      "Iteration 1, loss = 1.11565058\n",
      "Iteration 2, loss = 1.11496195\n",
      "Iteration 3, loss = 1.07962958\n",
      "Iteration 4, loss = 1.13810711\n",
      "Iteration 5, loss = 1.03546167\n",
      "Iteration 6, loss = 1.06477224\n",
      "Iteration 7, loss = 1.16621837\n",
      "Iteration 8, loss = 1.27615638\n",
      "Iteration 9, loss = 1.25157512\n",
      "Iteration 10, loss = 1.25228835\n",
      "Iteration 1, loss = 1.25809251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.28768807\n",
      "Iteration 3, loss = 1.28239582\n",
      "Iteration 4, loss = 1.28448187\n",
      "Iteration 5, loss = 1.25882410\n",
      "Iteration 6, loss = 1.26986639\n",
      "Iteration 7, loss = 1.27431709\n",
      "Iteration 8, loss = 1.27490949\n",
      "Iteration 9, loss = 1.27227529\n",
      "Iteration 10, loss = 1.27036707\n",
      "Iteration 1, loss = 1.23555453\n",
      "Iteration 2, loss = 1.15772116\n",
      "Iteration 3, loss = 1.12789875\n",
      "Iteration 4, loss = 1.09077005\n",
      "Iteration 2, loss = 1.28768807\n",
      "Iteration 3, loss = 1.28239582\n",
      "Iteration 4, loss = 1.28448187\n",
      "Iteration 5, loss = 1.25882410\n",
      "Iteration 6, loss = 1.26986639\n",
      "Iteration 7, loss = 1.27431709\n",
      "Iteration 8, loss = 1.27490949\n",
      "Iteration 9, loss = 1.27227529\n",
      "Iteration 10, loss = 1.27036707\n",
      "Iteration 1, loss = 1.23555453\n",
      "Iteration 2, loss = 1.15772116\n",
      "Iteration 3, loss = 1.12789875\n",
      "Iteration 4, loss = 1.09077005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.11571427\n",
      "Iteration 6, loss = 1.21560564\n",
      "Iteration 7, loss = 1.27471575\n",
      "Iteration 8, loss = 1.29054172\n",
      "Iteration 9, loss = 1.25352168\n",
      "Iteration 10, loss = 1.26276565\n",
      "Iteration 1, loss = 1.26362548\n",
      "Iteration 2, loss = 1.13468612\n",
      "Iteration 3, loss = 1.27658381\n",
      "Iteration 4, loss = 1.26848167\n",
      "Iteration 5, loss = 1.27966802\n",
      "Iteration 6, loss = 1.27320736\n",
      "Iteration 7, loss = 1.26520714\n",
      "Iteration 5, loss = 1.11571427\n",
      "Iteration 6, loss = 1.21560564\n",
      "Iteration 7, loss = 1.27471575\n",
      "Iteration 8, loss = 1.29054172\n",
      "Iteration 9, loss = 1.25352168\n",
      "Iteration 10, loss = 1.26276565\n",
      "Iteration 1, loss = 1.26362548\n",
      "Iteration 2, loss = 1.13468612\n",
      "Iteration 3, loss = 1.27658381\n",
      "Iteration 4, loss = 1.26848167\n",
      "Iteration 5, loss = 1.27966802\n",
      "Iteration 6, loss = 1.27320736\n",
      "Iteration 7, loss = 1.26520714\n",
      "Iteration 8, loss = 1.28830256\n",
      "Iteration 9, loss = 1.25679058\n",
      "Iteration 10, loss = 1.27814126\n",
      "Iteration 1, loss = 1.26420190\n",
      "Iteration 2, loss = 1.16744510\n",
      "Iteration 3, loss = 1.11104519\n",
      "Iteration 4, loss = 1.25664341\n",
      "Iteration 5, loss = 1.22320974\n",
      "Iteration 6, loss = 1.25926769\n",
      "Iteration 7, loss = 1.25145675\n",
      "Iteration 8, loss = 1.28105073\n",
      "Iteration 9, loss = 1.26662093\n",
      "Iteration 8, loss = 1.28830256\n",
      "Iteration 9, loss = 1.25679058\n",
      "Iteration 10, loss = 1.27814126\n",
      "Iteration 1, loss = 1.26420190\n",
      "Iteration 2, loss = 1.16744510\n",
      "Iteration 3, loss = 1.11104519\n",
      "Iteration 4, loss = 1.25664341\n",
      "Iteration 5, loss = 1.22320974\n",
      "Iteration 6, loss = 1.25926769\n",
      "Iteration 7, loss = 1.25145675\n",
      "Iteration 8, loss = 1.28105073\n",
      "Iteration 9, loss = 1.26662093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.26381929\n",
      "Iteration 11, loss = 1.25516235\n",
      "Iteration 12, loss = 1.26920589\n",
      "Iteration 13, loss = 1.24825895\n",
      "Iteration 14, loss = 1.26505668\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11565058\n",
      "Iteration 2, loss = 1.11496195\n",
      "Iteration 3, loss = 1.07962958\n",
      "Iteration 4, loss = 1.13810711\n",
      "Iteration 5, loss = 1.03546167\n",
      "Iteration 6, loss = 1.06477224\n",
      "Iteration 7, loss = 1.16621837\n",
      "Iteration 10, loss = 1.26381929\n",
      "Iteration 11, loss = 1.25516235\n",
      "Iteration 12, loss = 1.26920589\n",
      "Iteration 13, loss = 1.24825895\n",
      "Iteration 14, loss = 1.26505668\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11565058\n",
      "Iteration 2, loss = 1.11496195\n",
      "Iteration 3, loss = 1.07962958\n",
      "Iteration 4, loss = 1.13810711\n",
      "Iteration 5, loss = 1.03546167\n",
      "Iteration 6, loss = 1.06477224\n",
      "Iteration 7, loss = 1.16621837\n",
      "Iteration 8, loss = 1.27615638\n",
      "Iteration 9, loss = 1.25157512\n",
      "Iteration 10, loss = 1.25228835\n",
      "Iteration 11, loss = 1.24561211\n",
      "Iteration 12, loss = 1.27018016\n",
      "Iteration 13, loss = 1.25196042\n",
      "Iteration 14, loss = 1.25605662\n",
      "Iteration 15, loss = 1.26855384\n",
      "Iteration 16, loss = 1.27996810\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25809251\n",
      "Iteration 2, loss = 1.28768807\n",
      "Iteration 3, loss = 1.28239582\n",
      "Iteration 4, loss = 1.28448187\n",
      "Iteration 8, loss = 1.27615638\n",
      "Iteration 9, loss = 1.25157512\n",
      "Iteration 10, loss = 1.25228835\n",
      "Iteration 11, loss = 1.24561211\n",
      "Iteration 12, loss = 1.27018016\n",
      "Iteration 13, loss = 1.25196042\n",
      "Iteration 14, loss = 1.25605662\n",
      "Iteration 15, loss = 1.26855384\n",
      "Iteration 16, loss = 1.27996810\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25809251\n",
      "Iteration 2, loss = 1.28768807\n",
      "Iteration 3, loss = 1.28239582\n",
      "Iteration 4, loss = 1.28448187\n",
      "Iteration 5, loss = 1.25882410\n",
      "Iteration 6, loss = 1.26986639\n",
      "Iteration 7, loss = 1.27431709\n",
      "Iteration 8, loss = 1.27490949\n",
      "Iteration 9, loss = 1.27227529\n",
      "Iteration 10, loss = 1.27036707\n",
      "Iteration 11, loss = 1.28527976\n",
      "Iteration 12, loss = 1.27282842\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23555453\n",
      "Iteration 2, loss = 1.15772116\n",
      "Iteration 3, loss = 1.12789875\n",
      "Iteration 4, loss = 1.09077005\n",
      "Iteration 5, loss = 1.25882410\n",
      "Iteration 6, loss = 1.26986639\n",
      "Iteration 7, loss = 1.27431709\n",
      "Iteration 8, loss = 1.27490949\n",
      "Iteration 9, loss = 1.27227529\n",
      "Iteration 10, loss = 1.27036707\n",
      "Iteration 11, loss = 1.28527976\n",
      "Iteration 12, loss = 1.27282842\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23555453\n",
      "Iteration 2, loss = 1.15772116\n",
      "Iteration 3, loss = 1.12789875\n",
      "Iteration 4, loss = 1.09077005\n",
      "Iteration 5, loss = 1.11571427\n",
      "Iteration 6, loss = 1.21560564\n",
      "Iteration 7, loss = 1.27471575\n",
      "Iteration 8, loss = 1.29054172\n",
      "Iteration 9, loss = 1.25352168\n",
      "Iteration 10, loss = 1.26276565\n",
      "Iteration 11, loss = 1.26057114\n",
      "Iteration 12, loss = 1.27478469\n",
      "Iteration 13, loss = 1.28166463\n",
      "Iteration 14, loss = 1.25509304\n",
      "Iteration 15, loss = 1.25646957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26362548\n",
      "Iteration 2, loss = 1.13468612\n",
      "Iteration 5, loss = 1.11571427\n",
      "Iteration 6, loss = 1.21560564\n",
      "Iteration 7, loss = 1.27471575\n",
      "Iteration 8, loss = 1.29054172\n",
      "Iteration 9, loss = 1.25352168\n",
      "Iteration 10, loss = 1.26276565\n",
      "Iteration 11, loss = 1.26057114\n",
      "Iteration 12, loss = 1.27478469\n",
      "Iteration 13, loss = 1.28166463\n",
      "Iteration 14, loss = 1.25509304\n",
      "Iteration 15, loss = 1.25646957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26362548\n",
      "Iteration 2, loss = 1.13468612\n",
      "Iteration 3, loss = 1.27658381\n",
      "Iteration 4, loss = 1.26848167\n",
      "Iteration 5, loss = 1.27966802\n",
      "Iteration 6, loss = 1.27320736\n",
      "Iteration 7, loss = 1.26520714\n",
      "Iteration 8, loss = 1.28830256\n",
      "Iteration 9, loss = 1.25679058\n",
      "Iteration 10, loss = 1.27814126\n",
      "Iteration 11, loss = 1.26640002\n",
      "Iteration 12, loss = 1.29997802\n",
      "Iteration 13, loss = 1.28642380\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26420190\n",
      "Iteration 2, loss = 1.16744510\n",
      "Iteration 3, loss = 1.27658381\n",
      "Iteration 4, loss = 1.26848167\n",
      "Iteration 5, loss = 1.27966802\n",
      "Iteration 6, loss = 1.27320736\n",
      "Iteration 7, loss = 1.26520714\n",
      "Iteration 8, loss = 1.28830256\n",
      "Iteration 9, loss = 1.25679058\n",
      "Iteration 10, loss = 1.27814126\n",
      "Iteration 11, loss = 1.26640002\n",
      "Iteration 12, loss = 1.29997802\n",
      "Iteration 13, loss = 1.28642380\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26420190\n",
      "Iteration 2, loss = 1.16744510\n",
      "Iteration 3, loss = 1.11104519\n",
      "Iteration 4, loss = 1.25664341\n",
      "Iteration 5, loss = 1.22320974\n",
      "Iteration 6, loss = 1.25926769\n",
      "Iteration 7, loss = 1.25145675\n",
      "Iteration 8, loss = 1.28105073\n",
      "Iteration 9, loss = 1.26662093\n",
      "Iteration 10, loss = 1.26381929\n",
      "Iteration 11, loss = 1.25516235\n",
      "Iteration 12, loss = 1.26920589\n",
      "Iteration 13, loss = 1.24825895\n",
      "Iteration 14, loss = 1.26505668\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11565058\n",
      "Iteration 3, loss = 1.11104519\n",
      "Iteration 4, loss = 1.25664341\n",
      "Iteration 5, loss = 1.22320974\n",
      "Iteration 6, loss = 1.25926769\n",
      "Iteration 7, loss = 1.25145675\n",
      "Iteration 8, loss = 1.28105073\n",
      "Iteration 9, loss = 1.26662093\n",
      "Iteration 10, loss = 1.26381929\n",
      "Iteration 11, loss = 1.25516235\n",
      "Iteration 12, loss = 1.26920589\n",
      "Iteration 13, loss = 1.24825895\n",
      "Iteration 14, loss = 1.26505668\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.11565058\n",
      "Iteration 2, loss = 1.11496195\n",
      "Iteration 3, loss = 1.07962958\n",
      "Iteration 4, loss = 1.13810711\n",
      "Iteration 5, loss = 1.03546167\n",
      "Iteration 6, loss = 1.06477224\n",
      "Iteration 7, loss = 1.16621837\n",
      "Iteration 8, loss = 1.27615638\n",
      "Iteration 9, loss = 1.25157512\n",
      "Iteration 10, loss = 1.25228835\n",
      "Iteration 11, loss = 1.24561211\n",
      "Iteration 12, loss = 1.27018016\n",
      "Iteration 13, loss = 1.25196042\n",
      "Iteration 14, loss = 1.25605662\n",
      "Iteration 15, loss = 1.26855384\n",
      "Iteration 16, loss = 1.27996810\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 1.11496195\n",
      "Iteration 3, loss = 1.07962958\n",
      "Iteration 4, loss = 1.13810711\n",
      "Iteration 5, loss = 1.03546167\n",
      "Iteration 6, loss = 1.06477224\n",
      "Iteration 7, loss = 1.16621837\n",
      "Iteration 8, loss = 1.27615638\n",
      "Iteration 9, loss = 1.25157512\n",
      "Iteration 10, loss = 1.25228835\n",
      "Iteration 11, loss = 1.24561211\n",
      "Iteration 12, loss = 1.27018016\n",
      "Iteration 13, loss = 1.25196042\n",
      "Iteration 14, loss = 1.25605662\n",
      "Iteration 15, loss = 1.26855384\n",
      "Iteration 16, loss = 1.27996810\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25809251\n",
      "Iteration 2, loss = 1.28768807\n",
      "Iteration 3, loss = 1.28239582\n",
      "Iteration 4, loss = 1.28448187\n",
      "Iteration 5, loss = 1.25882410\n",
      "Iteration 6, loss = 1.26986639\n",
      "Iteration 7, loss = 1.27431709\n",
      "Iteration 8, loss = 1.27490949\n",
      "Iteration 9, loss = 1.27227529\n",
      "Iteration 10, loss = 1.27036707\n",
      "Iteration 11, loss = 1.28527976\n",
      "Iteration 12, loss = 1.27282842\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23555453\n",
      "Iteration 1, loss = 1.25809251\n",
      "Iteration 2, loss = 1.28768807\n",
      "Iteration 3, loss = 1.28239582\n",
      "Iteration 4, loss = 1.28448187\n",
      "Iteration 5, loss = 1.25882410\n",
      "Iteration 6, loss = 1.26986639\n",
      "Iteration 7, loss = 1.27431709\n",
      "Iteration 8, loss = 1.27490949\n",
      "Iteration 9, loss = 1.27227529\n",
      "Iteration 10, loss = 1.27036707\n",
      "Iteration 11, loss = 1.28527976\n",
      "Iteration 12, loss = 1.27282842\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23555453\n",
      "Iteration 2, loss = 1.15772116\n",
      "Iteration 3, loss = 1.12789875\n",
      "Iteration 4, loss = 1.09077005\n",
      "Iteration 5, loss = 1.11571427\n",
      "Iteration 6, loss = 1.21560564\n",
      "Iteration 7, loss = 1.27471575\n",
      "Iteration 8, loss = 1.29054172\n",
      "Iteration 9, loss = 1.25352168\n",
      "Iteration 10, loss = 1.26276565\n",
      "Iteration 11, loss = 1.26057114\n",
      "Iteration 12, loss = 1.27478469\n",
      "Iteration 13, loss = 1.28166463\n",
      "Iteration 2, loss = 1.15772116\n",
      "Iteration 3, loss = 1.12789875\n",
      "Iteration 4, loss = 1.09077005\n",
      "Iteration 5, loss = 1.11571427\n",
      "Iteration 6, loss = 1.21560564\n",
      "Iteration 7, loss = 1.27471575\n",
      "Iteration 8, loss = 1.29054172\n",
      "Iteration 9, loss = 1.25352168\n",
      "Iteration 10, loss = 1.26276565\n",
      "Iteration 11, loss = 1.26057114\n",
      "Iteration 12, loss = 1.27478469\n",
      "Iteration 13, loss = 1.28166463\n",
      "Iteration 14, loss = 1.25509304\n",
      "Iteration 15, loss = 1.25646957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26362548\n",
      "Iteration 2, loss = 1.13468612\n",
      "Iteration 3, loss = 1.27658381\n",
      "Iteration 4, loss = 1.26848167\n",
      "Iteration 5, loss = 1.27966802\n",
      "Iteration 6, loss = 1.27320736\n",
      "Iteration 7, loss = 1.26520714\n",
      "Iteration 8, loss = 1.28830256\n",
      "Iteration 9, loss = 1.25679058\n",
      "Iteration 10, loss = 1.27814126\n",
      "Iteration 11, loss = 1.26640002\n",
      "Iteration 14, loss = 1.25509304\n",
      "Iteration 15, loss = 1.25646957\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26362548\n",
      "Iteration 2, loss = 1.13468612\n",
      "Iteration 3, loss = 1.27658381\n",
      "Iteration 4, loss = 1.26848167\n",
      "Iteration 5, loss = 1.27966802\n",
      "Iteration 6, loss = 1.27320736\n",
      "Iteration 7, loss = 1.26520714\n",
      "Iteration 8, loss = 1.28830256\n",
      "Iteration 9, loss = 1.25679058\n",
      "Iteration 10, loss = 1.27814126\n",
      "Iteration 11, loss = 1.26640002\n",
      "Iteration 12, loss = 1.29997802\n",
      "Iteration 13, loss = 1.28642380\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24276304\n",
      "Iteration 2, loss = 1.09196289\n",
      "Iteration 3, loss = 1.01362661\n",
      "Iteration 4, loss = 0.97067710\n",
      "Iteration 5, loss = 0.98076333\n",
      "Iteration 6, loss = 0.98430130\n",
      "Iteration 7, loss = 0.97436685\n",
      "Iteration 8, loss = 0.95273224\n",
      "Iteration 9, loss = 0.94536403\n",
      "Iteration 12, loss = 1.29997802\n",
      "Iteration 13, loss = 1.28642380\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24276304\n",
      "Iteration 2, loss = 1.09196289\n",
      "Iteration 3, loss = 1.01362661\n",
      "Iteration 4, loss = 0.97067710\n",
      "Iteration 5, loss = 0.98076333\n",
      "Iteration 6, loss = 0.98430130\n",
      "Iteration 7, loss = 0.97436685\n",
      "Iteration 8, loss = 0.95273224\n",
      "Iteration 9, loss = 0.94536403\n",
      "Iteration 10, loss = 0.96828166\n",
      "Iteration 1, loss = 1.18302025\n",
      "Iteration 2, loss = 1.02082657\n",
      "Iteration 3, loss = 0.93895258\n",
      "Iteration 4, loss = 0.96206459\n",
      "Iteration 5, loss = 0.91627128\n",
      "Iteration 6, loss = 0.94189897\n",
      "Iteration 7, loss = 0.91963245\n",
      "Iteration 8, loss = 0.91634747\n",
      "Iteration 9, loss = 0.96970441\n",
      "Iteration 10, loss = 0.90041385\n",
      "Iteration 1, loss = 1.21944099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.96828166\n",
      "Iteration 1, loss = 1.18302025\n",
      "Iteration 2, loss = 1.02082657\n",
      "Iteration 3, loss = 0.93895258\n",
      "Iteration 4, loss = 0.96206459\n",
      "Iteration 5, loss = 0.91627128\n",
      "Iteration 6, loss = 0.94189897\n",
      "Iteration 7, loss = 0.91963245\n",
      "Iteration 8, loss = 0.91634747\n",
      "Iteration 9, loss = 0.96970441\n",
      "Iteration 10, loss = 0.90041385\n",
      "Iteration 1, loss = 1.21944099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.09436816\n",
      "Iteration 3, loss = 1.00977978\n",
      "Iteration 4, loss = 0.96212303\n",
      "Iteration 5, loss = 0.99170522\n",
      "Iteration 6, loss = 0.97263312\n",
      "Iteration 7, loss = 0.95093992\n",
      "Iteration 8, loss = 0.95896110\n",
      "Iteration 9, loss = 0.91442974\n",
      "Iteration 10, loss = 0.93765942\n",
      "Iteration 1, loss = 1.24894413\n",
      "Iteration 2, loss = 1.11679221\n",
      "Iteration 3, loss = 0.99595341\n",
      "Iteration 4, loss = 1.02081750\n",
      "Iteration 2, loss = 1.09436816\n",
      "Iteration 3, loss = 1.00977978\n",
      "Iteration 4, loss = 0.96212303\n",
      "Iteration 5, loss = 0.99170522\n",
      "Iteration 6, loss = 0.97263312\n",
      "Iteration 7, loss = 0.95093992\n",
      "Iteration 8, loss = 0.95896110\n",
      "Iteration 9, loss = 0.91442974\n",
      "Iteration 10, loss = 0.93765942\n",
      "Iteration 1, loss = 1.24894413\n",
      "Iteration 2, loss = 1.11679221\n",
      "Iteration 3, loss = 0.99595341\n",
      "Iteration 4, loss = 1.02081750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.00730691\n",
      "Iteration 6, loss = 0.98779343\n",
      "Iteration 7, loss = 0.95889833\n",
      "Iteration 8, loss = 0.96897503\n",
      "Iteration 9, loss = 0.94436148\n",
      "Iteration 10, loss = 0.95453579\n",
      "Iteration 1, loss = 1.24995458\n",
      "Iteration 2, loss = 1.09945718\n",
      "Iteration 3, loss = 1.00512634\n",
      "Iteration 4, loss = 0.97215345\n",
      "Iteration 5, loss = 1.01803173\n",
      "Iteration 6, loss = 0.93854851\n",
      "Iteration 7, loss = 0.96332537\n",
      "Iteration 5, loss = 1.00730691\n",
      "Iteration 6, loss = 0.98779343\n",
      "Iteration 7, loss = 0.95889833\n",
      "Iteration 8, loss = 0.96897503\n",
      "Iteration 9, loss = 0.94436148\n",
      "Iteration 10, loss = 0.95453579\n",
      "Iteration 1, loss = 1.24995458\n",
      "Iteration 2, loss = 1.09945718\n",
      "Iteration 3, loss = 1.00512634\n",
      "Iteration 4, loss = 0.97215345\n",
      "Iteration 5, loss = 1.01803173\n",
      "Iteration 6, loss = 0.93854851\n",
      "Iteration 7, loss = 0.96332537\n",
      "Iteration 8, loss = 0.97449717\n",
      "Iteration 9, loss = 0.95301786\n",
      "Iteration 10, loss = 1.01873419\n",
      "Iteration 1, loss = 1.24276304\n",
      "Iteration 2, loss = 1.09196289\n",
      "Iteration 3, loss = 1.01362661\n",
      "Iteration 4, loss = 0.97067710\n",
      "Iteration 5, loss = 0.98076333\n",
      "Iteration 6, loss = 0.98430130\n",
      "Iteration 7, loss = 0.97436685\n",
      "Iteration 8, loss = 0.95273224\n",
      "Iteration 9, loss = 0.94536403\n",
      "Iteration 10, loss = 0.96828166\n",
      "Iteration 8, loss = 0.97449717\n",
      "Iteration 9, loss = 0.95301786\n",
      "Iteration 10, loss = 1.01873419\n",
      "Iteration 1, loss = 1.24276304\n",
      "Iteration 2, loss = 1.09196289\n",
      "Iteration 3, loss = 1.01362661\n",
      "Iteration 4, loss = 0.97067710\n",
      "Iteration 5, loss = 0.98076333\n",
      "Iteration 6, loss = 0.98430130\n",
      "Iteration 7, loss = 0.97436685\n",
      "Iteration 8, loss = 0.95273224\n",
      "Iteration 9, loss = 0.94536403\n",
      "Iteration 10, loss = 0.96828166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.94075931\n",
      "Iteration 12, loss = 0.92456246\n",
      "Iteration 13, loss = 0.92317211\n",
      "Iteration 14, loss = 0.92915519\n",
      "Iteration 15, loss = 0.95279385\n",
      "Iteration 16, loss = 0.92455546\n",
      "Iteration 17, loss = 0.92139918\n",
      "Iteration 18, loss = 0.90884001\n",
      "Iteration 19, loss = 0.90611228\n",
      "Iteration 20, loss = 0.89524877\n",
      "Iteration 21, loss = 0.89210578\n",
      "Iteration 22, loss = 0.88790083\n",
      "Iteration 23, loss = 0.87335744\n",
      "Iteration 24, loss = 0.87860654\n",
      "Iteration 11, loss = 0.94075931\n",
      "Iteration 12, loss = 0.92456246\n",
      "Iteration 13, loss = 0.92317211\n",
      "Iteration 14, loss = 0.92915519\n",
      "Iteration 15, loss = 0.95279385\n",
      "Iteration 16, loss = 0.92455546\n",
      "Iteration 17, loss = 0.92139918\n",
      "Iteration 18, loss = 0.90884001\n",
      "Iteration 19, loss = 0.90611228\n",
      "Iteration 20, loss = 0.89524877\n",
      "Iteration 21, loss = 0.89210578\n",
      "Iteration 22, loss = 0.88790083\n",
      "Iteration 23, loss = 0.87335744\n",
      "Iteration 24, loss = 0.87860654\n",
      "Iteration 25, loss = 0.85510696\n",
      "Iteration 26, loss = 0.95678223\n",
      "Iteration 27, loss = 0.90876046\n",
      "Iteration 28, loss = 0.85431692\n",
      "Iteration 29, loss = 0.86013611\n",
      "Iteration 30, loss = 0.84976114\n",
      "Iteration 31, loss = 0.84030566\n",
      "Iteration 32, loss = 0.83341727\n",
      "Iteration 33, loss = 0.87199303\n",
      "Iteration 34, loss = 0.86778397\n",
      "Iteration 35, loss = 0.84360600\n",
      "Iteration 36, loss = 0.81888832\n",
      "Iteration 37, loss = 0.82396951\n",
      "Iteration 38, loss = 0.83234725\n",
      "Iteration 39, loss = 0.83132377\n",
      "Iteration 25, loss = 0.85510696\n",
      "Iteration 26, loss = 0.95678223\n",
      "Iteration 27, loss = 0.90876046\n",
      "Iteration 28, loss = 0.85431692\n",
      "Iteration 29, loss = 0.86013611\n",
      "Iteration 30, loss = 0.84976114\n",
      "Iteration 31, loss = 0.84030566\n",
      "Iteration 32, loss = 0.83341727\n",
      "Iteration 33, loss = 0.87199303\n",
      "Iteration 34, loss = 0.86778397\n",
      "Iteration 35, loss = 0.84360600\n",
      "Iteration 36, loss = 0.81888832\n",
      "Iteration 37, loss = 0.82396951\n",
      "Iteration 38, loss = 0.83234725\n",
      "Iteration 39, loss = 0.83132377\n",
      "Iteration 40, loss = 0.82103500\n",
      "Iteration 41, loss = 0.77907821\n",
      "Iteration 42, loss = 0.79589334\n",
      "Iteration 43, loss = 0.79322831\n",
      "Iteration 44, loss = 0.78083791\n",
      "Iteration 45, loss = 0.79725962\n",
      "Iteration 46, loss = 0.80872165\n",
      "Iteration 47, loss = 0.77549995\n",
      "Iteration 48, loss = 0.82690400\n",
      "Iteration 49, loss = 0.80613994\n",
      "Iteration 50, loss = 0.75474906\n",
      "Iteration 1, loss = 1.18302025\n",
      "Iteration 2, loss = 1.02082657\n",
      "Iteration 3, loss = 0.93895258\n",
      "Iteration 40, loss = 0.82103500\n",
      "Iteration 41, loss = 0.77907821\n",
      "Iteration 42, loss = 0.79589334\n",
      "Iteration 43, loss = 0.79322831\n",
      "Iteration 44, loss = 0.78083791\n",
      "Iteration 45, loss = 0.79725962\n",
      "Iteration 46, loss = 0.80872165\n",
      "Iteration 47, loss = 0.77549995\n",
      "Iteration 48, loss = 0.82690400\n",
      "Iteration 49, loss = 0.80613994\n",
      "Iteration 50, loss = 0.75474906\n",
      "Iteration 1, loss = 1.18302025\n",
      "Iteration 2, loss = 1.02082657\n",
      "Iteration 3, loss = 0.93895258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.96206459\n",
      "Iteration 5, loss = 0.91627128\n",
      "Iteration 6, loss = 0.94189897\n",
      "Iteration 7, loss = 0.91963245\n",
      "Iteration 8, loss = 0.91634747\n",
      "Iteration 9, loss = 0.96970441\n",
      "Iteration 10, loss = 0.90041385\n",
      "Iteration 11, loss = 0.89851128\n",
      "Iteration 12, loss = 0.88213448\n",
      "Iteration 13, loss = 0.93865045\n",
      "Iteration 14, loss = 0.89244079\n",
      "Iteration 15, loss = 0.89727380\n",
      "Iteration 16, loss = 0.89046329\n",
      "Iteration 4, loss = 0.96206459\n",
      "Iteration 5, loss = 0.91627128\n",
      "Iteration 6, loss = 0.94189897\n",
      "Iteration 7, loss = 0.91963245\n",
      "Iteration 8, loss = 0.91634747\n",
      "Iteration 9, loss = 0.96970441\n",
      "Iteration 10, loss = 0.90041385\n",
      "Iteration 11, loss = 0.89851128\n",
      "Iteration 12, loss = 0.88213448\n",
      "Iteration 13, loss = 0.93865045\n",
      "Iteration 14, loss = 0.89244079\n",
      "Iteration 15, loss = 0.89727380\n",
      "Iteration 16, loss = 0.89046329\n",
      "Iteration 17, loss = 0.85655811\n",
      "Iteration 18, loss = 0.87838120\n",
      "Iteration 19, loss = 0.88526262\n",
      "Iteration 20, loss = 0.88872292\n",
      "Iteration 21, loss = 0.87977228\n",
      "Iteration 22, loss = 0.87202507\n",
      "Iteration 23, loss = 0.86209515\n",
      "Iteration 24, loss = 0.84794301\n",
      "Iteration 25, loss = 0.84477994\n",
      "Iteration 26, loss = 0.82479119\n",
      "Iteration 27, loss = 0.84520994\n",
      "Iteration 28, loss = 0.80602000\n",
      "Iteration 29, loss = 0.81913045\n",
      "Iteration 30, loss = 0.77878949\n",
      "Iteration 17, loss = 0.85655811\n",
      "Iteration 18, loss = 0.87838120\n",
      "Iteration 19, loss = 0.88526262\n",
      "Iteration 20, loss = 0.88872292\n",
      "Iteration 21, loss = 0.87977228\n",
      "Iteration 22, loss = 0.87202507\n",
      "Iteration 23, loss = 0.86209515\n",
      "Iteration 24, loss = 0.84794301\n",
      "Iteration 25, loss = 0.84477994\n",
      "Iteration 26, loss = 0.82479119\n",
      "Iteration 27, loss = 0.84520994\n",
      "Iteration 28, loss = 0.80602000\n",
      "Iteration 29, loss = 0.81913045\n",
      "Iteration 30, loss = 0.77878949\n",
      "Iteration 31, loss = 0.79008673\n",
      "Iteration 32, loss = 0.84015925\n",
      "Iteration 33, loss = 0.79876297\n",
      "Iteration 34, loss = 0.84091702\n",
      "Iteration 35, loss = 0.81332428\n",
      "Iteration 36, loss = 0.78413947\n",
      "Iteration 37, loss = 0.80944459\n",
      "Iteration 38, loss = 0.78683100\n",
      "Iteration 39, loss = 0.77028919\n",
      "Iteration 40, loss = 0.77259885\n",
      "Iteration 41, loss = 0.78330203\n",
      "Iteration 42, loss = 0.77675556\n",
      "Iteration 43, loss = 0.77664263\n",
      "Iteration 44, loss = 0.77643149\n",
      "Iteration 31, loss = 0.79008673\n",
      "Iteration 32, loss = 0.84015925\n",
      "Iteration 33, loss = 0.79876297\n",
      "Iteration 34, loss = 0.84091702\n",
      "Iteration 35, loss = 0.81332428\n",
      "Iteration 36, loss = 0.78413947\n",
      "Iteration 37, loss = 0.80944459\n",
      "Iteration 38, loss = 0.78683100\n",
      "Iteration 39, loss = 0.77028919\n",
      "Iteration 40, loss = 0.77259885\n",
      "Iteration 41, loss = 0.78330203\n",
      "Iteration 42, loss = 0.77675556\n",
      "Iteration 43, loss = 0.77664263\n",
      "Iteration 44, loss = 0.77643149\n",
      "Iteration 45, loss = 0.77205228\n",
      "Iteration 46, loss = 0.75800348\n",
      "Iteration 47, loss = 0.76967306\n",
      "Iteration 48, loss = 0.80195917\n",
      "Iteration 49, loss = 0.75291240\n",
      "Iteration 50, loss = 0.76450413\n",
      "Iteration 1, loss = 1.21944099\n",
      "Iteration 2, loss = 1.09436816\n",
      "Iteration 3, loss = 1.00977978\n",
      "Iteration 4, loss = 0.96212303\n",
      "Iteration 5, loss = 0.99170522\n",
      "Iteration 6, loss = 0.97263312\n",
      "Iteration 7, loss = 0.95093992\n",
      "Iteration 8, loss = 0.95896110\n",
      "Iteration 45, loss = 0.77205228\n",
      "Iteration 46, loss = 0.75800348\n",
      "Iteration 47, loss = 0.76967306\n",
      "Iteration 48, loss = 0.80195917\n",
      "Iteration 49, loss = 0.75291240\n",
      "Iteration 50, loss = 0.76450413\n",
      "Iteration 1, loss = 1.21944099\n",
      "Iteration 2, loss = 1.09436816\n",
      "Iteration 3, loss = 1.00977978\n",
      "Iteration 4, loss = 0.96212303\n",
      "Iteration 5, loss = 0.99170522\n",
      "Iteration 6, loss = 0.97263312\n",
      "Iteration 7, loss = 0.95093992\n",
      "Iteration 8, loss = 0.95896110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.91442974\n",
      "Iteration 10, loss = 0.93765942\n",
      "Iteration 11, loss = 0.92025360\n",
      "Iteration 12, loss = 0.97530460\n",
      "Iteration 13, loss = 0.92402404\n",
      "Iteration 14, loss = 0.90481097\n",
      "Iteration 15, loss = 0.94038199\n",
      "Iteration 16, loss = 0.91506773\n",
      "Iteration 17, loss = 0.90279489\n",
      "Iteration 18, loss = 0.96139356\n",
      "Iteration 19, loss = 0.94485902\n",
      "Iteration 20, loss = 0.90990588\n",
      "Iteration 21, loss = 0.89838170\n",
      "Iteration 22, loss = 0.89858915\n",
      "Iteration 23, loss = 0.89820850\n",
      "Iteration 9, loss = 0.91442974\n",
      "Iteration 10, loss = 0.93765942\n",
      "Iteration 11, loss = 0.92025360\n",
      "Iteration 12, loss = 0.97530460\n",
      "Iteration 13, loss = 0.92402404\n",
      "Iteration 14, loss = 0.90481097\n",
      "Iteration 15, loss = 0.94038199\n",
      "Iteration 16, loss = 0.91506773\n",
      "Iteration 17, loss = 0.90279489\n",
      "Iteration 18, loss = 0.96139356\n",
      "Iteration 19, loss = 0.94485902\n",
      "Iteration 20, loss = 0.90990588\n",
      "Iteration 21, loss = 0.89838170\n",
      "Iteration 22, loss = 0.89858915\n",
      "Iteration 23, loss = 0.89820850\n",
      "Iteration 24, loss = 0.87988333\n",
      "Iteration 25, loss = 0.89830948\n",
      "Iteration 26, loss = 0.87711910\n",
      "Iteration 27, loss = 0.88150555\n",
      "Iteration 28, loss = 0.87814295\n",
      "Iteration 29, loss = 0.85622230\n",
      "Iteration 30, loss = 0.85461566\n",
      "Iteration 31, loss = 0.89761459\n",
      "Iteration 32, loss = 0.89934060\n",
      "Iteration 33, loss = 0.86640487\n",
      "Iteration 34, loss = 0.88280615\n",
      "Iteration 35, loss = 0.87798115\n",
      "Iteration 36, loss = 0.88443756\n",
      "Iteration 37, loss = 0.82722457\n",
      "Iteration 38, loss = 0.86845173\n",
      "Iteration 24, loss = 0.87988333\n",
      "Iteration 25, loss = 0.89830948\n",
      "Iteration 26, loss = 0.87711910\n",
      "Iteration 27, loss = 0.88150555\n",
      "Iteration 28, loss = 0.87814295\n",
      "Iteration 29, loss = 0.85622230\n",
      "Iteration 30, loss = 0.85461566\n",
      "Iteration 31, loss = 0.89761459\n",
      "Iteration 32, loss = 0.89934060\n",
      "Iteration 33, loss = 0.86640487\n",
      "Iteration 34, loss = 0.88280615\n",
      "Iteration 35, loss = 0.87798115\n",
      "Iteration 36, loss = 0.88443756\n",
      "Iteration 37, loss = 0.82722457\n",
      "Iteration 38, loss = 0.86845173\n",
      "Iteration 39, loss = 0.91101969\n",
      "Iteration 40, loss = 0.91735451\n",
      "Iteration 41, loss = 0.86385471\n",
      "Iteration 42, loss = 0.84820909\n",
      "Iteration 43, loss = 0.80488179\n",
      "Iteration 44, loss = 0.82972285\n",
      "Iteration 45, loss = 0.82256967\n",
      "Iteration 46, loss = 0.79500961\n",
      "Iteration 47, loss = 0.81525004\n",
      "Iteration 48, loss = 0.84328418\n",
      "Iteration 49, loss = 0.83443870\n",
      "Iteration 50, loss = 0.80183200\n",
      "Iteration 1, loss = 1.24894413\n",
      "Iteration 39, loss = 0.91101969\n",
      "Iteration 40, loss = 0.91735451\n",
      "Iteration 41, loss = 0.86385471\n",
      "Iteration 42, loss = 0.84820909\n",
      "Iteration 43, loss = 0.80488179\n",
      "Iteration 44, loss = 0.82972285\n",
      "Iteration 45, loss = 0.82256967\n",
      "Iteration 46, loss = 0.79500961\n",
      "Iteration 47, loss = 0.81525004\n",
      "Iteration 48, loss = 0.84328418\n",
      "Iteration 49, loss = 0.83443870\n",
      "Iteration 50, loss = 0.80183200\n",
      "Iteration 1, loss = 1.24894413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.11679221\n",
      "Iteration 3, loss = 0.99595341\n",
      "Iteration 4, loss = 1.02081750\n",
      "Iteration 5, loss = 1.00730691\n",
      "Iteration 6, loss = 0.98779343\n",
      "Iteration 7, loss = 0.95889833\n",
      "Iteration 8, loss = 0.96897503\n",
      "Iteration 9, loss = 0.94436148\n",
      "Iteration 10, loss = 0.95453579\n",
      "Iteration 11, loss = 0.90579356\n",
      "Iteration 12, loss = 0.92510890\n",
      "Iteration 13, loss = 0.91326776\n",
      "Iteration 14, loss = 0.94083751\n",
      "Iteration 15, loss = 0.91813798\n",
      "Iteration 2, loss = 1.11679221\n",
      "Iteration 3, loss = 0.99595341\n",
      "Iteration 4, loss = 1.02081750\n",
      "Iteration 5, loss = 1.00730691\n",
      "Iteration 6, loss = 0.98779343\n",
      "Iteration 7, loss = 0.95889833\n",
      "Iteration 8, loss = 0.96897503\n",
      "Iteration 9, loss = 0.94436148\n",
      "Iteration 10, loss = 0.95453579\n",
      "Iteration 11, loss = 0.90579356\n",
      "Iteration 12, loss = 0.92510890\n",
      "Iteration 13, loss = 0.91326776\n",
      "Iteration 14, loss = 0.94083751\n",
      "Iteration 15, loss = 0.91813798\n",
      "Iteration 16, loss = 0.94889702\n",
      "Iteration 17, loss = 0.93330759\n",
      "Iteration 18, loss = 0.90854703\n",
      "Iteration 19, loss = 0.92221678\n",
      "Iteration 20, loss = 0.93249406\n",
      "Iteration 21, loss = 0.85456213\n",
      "Iteration 22, loss = 0.86519728\n",
      "Iteration 23, loss = 0.86128898\n",
      "Iteration 24, loss = 0.86389637\n",
      "Iteration 25, loss = 0.87184571\n",
      "Iteration 26, loss = 0.86324725\n",
      "Iteration 16, loss = 0.94889702\n",
      "Iteration 17, loss = 0.93330759\n",
      "Iteration 18, loss = 0.90854703\n",
      "Iteration 19, loss = 0.92221678\n",
      "Iteration 20, loss = 0.93249406\n",
      "Iteration 21, loss = 0.85456213\n",
      "Iteration 22, loss = 0.86519728\n",
      "Iteration 23, loss = 0.86128898\n",
      "Iteration 24, loss = 0.86389637\n",
      "Iteration 25, loss = 0.87184571\n",
      "Iteration 26, loss = 0.86324725\n",
      "Iteration 27, loss = 0.86123110\n",
      "Iteration 28, loss = 0.81564145\n",
      "Iteration 29, loss = 0.84656283\n",
      "Iteration 30, loss = 0.85591686\n",
      "Iteration 31, loss = 0.87089461\n",
      "Iteration 32, loss = 0.85828792\n",
      "Iteration 33, loss = 0.84934108\n",
      "Iteration 34, loss = 0.81150055\n",
      "Iteration 35, loss = 0.82495639\n",
      "Iteration 36, loss = 0.80346793\n",
      "Iteration 37, loss = 0.85007488\n",
      "Iteration 38, loss = 0.84760639\n",
      "Iteration 39, loss = 0.84176421\n",
      "Iteration 40, loss = 0.79213095\n",
      "Iteration 27, loss = 0.86123110\n",
      "Iteration 28, loss = 0.81564145\n",
      "Iteration 29, loss = 0.84656283\n",
      "Iteration 30, loss = 0.85591686\n",
      "Iteration 31, loss = 0.87089461\n",
      "Iteration 32, loss = 0.85828792\n",
      "Iteration 33, loss = 0.84934108\n",
      "Iteration 34, loss = 0.81150055\n",
      "Iteration 35, loss = 0.82495639\n",
      "Iteration 36, loss = 0.80346793\n",
      "Iteration 37, loss = 0.85007488\n",
      "Iteration 38, loss = 0.84760639\n",
      "Iteration 39, loss = 0.84176421\n",
      "Iteration 40, loss = 0.79213095\n",
      "Iteration 41, loss = 0.80853233\n",
      "Iteration 42, loss = 0.84116446\n",
      "Iteration 43, loss = 0.78999046\n",
      "Iteration 44, loss = 0.79414793\n",
      "Iteration 45, loss = 0.77966299\n",
      "Iteration 46, loss = 0.81016266\n",
      "Iteration 47, loss = 0.80267882\n",
      "Iteration 48, loss = 0.73408369\n",
      "Iteration 49, loss = 0.75823501\n",
      "Iteration 50, loss = 0.75811547\n",
      "Iteration 1, loss = 1.24995458\n",
      "Iteration 41, loss = 0.80853233\n",
      "Iteration 42, loss = 0.84116446\n",
      "Iteration 43, loss = 0.78999046\n",
      "Iteration 44, loss = 0.79414793\n",
      "Iteration 45, loss = 0.77966299\n",
      "Iteration 46, loss = 0.81016266\n",
      "Iteration 47, loss = 0.80267882\n",
      "Iteration 48, loss = 0.73408369\n",
      "Iteration 49, loss = 0.75823501\n",
      "Iteration 50, loss = 0.75811547\n",
      "Iteration 1, loss = 1.24995458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.09945718\n",
      "Iteration 3, loss = 1.00512634\n",
      "Iteration 4, loss = 0.97215345\n",
      "Iteration 5, loss = 1.01803173\n",
      "Iteration 6, loss = 0.93854851\n",
      "Iteration 7, loss = 0.96332537\n",
      "Iteration 8, loss = 0.97449717\n",
      "Iteration 9, loss = 0.95301786\n",
      "Iteration 10, loss = 1.01873419\n",
      "Iteration 11, loss = 0.91892385\n",
      "Iteration 12, loss = 0.90386900\n",
      "Iteration 13, loss = 0.90518288\n",
      "Iteration 14, loss = 0.90870868\n",
      "Iteration 15, loss = 0.90104589\n",
      "Iteration 2, loss = 1.09945718\n",
      "Iteration 3, loss = 1.00512634\n",
      "Iteration 4, loss = 0.97215345\n",
      "Iteration 5, loss = 1.01803173\n",
      "Iteration 6, loss = 0.93854851\n",
      "Iteration 7, loss = 0.96332537\n",
      "Iteration 8, loss = 0.97449717\n",
      "Iteration 9, loss = 0.95301786\n",
      "Iteration 10, loss = 1.01873419\n",
      "Iteration 11, loss = 0.91892385\n",
      "Iteration 12, loss = 0.90386900\n",
      "Iteration 13, loss = 0.90518288\n",
      "Iteration 14, loss = 0.90870868\n",
      "Iteration 15, loss = 0.90104589\n",
      "Iteration 16, loss = 0.90210944\n",
      "Iteration 17, loss = 0.91565008\n",
      "Iteration 18, loss = 0.92538545\n",
      "Iteration 19, loss = 0.91045483\n",
      "Iteration 20, loss = 0.89055453\n",
      "Iteration 21, loss = 0.90588950\n",
      "Iteration 22, loss = 0.86976170\n",
      "Iteration 23, loss = 0.87044248\n",
      "Iteration 24, loss = 0.89026561\n",
      "Iteration 25, loss = 0.88472963\n",
      "Iteration 26, loss = 0.86129868\n",
      "Iteration 27, loss = 0.85455982\n",
      "Iteration 28, loss = 0.83208085\n",
      "Iteration 16, loss = 0.90210944\n",
      "Iteration 17, loss = 0.91565008\n",
      "Iteration 18, loss = 0.92538545\n",
      "Iteration 19, loss = 0.91045483\n",
      "Iteration 20, loss = 0.89055453\n",
      "Iteration 21, loss = 0.90588950\n",
      "Iteration 22, loss = 0.86976170\n",
      "Iteration 23, loss = 0.87044248\n",
      "Iteration 24, loss = 0.89026561\n",
      "Iteration 25, loss = 0.88472963\n",
      "Iteration 26, loss = 0.86129868\n",
      "Iteration 27, loss = 0.85455982\n",
      "Iteration 28, loss = 0.83208085\n",
      "Iteration 29, loss = 0.83435540\n",
      "Iteration 30, loss = 0.84644625\n",
      "Iteration 31, loss = 0.83637708\n",
      "Iteration 32, loss = 0.85943787\n",
      "Iteration 33, loss = 0.87008924\n",
      "Iteration 34, loss = 0.82751954\n",
      "Iteration 35, loss = 0.83994481\n",
      "Iteration 36, loss = 0.80977274\n",
      "Iteration 37, loss = 0.80416961\n",
      "Iteration 38, loss = 0.83002671\n",
      "Iteration 39, loss = 0.80328019\n",
      "Iteration 40, loss = 0.80879046\n",
      "Iteration 41, loss = 0.79465548\n",
      "Iteration 42, loss = 0.89224340\n",
      "Iteration 29, loss = 0.83435540\n",
      "Iteration 30, loss = 0.84644625\n",
      "Iteration 31, loss = 0.83637708\n",
      "Iteration 32, loss = 0.85943787\n",
      "Iteration 33, loss = 0.87008924\n",
      "Iteration 34, loss = 0.82751954\n",
      "Iteration 35, loss = 0.83994481\n",
      "Iteration 36, loss = 0.80977274\n",
      "Iteration 37, loss = 0.80416961\n",
      "Iteration 38, loss = 0.83002671\n",
      "Iteration 39, loss = 0.80328019\n",
      "Iteration 40, loss = 0.80879046\n",
      "Iteration 41, loss = 0.79465548\n",
      "Iteration 42, loss = 0.89224340\n",
      "Iteration 43, loss = 0.83423415\n",
      "Iteration 44, loss = 0.79462880\n",
      "Iteration 45, loss = 0.80041070\n",
      "Iteration 46, loss = 0.79304001\n",
      "Iteration 47, loss = 0.77100330\n",
      "Iteration 48, loss = 0.73059374\n",
      "Iteration 49, loss = 0.79303988\n",
      "Iteration 50, loss = 0.76937298\n",
      "Iteration 1, loss = 1.24276304\n",
      "Iteration 2, loss = 1.09196289\n",
      "Iteration 3, loss = 1.01362661\n",
      "Iteration 4, loss = 0.97067710\n",
      "Iteration 43, loss = 0.83423415\n",
      "Iteration 44, loss = 0.79462880\n",
      "Iteration 45, loss = 0.80041070\n",
      "Iteration 46, loss = 0.79304001\n",
      "Iteration 47, loss = 0.77100330\n",
      "Iteration 48, loss = 0.73059374\n",
      "Iteration 49, loss = 0.79303988\n",
      "Iteration 50, loss = 0.76937298\n",
      "Iteration 1, loss = 1.24276304\n",
      "Iteration 2, loss = 1.09196289\n",
      "Iteration 3, loss = 1.01362661\n",
      "Iteration 4, loss = 0.97067710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.98076333\n",
      "Iteration 6, loss = 0.98430130\n",
      "Iteration 7, loss = 0.97436685\n",
      "Iteration 8, loss = 0.95273224\n",
      "Iteration 9, loss = 0.94536403\n",
      "Iteration 10, loss = 0.96828166\n",
      "Iteration 11, loss = 0.94075931\n",
      "Iteration 12, loss = 0.92456246\n",
      "Iteration 13, loss = 0.92317211\n",
      "Iteration 14, loss = 0.92915519\n",
      "Iteration 15, loss = 0.95279385\n",
      "Iteration 16, loss = 0.92455546\n",
      "Iteration 5, loss = 0.98076333\n",
      "Iteration 6, loss = 0.98430130\n",
      "Iteration 7, loss = 0.97436685\n",
      "Iteration 8, loss = 0.95273224\n",
      "Iteration 9, loss = 0.94536403\n",
      "Iteration 10, loss = 0.96828166\n",
      "Iteration 11, loss = 0.94075931\n",
      "Iteration 12, loss = 0.92456246\n",
      "Iteration 13, loss = 0.92317211\n",
      "Iteration 14, loss = 0.92915519\n",
      "Iteration 15, loss = 0.95279385\n",
      "Iteration 16, loss = 0.92455546\n",
      "Iteration 17, loss = 0.92139918\n",
      "Iteration 18, loss = 0.90884001\n",
      "Iteration 19, loss = 0.90611228\n",
      "Iteration 20, loss = 0.89524877\n",
      "Iteration 21, loss = 0.89210578\n",
      "Iteration 22, loss = 0.88790083\n",
      "Iteration 23, loss = 0.87335744\n",
      "Iteration 24, loss = 0.87860654\n",
      "Iteration 25, loss = 0.85510696\n",
      "Iteration 26, loss = 0.95678223\n",
      "Iteration 27, loss = 0.90876046\n",
      "Iteration 28, loss = 0.85431692\n",
      "Iteration 29, loss = 0.86013611\n",
      "Iteration 30, loss = 0.84976114\n",
      "Iteration 17, loss = 0.92139918\n",
      "Iteration 18, loss = 0.90884001\n",
      "Iteration 19, loss = 0.90611228\n",
      "Iteration 20, loss = 0.89524877\n",
      "Iteration 21, loss = 0.89210578\n",
      "Iteration 22, loss = 0.88790083\n",
      "Iteration 23, loss = 0.87335744\n",
      "Iteration 24, loss = 0.87860654\n",
      "Iteration 25, loss = 0.85510696\n",
      "Iteration 26, loss = 0.95678223\n",
      "Iteration 27, loss = 0.90876046\n",
      "Iteration 28, loss = 0.85431692\n",
      "Iteration 29, loss = 0.86013611\n",
      "Iteration 30, loss = 0.84976114\n",
      "Iteration 31, loss = 0.84030566\n",
      "Iteration 32, loss = 0.83341727\n",
      "Iteration 33, loss = 0.87199303\n",
      "Iteration 34, loss = 0.86778397\n",
      "Iteration 35, loss = 0.84360600\n",
      "Iteration 36, loss = 0.81888832\n",
      "Iteration 37, loss = 0.82396951\n",
      "Iteration 38, loss = 0.83234725\n",
      "Iteration 39, loss = 0.83132377\n",
      "Iteration 40, loss = 0.82103500\n",
      "Iteration 41, loss = 0.77907821\n",
      "Iteration 42, loss = 0.79589334\n",
      "Iteration 43, loss = 0.79322831\n",
      "Iteration 44, loss = 0.78083791\n",
      "Iteration 45, loss = 0.79725962\n",
      "Iteration 31, loss = 0.84030566\n",
      "Iteration 32, loss = 0.83341727\n",
      "Iteration 33, loss = 0.87199303\n",
      "Iteration 34, loss = 0.86778397\n",
      "Iteration 35, loss = 0.84360600\n",
      "Iteration 36, loss = 0.81888832\n",
      "Iteration 37, loss = 0.82396951\n",
      "Iteration 38, loss = 0.83234725\n",
      "Iteration 39, loss = 0.83132377\n",
      "Iteration 40, loss = 0.82103500\n",
      "Iteration 41, loss = 0.77907821\n",
      "Iteration 42, loss = 0.79589334\n",
      "Iteration 43, loss = 0.79322831\n",
      "Iteration 44, loss = 0.78083791\n",
      "Iteration 45, loss = 0.79725962\n",
      "Iteration 46, loss = 0.80872165\n",
      "Iteration 47, loss = 0.77549995\n",
      "Iteration 48, loss = 0.82690400\n",
      "Iteration 49, loss = 0.80613994\n",
      "Iteration 50, loss = 0.75474906\n",
      "Iteration 51, loss = 0.76068491\n",
      "Iteration 52, loss = 0.86530192\n",
      "Iteration 53, loss = 0.78494670\n",
      "Iteration 54, loss = 0.81104307\n",
      "Iteration 55, loss = 0.79671141\n",
      "Iteration 56, loss = 0.77676834\n",
      "Iteration 46, loss = 0.80872165\n",
      "Iteration 47, loss = 0.77549995\n",
      "Iteration 48, loss = 0.82690400\n",
      "Iteration 49, loss = 0.80613994\n",
      "Iteration 50, loss = 0.75474906\n",
      "Iteration 51, loss = 0.76068491\n",
      "Iteration 52, loss = 0.86530192\n",
      "Iteration 53, loss = 0.78494670\n",
      "Iteration 54, loss = 0.81104307\n",
      "Iteration 55, loss = 0.79671141\n",
      "Iteration 56, loss = 0.77676834\n",
      "Iteration 57, loss = 0.79994508\n",
      "Iteration 58, loss = 0.74977048\n",
      "Iteration 59, loss = 0.74010150\n",
      "Iteration 60, loss = 0.76671801\n",
      "Iteration 61, loss = 0.78522177\n",
      "Iteration 62, loss = 0.75018643\n",
      "Iteration 63, loss = 0.74655938\n",
      "Iteration 64, loss = 0.72543173\n",
      "Iteration 65, loss = 0.71963195\n",
      "Iteration 66, loss = 0.72405424\n",
      "Iteration 67, loss = 0.80066226\n",
      "Iteration 68, loss = 0.73103882\n",
      "Iteration 69, loss = 0.72055120\n",
      "Iteration 70, loss = 0.74161341\n",
      "Iteration 57, loss = 0.79994508\n",
      "Iteration 58, loss = 0.74977048\n",
      "Iteration 59, loss = 0.74010150\n",
      "Iteration 60, loss = 0.76671801\n",
      "Iteration 61, loss = 0.78522177\n",
      "Iteration 62, loss = 0.75018643\n",
      "Iteration 63, loss = 0.74655938\n",
      "Iteration 64, loss = 0.72543173\n",
      "Iteration 65, loss = 0.71963195\n",
      "Iteration 66, loss = 0.72405424\n",
      "Iteration 67, loss = 0.80066226\n",
      "Iteration 68, loss = 0.73103882\n",
      "Iteration 69, loss = 0.72055120\n",
      "Iteration 70, loss = 0.74161341\n",
      "Iteration 71, loss = 0.85446994\n",
      "Iteration 72, loss = 0.74505467\n",
      "Iteration 73, loss = 0.76351134\n",
      "Iteration 74, loss = 0.73341016\n",
      "Iteration 75, loss = 0.72556391\n",
      "Iteration 76, loss = 0.73398140\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18302025\n",
      "Iteration 2, loss = 1.02082657\n",
      "Iteration 3, loss = 0.93895258\n",
      "Iteration 4, loss = 0.96206459\n",
      "Iteration 5, loss = 0.91627128\n",
      "Iteration 71, loss = 0.85446994\n",
      "Iteration 72, loss = 0.74505467\n",
      "Iteration 73, loss = 0.76351134\n",
      "Iteration 74, loss = 0.73341016\n",
      "Iteration 75, loss = 0.72556391\n",
      "Iteration 76, loss = 0.73398140\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18302025\n",
      "Iteration 2, loss = 1.02082657\n",
      "Iteration 3, loss = 0.93895258\n",
      "Iteration 4, loss = 0.96206459\n",
      "Iteration 5, loss = 0.91627128\n",
      "Iteration 6, loss = 0.94189897\n",
      "Iteration 7, loss = 0.91963245\n",
      "Iteration 8, loss = 0.91634747\n",
      "Iteration 9, loss = 0.96970441\n",
      "Iteration 10, loss = 0.90041385\n",
      "Iteration 11, loss = 0.89851128\n",
      "Iteration 12, loss = 0.88213448\n",
      "Iteration 13, loss = 0.93865045\n",
      "Iteration 14, loss = 0.89244079\n",
      "Iteration 15, loss = 0.89727380\n",
      "Iteration 16, loss = 0.89046329\n",
      "Iteration 17, loss = 0.85655811\n",
      "Iteration 18, loss = 0.87838120\n",
      "Iteration 6, loss = 0.94189897\n",
      "Iteration 7, loss = 0.91963245\n",
      "Iteration 8, loss = 0.91634747\n",
      "Iteration 9, loss = 0.96970441\n",
      "Iteration 10, loss = 0.90041385\n",
      "Iteration 11, loss = 0.89851128\n",
      "Iteration 12, loss = 0.88213448\n",
      "Iteration 13, loss = 0.93865045\n",
      "Iteration 14, loss = 0.89244079\n",
      "Iteration 15, loss = 0.89727380\n",
      "Iteration 16, loss = 0.89046329\n",
      "Iteration 17, loss = 0.85655811\n",
      "Iteration 18, loss = 0.87838120\n",
      "Iteration 19, loss = 0.88526262\n",
      "Iteration 20, loss = 0.88872292\n",
      "Iteration 21, loss = 0.87977228\n",
      "Iteration 22, loss = 0.87202507\n",
      "Iteration 23, loss = 0.86209515\n",
      "Iteration 24, loss = 0.84794301\n",
      "Iteration 25, loss = 0.84477994\n",
      "Iteration 26, loss = 0.82479119\n",
      "Iteration 27, loss = 0.84520994\n",
      "Iteration 28, loss = 0.80602000\n",
      "Iteration 29, loss = 0.81913045\n",
      "Iteration 30, loss = 0.77878949\n",
      "Iteration 31, loss = 0.79008673\n",
      "Iteration 19, loss = 0.88526262\n",
      "Iteration 20, loss = 0.88872292\n",
      "Iteration 21, loss = 0.87977228\n",
      "Iteration 22, loss = 0.87202507\n",
      "Iteration 23, loss = 0.86209515\n",
      "Iteration 24, loss = 0.84794301\n",
      "Iteration 25, loss = 0.84477994\n",
      "Iteration 26, loss = 0.82479119\n",
      "Iteration 27, loss = 0.84520994\n",
      "Iteration 28, loss = 0.80602000\n",
      "Iteration 29, loss = 0.81913045\n",
      "Iteration 30, loss = 0.77878949\n",
      "Iteration 31, loss = 0.79008673\n",
      "Iteration 32, loss = 0.84015925\n",
      "Iteration 33, loss = 0.79876297\n",
      "Iteration 34, loss = 0.84091702\n",
      "Iteration 35, loss = 0.81332428\n",
      "Iteration 36, loss = 0.78413947\n",
      "Iteration 37, loss = 0.80944459\n",
      "Iteration 38, loss = 0.78683100\n",
      "Iteration 39, loss = 0.77028919\n",
      "Iteration 40, loss = 0.77259885\n",
      "Iteration 41, loss = 0.78330203\n",
      "Iteration 42, loss = 0.77675556\n",
      "Iteration 43, loss = 0.77664263\n",
      "Iteration 44, loss = 0.77643149\n",
      "Iteration 45, loss = 0.77205228\n",
      "Iteration 32, loss = 0.84015925\n",
      "Iteration 33, loss = 0.79876297\n",
      "Iteration 34, loss = 0.84091702\n",
      "Iteration 35, loss = 0.81332428\n",
      "Iteration 36, loss = 0.78413947\n",
      "Iteration 37, loss = 0.80944459\n",
      "Iteration 38, loss = 0.78683100\n",
      "Iteration 39, loss = 0.77028919\n",
      "Iteration 40, loss = 0.77259885\n",
      "Iteration 41, loss = 0.78330203\n",
      "Iteration 42, loss = 0.77675556\n",
      "Iteration 43, loss = 0.77664263\n",
      "Iteration 44, loss = 0.77643149\n",
      "Iteration 45, loss = 0.77205228\n",
      "Iteration 46, loss = 0.75800348\n",
      "Iteration 47, loss = 0.76967306\n",
      "Iteration 48, loss = 0.80195917\n",
      "Iteration 49, loss = 0.75291240\n",
      "Iteration 50, loss = 0.76450413\n",
      "Iteration 51, loss = 0.73276272\n",
      "Iteration 52, loss = 0.74850834\n",
      "Iteration 53, loss = 0.76714795\n",
      "Iteration 54, loss = 0.71254042\n",
      "Iteration 55, loss = 0.70115135\n",
      "Iteration 56, loss = 0.74648411\n",
      "Iteration 57, loss = 0.78381937\n",
      "Iteration 58, loss = 0.74393596\n",
      "Iteration 59, loss = 0.71038965\n",
      "Iteration 60, loss = 0.72603731\n",
      "Iteration 46, loss = 0.75800348\n",
      "Iteration 47, loss = 0.76967306\n",
      "Iteration 48, loss = 0.80195917\n",
      "Iteration 49, loss = 0.75291240\n",
      "Iteration 50, loss = 0.76450413\n",
      "Iteration 51, loss = 0.73276272\n",
      "Iteration 52, loss = 0.74850834\n",
      "Iteration 53, loss = 0.76714795\n",
      "Iteration 54, loss = 0.71254042\n",
      "Iteration 55, loss = 0.70115135\n",
      "Iteration 56, loss = 0.74648411\n",
      "Iteration 57, loss = 0.78381937\n",
      "Iteration 58, loss = 0.74393596\n",
      "Iteration 59, loss = 0.71038965\n",
      "Iteration 60, loss = 0.72603731\n",
      "Iteration 61, loss = 0.75289162\n",
      "Iteration 62, loss = 0.73108228\n",
      "Iteration 63, loss = 0.70050569\n",
      "Iteration 64, loss = 0.69838158\n",
      "Iteration 65, loss = 0.66587535\n",
      "Iteration 66, loss = 0.75567058\n",
      "Iteration 67, loss = 0.74202128\n",
      "Iteration 68, loss = 0.70001094\n",
      "Iteration 69, loss = 0.68081177\n",
      "Iteration 70, loss = 0.71117705\n",
      "Iteration 71, loss = 0.77636134\n",
      "Iteration 72, loss = 0.69824026\n",
      "Iteration 73, loss = 0.72054867\n",
      "Iteration 74, loss = 0.70135502\n",
      "Iteration 61, loss = 0.75289162\n",
      "Iteration 62, loss = 0.73108228\n",
      "Iteration 63, loss = 0.70050569\n",
      "Iteration 64, loss = 0.69838158\n",
      "Iteration 65, loss = 0.66587535\n",
      "Iteration 66, loss = 0.75567058\n",
      "Iteration 67, loss = 0.74202128\n",
      "Iteration 68, loss = 0.70001094\n",
      "Iteration 69, loss = 0.68081177\n",
      "Iteration 70, loss = 0.71117705\n",
      "Iteration 71, loss = 0.77636134\n",
      "Iteration 72, loss = 0.69824026\n",
      "Iteration 73, loss = 0.72054867\n",
      "Iteration 74, loss = 0.70135502\n",
      "Iteration 75, loss = 0.70405607\n",
      "Iteration 76, loss = 0.68024681\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21944099\n",
      "Iteration 2, loss = 1.09436816\n",
      "Iteration 3, loss = 1.00977978\n",
      "Iteration 4, loss = 0.96212303\n",
      "Iteration 5, loss = 0.99170522\n",
      "Iteration 6, loss = 0.97263312\n",
      "Iteration 7, loss = 0.95093992\n",
      "Iteration 8, loss = 0.95896110\n",
      "Iteration 75, loss = 0.70405607\n",
      "Iteration 76, loss = 0.68024681\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21944099\n",
      "Iteration 2, loss = 1.09436816\n",
      "Iteration 3, loss = 1.00977978\n",
      "Iteration 4, loss = 0.96212303\n",
      "Iteration 5, loss = 0.99170522\n",
      "Iteration 6, loss = 0.97263312\n",
      "Iteration 7, loss = 0.95093992\n",
      "Iteration 8, loss = 0.95896110\n",
      "Iteration 9, loss = 0.91442974\n",
      "Iteration 10, loss = 0.93765942\n",
      "Iteration 11, loss = 0.92025360\n",
      "Iteration 12, loss = 0.97530460\n",
      "Iteration 13, loss = 0.92402404\n",
      "Iteration 14, loss = 0.90481097\n",
      "Iteration 15, loss = 0.94038199\n",
      "Iteration 16, loss = 0.91506773\n",
      "Iteration 17, loss = 0.90279489\n",
      "Iteration 18, loss = 0.96139356\n",
      "Iteration 19, loss = 0.94485902\n",
      "Iteration 20, loss = 0.90990588\n",
      "Iteration 21, loss = 0.89838170\n",
      "Iteration 22, loss = 0.89858915\n",
      "Iteration 9, loss = 0.91442974\n",
      "Iteration 10, loss = 0.93765942\n",
      "Iteration 11, loss = 0.92025360\n",
      "Iteration 12, loss = 0.97530460\n",
      "Iteration 13, loss = 0.92402404\n",
      "Iteration 14, loss = 0.90481097\n",
      "Iteration 15, loss = 0.94038199\n",
      "Iteration 16, loss = 0.91506773\n",
      "Iteration 17, loss = 0.90279489\n",
      "Iteration 18, loss = 0.96139356\n",
      "Iteration 19, loss = 0.94485902\n",
      "Iteration 20, loss = 0.90990588\n",
      "Iteration 21, loss = 0.89838170\n",
      "Iteration 22, loss = 0.89858915\n",
      "Iteration 23, loss = 0.89820850\n",
      "Iteration 24, loss = 0.87988333\n",
      "Iteration 25, loss = 0.89830948\n",
      "Iteration 26, loss = 0.87711910\n",
      "Iteration 27, loss = 0.88150555\n",
      "Iteration 28, loss = 0.87814295\n",
      "Iteration 29, loss = 0.85622230\n",
      "Iteration 30, loss = 0.85461566\n",
      "Iteration 31, loss = 0.89761459\n",
      "Iteration 32, loss = 0.89934060\n",
      "Iteration 33, loss = 0.86640487\n",
      "Iteration 34, loss = 0.88280615\n",
      "Iteration 35, loss = 0.87798115\n",
      "Iteration 36, loss = 0.88443756\n",
      "Iteration 37, loss = 0.82722457\n",
      "Iteration 23, loss = 0.89820850\n",
      "Iteration 24, loss = 0.87988333\n",
      "Iteration 25, loss = 0.89830948\n",
      "Iteration 26, loss = 0.87711910\n",
      "Iteration 27, loss = 0.88150555\n",
      "Iteration 28, loss = 0.87814295\n",
      "Iteration 29, loss = 0.85622230\n",
      "Iteration 30, loss = 0.85461566\n",
      "Iteration 31, loss = 0.89761459\n",
      "Iteration 32, loss = 0.89934060\n",
      "Iteration 33, loss = 0.86640487\n",
      "Iteration 34, loss = 0.88280615\n",
      "Iteration 35, loss = 0.87798115\n",
      "Iteration 36, loss = 0.88443756\n",
      "Iteration 37, loss = 0.82722457\n",
      "Iteration 38, loss = 0.86845173\n",
      "Iteration 39, loss = 0.91101969\n",
      "Iteration 40, loss = 0.91735451\n",
      "Iteration 41, loss = 0.86385471\n",
      "Iteration 42, loss = 0.84820909\n",
      "Iteration 43, loss = 0.80488179\n",
      "Iteration 44, loss = 0.82972285\n",
      "Iteration 45, loss = 0.82256967\n",
      "Iteration 46, loss = 0.79500961\n",
      "Iteration 47, loss = 0.81525004\n",
      "Iteration 48, loss = 0.84328418\n",
      "Iteration 49, loss = 0.83443870\n",
      "Iteration 50, loss = 0.80183200\n",
      "Iteration 51, loss = 0.78019822\n",
      "Iteration 52, loss = 0.80338310\n",
      "Iteration 38, loss = 0.86845173\n",
      "Iteration 39, loss = 0.91101969\n",
      "Iteration 40, loss = 0.91735451\n",
      "Iteration 41, loss = 0.86385471\n",
      "Iteration 42, loss = 0.84820909\n",
      "Iteration 43, loss = 0.80488179\n",
      "Iteration 44, loss = 0.82972285\n",
      "Iteration 45, loss = 0.82256967\n",
      "Iteration 46, loss = 0.79500961\n",
      "Iteration 47, loss = 0.81525004\n",
      "Iteration 48, loss = 0.84328418\n",
      "Iteration 49, loss = 0.83443870\n",
      "Iteration 50, loss = 0.80183200\n",
      "Iteration 51, loss = 0.78019822\n",
      "Iteration 52, loss = 0.80338310\n",
      "Iteration 53, loss = 0.78966273\n",
      "Iteration 54, loss = 0.78090504\n",
      "Iteration 55, loss = 0.80766961\n",
      "Iteration 56, loss = 0.75722808\n",
      "Iteration 57, loss = 0.83811574\n",
      "Iteration 58, loss = 0.80682820\n",
      "Iteration 59, loss = 0.77432809\n",
      "Iteration 60, loss = 0.79627534\n",
      "Iteration 61, loss = 0.76338563\n",
      "Iteration 62, loss = 0.74096780\n",
      "Iteration 63, loss = 0.75595701\n",
      "Iteration 64, loss = 0.77898398\n",
      "Iteration 65, loss = 0.74721282\n",
      "Iteration 66, loss = 0.75293552\n",
      "Iteration 67, loss = 0.75562854\n",
      "Iteration 53, loss = 0.78966273\n",
      "Iteration 54, loss = 0.78090504\n",
      "Iteration 55, loss = 0.80766961\n",
      "Iteration 56, loss = 0.75722808\n",
      "Iteration 57, loss = 0.83811574\n",
      "Iteration 58, loss = 0.80682820\n",
      "Iteration 59, loss = 0.77432809\n",
      "Iteration 60, loss = 0.79627534\n",
      "Iteration 61, loss = 0.76338563\n",
      "Iteration 62, loss = 0.74096780\n",
      "Iteration 63, loss = 0.75595701\n",
      "Iteration 64, loss = 0.77898398\n",
      "Iteration 65, loss = 0.74721282\n",
      "Iteration 66, loss = 0.75293552\n",
      "Iteration 67, loss = 0.75562854\n",
      "Iteration 68, loss = 0.72214244\n",
      "Iteration 69, loss = 0.70992119\n",
      "Iteration 70, loss = 0.76877294\n",
      "Iteration 71, loss = 0.74257064\n",
      "Iteration 72, loss = 0.77828840\n",
      "Iteration 73, loss = 0.73622029\n",
      "Iteration 74, loss = 0.75502709\n",
      "Iteration 75, loss = 0.75255474\n",
      "Iteration 76, loss = 0.73830276\n",
      "Iteration 77, loss = 0.71512275\n",
      "Iteration 78, loss = 0.74032852\n",
      "Iteration 79, loss = 0.75924996\n",
      "Iteration 68, loss = 0.72214244\n",
      "Iteration 69, loss = 0.70992119\n",
      "Iteration 70, loss = 0.76877294\n",
      "Iteration 71, loss = 0.74257064\n",
      "Iteration 72, loss = 0.77828840\n",
      "Iteration 73, loss = 0.73622029\n",
      "Iteration 74, loss = 0.75502709\n",
      "Iteration 75, loss = 0.75255474\n",
      "Iteration 76, loss = 0.73830276\n",
      "Iteration 77, loss = 0.71512275\n",
      "Iteration 78, loss = 0.74032852\n",
      "Iteration 79, loss = 0.75924996\n",
      "Iteration 80, loss = 0.70447598\n",
      "Iteration 81, loss = 0.75848316\n",
      "Iteration 82, loss = 0.74503430\n",
      "Iteration 83, loss = 0.73747263\n",
      "Iteration 84, loss = 0.73791013\n",
      "Iteration 85, loss = 0.78922270\n",
      "Iteration 86, loss = 0.77576265\n",
      "Iteration 87, loss = 0.83776030\n",
      "Iteration 88, loss = 0.81068737\n",
      "Iteration 89, loss = 0.76911531\n",
      "Iteration 90, loss = 0.75699633\n",
      "Iteration 91, loss = 0.82506414\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24894413\n",
      "Iteration 2, loss = 1.11679221\n",
      "Iteration 80, loss = 0.70447598\n",
      "Iteration 81, loss = 0.75848316\n",
      "Iteration 82, loss = 0.74503430\n",
      "Iteration 83, loss = 0.73747263\n",
      "Iteration 84, loss = 0.73791013\n",
      "Iteration 85, loss = 0.78922270\n",
      "Iteration 86, loss = 0.77576265\n",
      "Iteration 87, loss = 0.83776030\n",
      "Iteration 88, loss = 0.81068737\n",
      "Iteration 89, loss = 0.76911531\n",
      "Iteration 90, loss = 0.75699633\n",
      "Iteration 91, loss = 0.82506414\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24894413\n",
      "Iteration 2, loss = 1.11679221\n",
      "Iteration 3, loss = 0.99595341\n",
      "Iteration 4, loss = 1.02081750\n",
      "Iteration 5, loss = 1.00730691\n",
      "Iteration 6, loss = 0.98779343\n",
      "Iteration 7, loss = 0.95889833\n",
      "Iteration 8, loss = 0.96897503\n",
      "Iteration 9, loss = 0.94436148\n",
      "Iteration 10, loss = 0.95453579\n",
      "Iteration 11, loss = 0.90579356\n",
      "Iteration 12, loss = 0.92510890\n",
      "Iteration 13, loss = 0.91326776\n",
      "Iteration 14, loss = 0.94083751\n",
      "Iteration 15, loss = 0.91813798\n",
      "Iteration 16, loss = 0.94889702\n",
      "Iteration 17, loss = 0.93330759\n",
      "Iteration 3, loss = 0.99595341\n",
      "Iteration 4, loss = 1.02081750\n",
      "Iteration 5, loss = 1.00730691\n",
      "Iteration 6, loss = 0.98779343\n",
      "Iteration 7, loss = 0.95889833\n",
      "Iteration 8, loss = 0.96897503\n",
      "Iteration 9, loss = 0.94436148\n",
      "Iteration 10, loss = 0.95453579\n",
      "Iteration 11, loss = 0.90579356\n",
      "Iteration 12, loss = 0.92510890\n",
      "Iteration 13, loss = 0.91326776\n",
      "Iteration 14, loss = 0.94083751\n",
      "Iteration 15, loss = 0.91813798\n",
      "Iteration 16, loss = 0.94889702\n",
      "Iteration 17, loss = 0.93330759\n",
      "Iteration 18, loss = 0.90854703\n",
      "Iteration 19, loss = 0.92221678\n",
      "Iteration 20, loss = 0.93249406\n",
      "Iteration 21, loss = 0.85456213\n",
      "Iteration 22, loss = 0.86519728\n",
      "Iteration 23, loss = 0.86128898\n",
      "Iteration 24, loss = 0.86389637\n",
      "Iteration 25, loss = 0.87184571\n",
      "Iteration 26, loss = 0.86324725\n",
      "Iteration 27, loss = 0.86123110\n",
      "Iteration 28, loss = 0.81564145\n",
      "Iteration 29, loss = 0.84656283\n",
      "Iteration 30, loss = 0.85591686\n",
      "Iteration 31, loss = 0.87089461\n",
      "Iteration 32, loss = 0.85828792\n",
      "Iteration 18, loss = 0.90854703\n",
      "Iteration 19, loss = 0.92221678\n",
      "Iteration 20, loss = 0.93249406\n",
      "Iteration 21, loss = 0.85456213\n",
      "Iteration 22, loss = 0.86519728\n",
      "Iteration 23, loss = 0.86128898\n",
      "Iteration 24, loss = 0.86389637\n",
      "Iteration 25, loss = 0.87184571\n",
      "Iteration 26, loss = 0.86324725\n",
      "Iteration 27, loss = 0.86123110\n",
      "Iteration 28, loss = 0.81564145\n",
      "Iteration 29, loss = 0.84656283\n",
      "Iteration 30, loss = 0.85591686\n",
      "Iteration 31, loss = 0.87089461\n",
      "Iteration 32, loss = 0.85828792\n",
      "Iteration 33, loss = 0.84934108\n",
      "Iteration 34, loss = 0.81150055\n",
      "Iteration 35, loss = 0.82495639\n",
      "Iteration 36, loss = 0.80346793\n",
      "Iteration 37, loss = 0.85007488\n",
      "Iteration 38, loss = 0.84760639\n",
      "Iteration 39, loss = 0.84176421\n",
      "Iteration 40, loss = 0.79213095\n",
      "Iteration 41, loss = 0.80853233\n",
      "Iteration 42, loss = 0.84116446\n",
      "Iteration 43, loss = 0.78999046\n",
      "Iteration 44, loss = 0.79414793\n",
      "Iteration 45, loss = 0.77966299\n",
      "Iteration 46, loss = 0.81016266\n",
      "Iteration 47, loss = 0.80267882\n",
      "Iteration 33, loss = 0.84934108\n",
      "Iteration 34, loss = 0.81150055\n",
      "Iteration 35, loss = 0.82495639\n",
      "Iteration 36, loss = 0.80346793\n",
      "Iteration 37, loss = 0.85007488\n",
      "Iteration 38, loss = 0.84760639\n",
      "Iteration 39, loss = 0.84176421\n",
      "Iteration 40, loss = 0.79213095\n",
      "Iteration 41, loss = 0.80853233\n",
      "Iteration 42, loss = 0.84116446\n",
      "Iteration 43, loss = 0.78999046\n",
      "Iteration 44, loss = 0.79414793\n",
      "Iteration 45, loss = 0.77966299\n",
      "Iteration 46, loss = 0.81016266\n",
      "Iteration 47, loss = 0.80267882\n",
      "Iteration 48, loss = 0.73408369\n",
      "Iteration 49, loss = 0.75823501\n",
      "Iteration 50, loss = 0.75811547\n",
      "Iteration 51, loss = 0.77516432\n",
      "Iteration 52, loss = 0.78010337\n",
      "Iteration 53, loss = 0.77270149\n",
      "Iteration 54, loss = 0.75098696\n",
      "Iteration 55, loss = 0.73060574\n",
      "Iteration 56, loss = 0.76273475\n",
      "Iteration 57, loss = 0.75144157\n",
      "Iteration 58, loss = 0.74020944\n",
      "Iteration 59, loss = 0.73999094\n",
      "Iteration 60, loss = 0.76669643\n",
      "Iteration 61, loss = 0.71813934\n",
      "Iteration 48, loss = 0.73408369\n",
      "Iteration 49, loss = 0.75823501\n",
      "Iteration 50, loss = 0.75811547\n",
      "Iteration 51, loss = 0.77516432\n",
      "Iteration 52, loss = 0.78010337\n",
      "Iteration 53, loss = 0.77270149\n",
      "Iteration 54, loss = 0.75098696\n",
      "Iteration 55, loss = 0.73060574\n",
      "Iteration 56, loss = 0.76273475\n",
      "Iteration 57, loss = 0.75144157\n",
      "Iteration 58, loss = 0.74020944\n",
      "Iteration 59, loss = 0.73999094\n",
      "Iteration 60, loss = 0.76669643\n",
      "Iteration 61, loss = 0.71813934\n",
      "Iteration 62, loss = 0.72027151\n",
      "Iteration 63, loss = 0.72387078\n",
      "Iteration 64, loss = 0.72090904\n",
      "Iteration 65, loss = 0.71249366\n",
      "Iteration 66, loss = 0.70784210\n",
      "Iteration 67, loss = 0.70297703\n",
      "Iteration 68, loss = 0.71746927\n",
      "Iteration 69, loss = 0.66838170\n",
      "Iteration 70, loss = 0.73312604\n",
      "Iteration 71, loss = 0.69991656\n",
      "Iteration 72, loss = 0.73181272\n",
      "Iteration 73, loss = 0.70401545\n",
      "Iteration 74, loss = 0.75833601\n",
      "Iteration 75, loss = 0.75593374\n",
      "Iteration 62, loss = 0.72027151\n",
      "Iteration 63, loss = 0.72387078\n",
      "Iteration 64, loss = 0.72090904\n",
      "Iteration 65, loss = 0.71249366\n",
      "Iteration 66, loss = 0.70784210\n",
      "Iteration 67, loss = 0.70297703\n",
      "Iteration 68, loss = 0.71746927\n",
      "Iteration 69, loss = 0.66838170\n",
      "Iteration 70, loss = 0.73312604\n",
      "Iteration 71, loss = 0.69991656\n",
      "Iteration 72, loss = 0.73181272\n",
      "Iteration 73, loss = 0.70401545\n",
      "Iteration 74, loss = 0.75833601\n",
      "Iteration 75, loss = 0.75593374\n",
      "Iteration 76, loss = 0.70877362\n",
      "Iteration 77, loss = 0.67430082\n",
      "Iteration 78, loss = 0.69742176\n",
      "Iteration 79, loss = 0.66901332\n",
      "Iteration 80, loss = 0.68047290\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24995458\n",
      "Iteration 2, loss = 1.09945718\n",
      "Iteration 3, loss = 1.00512634\n",
      "Iteration 4, loss = 0.97215345\n",
      "Iteration 5, loss = 1.01803173\n",
      "Iteration 6, loss = 0.93854851\n",
      "Iteration 7, loss = 0.96332537\n",
      "Iteration 76, loss = 0.70877362\n",
      "Iteration 77, loss = 0.67430082\n",
      "Iteration 78, loss = 0.69742176\n",
      "Iteration 79, loss = 0.66901332\n",
      "Iteration 80, loss = 0.68047290\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24995458\n",
      "Iteration 2, loss = 1.09945718\n",
      "Iteration 3, loss = 1.00512634\n",
      "Iteration 4, loss = 0.97215345\n",
      "Iteration 5, loss = 1.01803173\n",
      "Iteration 6, loss = 0.93854851\n",
      "Iteration 7, loss = 0.96332537\n",
      "Iteration 8, loss = 0.97449717\n",
      "Iteration 9, loss = 0.95301786\n",
      "Iteration 10, loss = 1.01873419\n",
      "Iteration 11, loss = 0.91892385\n",
      "Iteration 12, loss = 0.90386900\n",
      "Iteration 13, loss = 0.90518288\n",
      "Iteration 14, loss = 0.90870868\n",
      "Iteration 15, loss = 0.90104589\n",
      "Iteration 16, loss = 0.90210944\n",
      "Iteration 17, loss = 0.91565008\n",
      "Iteration 18, loss = 0.92538545\n",
      "Iteration 19, loss = 0.91045483\n",
      "Iteration 20, loss = 0.89055453\n",
      "Iteration 21, loss = 0.90588950\n",
      "Iteration 22, loss = 0.86976170\n",
      "Iteration 8, loss = 0.97449717\n",
      "Iteration 9, loss = 0.95301786\n",
      "Iteration 10, loss = 1.01873419\n",
      "Iteration 11, loss = 0.91892385\n",
      "Iteration 12, loss = 0.90386900\n",
      "Iteration 13, loss = 0.90518288\n",
      "Iteration 14, loss = 0.90870868\n",
      "Iteration 15, loss = 0.90104589\n",
      "Iteration 16, loss = 0.90210944\n",
      "Iteration 17, loss = 0.91565008\n",
      "Iteration 18, loss = 0.92538545\n",
      "Iteration 19, loss = 0.91045483\n",
      "Iteration 20, loss = 0.89055453\n",
      "Iteration 21, loss = 0.90588950\n",
      "Iteration 22, loss = 0.86976170\n",
      "Iteration 23, loss = 0.87044248\n",
      "Iteration 24, loss = 0.89026561\n",
      "Iteration 25, loss = 0.88472963\n",
      "Iteration 26, loss = 0.86129868\n",
      "Iteration 27, loss = 0.85455982\n",
      "Iteration 28, loss = 0.83208085\n",
      "Iteration 29, loss = 0.83435540\n",
      "Iteration 30, loss = 0.84644625\n",
      "Iteration 31, loss = 0.83637708\n",
      "Iteration 32, loss = 0.85943787\n",
      "Iteration 33, loss = 0.87008924\n",
      "Iteration 34, loss = 0.82751954\n",
      "Iteration 35, loss = 0.83994481\n",
      "Iteration 36, loss = 0.80977274\n",
      "Iteration 37, loss = 0.80416961\n",
      "Iteration 23, loss = 0.87044248\n",
      "Iteration 24, loss = 0.89026561\n",
      "Iteration 25, loss = 0.88472963\n",
      "Iteration 26, loss = 0.86129868\n",
      "Iteration 27, loss = 0.85455982\n",
      "Iteration 28, loss = 0.83208085\n",
      "Iteration 29, loss = 0.83435540\n",
      "Iteration 30, loss = 0.84644625\n",
      "Iteration 31, loss = 0.83637708\n",
      "Iteration 32, loss = 0.85943787\n",
      "Iteration 33, loss = 0.87008924\n",
      "Iteration 34, loss = 0.82751954\n",
      "Iteration 35, loss = 0.83994481\n",
      "Iteration 36, loss = 0.80977274\n",
      "Iteration 37, loss = 0.80416961\n",
      "Iteration 38, loss = 0.83002671\n",
      "Iteration 39, loss = 0.80328019\n",
      "Iteration 40, loss = 0.80879046\n",
      "Iteration 41, loss = 0.79465548\n",
      "Iteration 42, loss = 0.89224340\n",
      "Iteration 43, loss = 0.83423415\n",
      "Iteration 44, loss = 0.79462880\n",
      "Iteration 45, loss = 0.80041070\n",
      "Iteration 46, loss = 0.79304001\n",
      "Iteration 47, loss = 0.77100330\n",
      "Iteration 48, loss = 0.73059374\n",
      "Iteration 49, loss = 0.79303988\n",
      "Iteration 50, loss = 0.76937298\n",
      "Iteration 51, loss = 0.76850803\n",
      "Iteration 52, loss = 0.76302965\n",
      "Iteration 38, loss = 0.83002671\n",
      "Iteration 39, loss = 0.80328019\n",
      "Iteration 40, loss = 0.80879046\n",
      "Iteration 41, loss = 0.79465548\n",
      "Iteration 42, loss = 0.89224340\n",
      "Iteration 43, loss = 0.83423415\n",
      "Iteration 44, loss = 0.79462880\n",
      "Iteration 45, loss = 0.80041070\n",
      "Iteration 46, loss = 0.79304001\n",
      "Iteration 47, loss = 0.77100330\n",
      "Iteration 48, loss = 0.73059374\n",
      "Iteration 49, loss = 0.79303988\n",
      "Iteration 50, loss = 0.76937298\n",
      "Iteration 51, loss = 0.76850803\n",
      "Iteration 52, loss = 0.76302965\n",
      "Iteration 53, loss = 0.78844047\n",
      "Iteration 54, loss = 0.77045268\n",
      "Iteration 55, loss = 0.77957456\n",
      "Iteration 56, loss = 0.78746372\n",
      "Iteration 57, loss = 0.75934252\n",
      "Iteration 58, loss = 0.82356415\n",
      "Iteration 59, loss = 0.82224304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29383425\n",
      "Iteration 2, loss = 1.22107106\n",
      "Iteration 3, loss = 1.10173858\n",
      "Iteration 4, loss = 1.01403034\n",
      "Iteration 5, loss = 1.01060812\n",
      "Iteration 53, loss = 0.78844047\n",
      "Iteration 54, loss = 0.77045268\n",
      "Iteration 55, loss = 0.77957456\n",
      "Iteration 56, loss = 0.78746372\n",
      "Iteration 57, loss = 0.75934252\n",
      "Iteration 58, loss = 0.82356415\n",
      "Iteration 59, loss = 0.82224304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29383425\n",
      "Iteration 2, loss = 1.22107106\n",
      "Iteration 3, loss = 1.10173858\n",
      "Iteration 4, loss = 1.01403034\n",
      "Iteration 5, loss = 1.01060812\n",
      "Iteration 6, loss = 1.02047531\n",
      "Iteration 7, loss = 0.99091045\n",
      "Iteration 8, loss = 0.97447332\n",
      "Iteration 9, loss = 1.01902676\n",
      "Iteration 10, loss = 1.08043272\n",
      "Iteration 1, loss = 1.17591372\n",
      "Iteration 2, loss = 1.09748093\n",
      "Iteration 3, loss = 0.99811079\n",
      "Iteration 4, loss = 0.99275652\n",
      "Iteration 5, loss = 0.96654072\n",
      "Iteration 6, loss = 1.01636524\n",
      "Iteration 7, loss = 0.96327220\n",
      "Iteration 6, loss = 1.02047531\n",
      "Iteration 7, loss = 0.99091045\n",
      "Iteration 8, loss = 0.97447332\n",
      "Iteration 9, loss = 1.01902676\n",
      "Iteration 10, loss = 1.08043272\n",
      "Iteration 1, loss = 1.17591372\n",
      "Iteration 2, loss = 1.09748093\n",
      "Iteration 3, loss = 0.99811079\n",
      "Iteration 4, loss = 0.99275652\n",
      "Iteration 5, loss = 0.96654072\n",
      "Iteration 6, loss = 1.01636524\n",
      "Iteration 7, loss = 0.96327220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.05335657\n",
      "Iteration 9, loss = 0.98773141\n",
      "Iteration 10, loss = 0.99540782\n",
      "Iteration 1, loss = 1.21619103\n",
      "Iteration 2, loss = 1.14629552\n",
      "Iteration 3, loss = 1.08214879\n",
      "Iteration 4, loss = 0.99144081\n",
      "Iteration 5, loss = 1.00693377\n",
      "Iteration 6, loss = 0.96846238\n",
      "Iteration 7, loss = 0.99859452\n",
      "Iteration 8, loss = 0.97593364\n",
      "Iteration 9, loss = 0.94206936\n",
      "Iteration 10, loss = 0.94567295\n",
      "Iteration 8, loss = 1.05335657\n",
      "Iteration 9, loss = 0.98773141\n",
      "Iteration 10, loss = 0.99540782\n",
      "Iteration 1, loss = 1.21619103\n",
      "Iteration 2, loss = 1.14629552\n",
      "Iteration 3, loss = 1.08214879\n",
      "Iteration 4, loss = 0.99144081\n",
      "Iteration 5, loss = 1.00693377\n",
      "Iteration 6, loss = 0.96846238\n",
      "Iteration 7, loss = 0.99859452\n",
      "Iteration 8, loss = 0.97593364\n",
      "Iteration 9, loss = 0.94206936\n",
      "Iteration 10, loss = 0.94567295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22731989\n",
      "Iteration 2, loss = 1.09251313\n",
      "Iteration 3, loss = 1.02908475\n",
      "Iteration 4, loss = 1.03387819\n",
      "Iteration 5, loss = 1.05126476\n",
      "Iteration 6, loss = 1.01660627\n",
      "Iteration 7, loss = 1.00334088\n",
      "Iteration 8, loss = 0.98091388\n",
      "Iteration 9, loss = 1.00697887\n",
      "Iteration 10, loss = 0.98367659\n",
      "Iteration 1, loss = 1.23138776\n",
      "Iteration 2, loss = 1.13634414\n",
      "Iteration 3, loss = 0.99960090\n",
      "Iteration 4, loss = 0.99281029\n",
      "Iteration 1, loss = 1.22731989\n",
      "Iteration 2, loss = 1.09251313\n",
      "Iteration 3, loss = 1.02908475\n",
      "Iteration 4, loss = 1.03387819\n",
      "Iteration 5, loss = 1.05126476\n",
      "Iteration 6, loss = 1.01660627\n",
      "Iteration 7, loss = 1.00334088\n",
      "Iteration 8, loss = 0.98091388\n",
      "Iteration 9, loss = 1.00697887\n",
      "Iteration 10, loss = 0.98367659\n",
      "Iteration 1, loss = 1.23138776\n",
      "Iteration 2, loss = 1.13634414\n",
      "Iteration 3, loss = 0.99960090\n",
      "Iteration 4, loss = 0.99281029\n",
      "Iteration 5, loss = 1.02008113\n",
      "Iteration 6, loss = 0.95393597\n",
      "Iteration 7, loss = 0.98099506\n",
      "Iteration 8, loss = 0.98553403\n",
      "Iteration 9, loss = 0.96644247\n",
      "Iteration 10, loss = 1.03567465\n",
      "Iteration 1, loss = 1.29383425\n",
      "Iteration 2, loss = 1.22107106\n",
      "Iteration 3, loss = 1.10173858\n",
      "Iteration 4, loss = 1.01403034\n",
      "Iteration 5, loss = 1.01060812\n",
      "Iteration 6, loss = 1.02047531\n",
      "Iteration 5, loss = 1.02008113\n",
      "Iteration 6, loss = 0.95393597\n",
      "Iteration 7, loss = 0.98099506\n",
      "Iteration 8, loss = 0.98553403\n",
      "Iteration 9, loss = 0.96644247\n",
      "Iteration 10, loss = 1.03567465\n",
      "Iteration 1, loss = 1.29383425\n",
      "Iteration 2, loss = 1.22107106\n",
      "Iteration 3, loss = 1.10173858\n",
      "Iteration 4, loss = 1.01403034\n",
      "Iteration 5, loss = 1.01060812\n",
      "Iteration 6, loss = 1.02047531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.99091045\n",
      "Iteration 8, loss = 0.97447332\n",
      "Iteration 9, loss = 1.01902676\n",
      "Iteration 10, loss = 1.08043272\n",
      "Iteration 11, loss = 0.97785036\n",
      "Iteration 12, loss = 0.97584697\n",
      "Iteration 13, loss = 0.97335582\n",
      "Iteration 14, loss = 0.96915507\n",
      "Iteration 15, loss = 0.96894288\n",
      "Iteration 16, loss = 0.96710962\n",
      "Iteration 17, loss = 0.97996399\n",
      "Iteration 18, loss = 1.00226016\n",
      "Iteration 19, loss = 1.01757937\n",
      "Iteration 7, loss = 0.99091045\n",
      "Iteration 8, loss = 0.97447332\n",
      "Iteration 9, loss = 1.01902676\n",
      "Iteration 10, loss = 1.08043272\n",
      "Iteration 11, loss = 0.97785036\n",
      "Iteration 12, loss = 0.97584697\n",
      "Iteration 13, loss = 0.97335582\n",
      "Iteration 14, loss = 0.96915507\n",
      "Iteration 15, loss = 0.96894288\n",
      "Iteration 16, loss = 0.96710962\n",
      "Iteration 17, loss = 0.97996399\n",
      "Iteration 18, loss = 1.00226016\n",
      "Iteration 19, loss = 1.01757937\n",
      "Iteration 20, loss = 0.98504494\n",
      "Iteration 21, loss = 1.03868911\n",
      "Iteration 22, loss = 0.97859392\n",
      "Iteration 23, loss = 0.97557568\n",
      "Iteration 24, loss = 0.95797267\n",
      "Iteration 25, loss = 0.96372732\n",
      "Iteration 26, loss = 1.00650651\n",
      "Iteration 27, loss = 0.96046619\n",
      "Iteration 28, loss = 0.95773119\n",
      "Iteration 29, loss = 0.95018638\n",
      "Iteration 30, loss = 0.96150826\n",
      "Iteration 31, loss = 0.94870827\n",
      "Iteration 32, loss = 0.94012868\n",
      "Iteration 33, loss = 0.94055373\n",
      "Iteration 20, loss = 0.98504494\n",
      "Iteration 21, loss = 1.03868911\n",
      "Iteration 22, loss = 0.97859392\n",
      "Iteration 23, loss = 0.97557568\n",
      "Iteration 24, loss = 0.95797267\n",
      "Iteration 25, loss = 0.96372732\n",
      "Iteration 26, loss = 1.00650651\n",
      "Iteration 27, loss = 0.96046619\n",
      "Iteration 28, loss = 0.95773119\n",
      "Iteration 29, loss = 0.95018638\n",
      "Iteration 30, loss = 0.96150826\n",
      "Iteration 31, loss = 0.94870827\n",
      "Iteration 32, loss = 0.94012868\n",
      "Iteration 33, loss = 0.94055373\n",
      "Iteration 34, loss = 0.98997028\n",
      "Iteration 35, loss = 0.94821270\n",
      "Iteration 36, loss = 0.94020523\n",
      "Iteration 37, loss = 0.96072724\n",
      "Iteration 38, loss = 0.94856820\n",
      "Iteration 39, loss = 1.06232737\n",
      "Iteration 40, loss = 0.98450902\n",
      "Iteration 41, loss = 0.94867879\n",
      "Iteration 42, loss = 0.93418141\n",
      "Iteration 43, loss = 0.95001745\n",
      "Iteration 44, loss = 0.95041188\n",
      "Iteration 45, loss = 0.96774931\n",
      "Iteration 46, loss = 0.95666424\n",
      "Iteration 47, loss = 0.93796267\n",
      "Iteration 34, loss = 0.98997028\n",
      "Iteration 35, loss = 0.94821270\n",
      "Iteration 36, loss = 0.94020523\n",
      "Iteration 37, loss = 0.96072724\n",
      "Iteration 38, loss = 0.94856820\n",
      "Iteration 39, loss = 1.06232737\n",
      "Iteration 40, loss = 0.98450902\n",
      "Iteration 41, loss = 0.94867879\n",
      "Iteration 42, loss = 0.93418141\n",
      "Iteration 43, loss = 0.95001745\n",
      "Iteration 44, loss = 0.95041188\n",
      "Iteration 45, loss = 0.96774931\n",
      "Iteration 46, loss = 0.95666424\n",
      "Iteration 47, loss = 0.93796267\n",
      "Iteration 48, loss = 0.94756537\n",
      "Iteration 49, loss = 0.93050052\n",
      "Iteration 50, loss = 0.92122563\n",
      "Iteration 1, loss = 1.17591372\n",
      "Iteration 2, loss = 1.09748093\n",
      "Iteration 3, loss = 0.99811079\n",
      "Iteration 4, loss = 0.99275652\n",
      "Iteration 5, loss = 0.96654072\n",
      "Iteration 6, loss = 1.01636524\n",
      "Iteration 7, loss = 0.96327220\n",
      "Iteration 8, loss = 1.05335657\n",
      "Iteration 9, loss = 0.98773141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.94756537\n",
      "Iteration 49, loss = 0.93050052\n",
      "Iteration 50, loss = 0.92122563\n",
      "Iteration 1, loss = 1.17591372\n",
      "Iteration 2, loss = 1.09748093\n",
      "Iteration 3, loss = 0.99811079\n",
      "Iteration 4, loss = 0.99275652\n",
      "Iteration 5, loss = 0.96654072\n",
      "Iteration 6, loss = 1.01636524\n",
      "Iteration 7, loss = 0.96327220\n",
      "Iteration 8, loss = 1.05335657\n",
      "Iteration 9, loss = 0.98773141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.99540782\n",
      "Iteration 11, loss = 0.92086806\n",
      "Iteration 12, loss = 0.94363649\n",
      "Iteration 13, loss = 1.00817384\n",
      "Iteration 14, loss = 0.91522370\n",
      "Iteration 15, loss = 0.95557937\n",
      "Iteration 16, loss = 1.02448559\n",
      "Iteration 17, loss = 0.91978695\n",
      "Iteration 18, loss = 0.96863440\n",
      "Iteration 19, loss = 0.95616200\n",
      "Iteration 20, loss = 0.92517831\n",
      "Iteration 21, loss = 0.95821845\n",
      "Iteration 22, loss = 0.92205844\n",
      "Iteration 23, loss = 0.89838955\n",
      "Iteration 10, loss = 0.99540782\n",
      "Iteration 11, loss = 0.92086806\n",
      "Iteration 12, loss = 0.94363649\n",
      "Iteration 13, loss = 1.00817384\n",
      "Iteration 14, loss = 0.91522370\n",
      "Iteration 15, loss = 0.95557937\n",
      "Iteration 16, loss = 1.02448559\n",
      "Iteration 17, loss = 0.91978695\n",
      "Iteration 18, loss = 0.96863440\n",
      "Iteration 19, loss = 0.95616200\n",
      "Iteration 20, loss = 0.92517831\n",
      "Iteration 21, loss = 0.95821845\n",
      "Iteration 22, loss = 0.92205844\n",
      "Iteration 23, loss = 0.89838955\n",
      "Iteration 24, loss = 0.91579183\n",
      "Iteration 25, loss = 0.97498358\n",
      "Iteration 26, loss = 0.95071960\n",
      "Iteration 27, loss = 0.96401069\n",
      "Iteration 28, loss = 0.92138449\n",
      "Iteration 29, loss = 0.88831274\n",
      "Iteration 30, loss = 0.91434419\n",
      "Iteration 31, loss = 0.91361708\n",
      "Iteration 32, loss = 0.96074963\n",
      "Iteration 33, loss = 0.87325455\n",
      "Iteration 34, loss = 0.91500002\n",
      "Iteration 35, loss = 1.00268380\n",
      "Iteration 36, loss = 1.02156735\n",
      "Iteration 37, loss = 0.93950861\n",
      "Iteration 38, loss = 1.02803901\n",
      "Iteration 24, loss = 0.91579183\n",
      "Iteration 25, loss = 0.97498358\n",
      "Iteration 26, loss = 0.95071960\n",
      "Iteration 27, loss = 0.96401069\n",
      "Iteration 28, loss = 0.92138449\n",
      "Iteration 29, loss = 0.88831274\n",
      "Iteration 30, loss = 0.91434419\n",
      "Iteration 31, loss = 0.91361708\n",
      "Iteration 32, loss = 0.96074963\n",
      "Iteration 33, loss = 0.87325455\n",
      "Iteration 34, loss = 0.91500002\n",
      "Iteration 35, loss = 1.00268380\n",
      "Iteration 36, loss = 1.02156735\n",
      "Iteration 37, loss = 0.93950861\n",
      "Iteration 38, loss = 1.02803901\n",
      "Iteration 39, loss = 0.93471638\n",
      "Iteration 40, loss = 0.90897353\n",
      "Iteration 41, loss = 0.92873634\n",
      "Iteration 42, loss = 0.89515712\n",
      "Iteration 43, loss = 0.95571292\n",
      "Iteration 44, loss = 0.94758401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21619103\n",
      "Iteration 2, loss = 1.14629552\n",
      "Iteration 3, loss = 1.08214879\n",
      "Iteration 4, loss = 0.99144081\n",
      "Iteration 5, loss = 1.00693377\n",
      "Iteration 6, loss = 0.96846238\n",
      "Iteration 7, loss = 0.99859452\n",
      "Iteration 39, loss = 0.93471638\n",
      "Iteration 40, loss = 0.90897353\n",
      "Iteration 41, loss = 0.92873634\n",
      "Iteration 42, loss = 0.89515712\n",
      "Iteration 43, loss = 0.95571292\n",
      "Iteration 44, loss = 0.94758401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21619103\n",
      "Iteration 2, loss = 1.14629552\n",
      "Iteration 3, loss = 1.08214879\n",
      "Iteration 4, loss = 0.99144081\n",
      "Iteration 5, loss = 1.00693377\n",
      "Iteration 6, loss = 0.96846238\n",
      "Iteration 7, loss = 0.99859452\n",
      "Iteration 8, loss = 0.97593364\n",
      "Iteration 9, loss = 0.94206936\n",
      "Iteration 10, loss = 0.94567295\n",
      "Iteration 11, loss = 0.97254706\n",
      "Iteration 12, loss = 0.98489409\n",
      "Iteration 13, loss = 0.99917149\n",
      "Iteration 14, loss = 0.98624347\n",
      "Iteration 15, loss = 0.97680866\n",
      "Iteration 16, loss = 0.98467212\n",
      "Iteration 17, loss = 0.95633598\n",
      "Iteration 18, loss = 0.99029537\n",
      "Iteration 19, loss = 0.94405118\n",
      "Iteration 20, loss = 0.96136429\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22731989\n",
      "Iteration 8, loss = 0.97593364\n",
      "Iteration 9, loss = 0.94206936\n",
      "Iteration 10, loss = 0.94567295\n",
      "Iteration 11, loss = 0.97254706\n",
      "Iteration 12, loss = 0.98489409\n",
      "Iteration 13, loss = 0.99917149\n",
      "Iteration 14, loss = 0.98624347\n",
      "Iteration 15, loss = 0.97680866\n",
      "Iteration 16, loss = 0.98467212\n",
      "Iteration 17, loss = 0.95633598\n",
      "Iteration 18, loss = 0.99029537\n",
      "Iteration 19, loss = 0.94405118\n",
      "Iteration 20, loss = 0.96136429\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22731989\n",
      "Iteration 2, loss = 1.09251313\n",
      "Iteration 3, loss = 1.02908475\n",
      "Iteration 4, loss = 1.03387819\n",
      "Iteration 5, loss = 1.05126476\n",
      "Iteration 6, loss = 1.01660627\n",
      "Iteration 7, loss = 1.00334088\n",
      "Iteration 8, loss = 0.98091388\n",
      "Iteration 9, loss = 1.00697887\n",
      "Iteration 10, loss = 0.98367659\n",
      "Iteration 11, loss = 0.97070771\n",
      "Iteration 12, loss = 0.97619023\n",
      "Iteration 2, loss = 1.09251313\n",
      "Iteration 3, loss = 1.02908475\n",
      "Iteration 4, loss = 1.03387819\n",
      "Iteration 5, loss = 1.05126476\n",
      "Iteration 6, loss = 1.01660627\n",
      "Iteration 7, loss = 1.00334088\n",
      "Iteration 8, loss = 0.98091388\n",
      "Iteration 9, loss = 1.00697887\n",
      "Iteration 10, loss = 0.98367659\n",
      "Iteration 11, loss = 0.97070771\n",
      "Iteration 12, loss = 0.97619023\n",
      "Iteration 13, loss = 0.99558604\n",
      "Iteration 14, loss = 0.95733991\n",
      "Iteration 15, loss = 1.02829585\n",
      "Iteration 16, loss = 1.01962285\n",
      "Iteration 17, loss = 1.00869345\n",
      "Iteration 18, loss = 1.07087195\n",
      "Iteration 19, loss = 1.02563410\n",
      "Iteration 20, loss = 1.03177996\n",
      "Iteration 21, loss = 0.98745218\n",
      "Iteration 22, loss = 1.04411370\n",
      "Iteration 23, loss = 1.03326814\n",
      "Iteration 24, loss = 1.03229636\n",
      "Iteration 25, loss = 0.99834348\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23138776\n",
      "Iteration 13, loss = 0.99558604\n",
      "Iteration 14, loss = 0.95733991\n",
      "Iteration 15, loss = 1.02829585\n",
      "Iteration 16, loss = 1.01962285\n",
      "Iteration 17, loss = 1.00869345\n",
      "Iteration 18, loss = 1.07087195\n",
      "Iteration 19, loss = 1.02563410\n",
      "Iteration 20, loss = 1.03177996\n",
      "Iteration 21, loss = 0.98745218\n",
      "Iteration 22, loss = 1.04411370\n",
      "Iteration 23, loss = 1.03326814\n",
      "Iteration 24, loss = 1.03229636\n",
      "Iteration 25, loss = 0.99834348\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23138776\n",
      "Iteration 2, loss = 1.13634414\n",
      "Iteration 3, loss = 0.99960090\n",
      "Iteration 4, loss = 0.99281029\n",
      "Iteration 5, loss = 1.02008113\n",
      "Iteration 6, loss = 0.95393597\n",
      "Iteration 7, loss = 0.98099506\n",
      "Iteration 8, loss = 0.98553403\n",
      "Iteration 9, loss = 0.96644247\n",
      "Iteration 10, loss = 1.03567465\n",
      "Iteration 11, loss = 1.02989240\n",
      "Iteration 12, loss = 1.00279490\n",
      "Iteration 13, loss = 0.96846620\n",
      "Iteration 2, loss = 1.13634414\n",
      "Iteration 3, loss = 0.99960090\n",
      "Iteration 4, loss = 0.99281029\n",
      "Iteration 5, loss = 1.02008113\n",
      "Iteration 6, loss = 0.95393597\n",
      "Iteration 7, loss = 0.98099506\n",
      "Iteration 8, loss = 0.98553403\n",
      "Iteration 9, loss = 0.96644247\n",
      "Iteration 10, loss = 1.03567465\n",
      "Iteration 11, loss = 1.02989240\n",
      "Iteration 12, loss = 1.00279490\n",
      "Iteration 13, loss = 0.96846620\n",
      "Iteration 14, loss = 0.95860771\n",
      "Iteration 15, loss = 0.99095382\n",
      "Iteration 16, loss = 0.98283147\n",
      "Iteration 17, loss = 0.99496353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29383425\n",
      "Iteration 2, loss = 1.22107106\n",
      "Iteration 3, loss = 1.10173858\n",
      "Iteration 4, loss = 1.01403034\n",
      "Iteration 5, loss = 1.01060812\n",
      "Iteration 6, loss = 1.02047531\n",
      "Iteration 7, loss = 0.99091045\n",
      "Iteration 8, loss = 0.97447332\n",
      "Iteration 9, loss = 1.01902676\n",
      "Iteration 14, loss = 0.95860771\n",
      "Iteration 15, loss = 0.99095382\n",
      "Iteration 16, loss = 0.98283147\n",
      "Iteration 17, loss = 0.99496353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29383425\n",
      "Iteration 2, loss = 1.22107106\n",
      "Iteration 3, loss = 1.10173858\n",
      "Iteration 4, loss = 1.01403034\n",
      "Iteration 5, loss = 1.01060812\n",
      "Iteration 6, loss = 1.02047531\n",
      "Iteration 7, loss = 0.99091045\n",
      "Iteration 8, loss = 0.97447332\n",
      "Iteration 9, loss = 1.01902676\n",
      "Iteration 10, loss = 1.08043272\n",
      "Iteration 11, loss = 0.97785036\n",
      "Iteration 12, loss = 0.97584697\n",
      "Iteration 13, loss = 0.97335582\n",
      "Iteration 14, loss = 0.96915507\n",
      "Iteration 15, loss = 0.96894288\n",
      "Iteration 16, loss = 0.96710962\n",
      "Iteration 17, loss = 0.97996399\n",
      "Iteration 18, loss = 1.00226016\n",
      "Iteration 19, loss = 1.01757937\n",
      "Iteration 20, loss = 0.98504494\n",
      "Iteration 21, loss = 1.03868911\n",
      "Iteration 22, loss = 0.97859392\n",
      "Iteration 23, loss = 0.97557568\n",
      "Iteration 10, loss = 1.08043272\n",
      "Iteration 11, loss = 0.97785036\n",
      "Iteration 12, loss = 0.97584697\n",
      "Iteration 13, loss = 0.97335582\n",
      "Iteration 14, loss = 0.96915507\n",
      "Iteration 15, loss = 0.96894288\n",
      "Iteration 16, loss = 0.96710962\n",
      "Iteration 17, loss = 0.97996399\n",
      "Iteration 18, loss = 1.00226016\n",
      "Iteration 19, loss = 1.01757937\n",
      "Iteration 20, loss = 0.98504494\n",
      "Iteration 21, loss = 1.03868911\n",
      "Iteration 22, loss = 0.97859392\n",
      "Iteration 23, loss = 0.97557568\n",
      "Iteration 24, loss = 0.95797267\n",
      "Iteration 25, loss = 0.96372732\n",
      "Iteration 26, loss = 1.00650651\n",
      "Iteration 27, loss = 0.96046619\n",
      "Iteration 28, loss = 0.95773119\n",
      "Iteration 29, loss = 0.95018638\n",
      "Iteration 30, loss = 0.96150826\n",
      "Iteration 31, loss = 0.94870827\n",
      "Iteration 32, loss = 0.94012868\n",
      "Iteration 33, loss = 0.94055373\n",
      "Iteration 34, loss = 0.98997028\n",
      "Iteration 35, loss = 0.94821270\n",
      "Iteration 36, loss = 0.94020523\n",
      "Iteration 37, loss = 0.96072724\n",
      "Iteration 38, loss = 0.94856820\n",
      "Iteration 24, loss = 0.95797267\n",
      "Iteration 25, loss = 0.96372732\n",
      "Iteration 26, loss = 1.00650651\n",
      "Iteration 27, loss = 0.96046619\n",
      "Iteration 28, loss = 0.95773119\n",
      "Iteration 29, loss = 0.95018638\n",
      "Iteration 30, loss = 0.96150826\n",
      "Iteration 31, loss = 0.94870827\n",
      "Iteration 32, loss = 0.94012868\n",
      "Iteration 33, loss = 0.94055373\n",
      "Iteration 34, loss = 0.98997028\n",
      "Iteration 35, loss = 0.94821270\n",
      "Iteration 36, loss = 0.94020523\n",
      "Iteration 37, loss = 0.96072724\n",
      "Iteration 38, loss = 0.94856820\n",
      "Iteration 39, loss = 1.06232737\n",
      "Iteration 40, loss = 0.98450902\n",
      "Iteration 41, loss = 0.94867879\n",
      "Iteration 42, loss = 0.93418141\n",
      "Iteration 43, loss = 0.95001745\n",
      "Iteration 44, loss = 0.95041188\n",
      "Iteration 45, loss = 0.96774931\n",
      "Iteration 46, loss = 0.95666424\n",
      "Iteration 47, loss = 0.93796267\n",
      "Iteration 48, loss = 0.94756537\n",
      "Iteration 49, loss = 0.93050052\n",
      "Iteration 50, loss = 0.92122563\n",
      "Iteration 51, loss = 0.93888983\n",
      "Iteration 52, loss = 0.94757196\n",
      "Iteration 53, loss = 0.95271475\n",
      "Iteration 39, loss = 1.06232737\n",
      "Iteration 40, loss = 0.98450902\n",
      "Iteration 41, loss = 0.94867879\n",
      "Iteration 42, loss = 0.93418141\n",
      "Iteration 43, loss = 0.95001745\n",
      "Iteration 44, loss = 0.95041188\n",
      "Iteration 45, loss = 0.96774931\n",
      "Iteration 46, loss = 0.95666424\n",
      "Iteration 47, loss = 0.93796267\n",
      "Iteration 48, loss = 0.94756537\n",
      "Iteration 49, loss = 0.93050052\n",
      "Iteration 50, loss = 0.92122563\n",
      "Iteration 51, loss = 0.93888983\n",
      "Iteration 52, loss = 0.94757196\n",
      "Iteration 53, loss = 0.95271475\n",
      "Iteration 54, loss = 0.93642436\n",
      "Iteration 55, loss = 0.94605235\n",
      "Iteration 56, loss = 0.93868074\n",
      "Iteration 57, loss = 0.94469366\n",
      "Iteration 58, loss = 0.92644787\n",
      "Iteration 59, loss = 0.93306092\n",
      "Iteration 60, loss = 0.93737000\n",
      "Iteration 61, loss = 0.95469703\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17591372\n",
      "Iteration 2, loss = 1.09748093\n",
      "Iteration 3, loss = 0.99811079\n",
      "Iteration 4, loss = 0.99275652\n",
      "Iteration 5, loss = 0.96654072\n",
      "Iteration 6, loss = 1.01636524\n",
      "Iteration 7, loss = 0.96327220\n",
      "Iteration 54, loss = 0.93642436\n",
      "Iteration 55, loss = 0.94605235\n",
      "Iteration 56, loss = 0.93868074\n",
      "Iteration 57, loss = 0.94469366\n",
      "Iteration 58, loss = 0.92644787\n",
      "Iteration 59, loss = 0.93306092\n",
      "Iteration 60, loss = 0.93737000\n",
      "Iteration 61, loss = 0.95469703\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17591372\n",
      "Iteration 2, loss = 1.09748093\n",
      "Iteration 3, loss = 0.99811079\n",
      "Iteration 4, loss = 0.99275652\n",
      "Iteration 5, loss = 0.96654072\n",
      "Iteration 6, loss = 1.01636524\n",
      "Iteration 7, loss = 0.96327220\n",
      "Iteration 8, loss = 1.05335657\n",
      "Iteration 9, loss = 0.98773141\n",
      "Iteration 10, loss = 0.99540782\n",
      "Iteration 11, loss = 0.92086806\n",
      "Iteration 12, loss = 0.94363649\n",
      "Iteration 13, loss = 1.00817384\n",
      "Iteration 14, loss = 0.91522370\n",
      "Iteration 15, loss = 0.95557937\n",
      "Iteration 16, loss = 1.02448559\n",
      "Iteration 17, loss = 0.91978695\n",
      "Iteration 18, loss = 0.96863440\n",
      "Iteration 19, loss = 0.95616200\n",
      "Iteration 20, loss = 0.92517831\n",
      "Iteration 21, loss = 0.95821845\n",
      "Iteration 8, loss = 1.05335657\n",
      "Iteration 9, loss = 0.98773141\n",
      "Iteration 10, loss = 0.99540782\n",
      "Iteration 11, loss = 0.92086806\n",
      "Iteration 12, loss = 0.94363649\n",
      "Iteration 13, loss = 1.00817384\n",
      "Iteration 14, loss = 0.91522370\n",
      "Iteration 15, loss = 0.95557937\n",
      "Iteration 16, loss = 1.02448559\n",
      "Iteration 17, loss = 0.91978695\n",
      "Iteration 18, loss = 0.96863440\n",
      "Iteration 19, loss = 0.95616200\n",
      "Iteration 20, loss = 0.92517831\n",
      "Iteration 21, loss = 0.95821845\n",
      "Iteration 22, loss = 0.92205844\n",
      "Iteration 23, loss = 0.89838955\n",
      "Iteration 24, loss = 0.91579183\n",
      "Iteration 25, loss = 0.97498358\n",
      "Iteration 26, loss = 0.95071960\n",
      "Iteration 27, loss = 0.96401069\n",
      "Iteration 28, loss = 0.92138449\n",
      "Iteration 29, loss = 0.88831274\n",
      "Iteration 30, loss = 0.91434419\n",
      "Iteration 31, loss = 0.91361708\n",
      "Iteration 32, loss = 0.96074963\n",
      "Iteration 33, loss = 0.87325455\n",
      "Iteration 34, loss = 0.91500002\n",
      "Iteration 35, loss = 1.00268380\n",
      "Iteration 36, loss = 1.02156735\n",
      "Iteration 22, loss = 0.92205844\n",
      "Iteration 23, loss = 0.89838955\n",
      "Iteration 24, loss = 0.91579183\n",
      "Iteration 25, loss = 0.97498358\n",
      "Iteration 26, loss = 0.95071960\n",
      "Iteration 27, loss = 0.96401069\n",
      "Iteration 28, loss = 0.92138449\n",
      "Iteration 29, loss = 0.88831274\n",
      "Iteration 30, loss = 0.91434419\n",
      "Iteration 31, loss = 0.91361708\n",
      "Iteration 32, loss = 0.96074963\n",
      "Iteration 33, loss = 0.87325455\n",
      "Iteration 34, loss = 0.91500002\n",
      "Iteration 35, loss = 1.00268380\n",
      "Iteration 36, loss = 1.02156735\n",
      "Iteration 37, loss = 0.93950861\n",
      "Iteration 38, loss = 1.02803901\n",
      "Iteration 39, loss = 0.93471638\n",
      "Iteration 40, loss = 0.90897353\n",
      "Iteration 41, loss = 0.92873634\n",
      "Iteration 42, loss = 0.89515712\n",
      "Iteration 43, loss = 0.95571292\n",
      "Iteration 44, loss = 0.94758401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21619103\n",
      "Iteration 2, loss = 1.14629552\n",
      "Iteration 3, loss = 1.08214879\n",
      "Iteration 4, loss = 0.99144081\n",
      "Iteration 5, loss = 1.00693377\n",
      "Iteration 37, loss = 0.93950861\n",
      "Iteration 38, loss = 1.02803901\n",
      "Iteration 39, loss = 0.93471638\n",
      "Iteration 40, loss = 0.90897353\n",
      "Iteration 41, loss = 0.92873634\n",
      "Iteration 42, loss = 0.89515712\n",
      "Iteration 43, loss = 0.95571292\n",
      "Iteration 44, loss = 0.94758401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21619103\n",
      "Iteration 2, loss = 1.14629552\n",
      "Iteration 3, loss = 1.08214879\n",
      "Iteration 4, loss = 0.99144081\n",
      "Iteration 5, loss = 1.00693377\n",
      "Iteration 6, loss = 0.96846238\n",
      "Iteration 7, loss = 0.99859452\n",
      "Iteration 8, loss = 0.97593364\n",
      "Iteration 9, loss = 0.94206936\n",
      "Iteration 10, loss = 0.94567295\n",
      "Iteration 11, loss = 0.97254706\n",
      "Iteration 12, loss = 0.98489409\n",
      "Iteration 13, loss = 0.99917149\n",
      "Iteration 14, loss = 0.98624347\n",
      "Iteration 15, loss = 0.97680866\n",
      "Iteration 16, loss = 0.98467212\n",
      "Iteration 17, loss = 0.95633598\n",
      "Iteration 18, loss = 0.99029537\n",
      "Iteration 6, loss = 0.96846238\n",
      "Iteration 7, loss = 0.99859452\n",
      "Iteration 8, loss = 0.97593364\n",
      "Iteration 9, loss = 0.94206936\n",
      "Iteration 10, loss = 0.94567295\n",
      "Iteration 11, loss = 0.97254706\n",
      "Iteration 12, loss = 0.98489409\n",
      "Iteration 13, loss = 0.99917149\n",
      "Iteration 14, loss = 0.98624347\n",
      "Iteration 15, loss = 0.97680866\n",
      "Iteration 16, loss = 0.98467212\n",
      "Iteration 17, loss = 0.95633598\n",
      "Iteration 18, loss = 0.99029537\n",
      "Iteration 19, loss = 0.94405118\n",
      "Iteration 20, loss = 0.96136429\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22731989\n",
      "Iteration 2, loss = 1.09251313\n",
      "Iteration 3, loss = 1.02908475\n",
      "Iteration 4, loss = 1.03387819\n",
      "Iteration 5, loss = 1.05126476\n",
      "Iteration 6, loss = 1.01660627\n",
      "Iteration 7, loss = 1.00334088\n",
      "Iteration 8, loss = 0.98091388\n",
      "Iteration 9, loss = 1.00697887\n",
      "Iteration 10, loss = 0.98367659\n",
      "Iteration 19, loss = 0.94405118\n",
      "Iteration 20, loss = 0.96136429\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22731989\n",
      "Iteration 2, loss = 1.09251313\n",
      "Iteration 3, loss = 1.02908475\n",
      "Iteration 4, loss = 1.03387819\n",
      "Iteration 5, loss = 1.05126476\n",
      "Iteration 6, loss = 1.01660627\n",
      "Iteration 7, loss = 1.00334088\n",
      "Iteration 8, loss = 0.98091388\n",
      "Iteration 9, loss = 1.00697887\n",
      "Iteration 10, loss = 0.98367659\n",
      "Iteration 11, loss = 0.97070771\n",
      "Iteration 12, loss = 0.97619023\n",
      "Iteration 13, loss = 0.99558604\n",
      "Iteration 14, loss = 0.95733991\n",
      "Iteration 15, loss = 1.02829585\n",
      "Iteration 16, loss = 1.01962285\n",
      "Iteration 17, loss = 1.00869345\n",
      "Iteration 18, loss = 1.07087195\n",
      "Iteration 19, loss = 1.02563410\n",
      "Iteration 20, loss = 1.03177996\n",
      "Iteration 21, loss = 0.98745218\n",
      "Iteration 22, loss = 1.04411370\n",
      "Iteration 23, loss = 1.03326814\n",
      "Iteration 24, loss = 1.03229636\n",
      "Iteration 25, loss = 0.99834348\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.97070771\n",
      "Iteration 12, loss = 0.97619023\n",
      "Iteration 13, loss = 0.99558604\n",
      "Iteration 14, loss = 0.95733991\n",
      "Iteration 15, loss = 1.02829585\n",
      "Iteration 16, loss = 1.01962285\n",
      "Iteration 17, loss = 1.00869345\n",
      "Iteration 18, loss = 1.07087195\n",
      "Iteration 19, loss = 1.02563410\n",
      "Iteration 20, loss = 1.03177996\n",
      "Iteration 21, loss = 0.98745218\n",
      "Iteration 22, loss = 1.04411370\n",
      "Iteration 23, loss = 1.03326814\n",
      "Iteration 24, loss = 1.03229636\n",
      "Iteration 25, loss = 0.99834348\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23138776\n",
      "Iteration 2, loss = 1.13634414\n",
      "Iteration 3, loss = 0.99960090\n",
      "Iteration 4, loss = 0.99281029\n",
      "Iteration 5, loss = 1.02008113\n",
      "Iteration 6, loss = 0.95393597\n",
      "Iteration 7, loss = 0.98099506\n",
      "Iteration 8, loss = 0.98553403\n",
      "Iteration 9, loss = 0.96644247\n",
      "Iteration 10, loss = 1.03567465\n",
      "Iteration 11, loss = 1.02989240\n",
      "Iteration 12, loss = 1.00279490\n",
      "Iteration 13, loss = 0.96846620\n",
      "Iteration 14, loss = 0.95860771\n",
      "Iteration 1, loss = 1.23138776\n",
      "Iteration 2, loss = 1.13634414\n",
      "Iteration 3, loss = 0.99960090\n",
      "Iteration 4, loss = 0.99281029\n",
      "Iteration 5, loss = 1.02008113\n",
      "Iteration 6, loss = 0.95393597\n",
      "Iteration 7, loss = 0.98099506\n",
      "Iteration 8, loss = 0.98553403\n",
      "Iteration 9, loss = 0.96644247\n",
      "Iteration 10, loss = 1.03567465\n",
      "Iteration 11, loss = 1.02989240\n",
      "Iteration 12, loss = 1.00279490\n",
      "Iteration 13, loss = 0.96846620\n",
      "Iteration 14, loss = 0.95860771\n",
      "Iteration 15, loss = 0.99095382\n",
      "Iteration 16, loss = 0.98283147\n",
      "Iteration 17, loss = 0.99496353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27792661\n",
      "Iteration 2, loss = 1.18399969\n",
      "Iteration 3, loss = 1.14433759\n",
      "Iteration 4, loss = 1.03548086\n",
      "Iteration 5, loss = 1.03050401\n",
      "Iteration 6, loss = 1.03700569\n",
      "Iteration 7, loss = 1.07005369\n",
      "Iteration 8, loss = 1.01645413\n",
      "Iteration 9, loss = 1.12181877\n",
      "Iteration 15, loss = 0.99095382\n",
      "Iteration 16, loss = 0.98283147\n",
      "Iteration 17, loss = 0.99496353\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27792661\n",
      "Iteration 2, loss = 1.18399969\n",
      "Iteration 3, loss = 1.14433759\n",
      "Iteration 4, loss = 1.03548086\n",
      "Iteration 5, loss = 1.03050401\n",
      "Iteration 6, loss = 1.03700569\n",
      "Iteration 7, loss = 1.07005369\n",
      "Iteration 8, loss = 1.01645413\n",
      "Iteration 9, loss = 1.12181877\n",
      "Iteration 10, loss = 1.12336541\n",
      "Iteration 1, loss = 1.18124993\n",
      "Iteration 2, loss = 1.04676682\n",
      "Iteration 3, loss = 0.95920813\n",
      "Iteration 4, loss = 0.99922511\n",
      "Iteration 5, loss = 0.95909927\n",
      "Iteration 6, loss = 1.00233556\n",
      "Iteration 7, loss = 0.97970078\n",
      "Iteration 8, loss = 1.00234333\n",
      "Iteration 9, loss = 0.99696446\n",
      "Iteration 10, loss = 1.15740115\n",
      "Iteration 1, loss = 1.24306326\n",
      "Iteration 10, loss = 1.12336541\n",
      "Iteration 1, loss = 1.18124993\n",
      "Iteration 2, loss = 1.04676682\n",
      "Iteration 3, loss = 0.95920813\n",
      "Iteration 4, loss = 0.99922511\n",
      "Iteration 5, loss = 0.95909927\n",
      "Iteration 6, loss = 1.00233556\n",
      "Iteration 7, loss = 0.97970078\n",
      "Iteration 8, loss = 1.00234333\n",
      "Iteration 9, loss = 0.99696446\n",
      "Iteration 10, loss = 1.15740115\n",
      "Iteration 1, loss = 1.24306326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.16800733\n",
      "Iteration 3, loss = 1.08807803\n",
      "Iteration 4, loss = 1.17984837\n",
      "Iteration 5, loss = 1.26923703\n",
      "Iteration 6, loss = 1.25934030\n",
      "Iteration 7, loss = 1.27258934\n",
      "Iteration 8, loss = 1.27414150\n",
      "Iteration 9, loss = 1.26245247\n",
      "Iteration 10, loss = 1.26495253\n",
      "Iteration 1, loss = 1.25299888\n",
      "Iteration 2, loss = 1.13510334\n",
      "Iteration 3, loss = 1.02417425\n",
      "Iteration 2, loss = 1.16800733\n",
      "Iteration 3, loss = 1.08807803\n",
      "Iteration 4, loss = 1.17984837\n",
      "Iteration 5, loss = 1.26923703\n",
      "Iteration 6, loss = 1.25934030\n",
      "Iteration 7, loss = 1.27258934\n",
      "Iteration 8, loss = 1.27414150\n",
      "Iteration 9, loss = 1.26245247\n",
      "Iteration 10, loss = 1.26495253\n",
      "Iteration 1, loss = 1.25299888\n",
      "Iteration 2, loss = 1.13510334\n",
      "Iteration 3, loss = 1.02417425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.08000839\n",
      "Iteration 5, loss = 1.28025996\n",
      "Iteration 6, loss = 1.26860417\n",
      "Iteration 7, loss = 1.25612496\n",
      "Iteration 8, loss = 1.25482085\n",
      "Iteration 9, loss = 1.24553383\n",
      "Iteration 10, loss = 1.24840006\n",
      "Iteration 1, loss = 1.24511917\n",
      "Iteration 2, loss = 1.15659879\n",
      "Iteration 3, loss = 1.12002812\n",
      "Iteration 4, loss = 1.08716198\n",
      "Iteration 5, loss = 1.18339740\n",
      "Iteration 4, loss = 1.08000839\n",
      "Iteration 5, loss = 1.28025996\n",
      "Iteration 6, loss = 1.26860417\n",
      "Iteration 7, loss = 1.25612496\n",
      "Iteration 8, loss = 1.25482085\n",
      "Iteration 9, loss = 1.24553383\n",
      "Iteration 10, loss = 1.24840006\n",
      "Iteration 1, loss = 1.24511917\n",
      "Iteration 2, loss = 1.15659879\n",
      "Iteration 3, loss = 1.12002812\n",
      "Iteration 4, loss = 1.08716198\n",
      "Iteration 5, loss = 1.18339740\n",
      "Iteration 6, loss = 1.29915869\n",
      "Iteration 7, loss = 1.27745286\n",
      "Iteration 8, loss = 1.27853286\n",
      "Iteration 9, loss = 1.27178550\n",
      "Iteration 10, loss = 1.27380708\n",
      "Iteration 1, loss = 1.27792661\n",
      "Iteration 2, loss = 1.18399969\n",
      "Iteration 3, loss = 1.14433759\n",
      "Iteration 4, loss = 1.03548086\n",
      "Iteration 5, loss = 1.03050401\n",
      "Iteration 6, loss = 1.03700569\n",
      "Iteration 7, loss = 1.07005369\n",
      "Iteration 6, loss = 1.29915869\n",
      "Iteration 7, loss = 1.27745286\n",
      "Iteration 8, loss = 1.27853286\n",
      "Iteration 9, loss = 1.27178550\n",
      "Iteration 10, loss = 1.27380708\n",
      "Iteration 1, loss = 1.27792661\n",
      "Iteration 2, loss = 1.18399969\n",
      "Iteration 3, loss = 1.14433759\n",
      "Iteration 4, loss = 1.03548086\n",
      "Iteration 5, loss = 1.03050401\n",
      "Iteration 6, loss = 1.03700569\n",
      "Iteration 7, loss = 1.07005369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 1.01645413\n",
      "Iteration 9, loss = 1.12181877\n",
      "Iteration 10, loss = 1.12336541\n",
      "Iteration 11, loss = 1.18993088\n",
      "Iteration 12, loss = 1.23136747\n",
      "Iteration 13, loss = 1.09944415\n",
      "Iteration 14, loss = 1.02634123\n",
      "Iteration 15, loss = 1.22159970\n",
      "Iteration 16, loss = 1.26115722\n",
      "Iteration 17, loss = 1.16503133\n",
      "Iteration 18, loss = 1.11206908\n",
      "Iteration 19, loss = 1.26242880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18124993\n",
      "Iteration 8, loss = 1.01645413\n",
      "Iteration 9, loss = 1.12181877\n",
      "Iteration 10, loss = 1.12336541\n",
      "Iteration 11, loss = 1.18993088\n",
      "Iteration 12, loss = 1.23136747\n",
      "Iteration 13, loss = 1.09944415\n",
      "Iteration 14, loss = 1.02634123\n",
      "Iteration 15, loss = 1.22159970\n",
      "Iteration 16, loss = 1.26115722\n",
      "Iteration 17, loss = 1.16503133\n",
      "Iteration 18, loss = 1.11206908\n",
      "Iteration 19, loss = 1.26242880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18124993\n",
      "Iteration 2, loss = 1.04676682\n",
      "Iteration 3, loss = 0.95920813\n",
      "Iteration 4, loss = 0.99922511\n",
      "Iteration 5, loss = 0.95909927\n",
      "Iteration 6, loss = 1.00233556\n",
      "Iteration 7, loss = 0.97970078\n",
      "Iteration 8, loss = 1.00234333\n",
      "Iteration 9, loss = 0.99696446\n",
      "Iteration 10, loss = 1.15740115\n",
      "Iteration 11, loss = 1.04999235\n",
      "Iteration 12, loss = 0.97244943\n",
      "Iteration 13, loss = 0.99271825\n",
      "Iteration 2, loss = 1.04676682\n",
      "Iteration 3, loss = 0.95920813\n",
      "Iteration 4, loss = 0.99922511\n",
      "Iteration 5, loss = 0.95909927\n",
      "Iteration 6, loss = 1.00233556\n",
      "Iteration 7, loss = 0.97970078\n",
      "Iteration 8, loss = 1.00234333\n",
      "Iteration 9, loss = 0.99696446\n",
      "Iteration 10, loss = 1.15740115\n",
      "Iteration 11, loss = 1.04999235\n",
      "Iteration 12, loss = 0.97244943\n",
      "Iteration 13, loss = 0.99271825\n",
      "Iteration 14, loss = 0.94990058\n",
      "Iteration 15, loss = 0.94770527\n",
      "Iteration 16, loss = 0.96154173\n",
      "Iteration 17, loss = 0.96015840\n",
      "Iteration 18, loss = 1.03325133\n",
      "Iteration 19, loss = 0.96540185\n",
      "Iteration 20, loss = 0.95464293\n",
      "Iteration 21, loss = 0.96487106\n",
      "Iteration 22, loss = 0.95846799\n",
      "Iteration 23, loss = 0.95056709\n",
      "Iteration 24, loss = 0.95509902\n",
      "Iteration 25, loss = 0.97406757\n",
      "Iteration 26, loss = 0.96166258\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24306326\n",
      "Iteration 14, loss = 0.94990058\n",
      "Iteration 15, loss = 0.94770527\n",
      "Iteration 16, loss = 0.96154173\n",
      "Iteration 17, loss = 0.96015840\n",
      "Iteration 18, loss = 1.03325133\n",
      "Iteration 19, loss = 0.96540185\n",
      "Iteration 20, loss = 0.95464293\n",
      "Iteration 21, loss = 0.96487106\n",
      "Iteration 22, loss = 0.95846799\n",
      "Iteration 23, loss = 0.95056709\n",
      "Iteration 24, loss = 0.95509902\n",
      "Iteration 25, loss = 0.97406757\n",
      "Iteration 26, loss = 0.96166258\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24306326\n",
      "Iteration 2, loss = 1.16800733\n",
      "Iteration 3, loss = 1.08807803\n",
      "Iteration 4, loss = 1.17984837\n",
      "Iteration 5, loss = 1.26923703\n",
      "Iteration 6, loss = 1.25934030\n",
      "Iteration 7, loss = 1.27258934\n",
      "Iteration 8, loss = 1.27414150\n",
      "Iteration 9, loss = 1.26245247\n",
      "Iteration 10, loss = 1.26495253\n",
      "Iteration 11, loss = 1.28557168\n",
      "Iteration 12, loss = 1.27341437\n",
      "Iteration 13, loss = 1.26336036\n",
      "Iteration 14, loss = 1.26638808\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25299888\n",
      "Iteration 2, loss = 1.16800733\n",
      "Iteration 3, loss = 1.08807803\n",
      "Iteration 4, loss = 1.17984837\n",
      "Iteration 5, loss = 1.26923703\n",
      "Iteration 6, loss = 1.25934030\n",
      "Iteration 7, loss = 1.27258934\n",
      "Iteration 8, loss = 1.27414150\n",
      "Iteration 9, loss = 1.26245247\n",
      "Iteration 10, loss = 1.26495253\n",
      "Iteration 11, loss = 1.28557168\n",
      "Iteration 12, loss = 1.27341437\n",
      "Iteration 13, loss = 1.26336036\n",
      "Iteration 14, loss = 1.26638808\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25299888\n",
      "Iteration 2, loss = 1.13510334\n",
      "Iteration 3, loss = 1.02417425\n",
      "Iteration 4, loss = 1.08000839\n",
      "Iteration 5, loss = 1.28025996\n",
      "Iteration 6, loss = 1.26860417\n",
      "Iteration 7, loss = 1.25612496\n",
      "Iteration 8, loss = 1.25482085\n",
      "Iteration 9, loss = 1.24553383\n",
      "Iteration 10, loss = 1.24840006\n",
      "Iteration 11, loss = 1.26000039\n",
      "Iteration 12, loss = 1.26716842\n",
      "Iteration 13, loss = 1.25782294\n",
      "Iteration 14, loss = 1.25428084\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24511917\n",
      "Iteration 2, loss = 1.13510334\n",
      "Iteration 3, loss = 1.02417425\n",
      "Iteration 4, loss = 1.08000839\n",
      "Iteration 5, loss = 1.28025996\n",
      "Iteration 6, loss = 1.26860417\n",
      "Iteration 7, loss = 1.25612496\n",
      "Iteration 8, loss = 1.25482085\n",
      "Iteration 9, loss = 1.24553383\n",
      "Iteration 10, loss = 1.24840006\n",
      "Iteration 11, loss = 1.26000039\n",
      "Iteration 12, loss = 1.26716842\n",
      "Iteration 13, loss = 1.25782294\n",
      "Iteration 14, loss = 1.25428084\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24511917\n",
      "Iteration 2, loss = 1.15659879\n",
      "Iteration 3, loss = 1.12002812\n",
      "Iteration 4, loss = 1.08716198\n",
      "Iteration 5, loss = 1.18339740\n",
      "Iteration 6, loss = 1.29915869\n",
      "Iteration 7, loss = 1.27745286\n",
      "Iteration 8, loss = 1.27853286\n",
      "Iteration 9, loss = 1.27178550\n",
      "Iteration 10, loss = 1.27380708\n",
      "Iteration 11, loss = 1.28109681\n",
      "Iteration 12, loss = 1.27320017\n",
      "Iteration 13, loss = 1.26932303\n",
      "Iteration 14, loss = 1.27493422\n",
      "Iteration 15, loss = 1.25704625\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.Iteration 2, loss = 1.15659879\n",
      "Iteration 3, loss = 1.12002812\n",
      "Iteration 4, loss = 1.08716198\n",
      "Iteration 5, loss = 1.18339740\n",
      "Iteration 6, loss = 1.29915869\n",
      "Iteration 7, loss = 1.27745286\n",
      "Iteration 8, loss = 1.27853286\n",
      "Iteration 9, loss = 1.27178550\n",
      "Iteration 10, loss = 1.27380708\n",
      "Iteration 11, loss = 1.28109681\n",
      "Iteration 12, loss = 1.27320017\n",
      "Iteration 13, loss = 1.26932303\n",
      "Iteration 14, loss = 1.27493422\n",
      "Iteration 15, loss = 1.25704625\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27792661\n",
      "Iteration 2, loss = 1.18399969\n",
      "Iteration 3, loss = 1.14433759\n",
      "Iteration 4, loss = 1.03548086\n",
      "Iteration 5, loss = 1.03050401\n",
      "Iteration 6, loss = 1.03700569\n",
      "Iteration 7, loss = 1.07005369\n",
      "Iteration 8, loss = 1.01645413\n",
      "Iteration 9, loss = 1.12181877\n",
      "Iteration 10, loss = 1.12336541\n",
      "\n",
      "Iteration 1, loss = 1.27792661\n",
      "Iteration 2, loss = 1.18399969\n",
      "Iteration 3, loss = 1.14433759\n",
      "Iteration 4, loss = 1.03548086\n",
      "Iteration 5, loss = 1.03050401\n",
      "Iteration 6, loss = 1.03700569\n",
      "Iteration 7, loss = 1.07005369\n",
      "Iteration 8, loss = 1.01645413\n",
      "Iteration 9, loss = 1.12181877\n",
      "Iteration 10, loss = 1.12336541\n",
      "Iteration 11, loss = 1.18993088\n",
      "Iteration 12, loss = 1.23136747\n",
      "Iteration 13, loss = 1.09944415\n",
      "Iteration 14, loss = 1.02634123\n",
      "Iteration 15, loss = 1.22159970\n",
      "Iteration 16, loss = 1.26115722\n",
      "Iteration 17, loss = 1.16503133\n",
      "Iteration 18, loss = 1.11206908\n",
      "Iteration 19, loss = 1.26242880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18124993\n",
      "Iteration 2, loss = 1.04676682\n",
      "Iteration 3, loss = 0.95920813\n",
      "Iteration 4, loss = 0.99922511\n",
      "Iteration 11, loss = 1.18993088\n",
      "Iteration 12, loss = 1.23136747\n",
      "Iteration 13, loss = 1.09944415\n",
      "Iteration 14, loss = 1.02634123\n",
      "Iteration 15, loss = 1.22159970\n",
      "Iteration 16, loss = 1.26115722\n",
      "Iteration 17, loss = 1.16503133\n",
      "Iteration 18, loss = 1.11206908\n",
      "Iteration 19, loss = 1.26242880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18124993\n",
      "Iteration 2, loss = 1.04676682\n",
      "Iteration 3, loss = 0.95920813\n",
      "Iteration 4, loss = 0.99922511\n",
      "Iteration 5, loss = 0.95909927\n",
      "Iteration 6, loss = 1.00233556\n",
      "Iteration 7, loss = 0.97970078\n",
      "Iteration 8, loss = 1.00234333\n",
      "Iteration 9, loss = 0.99696446\n",
      "Iteration 10, loss = 1.15740115\n",
      "Iteration 11, loss = 1.04999235\n",
      "Iteration 12, loss = 0.97244943\n",
      "Iteration 13, loss = 0.99271825\n",
      "Iteration 14, loss = 0.94990058\n",
      "Iteration 15, loss = 0.94770527\n",
      "Iteration 16, loss = 0.96154173\n",
      "Iteration 17, loss = 0.96015840\n",
      "Iteration 18, loss = 1.03325133\n",
      "Iteration 5, loss = 0.95909927\n",
      "Iteration 6, loss = 1.00233556\n",
      "Iteration 7, loss = 0.97970078\n",
      "Iteration 8, loss = 1.00234333\n",
      "Iteration 9, loss = 0.99696446\n",
      "Iteration 10, loss = 1.15740115\n",
      "Iteration 11, loss = 1.04999235\n",
      "Iteration 12, loss = 0.97244943\n",
      "Iteration 13, loss = 0.99271825\n",
      "Iteration 14, loss = 0.94990058\n",
      "Iteration 15, loss = 0.94770527\n",
      "Iteration 16, loss = 0.96154173\n",
      "Iteration 17, loss = 0.96015840\n",
      "Iteration 18, loss = 1.03325133\n",
      "Iteration 19, loss = 0.96540185\n",
      "Iteration 20, loss = 0.95464293\n",
      "Iteration 21, loss = 0.96487106\n",
      "Iteration 22, loss = 0.95846799\n",
      "Iteration 23, loss = 0.95056709\n",
      "Iteration 24, loss = 0.95509902\n",
      "Iteration 25, loss = 0.97406757\n",
      "Iteration 26, loss = 0.96166258\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24306326\n",
      "Iteration 2, loss = 1.16800733\n",
      "Iteration 3, loss = 1.08807803\n",
      "Iteration 4, loss = 1.17984837\n",
      "Iteration 5, loss = 1.26923703\n",
      "Iteration 6, loss = 1.25934030\n",
      "Iteration 7, loss = 1.27258934\n",
      "Iteration 19, loss = 0.96540185\n",
      "Iteration 20, loss = 0.95464293\n",
      "Iteration 21, loss = 0.96487106\n",
      "Iteration 22, loss = 0.95846799\n",
      "Iteration 23, loss = 0.95056709\n",
      "Iteration 24, loss = 0.95509902\n",
      "Iteration 25, loss = 0.97406757\n",
      "Iteration 26, loss = 0.96166258\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24306326\n",
      "Iteration 2, loss = 1.16800733\n",
      "Iteration 3, loss = 1.08807803\n",
      "Iteration 4, loss = 1.17984837\n",
      "Iteration 5, loss = 1.26923703\n",
      "Iteration 6, loss = 1.25934030\n",
      "Iteration 7, loss = 1.27258934\n",
      "Iteration 8, loss = 1.27414150\n",
      "Iteration 9, loss = 1.26245247\n",
      "Iteration 10, loss = 1.26495253\n",
      "Iteration 11, loss = 1.28557168\n",
      "Iteration 12, loss = 1.27341437\n",
      "Iteration 13, loss = 1.26336036\n",
      "Iteration 14, loss = 1.26638808\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25299888\n",
      "Iteration 2, loss = 1.13510334\n",
      "Iteration 3, loss = 1.02417425\n",
      "Iteration 4, loss = 1.08000839\n",
      "Iteration 5, loss = 1.28025996\n",
      "Iteration 8, loss = 1.27414150\n",
      "Iteration 9, loss = 1.26245247\n",
      "Iteration 10, loss = 1.26495253\n",
      "Iteration 11, loss = 1.28557168\n",
      "Iteration 12, loss = 1.27341437\n",
      "Iteration 13, loss = 1.26336036\n",
      "Iteration 14, loss = 1.26638808\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25299888\n",
      "Iteration 2, loss = 1.13510334\n",
      "Iteration 3, loss = 1.02417425\n",
      "Iteration 4, loss = 1.08000839\n",
      "Iteration 5, loss = 1.28025996\n",
      "Iteration 6, loss = 1.26860417\n",
      "Iteration 7, loss = 1.25612496\n",
      "Iteration 8, loss = 1.25482085\n",
      "Iteration 9, loss = 1.24553383\n",
      "Iteration 10, loss = 1.24840006\n",
      "Iteration 11, loss = 1.26000039\n",
      "Iteration 12, loss = 1.26716842\n",
      "Iteration 13, loss = 1.25782294\n",
      "Iteration 14, loss = 1.25428084\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24511917\n",
      "Iteration 2, loss = 1.15659879\n",
      "Iteration 3, loss = 1.12002812\n",
      "Iteration 6, loss = 1.26860417\n",
      "Iteration 7, loss = 1.25612496\n",
      "Iteration 8, loss = 1.25482085\n",
      "Iteration 9, loss = 1.24553383\n",
      "Iteration 10, loss = 1.24840006\n",
      "Iteration 11, loss = 1.26000039\n",
      "Iteration 12, loss = 1.26716842\n",
      "Iteration 13, loss = 1.25782294\n",
      "Iteration 14, loss = 1.25428084\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24511917\n",
      "Iteration 2, loss = 1.15659879\n",
      "Iteration 3, loss = 1.12002812\n",
      "Iteration 4, loss = 1.08716198\n",
      "Iteration 5, loss = 1.18339740\n",
      "Iteration 6, loss = 1.29915869\n",
      "Iteration 7, loss = 1.27745286\n",
      "Iteration 8, loss = 1.27853286\n",
      "Iteration 9, loss = 1.27178550\n",
      "Iteration 10, loss = 1.27380708\n",
      "Iteration 11, loss = 1.28109681\n",
      "Iteration 12, loss = 1.27320017\n",
      "Iteration 13, loss = 1.26932303\n",
      "Iteration 14, loss = 1.27493422\n",
      "Iteration 15, loss = 1.25704625\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528561\n",
      "Iteration 2, loss = 1.24607801\n",
      "Iteration 4, loss = 1.08716198\n",
      "Iteration 5, loss = 1.18339740\n",
      "Iteration 6, loss = 1.29915869\n",
      "Iteration 7, loss = 1.27745286\n",
      "Iteration 8, loss = 1.27853286\n",
      "Iteration 9, loss = 1.27178550\n",
      "Iteration 10, loss = 1.27380708\n",
      "Iteration 11, loss = 1.28109681\n",
      "Iteration 12, loss = 1.27320017\n",
      "Iteration 13, loss = 1.26932303\n",
      "Iteration 14, loss = 1.27493422\n",
      "Iteration 15, loss = 1.25704625\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528561\n",
      "Iteration 2, loss = 1.24607801\n",
      "Iteration 3, loss = 1.28420275\n",
      "Iteration 4, loss = 1.24442588\n",
      "Iteration 5, loss = 1.26279859\n",
      "Iteration 6, loss = 1.24881679\n",
      "Iteration 7, loss = 1.24744751\n",
      "Iteration 8, loss = 1.24330141\n",
      "Iteration 9, loss = 1.25435734\n",
      "Iteration 10, loss = 1.26114832\n",
      "Iteration 1, loss = 1.16925680\n",
      "Iteration 2, loss = 1.05672175\n",
      "Iteration 3, loss = 1.22140008\n",
      "Iteration 4, loss = 1.29760398\n",
      "Iteration 3, loss = 1.28420275\n",
      "Iteration 4, loss = 1.24442588\n",
      "Iteration 5, loss = 1.26279859\n",
      "Iteration 6, loss = 1.24881679\n",
      "Iteration 7, loss = 1.24744751\n",
      "Iteration 8, loss = 1.24330141\n",
      "Iteration 9, loss = 1.25435734\n",
      "Iteration 10, loss = 1.26114832\n",
      "Iteration 1, loss = 1.16925680\n",
      "Iteration 2, loss = 1.05672175\n",
      "Iteration 3, loss = 1.22140008\n",
      "Iteration 4, loss = 1.29760398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.25417612\n",
      "Iteration 6, loss = 1.32858306\n",
      "Iteration 7, loss = 1.30272442\n",
      "Iteration 8, loss = 1.30102843\n",
      "Iteration 9, loss = 1.28950592\n",
      "Iteration 10, loss = 1.29301826\n",
      "Iteration 1, loss = 1.28505877\n",
      "Iteration 2, loss = 1.19994660\n",
      "Iteration 3, loss = 1.21630710\n",
      "Iteration 4, loss = 1.26379995\n",
      "Iteration 5, loss = 1.25417612\n",
      "Iteration 6, loss = 1.32858306\n",
      "Iteration 7, loss = 1.30272442\n",
      "Iteration 8, loss = 1.30102843\n",
      "Iteration 9, loss = 1.28950592\n",
      "Iteration 10, loss = 1.29301826\n",
      "Iteration 1, loss = 1.28505877\n",
      "Iteration 2, loss = 1.19994660\n",
      "Iteration 3, loss = 1.21630710\n",
      "Iteration 4, loss = 1.26379995\n",
      "Iteration 5, loss = 1.28022082\n",
      "Iteration 6, loss = 1.07835808\n",
      "Iteration 7, loss = 1.02852378\n",
      "Iteration 8, loss = 1.09545354\n",
      "Iteration 9, loss = 1.00903424\n",
      "Iteration 10, loss = 1.10120694\n",
      "Iteration 1, loss = 1.27050903\n",
      "Iteration 2, loss = 1.19944210\n",
      "Iteration 3, loss = 1.09941314\n",
      "Iteration 4, loss = 1.19191463\n",
      "Iteration 5, loss = 1.28181448\n",
      "Iteration 6, loss = 1.27206038\n",
      "Iteration 5, loss = 1.28022082\n",
      "Iteration 6, loss = 1.07835808\n",
      "Iteration 7, loss = 1.02852378\n",
      "Iteration 8, loss = 1.09545354\n",
      "Iteration 9, loss = 1.00903424\n",
      "Iteration 10, loss = 1.10120694\n",
      "Iteration 1, loss = 1.27050903\n",
      "Iteration 2, loss = 1.19944210\n",
      "Iteration 3, loss = 1.09941314\n",
      "Iteration 4, loss = 1.19191463\n",
      "Iteration 5, loss = 1.28181448\n",
      "Iteration 6, loss = 1.27206038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.26104015\n",
      "Iteration 8, loss = 1.26128042\n",
      "Iteration 9, loss = 1.24422677\n",
      "Iteration 10, loss = 1.25485188\n",
      "Iteration 1, loss = 1.28881802\n",
      "Iteration 2, loss = 1.13875664\n",
      "Iteration 3, loss = 1.02822887\n",
      "Iteration 4, loss = 1.30617934\n",
      "Iteration 5, loss = 1.21006795\n",
      "Iteration 6, loss = 1.27573767\n",
      "Iteration 7, loss = 1.28253670\n",
      "Iteration 8, loss = 1.22584698\n",
      "Iteration 9, loss = 1.25057485\n",
      "Iteration 7, loss = 1.26104015\n",
      "Iteration 8, loss = 1.26128042\n",
      "Iteration 9, loss = 1.24422677\n",
      "Iteration 10, loss = 1.25485188\n",
      "Iteration 1, loss = 1.28881802\n",
      "Iteration 2, loss = 1.13875664\n",
      "Iteration 3, loss = 1.02822887\n",
      "Iteration 4, loss = 1.30617934\n",
      "Iteration 5, loss = 1.21006795\n",
      "Iteration 6, loss = 1.27573767\n",
      "Iteration 7, loss = 1.28253670\n",
      "Iteration 8, loss = 1.22584698\n",
      "Iteration 9, loss = 1.25057485\n",
      "Iteration 10, loss = 1.18678864\n",
      "Iteration 1, loss = 1.26528561\n",
      "Iteration 2, loss = 1.24607801\n",
      "Iteration 3, loss = 1.28420275\n",
      "Iteration 4, loss = 1.24442588\n",
      "Iteration 5, loss = 1.26279859\n",
      "Iteration 6, loss = 1.24881679\n",
      "Iteration 7, loss = 1.24744751\n",
      "Iteration 8, loss = 1.24330141\n",
      "Iteration 9, loss = 1.25435734\n",
      "Iteration 10, loss = 1.26114832\n",
      "Iteration 11, loss = 1.25567086\n",
      "Iteration 12, loss = 1.25232863\n",
      "Iteration 10, loss = 1.18678864\n",
      "Iteration 1, loss = 1.26528561\n",
      "Iteration 2, loss = 1.24607801\n",
      "Iteration 3, loss = 1.28420275\n",
      "Iteration 4, loss = 1.24442588\n",
      "Iteration 5, loss = 1.26279859\n",
      "Iteration 6, loss = 1.24881679\n",
      "Iteration 7, loss = 1.24744751\n",
      "Iteration 8, loss = 1.24330141\n",
      "Iteration 9, loss = 1.25435734\n",
      "Iteration 10, loss = 1.26114832\n",
      "Iteration 11, loss = 1.25567086\n",
      "Iteration 12, loss = 1.25232863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.24962995\n",
      "Iteration 14, loss = 1.25157440\n",
      "Iteration 15, loss = 1.26922937\n",
      "Iteration 16, loss = 1.25690239\n",
      "Iteration 17, loss = 1.25110399\n",
      "Iteration 18, loss = 1.26175791\n",
      "Iteration 19, loss = 1.25658512\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16925680\n",
      "Iteration 2, loss = 1.05672175\n",
      "Iteration 3, loss = 1.22140008\n",
      "Iteration 4, loss = 1.29760398\n",
      "Iteration 5, loss = 1.25417612\n",
      "Iteration 6, loss = 1.32858306\n",
      "Iteration 13, loss = 1.24962995\n",
      "Iteration 14, loss = 1.25157440\n",
      "Iteration 15, loss = 1.26922937\n",
      "Iteration 16, loss = 1.25690239\n",
      "Iteration 17, loss = 1.25110399\n",
      "Iteration 18, loss = 1.26175791\n",
      "Iteration 19, loss = 1.25658512\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16925680\n",
      "Iteration 2, loss = 1.05672175\n",
      "Iteration 3, loss = 1.22140008\n",
      "Iteration 4, loss = 1.29760398\n",
      "Iteration 5, loss = 1.25417612\n",
      "Iteration 6, loss = 1.32858306\n",
      "Iteration 7, loss = 1.30272442\n",
      "Iteration 8, loss = 1.30102843\n",
      "Iteration 9, loss = 1.28950592\n",
      "Iteration 10, loss = 1.29301826\n",
      "Iteration 11, loss = 1.30414780\n",
      "Iteration 12, loss = 1.29423792\n",
      "Iteration 13, loss = 1.28629635\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28505877\n",
      "Iteration 2, loss = 1.19994660\n",
      "Iteration 3, loss = 1.21630710\n",
      "Iteration 4, loss = 1.26379995\n",
      "Iteration 5, loss = 1.28022082\n",
      "Iteration 7, loss = 1.30272442\n",
      "Iteration 8, loss = 1.30102843\n",
      "Iteration 9, loss = 1.28950592\n",
      "Iteration 10, loss = 1.29301826\n",
      "Iteration 11, loss = 1.30414780\n",
      "Iteration 12, loss = 1.29423792\n",
      "Iteration 13, loss = 1.28629635\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28505877\n",
      "Iteration 2, loss = 1.19994660\n",
      "Iteration 3, loss = 1.21630710\n",
      "Iteration 4, loss = 1.26379995\n",
      "Iteration 5, loss = 1.28022082\n",
      "Iteration 6, loss = 1.07835808\n",
      "Iteration 7, loss = 1.02852378\n",
      "Iteration 8, loss = 1.09545354\n",
      "Iteration 9, loss = 1.00903424\n",
      "Iteration 10, loss = 1.10120694\n",
      "Iteration 11, loss = 1.00502218\n",
      "Iteration 12, loss = 1.14579528\n",
      "Iteration 13, loss = 1.11744385\n",
      "Iteration 14, loss = 1.03808119\n",
      "Iteration 15, loss = 1.19260870\n",
      "Iteration 16, loss = 1.27983579\n",
      "Iteration 17, loss = 1.27098821\n",
      "Iteration 18, loss = 1.28382738\n",
      "Iteration 19, loss = 1.28533343\n",
      "Iteration 6, loss = 1.07835808\n",
      "Iteration 7, loss = 1.02852378\n",
      "Iteration 8, loss = 1.09545354\n",
      "Iteration 9, loss = 1.00903424\n",
      "Iteration 10, loss = 1.10120694\n",
      "Iteration 11, loss = 1.00502218\n",
      "Iteration 12, loss = 1.14579528\n",
      "Iteration 13, loss = 1.11744385\n",
      "Iteration 14, loss = 1.03808119\n",
      "Iteration 15, loss = 1.19260870\n",
      "Iteration 16, loss = 1.27983579\n",
      "Iteration 17, loss = 1.27098821\n",
      "Iteration 18, loss = 1.28382738\n",
      "Iteration 19, loss = 1.28533343\n",
      "Iteration 20, loss = 1.28192369\n",
      "Iteration 21, loss = 1.28462842\n",
      "Iteration 22, loss = 1.27574999\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27050903\n",
      "Iteration 2, loss = 1.19944210\n",
      "Iteration 3, loss = 1.09941314\n",
      "Iteration 4, loss = 1.19191463\n",
      "Iteration 5, loss = 1.28181448\n",
      "Iteration 6, loss = 1.27206038\n",
      "Iteration 7, loss = 1.26104015\n",
      "Iteration 8, loss = 1.26128042Iteration 20, loss = 1.28192369\n",
      "Iteration 21, loss = 1.28462842\n",
      "Iteration 22, loss = 1.27574999\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27050903\n",
      "Iteration 2, loss = 1.19944210\n",
      "Iteration 3, loss = 1.09941314\n",
      "Iteration 4, loss = 1.19191463\n",
      "Iteration 5, loss = 1.28181448\n",
      "Iteration 6, loss = 1.27206038\n",
      "Iteration 7, loss = 1.26104015\n",
      "Iteration 8, loss = 1.26128042\n",
      "Iteration 9, loss = 1.24422677\n",
      "Iteration 10, loss = 1.25485188\n",
      "Iteration 11, loss = 1.26412665\n",
      "Iteration 12, loss = 1.27439364\n",
      "Iteration 13, loss = 1.26048633\n",
      "Iteration 14, loss = 1.26305319\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28881802\n",
      "Iteration 2, loss = 1.13875664\n",
      "Iteration 3, loss = 1.02822887\n",
      "Iteration 4, loss = 1.30617934\n",
      "Iteration 9, loss = 1.24422677\n",
      "Iteration 10, loss = 1.25485188\n",
      "Iteration 11, loss = 1.26412665\n",
      "Iteration 12, loss = 1.27439364\n",
      "Iteration 13, loss = 1.26048633\n",
      "Iteration 14, loss = 1.26305319\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28881802\n",
      "Iteration 2, loss = 1.13875664\n",
      "Iteration 3, loss = 1.02822887\n",
      "Iteration 4, loss = 1.30617934\n",
      "Iteration 5, loss = 1.21006795\n",
      "Iteration 6, loss = 1.27573767\n",
      "Iteration 7, loss = 1.28253670\n",
      "Iteration 8, loss = 1.22584698\n",
      "Iteration 9, loss = 1.25057485\n",
      "Iteration 10, loss = 1.18678864\n",
      "Iteration 11, loss = 1.19242273\n",
      "Iteration 12, loss = 1.14710698\n",
      "Iteration 13, loss = 1.23524208\n",
      "Iteration 14, loss = 1.12142561\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528561\n",
      "Iteration 2, loss = 1.24607801\n",
      "\n",
      "Iteration 5, loss = 1.21006795\n",
      "Iteration 6, loss = 1.27573767\n",
      "Iteration 7, loss = 1.28253670\n",
      "Iteration 8, loss = 1.22584698\n",
      "Iteration 9, loss = 1.25057485\n",
      "Iteration 10, loss = 1.18678864\n",
      "Iteration 11, loss = 1.19242273\n",
      "Iteration 12, loss = 1.14710698\n",
      "Iteration 13, loss = 1.23524208\n",
      "Iteration 14, loss = 1.12142561\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26528561\n",
      "Iteration 2, loss = 1.24607801\n",
      "Iteration 3, loss = 1.28420275\n",
      "Iteration 4, loss = 1.24442588\n",
      "Iteration 5, loss = 1.26279859\n",
      "Iteration 6, loss = 1.24881679\n",
      "Iteration 7, loss = 1.24744751\n",
      "Iteration 8, loss = 1.24330141\n",
      "Iteration 9, loss = 1.25435734\n",
      "Iteration 10, loss = 1.26114832\n",
      "Iteration 11, loss = 1.25567086\n",
      "Iteration 12, loss = 1.25232863\n",
      "Iteration 13, loss = 1.24962995\n",
      "Iteration 14, loss = 1.25157440\n",
      "Iteration 15, loss = 1.26922937\n",
      "Iteration 16, loss = 1.25690239\n",
      "Iteration 3, loss = 1.28420275\n",
      "Iteration 4, loss = 1.24442588\n",
      "Iteration 5, loss = 1.26279859\n",
      "Iteration 6, loss = 1.24881679\n",
      "Iteration 7, loss = 1.24744751\n",
      "Iteration 8, loss = 1.24330141\n",
      "Iteration 9, loss = 1.25435734\n",
      "Iteration 10, loss = 1.26114832\n",
      "Iteration 11, loss = 1.25567086\n",
      "Iteration 12, loss = 1.25232863\n",
      "Iteration 13, loss = 1.24962995\n",
      "Iteration 14, loss = 1.25157440\n",
      "Iteration 15, loss = 1.26922937\n",
      "Iteration 16, loss = 1.25690239\n",
      "Iteration 17, loss = 1.25110399\n",
      "Iteration 18, loss = 1.26175791\n",
      "Iteration 19, loss = 1.25658512\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16925680\n",
      "Iteration 2, loss = 1.05672175\n",
      "Iteration 3, loss = 1.22140008\n",
      "Iteration 4, loss = 1.29760398\n",
      "Iteration 5, loss = 1.25417612\n",
      "Iteration 6, loss = 1.32858306\n",
      "Iteration 7, loss = 1.30272442\n",
      "Iteration 8, loss = 1.30102843\n",
      "Iteration 9, loss = 1.28950592\n",
      "Iteration 17, loss = 1.25110399\n",
      "Iteration 18, loss = 1.26175791\n",
      "Iteration 19, loss = 1.25658512\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.16925680\n",
      "Iteration 2, loss = 1.05672175\n",
      "Iteration 3, loss = 1.22140008\n",
      "Iteration 4, loss = 1.29760398\n",
      "Iteration 5, loss = 1.25417612\n",
      "Iteration 6, loss = 1.32858306\n",
      "Iteration 7, loss = 1.30272442\n",
      "Iteration 8, loss = 1.30102843\n",
      "Iteration 9, loss = 1.28950592\n",
      "Iteration 10, loss = 1.29301826\n",
      "Iteration 11, loss = 1.30414780\n",
      "Iteration 12, loss = 1.29423792\n",
      "Iteration 13, loss = 1.28629635\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28505877\n",
      "Iteration 2, loss = 1.19994660\n",
      "Iteration 3, loss = 1.21630710\n",
      "Iteration 4, loss = 1.26379995\n",
      "Iteration 5, loss = 1.28022082\n",
      "Iteration 6, loss = 1.07835808\n",
      "Iteration 7, loss = 1.02852378\n",
      "Iteration 8, loss = 1.09545354\n",
      "Iteration 9, loss = 1.00903424\n",
      "Iteration 10, loss = 1.29301826\n",
      "Iteration 11, loss = 1.30414780\n",
      "Iteration 12, loss = 1.29423792\n",
      "Iteration 13, loss = 1.28629635\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28505877\n",
      "Iteration 2, loss = 1.19994660\n",
      "Iteration 3, loss = 1.21630710\n",
      "Iteration 4, loss = 1.26379995\n",
      "Iteration 5, loss = 1.28022082\n",
      "Iteration 6, loss = 1.07835808\n",
      "Iteration 7, loss = 1.02852378\n",
      "Iteration 8, loss = 1.09545354\n",
      "Iteration 9, loss = 1.00903424\n",
      "Iteration 10, loss = 1.10120694\n",
      "Iteration 11, loss = 1.00502218\n",
      "Iteration 12, loss = 1.14579528\n",
      "Iteration 13, loss = 1.11744385\n",
      "Iteration 14, loss = 1.03808119\n",
      "Iteration 15, loss = 1.19260870\n",
      "Iteration 16, loss = 1.27983579\n",
      "Iteration 17, loss = 1.27098821\n",
      "Iteration 18, loss = 1.28382738\n",
      "Iteration 19, loss = 1.28533343\n",
      "Iteration 20, loss = 1.28192369\n",
      "Iteration 21, loss = 1.28462842\n",
      "Iteration 22, loss = 1.27574999\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27050903\n",
      "Iteration 10, loss = 1.10120694\n",
      "Iteration 11, loss = 1.00502218\n",
      "Iteration 12, loss = 1.14579528\n",
      "Iteration 13, loss = 1.11744385\n",
      "Iteration 14, loss = 1.03808119\n",
      "Iteration 15, loss = 1.19260870\n",
      "Iteration 16, loss = 1.27983579\n",
      "Iteration 17, loss = 1.27098821\n",
      "Iteration 18, loss = 1.28382738\n",
      "Iteration 19, loss = 1.28533343\n",
      "Iteration 20, loss = 1.28192369\n",
      "Iteration 21, loss = 1.28462842\n",
      "Iteration 22, loss = 1.27574999\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27050903\n",
      "Iteration 2, loss = 1.19944210\n",
      "Iteration 3, loss = 1.09941314\n",
      "Iteration 4, loss = 1.19191463\n",
      "Iteration 5, loss = 1.28181448\n",
      "Iteration 6, loss = 1.27206038\n",
      "Iteration 7, loss = 1.26104015\n",
      "Iteration 8, loss = 1.26128042\n",
      "Iteration 9, loss = 1.24422677\n",
      "Iteration 10, loss = 1.25485188\n",
      "Iteration 11, loss = 1.26412665\n",
      "Iteration 12, loss = 1.27439364\n",
      "Iteration 13, loss = 1.26048633\n",
      "Iteration 14, loss = 1.26305319\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28881802\n",
      "Iteration 2, loss = 1.19944210\n",
      "Iteration 3, loss = 1.09941314\n",
      "Iteration 4, loss = 1.19191463\n",
      "Iteration 5, loss = 1.28181448\n",
      "Iteration 6, loss = 1.27206038\n",
      "Iteration 7, loss = 1.26104015\n",
      "Iteration 8, loss = 1.26128042\n",
      "Iteration 9, loss = 1.24422677\n",
      "Iteration 10, loss = 1.25485188\n",
      "Iteration 11, loss = 1.26412665\n",
      "Iteration 12, loss = 1.27439364\n",
      "Iteration 13, loss = 1.26048633\n",
      "Iteration 14, loss = 1.26305319\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28881802\n",
      "Iteration 2, loss = 1.13875664\n",
      "Iteration 3, loss = 1.02822887\n",
      "Iteration 4, loss = 1.30617934\n",
      "Iteration 5, loss = 1.21006795\n",
      "Iteration 6, loss = 1.27573767\n",
      "Iteration 7, loss = 1.28253670\n",
      "Iteration 8, loss = 1.22584698\n",
      "Iteration 9, loss = 1.25057485\n",
      "Iteration 10, loss = 1.18678864\n",
      "Iteration 11, loss = 1.19242273\n",
      "Iteration 12, loss = 1.14710698\n",
      "Iteration 13, loss = 1.23524208\n",
      "Iteration 14, loss = 1.12142561\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 1.13875664\n",
      "Iteration 3, loss = 1.02822887\n",
      "Iteration 4, loss = 1.30617934\n",
      "Iteration 5, loss = 1.21006795\n",
      "Iteration 6, loss = 1.27573767\n",
      "Iteration 7, loss = 1.28253670\n",
      "Iteration 8, loss = 1.22584698\n",
      "Iteration 9, loss = 1.25057485\n",
      "Iteration 10, loss = 1.18678864\n",
      "Iteration 11, loss = 1.19242273\n",
      "Iteration 12, loss = 1.14710698\n",
      "Iteration 13, loss = 1.23524208\n",
      "Iteration 14, loss = 1.12142561\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21383470\n",
      "Iteration 2, loss = 1.10338448\n",
      "Iteration 3, loss = 1.04755560\n",
      "Iteration 4, loss = 1.05730850\n",
      "Iteration 5, loss = 0.95925798\n",
      "Iteration 6, loss = 0.97383792\n",
      "Iteration 7, loss = 0.96223613\n",
      "Iteration 8, loss = 0.98081034\n",
      "Iteration 9, loss = 0.94275596\n",
      "Iteration 10, loss = 0.94469863\n",
      "Iteration 1, loss = 1.15335650\n",
      "Iteration 2, loss = 0.98166779\n",
      "Iteration 3, loss = 0.96694667\n",
      "Iteration 1, loss = 1.21383470\n",
      "Iteration 2, loss = 1.10338448\n",
      "Iteration 3, loss = 1.04755560\n",
      "Iteration 4, loss = 1.05730850\n",
      "Iteration 5, loss = 0.95925798\n",
      "Iteration 6, loss = 0.97383792\n",
      "Iteration 7, loss = 0.96223613\n",
      "Iteration 8, loss = 0.98081034\n",
      "Iteration 9, loss = 0.94275596\n",
      "Iteration 10, loss = 0.94469863\n",
      "Iteration 1, loss = 1.15335650\n",
      "Iteration 2, loss = 0.98166779\n",
      "Iteration 3, loss = 0.96694667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.96821252\n",
      "Iteration 5, loss = 0.88531771\n",
      "Iteration 6, loss = 0.88607639\n",
      "Iteration 7, loss = 0.91144624\n",
      "Iteration 8, loss = 0.88728297\n",
      "Iteration 9, loss = 0.88465381\n",
      "Iteration 10, loss = 0.89676479\n",
      "Iteration 1, loss = 1.19288628\n",
      "Iteration 2, loss = 1.02887090\n",
      "Iteration 3, loss = 0.98398798\n",
      "Iteration 4, loss = 0.97042978\n",
      "Iteration 5, loss = 0.97733353\n",
      "Iteration 4, loss = 0.96821252\n",
      "Iteration 5, loss = 0.88531771\n",
      "Iteration 6, loss = 0.88607639\n",
      "Iteration 7, loss = 0.91144624\n",
      "Iteration 8, loss = 0.88728297\n",
      "Iteration 9, loss = 0.88465381\n",
      "Iteration 10, loss = 0.89676479\n",
      "Iteration 1, loss = 1.19288628\n",
      "Iteration 2, loss = 1.02887090\n",
      "Iteration 3, loss = 0.98398798\n",
      "Iteration 4, loss = 0.97042978\n",
      "Iteration 5, loss = 0.97733353\n",
      "Iteration 6, loss = 0.93007778\n",
      "Iteration 7, loss = 0.96055653\n",
      "Iteration 8, loss = 0.91924604\n",
      "Iteration 9, loss = 0.94858516\n",
      "Iteration 10, loss = 0.94911522\n",
      "Iteration 1, loss = 1.20237473\n",
      "Iteration 2, loss = 1.04907491\n",
      "Iteration 3, loss = 1.01172096\n",
      "Iteration 4, loss = 0.97361034\n",
      "Iteration 5, loss = 0.96783666\n",
      "Iteration 6, loss = 0.96599106\n",
      "Iteration 7, loss = 1.01136884\n",
      "Iteration 6, loss = 0.93007778\n",
      "Iteration 7, loss = 0.96055653\n",
      "Iteration 8, loss = 0.91924604\n",
      "Iteration 9, loss = 0.94858516\n",
      "Iteration 10, loss = 0.94911522\n",
      "Iteration 1, loss = 1.20237473\n",
      "Iteration 2, loss = 1.04907491\n",
      "Iteration 3, loss = 1.01172096\n",
      "Iteration 4, loss = 0.97361034\n",
      "Iteration 5, loss = 0.96783666\n",
      "Iteration 6, loss = 0.96599106\n",
      "Iteration 7, loss = 1.01136884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.95997167\n",
      "Iteration 9, loss = 0.95509894\n",
      "Iteration 10, loss = 0.96117072\n",
      "Iteration 1, loss = 1.20641789\n",
      "Iteration 2, loss = 1.04456298\n",
      "Iteration 3, loss = 0.97964097\n",
      "Iteration 4, loss = 0.96684960\n",
      "Iteration 5, loss = 0.94673037\n",
      "Iteration 6, loss = 0.96814658\n",
      "Iteration 7, loss = 0.93870950\n",
      "Iteration 8, loss = 0.95152821\n",
      "Iteration 8, loss = 0.95997167\n",
      "Iteration 9, loss = 0.95509894\n",
      "Iteration 10, loss = 0.96117072\n",
      "Iteration 1, loss = 1.20641789\n",
      "Iteration 2, loss = 1.04456298\n",
      "Iteration 3, loss = 0.97964097\n",
      "Iteration 4, loss = 0.96684960\n",
      "Iteration 5, loss = 0.94673037\n",
      "Iteration 6, loss = 0.96814658\n",
      "Iteration 7, loss = 0.93870950\n",
      "Iteration 8, loss = 0.95152821\n",
      "Iteration 9, loss = 0.92391371\n",
      "Iteration 10, loss = 0.92351438\n",
      "Iteration 1, loss = 1.21383470\n",
      "Iteration 2, loss = 1.10338448\n",
      "Iteration 3, loss = 1.04755560\n",
      "Iteration 4, loss = 1.05730850\n",
      "Iteration 5, loss = 0.95925798\n",
      "Iteration 6, loss = 0.97383792\n",
      "Iteration 7, loss = 0.96223613\n",
      "Iteration 8, loss = 0.98081034\n",
      "Iteration 9, loss = 0.94275596\n",
      "Iteration 10, loss = 0.94469863\n",
      "Iteration 11, loss = 0.92066882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.92391371\n",
      "Iteration 10, loss = 0.92351438\n",
      "Iteration 1, loss = 1.21383470\n",
      "Iteration 2, loss = 1.10338448\n",
      "Iteration 3, loss = 1.04755560\n",
      "Iteration 4, loss = 1.05730850\n",
      "Iteration 5, loss = 0.95925798\n",
      "Iteration 6, loss = 0.97383792\n",
      "Iteration 7, loss = 0.96223613\n",
      "Iteration 8, loss = 0.98081034\n",
      "Iteration 9, loss = 0.94275596\n",
      "Iteration 10, loss = 0.94469863\n",
      "Iteration 11, loss = 0.92066882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.94424520\n",
      "Iteration 13, loss = 0.94347307\n",
      "Iteration 14, loss = 0.91489623\n",
      "Iteration 15, loss = 0.92058267\n",
      "Iteration 16, loss = 0.92044928\n",
      "Iteration 17, loss = 0.95230324\n",
      "Iteration 18, loss = 0.92745780\n",
      "Iteration 19, loss = 0.90087880\n",
      "Iteration 20, loss = 0.93753252\n",
      "Iteration 21, loss = 0.91742677\n",
      "Iteration 22, loss = 0.98563220\n",
      "Iteration 23, loss = 0.88320783\n",
      "Iteration 24, loss = 0.88733129\n",
      "Iteration 25, loss = 0.88185205\n",
      "Iteration 26, loss = 0.92313812\n",
      "Iteration 12, loss = 0.94424520\n",
      "Iteration 13, loss = 0.94347307\n",
      "Iteration 14, loss = 0.91489623\n",
      "Iteration 15, loss = 0.92058267\n",
      "Iteration 16, loss = 0.92044928\n",
      "Iteration 17, loss = 0.95230324\n",
      "Iteration 18, loss = 0.92745780\n",
      "Iteration 19, loss = 0.90087880\n",
      "Iteration 20, loss = 0.93753252\n",
      "Iteration 21, loss = 0.91742677\n",
      "Iteration 22, loss = 0.98563220\n",
      "Iteration 23, loss = 0.88320783\n",
      "Iteration 24, loss = 0.88733129\n",
      "Iteration 25, loss = 0.88185205\n",
      "Iteration 26, loss = 0.92313812\n",
      "Iteration 27, loss = 0.88421581\n",
      "Iteration 28, loss = 0.82505975\n",
      "Iteration 29, loss = 0.82482489\n",
      "Iteration 30, loss = 0.84590089\n",
      "Iteration 31, loss = 0.88952688\n",
      "Iteration 32, loss = 0.85846439\n",
      "Iteration 33, loss = 0.83946961\n",
      "Iteration 34, loss = 0.82098014\n",
      "Iteration 35, loss = 0.83204780\n",
      "Iteration 36, loss = 0.85336606\n",
      "Iteration 37, loss = 0.83348966\n",
      "Iteration 38, loss = 0.82831976\n",
      "Iteration 39, loss = 0.83865974\n",
      "Iteration 40, loss = 0.80544970\n",
      "Iteration 41, loss = 0.79767979\n",
      "Iteration 27, loss = 0.88421581\n",
      "Iteration 28, loss = 0.82505975\n",
      "Iteration 29, loss = 0.82482489\n",
      "Iteration 30, loss = 0.84590089\n",
      "Iteration 31, loss = 0.88952688\n",
      "Iteration 32, loss = 0.85846439\n",
      "Iteration 33, loss = 0.83946961\n",
      "Iteration 34, loss = 0.82098014\n",
      "Iteration 35, loss = 0.83204780\n",
      "Iteration 36, loss = 0.85336606\n",
      "Iteration 37, loss = 0.83348966\n",
      "Iteration 38, loss = 0.82831976\n",
      "Iteration 39, loss = 0.83865974\n",
      "Iteration 40, loss = 0.80544970\n",
      "Iteration 41, loss = 0.79767979\n",
      "Iteration 42, loss = 0.77247405\n",
      "Iteration 43, loss = 0.78583741\n",
      "Iteration 44, loss = 0.85735590\n",
      "Iteration 45, loss = 0.88216636\n",
      "Iteration 46, loss = 0.91321558\n",
      "Iteration 47, loss = 0.84305990\n",
      "Iteration 48, loss = 0.81698835\n",
      "Iteration 49, loss = 0.83348863\n",
      "Iteration 50, loss = 0.82000441\n",
      "Iteration 1, loss = 1.15335650\n",
      "Iteration 2, loss = 0.98166779\n",
      "Iteration 3, loss = 0.96694667\n",
      "Iteration 4, loss = 0.96821252\n",
      "Iteration 5, loss = 0.88531771\n",
      "Iteration 42, loss = 0.77247405\n",
      "Iteration 43, loss = 0.78583741\n",
      "Iteration 44, loss = 0.85735590\n",
      "Iteration 45, loss = 0.88216636\n",
      "Iteration 46, loss = 0.91321558\n",
      "Iteration 47, loss = 0.84305990\n",
      "Iteration 48, loss = 0.81698835\n",
      "Iteration 49, loss = 0.83348863\n",
      "Iteration 50, loss = 0.82000441\n",
      "Iteration 1, loss = 1.15335650\n",
      "Iteration 2, loss = 0.98166779\n",
      "Iteration 3, loss = 0.96694667\n",
      "Iteration 4, loss = 0.96821252\n",
      "Iteration 5, loss = 0.88531771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.88607639\n",
      "Iteration 7, loss = 0.91144624\n",
      "Iteration 8, loss = 0.88728297\n",
      "Iteration 9, loss = 0.88465381\n",
      "Iteration 10, loss = 0.89676479\n",
      "Iteration 11, loss = 0.86636281\n",
      "Iteration 12, loss = 0.85561700\n",
      "Iteration 13, loss = 0.88386961\n",
      "Iteration 14, loss = 0.86853019\n",
      "Iteration 15, loss = 0.90434571\n",
      "Iteration 16, loss = 0.86371027\n",
      "Iteration 17, loss = 0.84415095\n",
      "Iteration 18, loss = 0.85872548\n",
      "Iteration 19, loss = 0.87244445\n",
      "Iteration 20, loss = 0.88195495\n",
      "Iteration 6, loss = 0.88607639\n",
      "Iteration 7, loss = 0.91144624\n",
      "Iteration 8, loss = 0.88728297\n",
      "Iteration 9, loss = 0.88465381\n",
      "Iteration 10, loss = 0.89676479\n",
      "Iteration 11, loss = 0.86636281\n",
      "Iteration 12, loss = 0.85561700\n",
      "Iteration 13, loss = 0.88386961\n",
      "Iteration 14, loss = 0.86853019\n",
      "Iteration 15, loss = 0.90434571\n",
      "Iteration 16, loss = 0.86371027\n",
      "Iteration 17, loss = 0.84415095\n",
      "Iteration 18, loss = 0.85872548\n",
      "Iteration 19, loss = 0.87244445\n",
      "Iteration 20, loss = 0.88195495\n",
      "Iteration 21, loss = 0.87132403\n",
      "Iteration 22, loss = 0.83391542\n",
      "Iteration 23, loss = 0.83779534\n",
      "Iteration 24, loss = 0.80647451\n",
      "Iteration 25, loss = 0.82516571\n",
      "Iteration 26, loss = 0.81716709\n",
      "Iteration 27, loss = 0.82922919\n",
      "Iteration 28, loss = 0.81317821\n",
      "Iteration 29, loss = 0.79262691\n",
      "Iteration 30, loss = 0.83647712\n",
      "Iteration 31, loss = 0.80665967\n",
      "Iteration 32, loss = 0.80956621\n",
      "Iteration 33, loss = 0.78841289\n",
      "Iteration 34, loss = 0.78905786\n",
      "Iteration 35, loss = 0.76947873\n",
      "Iteration 21, loss = 0.87132403\n",
      "Iteration 22, loss = 0.83391542\n",
      "Iteration 23, loss = 0.83779534\n",
      "Iteration 24, loss = 0.80647451\n",
      "Iteration 25, loss = 0.82516571\n",
      "Iteration 26, loss = 0.81716709\n",
      "Iteration 27, loss = 0.82922919\n",
      "Iteration 28, loss = 0.81317821\n",
      "Iteration 29, loss = 0.79262691\n",
      "Iteration 30, loss = 0.83647712\n",
      "Iteration 31, loss = 0.80665967\n",
      "Iteration 32, loss = 0.80956621\n",
      "Iteration 33, loss = 0.78841289\n",
      "Iteration 34, loss = 0.78905786\n",
      "Iteration 35, loss = 0.76947873\n",
      "Iteration 36, loss = 0.76977025\n",
      "Iteration 37, loss = 0.79270720\n",
      "Iteration 38, loss = 0.74859814\n",
      "Iteration 39, loss = 0.82380893\n",
      "Iteration 40, loss = 0.81507643\n",
      "Iteration 41, loss = 0.78046009\n",
      "Iteration 42, loss = 0.76311527\n",
      "Iteration 43, loss = 0.76053201\n",
      "Iteration 44, loss = 0.80465968\n",
      "Iteration 45, loss = 0.77319536\n",
      "Iteration 46, loss = 0.74539798\n",
      "Iteration 47, loss = 0.74135573\n",
      "Iteration 48, loss = 0.73694145\n",
      "Iteration 49, loss = 0.74035245\n",
      "Iteration 50, loss = 0.73468232\n",
      "Iteration 1, loss = 1.19288628\n",
      "Iteration 36, loss = 0.76977025\n",
      "Iteration 37, loss = 0.79270720\n",
      "Iteration 38, loss = 0.74859814\n",
      "Iteration 39, loss = 0.82380893\n",
      "Iteration 40, loss = 0.81507643\n",
      "Iteration 41, loss = 0.78046009\n",
      "Iteration 42, loss = 0.76311527\n",
      "Iteration 43, loss = 0.76053201\n",
      "Iteration 44, loss = 0.80465968\n",
      "Iteration 45, loss = 0.77319536\n",
      "Iteration 46, loss = 0.74539798\n",
      "Iteration 47, loss = 0.74135573\n",
      "Iteration 48, loss = 0.73694145\n",
      "Iteration 49, loss = 0.74035245\n",
      "Iteration 50, loss = 0.73468232\n",
      "Iteration 1, loss = 1.19288628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.02887090\n",
      "Iteration 3, loss = 0.98398798\n",
      "Iteration 4, loss = 0.97042978\n",
      "Iteration 5, loss = 0.97733353\n",
      "Iteration 6, loss = 0.93007778\n",
      "Iteration 7, loss = 0.96055653\n",
      "Iteration 8, loss = 0.91924604\n",
      "Iteration 9, loss = 0.94858516\n",
      "Iteration 10, loss = 0.94911522\n",
      "Iteration 11, loss = 0.90715823\n",
      "Iteration 12, loss = 0.93699733\n",
      "Iteration 13, loss = 0.93171192\n",
      "Iteration 14, loss = 0.91781646\n",
      "Iteration 2, loss = 1.02887090\n",
      "Iteration 3, loss = 0.98398798\n",
      "Iteration 4, loss = 0.97042978\n",
      "Iteration 5, loss = 0.97733353\n",
      "Iteration 6, loss = 0.93007778\n",
      "Iteration 7, loss = 0.96055653\n",
      "Iteration 8, loss = 0.91924604\n",
      "Iteration 9, loss = 0.94858516\n",
      "Iteration 10, loss = 0.94911522\n",
      "Iteration 11, loss = 0.90715823\n",
      "Iteration 12, loss = 0.93699733\n",
      "Iteration 13, loss = 0.93171192\n",
      "Iteration 14, loss = 0.91781646\n",
      "Iteration 15, loss = 0.91728076\n",
      "Iteration 16, loss = 0.92368265\n",
      "Iteration 17, loss = 0.91305583\n",
      "Iteration 18, loss = 0.89549308\n",
      "Iteration 19, loss = 0.90330529\n",
      "Iteration 20, loss = 0.89478533\n",
      "Iteration 21, loss = 0.88886083\n",
      "Iteration 22, loss = 0.89538565\n",
      "Iteration 23, loss = 0.87430683\n",
      "Iteration 24, loss = 0.90249104\n",
      "Iteration 25, loss = 0.86707125\n",
      "Iteration 26, loss = 0.91254180\n",
      "Iteration 27, loss = 0.89974522\n",
      "Iteration 28, loss = 0.86010106\n",
      "Iteration 29, loss = 0.87864469\n",
      "Iteration 30, loss = 0.83395264\n",
      "Iteration 15, loss = 0.91728076\n",
      "Iteration 16, loss = 0.92368265\n",
      "Iteration 17, loss = 0.91305583\n",
      "Iteration 18, loss = 0.89549308\n",
      "Iteration 19, loss = 0.90330529\n",
      "Iteration 20, loss = 0.89478533\n",
      "Iteration 21, loss = 0.88886083\n",
      "Iteration 22, loss = 0.89538565\n",
      "Iteration 23, loss = 0.87430683\n",
      "Iteration 24, loss = 0.90249104\n",
      "Iteration 25, loss = 0.86707125\n",
      "Iteration 26, loss = 0.91254180\n",
      "Iteration 27, loss = 0.89974522\n",
      "Iteration 28, loss = 0.86010106\n",
      "Iteration 29, loss = 0.87864469\n",
      "Iteration 30, loss = 0.83395264\n",
      "Iteration 31, loss = 0.85262813\n",
      "Iteration 32, loss = 0.88050266\n",
      "Iteration 33, loss = 0.90861897\n",
      "Iteration 34, loss = 0.83310108\n",
      "Iteration 35, loss = 0.82131241\n",
      "Iteration 36, loss = 0.89156800\n",
      "Iteration 37, loss = 0.88119757\n",
      "Iteration 38, loss = 0.86776508\n",
      "Iteration 39, loss = 0.84860047\n",
      "Iteration 40, loss = 0.86862020\n",
      "Iteration 41, loss = 0.86290878\n",
      "Iteration 42, loss = 0.88911616\n",
      "Iteration 43, loss = 0.82893983\n",
      "Iteration 44, loss = 0.85501731\n",
      "Iteration 45, loss = 0.81570603\n",
      "Iteration 31, loss = 0.85262813\n",
      "Iteration 32, loss = 0.88050266\n",
      "Iteration 33, loss = 0.90861897\n",
      "Iteration 34, loss = 0.83310108\n",
      "Iteration 35, loss = 0.82131241\n",
      "Iteration 36, loss = 0.89156800\n",
      "Iteration 37, loss = 0.88119757\n",
      "Iteration 38, loss = 0.86776508\n",
      "Iteration 39, loss = 0.84860047\n",
      "Iteration 40, loss = 0.86862020\n",
      "Iteration 41, loss = 0.86290878\n",
      "Iteration 42, loss = 0.88911616\n",
      "Iteration 43, loss = 0.82893983\n",
      "Iteration 44, loss = 0.85501731\n",
      "Iteration 45, loss = 0.81570603\n",
      "Iteration 46, loss = 0.77575498\n",
      "Iteration 47, loss = 0.85790528\n",
      "Iteration 48, loss = 0.81951452\n",
      "Iteration 49, loss = 0.81814681\n",
      "Iteration 50, loss = 0.81160966\n",
      "Iteration 1, loss = 1.20237473\n",
      "Iteration 2, loss = 1.04907491\n",
      "Iteration 3, loss = 1.01172096\n",
      "Iteration 4, loss = 0.97361034\n",
      "Iteration 5, loss = 0.96783666\n",
      "Iteration 6, loss = 0.96599106\n",
      "Iteration 7, loss = 1.01136884\n",
      "Iteration 46, loss = 0.77575498\n",
      "Iteration 47, loss = 0.85790528\n",
      "Iteration 48, loss = 0.81951452\n",
      "Iteration 49, loss = 0.81814681\n",
      "Iteration 50, loss = 0.81160966\n",
      "Iteration 1, loss = 1.20237473\n",
      "Iteration 2, loss = 1.04907491\n",
      "Iteration 3, loss = 1.01172096\n",
      "Iteration 4, loss = 0.97361034\n",
      "Iteration 5, loss = 0.96783666\n",
      "Iteration 6, loss = 0.96599106\n",
      "Iteration 7, loss = 1.01136884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.95997167\n",
      "Iteration 9, loss = 0.95509894\n",
      "Iteration 10, loss = 0.96117072\n",
      "Iteration 11, loss = 0.93598114\n",
      "Iteration 12, loss = 0.95072850\n",
      "Iteration 13, loss = 0.95028537\n",
      "Iteration 14, loss = 0.93831089\n",
      "Iteration 15, loss = 0.94748112\n",
      "Iteration 16, loss = 0.90360845\n",
      "Iteration 17, loss = 0.92691140\n",
      "Iteration 18, loss = 0.90323397\n",
      "Iteration 19, loss = 0.86829531\n",
      "Iteration 20, loss = 0.90770280\n",
      "Iteration 21, loss = 0.89217483\n",
      "Iteration 8, loss = 0.95997167\n",
      "Iteration 9, loss = 0.95509894\n",
      "Iteration 10, loss = 0.96117072\n",
      "Iteration 11, loss = 0.93598114\n",
      "Iteration 12, loss = 0.95072850\n",
      "Iteration 13, loss = 0.95028537\n",
      "Iteration 14, loss = 0.93831089\n",
      "Iteration 15, loss = 0.94748112\n",
      "Iteration 16, loss = 0.90360845\n",
      "Iteration 17, loss = 0.92691140\n",
      "Iteration 18, loss = 0.90323397\n",
      "Iteration 19, loss = 0.86829531\n",
      "Iteration 20, loss = 0.90770280\n",
      "Iteration 21, loss = 0.89217483\n",
      "Iteration 22, loss = 0.89359987\n",
      "Iteration 23, loss = 0.87688420\n",
      "Iteration 24, loss = 0.90161152\n",
      "Iteration 25, loss = 0.88305125\n",
      "Iteration 26, loss = 0.92627240\n",
      "Iteration 27, loss = 0.93168295\n",
      "Iteration 28, loss = 0.87300948\n",
      "Iteration 29, loss = 0.88377921\n",
      "Iteration 30, loss = 0.85062646\n",
      "Iteration 31, loss = 0.85859233\n",
      "Iteration 32, loss = 0.88128167\n",
      "Iteration 33, loss = 0.89362108\n",
      "Iteration 34, loss = 0.83721384\n",
      "Iteration 35, loss = 0.85579093\n",
      "Iteration 36, loss = 0.82591341\n",
      "Iteration 37, loss = 0.86117186\n",
      "Iteration 22, loss = 0.89359987\n",
      "Iteration 23, loss = 0.87688420\n",
      "Iteration 24, loss = 0.90161152\n",
      "Iteration 25, loss = 0.88305125\n",
      "Iteration 26, loss = 0.92627240\n",
      "Iteration 27, loss = 0.93168295\n",
      "Iteration 28, loss = 0.87300948\n",
      "Iteration 29, loss = 0.88377921\n",
      "Iteration 30, loss = 0.85062646\n",
      "Iteration 31, loss = 0.85859233\n",
      "Iteration 32, loss = 0.88128167\n",
      "Iteration 33, loss = 0.89362108\n",
      "Iteration 34, loss = 0.83721384\n",
      "Iteration 35, loss = 0.85579093\n",
      "Iteration 36, loss = 0.82591341\n",
      "Iteration 37, loss = 0.86117186\n",
      "Iteration 38, loss = 0.87563597\n",
      "Iteration 39, loss = 0.84888886\n",
      "Iteration 40, loss = 0.83499682\n",
      "Iteration 41, loss = 0.85893071\n",
      "Iteration 42, loss = 0.84321137\n",
      "Iteration 43, loss = 0.87605909\n",
      "Iteration 44, loss = 0.83349970\n",
      "Iteration 45, loss = 0.81235522\n",
      "Iteration 46, loss = 0.80468081\n",
      "Iteration 47, loss = 0.81813944\n",
      "Iteration 48, loss = 0.82517946\n",
      "Iteration 49, loss = 0.81177892\n",
      "Iteration 50, loss = 0.83041327\n",
      "Iteration 1, loss = 1.20641789\n",
      "Iteration 38, loss = 0.87563597\n",
      "Iteration 39, loss = 0.84888886\n",
      "Iteration 40, loss = 0.83499682\n",
      "Iteration 41, loss = 0.85893071\n",
      "Iteration 42, loss = 0.84321137\n",
      "Iteration 43, loss = 0.87605909\n",
      "Iteration 44, loss = 0.83349970\n",
      "Iteration 45, loss = 0.81235522\n",
      "Iteration 46, loss = 0.80468081\n",
      "Iteration 47, loss = 0.81813944\n",
      "Iteration 48, loss = 0.82517946\n",
      "Iteration 49, loss = 0.81177892\n",
      "Iteration 50, loss = 0.83041327\n",
      "Iteration 1, loss = 1.20641789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.04456298\n",
      "Iteration 3, loss = 0.97964097\n",
      "Iteration 4, loss = 0.96684960\n",
      "Iteration 5, loss = 0.94673037\n",
      "Iteration 6, loss = 0.96814658\n",
      "Iteration 7, loss = 0.93870950\n",
      "Iteration 8, loss = 0.95152821\n",
      "Iteration 9, loss = 0.92391371\n",
      "Iteration 10, loss = 0.92351438\n",
      "Iteration 11, loss = 0.88665117\n",
      "Iteration 12, loss = 0.94922560\n",
      "Iteration 13, loss = 0.94594287\n",
      "Iteration 14, loss = 0.91975559\n",
      "Iteration 15, loss = 0.91585731\n",
      "Iteration 2, loss = 1.04456298\n",
      "Iteration 3, loss = 0.97964097\n",
      "Iteration 4, loss = 0.96684960\n",
      "Iteration 5, loss = 0.94673037\n",
      "Iteration 6, loss = 0.96814658\n",
      "Iteration 7, loss = 0.93870950\n",
      "Iteration 8, loss = 0.95152821\n",
      "Iteration 9, loss = 0.92391371\n",
      "Iteration 10, loss = 0.92351438\n",
      "Iteration 11, loss = 0.88665117\n",
      "Iteration 12, loss = 0.94922560\n",
      "Iteration 13, loss = 0.94594287\n",
      "Iteration 14, loss = 0.91975559\n",
      "Iteration 15, loss = 0.91585731\n",
      "Iteration 16, loss = 0.87290430\n",
      "Iteration 17, loss = 0.90854226\n",
      "Iteration 18, loss = 0.88194110\n",
      "Iteration 19, loss = 0.88434550\n",
      "Iteration 20, loss = 0.90513390\n",
      "Iteration 21, loss = 0.90702026\n",
      "Iteration 22, loss = 0.90003003\n",
      "Iteration 23, loss = 0.87104033\n",
      "Iteration 24, loss = 0.91529079\n",
      "Iteration 25, loss = 0.88151774\n",
      "Iteration 26, loss = 0.91156144\n",
      "Iteration 27, loss = 0.86531085\n",
      "Iteration 28, loss = 0.85757990\n",
      "Iteration 29, loss = 0.86685449\n",
      "Iteration 30, loss = 0.83182533\n",
      "Iteration 16, loss = 0.87290430\n",
      "Iteration 17, loss = 0.90854226\n",
      "Iteration 18, loss = 0.88194110\n",
      "Iteration 19, loss = 0.88434550\n",
      "Iteration 20, loss = 0.90513390\n",
      "Iteration 21, loss = 0.90702026\n",
      "Iteration 22, loss = 0.90003003\n",
      "Iteration 23, loss = 0.87104033\n",
      "Iteration 24, loss = 0.91529079\n",
      "Iteration 25, loss = 0.88151774\n",
      "Iteration 26, loss = 0.91156144\n",
      "Iteration 27, loss = 0.86531085\n",
      "Iteration 28, loss = 0.85757990\n",
      "Iteration 29, loss = 0.86685449\n",
      "Iteration 30, loss = 0.83182533\n",
      "Iteration 31, loss = 0.86579647\n",
      "Iteration 32, loss = 0.84502549\n",
      "Iteration 33, loss = 0.85930214\n",
      "Iteration 34, loss = 0.83317873\n",
      "Iteration 35, loss = 0.84005981\n",
      "Iteration 36, loss = 0.83452295\n",
      "Iteration 37, loss = 0.82666397\n",
      "Iteration 38, loss = 0.84982138\n",
      "Iteration 39, loss = 0.81447316\n",
      "Iteration 40, loss = 0.82796761\n",
      "Iteration 41, loss = 0.86940479\n",
      "Iteration 42, loss = 0.84916669\n",
      "Iteration 43, loss = 0.82133330\n",
      "Iteration 44, loss = 0.85284003\n",
      "Iteration 31, loss = 0.86579647\n",
      "Iteration 32, loss = 0.84502549\n",
      "Iteration 33, loss = 0.85930214\n",
      "Iteration 34, loss = 0.83317873\n",
      "Iteration 35, loss = 0.84005981\n",
      "Iteration 36, loss = 0.83452295\n",
      "Iteration 37, loss = 0.82666397\n",
      "Iteration 38, loss = 0.84982138\n",
      "Iteration 39, loss = 0.81447316\n",
      "Iteration 40, loss = 0.82796761\n",
      "Iteration 41, loss = 0.86940479\n",
      "Iteration 42, loss = 0.84916669\n",
      "Iteration 43, loss = 0.82133330\n",
      "Iteration 44, loss = 0.85284003\n",
      "Iteration 45, loss = 0.81777718\n",
      "Iteration 46, loss = 0.81233303\n",
      "Iteration 47, loss = 0.82493927\n",
      "Iteration 48, loss = 0.81541447\n",
      "Iteration 49, loss = 0.80500238\n",
      "Iteration 50, loss = 0.77675779\n",
      "Iteration 1, loss = 1.21383470\n",
      "Iteration 2, loss = 1.10338448\n",
      "Iteration 3, loss = 1.04755560\n",
      "Iteration 4, loss = 1.05730850\n",
      "Iteration 5, loss = 0.95925798\n",
      "Iteration 6, loss = 0.97383792\n",
      "Iteration 7, loss = 0.96223613\n",
      "Iteration 45, loss = 0.81777718\n",
      "Iteration 46, loss = 0.81233303\n",
      "Iteration 47, loss = 0.82493927\n",
      "Iteration 48, loss = 0.81541447\n",
      "Iteration 49, loss = 0.80500238\n",
      "Iteration 50, loss = 0.77675779\n",
      "Iteration 1, loss = 1.21383470\n",
      "Iteration 2, loss = 1.10338448\n",
      "Iteration 3, loss = 1.04755560\n",
      "Iteration 4, loss = 1.05730850\n",
      "Iteration 5, loss = 0.95925798\n",
      "Iteration 6, loss = 0.97383792\n",
      "Iteration 7, loss = 0.96223613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.98081034\n",
      "Iteration 9, loss = 0.94275596\n",
      "Iteration 10, loss = 0.94469863\n",
      "Iteration 11, loss = 0.92066882\n",
      "Iteration 12, loss = 0.94424520\n",
      "Iteration 13, loss = 0.94347307\n",
      "Iteration 14, loss = 0.91489623\n",
      "Iteration 15, loss = 0.92058267\n",
      "Iteration 16, loss = 0.92044928\n",
      "Iteration 17, loss = 0.95230324\n",
      "Iteration 18, loss = 0.92745780\n",
      "Iteration 19, loss = 0.90087880\n",
      "Iteration 20, loss = 0.93753252\n",
      "Iteration 21, loss = 0.91742677\n",
      "Iteration 8, loss = 0.98081034\n",
      "Iteration 9, loss = 0.94275596\n",
      "Iteration 10, loss = 0.94469863\n",
      "Iteration 11, loss = 0.92066882\n",
      "Iteration 12, loss = 0.94424520\n",
      "Iteration 13, loss = 0.94347307\n",
      "Iteration 14, loss = 0.91489623\n",
      "Iteration 15, loss = 0.92058267\n",
      "Iteration 16, loss = 0.92044928\n",
      "Iteration 17, loss = 0.95230324\n",
      "Iteration 18, loss = 0.92745780\n",
      "Iteration 19, loss = 0.90087880\n",
      "Iteration 20, loss = 0.93753252\n",
      "Iteration 21, loss = 0.91742677\n",
      "Iteration 22, loss = 0.98563220\n",
      "Iteration 23, loss = 0.88320783\n",
      "Iteration 24, loss = 0.88733129\n",
      "Iteration 25, loss = 0.88185205\n",
      "Iteration 26, loss = 0.92313812\n",
      "Iteration 27, loss = 0.88421581\n",
      "Iteration 28, loss = 0.82505975\n",
      "Iteration 29, loss = 0.82482489\n",
      "Iteration 30, loss = 0.84590089\n",
      "Iteration 31, loss = 0.88952688\n",
      "Iteration 32, loss = 0.85846439\n",
      "Iteration 33, loss = 0.83946961\n",
      "Iteration 34, loss = 0.82098014\n",
      "Iteration 35, loss = 0.83204780\n",
      "Iteration 36, loss = 0.85336606\n",
      "Iteration 22, loss = 0.98563220\n",
      "Iteration 23, loss = 0.88320783\n",
      "Iteration 24, loss = 0.88733129\n",
      "Iteration 25, loss = 0.88185205\n",
      "Iteration 26, loss = 0.92313812\n",
      "Iteration 27, loss = 0.88421581\n",
      "Iteration 28, loss = 0.82505975\n",
      "Iteration 29, loss = 0.82482489\n",
      "Iteration 30, loss = 0.84590089\n",
      "Iteration 31, loss = 0.88952688\n",
      "Iteration 32, loss = 0.85846439\n",
      "Iteration 33, loss = 0.83946961\n",
      "Iteration 34, loss = 0.82098014\n",
      "Iteration 35, loss = 0.83204780\n",
      "Iteration 36, loss = 0.85336606\n",
      "Iteration 37, loss = 0.83348966\n",
      "Iteration 38, loss = 0.82831976\n",
      "Iteration 39, loss = 0.83865974\n",
      "Iteration 40, loss = 0.80544970\n",
      "Iteration 41, loss = 0.79767979\n",
      "Iteration 42, loss = 0.77247405\n",
      "Iteration 43, loss = 0.78583741\n",
      "Iteration 44, loss = 0.85735590\n",
      "Iteration 45, loss = 0.88216636\n",
      "Iteration 46, loss = 0.91321558\n",
      "Iteration 47, loss = 0.84305990\n",
      "Iteration 48, loss = 0.81698835\n",
      "Iteration 49, loss = 0.83348863\n",
      "Iteration 50, loss = 0.82000441\n",
      "Iteration 37, loss = 0.83348966\n",
      "Iteration 38, loss = 0.82831976\n",
      "Iteration 39, loss = 0.83865974\n",
      "Iteration 40, loss = 0.80544970\n",
      "Iteration 41, loss = 0.79767979\n",
      "Iteration 42, loss = 0.77247405\n",
      "Iteration 43, loss = 0.78583741\n",
      "Iteration 44, loss = 0.85735590\n",
      "Iteration 45, loss = 0.88216636\n",
      "Iteration 46, loss = 0.91321558\n",
      "Iteration 47, loss = 0.84305990\n",
      "Iteration 48, loss = 0.81698835\n",
      "Iteration 49, loss = 0.83348863\n",
      "Iteration 50, loss = 0.82000441\n",
      "Iteration 51, loss = 0.83148598\n",
      "Iteration 52, loss = 0.77052875\n",
      "Iteration 53, loss = 0.77735662\n",
      "Iteration 54, loss = 0.81223744\n",
      "Iteration 55, loss = 0.79901032\n",
      "Iteration 56, loss = 0.79575754\n",
      "Iteration 57, loss = 0.78856521\n",
      "Iteration 58, loss = 0.80328224\n",
      "Iteration 59, loss = 0.79394473\n",
      "Iteration 60, loss = 0.80471091\n",
      "Iteration 61, loss = 0.76684876\n",
      "Iteration 62, loss = 0.81025986\n",
      "Iteration 63, loss = 0.80943641\n",
      "Iteration 64, loss = 0.77306597\n",
      "Iteration 65, loss = 0.89457945\n",
      "Iteration 51, loss = 0.83148598\n",
      "Iteration 52, loss = 0.77052875\n",
      "Iteration 53, loss = 0.77735662\n",
      "Iteration 54, loss = 0.81223744\n",
      "Iteration 55, loss = 0.79901032\n",
      "Iteration 56, loss = 0.79575754\n",
      "Iteration 57, loss = 0.78856521\n",
      "Iteration 58, loss = 0.80328224\n",
      "Iteration 59, loss = 0.79394473\n",
      "Iteration 60, loss = 0.80471091\n",
      "Iteration 61, loss = 0.76684876\n",
      "Iteration 62, loss = 0.81025986\n",
      "Iteration 63, loss = 0.80943641\n",
      "Iteration 64, loss = 0.77306597\n",
      "Iteration 65, loss = 0.89457945\n",
      "Iteration 66, loss = 0.80160663\n",
      "Iteration 67, loss = 0.76799954\n",
      "Iteration 68, loss = 0.79585787\n",
      "Iteration 69, loss = 0.73473340\n",
      "Iteration 70, loss = 0.72308816\n",
      "Iteration 71, loss = 0.71840367\n",
      "Iteration 72, loss = 0.76537674\n",
      "Iteration 73, loss = 0.76153441\n",
      "Iteration 74, loss = 0.73643491\n",
      "Iteration 75, loss = 0.71730021\n",
      "Iteration 76, loss = 0.78693778\n",
      "Iteration 77, loss = 0.74924925\n",
      "Iteration 78, loss = 0.73974395\n",
      "Iteration 79, loss = 0.71277584\n",
      "Iteration 80, loss = 0.72047849\n",
      "Iteration 81, loss = 0.74782841\n",
      "Iteration 66, loss = 0.80160663\n",
      "Iteration 67, loss = 0.76799954\n",
      "Iteration 68, loss = 0.79585787\n",
      "Iteration 69, loss = 0.73473340\n",
      "Iteration 70, loss = 0.72308816\n",
      "Iteration 71, loss = 0.71840367\n",
      "Iteration 72, loss = 0.76537674\n",
      "Iteration 73, loss = 0.76153441\n",
      "Iteration 74, loss = 0.73643491\n",
      "Iteration 75, loss = 0.71730021\n",
      "Iteration 76, loss = 0.78693778\n",
      "Iteration 77, loss = 0.74924925\n",
      "Iteration 78, loss = 0.73974395\n",
      "Iteration 79, loss = 0.71277584\n",
      "Iteration 80, loss = 0.72047849\n",
      "Iteration 81, loss = 0.74782841\n",
      "Iteration 82, loss = 0.73521347\n",
      "Iteration 83, loss = 0.72784927\n",
      "Iteration 84, loss = 0.73423616\n",
      "Iteration 85, loss = 0.70961310\n",
      "Iteration 86, loss = 0.71064801\n",
      "Iteration 87, loss = 0.70013318\n",
      "Iteration 88, loss = 0.72911724\n",
      "Iteration 89, loss = 0.71921597\n",
      "Iteration 90, loss = 0.73046990\n",
      "Iteration 91, loss = 0.71418487\n",
      "Iteration 92, loss = 0.72997143\n",
      "Iteration 93, loss = 0.71940389\n",
      "Iteration 94, loss = 0.68260095\n",
      "Iteration 95, loss = 0.72852858\n",
      "Iteration 96, loss = 0.70355111\n",
      "Iteration 82, loss = 0.73521347\n",
      "Iteration 83, loss = 0.72784927\n",
      "Iteration 84, loss = 0.73423616\n",
      "Iteration 85, loss = 0.70961310\n",
      "Iteration 86, loss = 0.71064801\n",
      "Iteration 87, loss = 0.70013318\n",
      "Iteration 88, loss = 0.72911724\n",
      "Iteration 89, loss = 0.71921597\n",
      "Iteration 90, loss = 0.73046990\n",
      "Iteration 91, loss = 0.71418487\n",
      "Iteration 92, loss = 0.72997143\n",
      "Iteration 93, loss = 0.71940389\n",
      "Iteration 94, loss = 0.68260095\n",
      "Iteration 95, loss = 0.72852858\n",
      "Iteration 96, loss = 0.70355111\n",
      "Iteration 97, loss = 0.72335945\n",
      "Iteration 98, loss = 0.68501068\n",
      "Iteration 99, loss = 0.70856128\n",
      "Iteration 100, loss = 0.72909447\n",
      "Iteration 1, loss = 1.15335650\n",
      "Iteration 2, loss = 0.98166779\n",
      "Iteration 3, loss = 0.96694667\n",
      "Iteration 4, loss = 0.96821252\n",
      "Iteration 5, loss = 0.88531771\n",
      "Iteration 6, loss = 0.88607639\n",
      "Iteration 7, loss = 0.91144624\n",
      "Iteration 8, loss = 0.88728297\n",
      "Iteration 9, loss = 0.88465381Iteration 97, loss = 0.72335945\n",
      "Iteration 98, loss = 0.68501068\n",
      "Iteration 99, loss = 0.70856128\n",
      "Iteration 100, loss = 0.72909447\n",
      "Iteration 1, loss = 1.15335650\n",
      "Iteration 2, loss = 0.98166779\n",
      "Iteration 3, loss = 0.96694667\n",
      "Iteration 4, loss = 0.96821252\n",
      "Iteration 5, loss = 0.88531771\n",
      "Iteration 6, loss = 0.88607639\n",
      "Iteration 7, loss = 0.91144624\n",
      "Iteration 8, loss = 0.88728297\n",
      "Iteration 9, loss = 0.88465381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 10, loss = 0.89676479\n",
      "Iteration 11, loss = 0.86636281\n",
      "Iteration 12, loss = 0.85561700\n",
      "Iteration 13, loss = 0.88386961\n",
      "Iteration 14, loss = 0.86853019\n",
      "Iteration 15, loss = 0.90434571\n",
      "Iteration 16, loss = 0.86371027\n",
      "Iteration 17, loss = 0.84415095\n",
      "Iteration 18, loss = 0.85872548\n",
      "Iteration 19, loss = 0.87244445\n",
      "Iteration 20, loss = 0.88195495\n",
      "Iteration 21, loss = 0.87132403\n",
      "Iteration 22, loss = 0.83391542\n",
      "Iteration 23, loss = 0.83779534\n",
      "\n",
      "Iteration 10, loss = 0.89676479\n",
      "Iteration 11, loss = 0.86636281\n",
      "Iteration 12, loss = 0.85561700\n",
      "Iteration 13, loss = 0.88386961\n",
      "Iteration 14, loss = 0.86853019\n",
      "Iteration 15, loss = 0.90434571\n",
      "Iteration 16, loss = 0.86371027\n",
      "Iteration 17, loss = 0.84415095\n",
      "Iteration 18, loss = 0.85872548\n",
      "Iteration 19, loss = 0.87244445\n",
      "Iteration 20, loss = 0.88195495\n",
      "Iteration 21, loss = 0.87132403\n",
      "Iteration 22, loss = 0.83391542\n",
      "Iteration 23, loss = 0.83779534\n",
      "Iteration 24, loss = 0.80647451\n",
      "Iteration 25, loss = 0.82516571\n",
      "Iteration 26, loss = 0.81716709\n",
      "Iteration 27, loss = 0.82922919\n",
      "Iteration 28, loss = 0.81317821\n",
      "Iteration 29, loss = 0.79262691\n",
      "Iteration 30, loss = 0.83647712\n",
      "Iteration 31, loss = 0.80665967\n",
      "Iteration 32, loss = 0.80956621\n",
      "Iteration 33, loss = 0.78841289\n",
      "Iteration 34, loss = 0.78905786\n",
      "Iteration 35, loss = 0.76947873\n",
      "Iteration 36, loss = 0.76977025\n",
      "Iteration 37, loss = 0.79270720\n",
      "Iteration 38, loss = 0.74859814\n",
      "Iteration 24, loss = 0.80647451\n",
      "Iteration 25, loss = 0.82516571\n",
      "Iteration 26, loss = 0.81716709\n",
      "Iteration 27, loss = 0.82922919\n",
      "Iteration 28, loss = 0.81317821\n",
      "Iteration 29, loss = 0.79262691\n",
      "Iteration 30, loss = 0.83647712\n",
      "Iteration 31, loss = 0.80665967\n",
      "Iteration 32, loss = 0.80956621\n",
      "Iteration 33, loss = 0.78841289\n",
      "Iteration 34, loss = 0.78905786\n",
      "Iteration 35, loss = 0.76947873\n",
      "Iteration 36, loss = 0.76977025\n",
      "Iteration 37, loss = 0.79270720\n",
      "Iteration 38, loss = 0.74859814\n",
      "Iteration 39, loss = 0.82380893\n",
      "Iteration 40, loss = 0.81507643\n",
      "Iteration 41, loss = 0.78046009\n",
      "Iteration 42, loss = 0.76311527\n",
      "Iteration 43, loss = 0.76053201\n",
      "Iteration 44, loss = 0.80465968\n",
      "Iteration 45, loss = 0.77319536\n",
      "Iteration 46, loss = 0.74539798\n",
      "Iteration 47, loss = 0.74135573\n",
      "Iteration 48, loss = 0.73694145\n",
      "Iteration 49, loss = 0.74035245\n",
      "Iteration 50, loss = 0.73468232\n",
      "Iteration 51, loss = 0.71134243\n",
      "Iteration 52, loss = 0.74766961\n",
      "Iteration 53, loss = 0.80082761\n",
      "Iteration 54, loss = 0.74294870\n",
      "Iteration 39, loss = 0.82380893\n",
      "Iteration 40, loss = 0.81507643\n",
      "Iteration 41, loss = 0.78046009\n",
      "Iteration 42, loss = 0.76311527\n",
      "Iteration 43, loss = 0.76053201\n",
      "Iteration 44, loss = 0.80465968\n",
      "Iteration 45, loss = 0.77319536\n",
      "Iteration 46, loss = 0.74539798\n",
      "Iteration 47, loss = 0.74135573\n",
      "Iteration 48, loss = 0.73694145\n",
      "Iteration 49, loss = 0.74035245\n",
      "Iteration 50, loss = 0.73468232\n",
      "Iteration 51, loss = 0.71134243\n",
      "Iteration 52, loss = 0.74766961\n",
      "Iteration 53, loss = 0.80082761\n",
      "Iteration 54, loss = 0.74294870\n",
      "Iteration 55, loss = 0.72851418\n",
      "Iteration 56, loss = 0.74304205\n",
      "Iteration 57, loss = 0.76100490\n",
      "Iteration 58, loss = 0.72929873\n",
      "Iteration 59, loss = 0.72683694\n",
      "Iteration 60, loss = 0.77838449\n",
      "Iteration 61, loss = 0.70939132\n",
      "Iteration 62, loss = 0.77213971\n",
      "Iteration 63, loss = 0.73065844\n",
      "Iteration 64, loss = 0.77169731\n",
      "Iteration 65, loss = 0.73275047\n",
      "Iteration 66, loss = 0.77062328\n",
      "Iteration 67, loss = 0.71683756\n",
      "Iteration 68, loss = 0.71986057\n",
      "Iteration 69, loss = 0.68183165\n",
      "Iteration 70, loss = 0.72232481\n",
      "Iteration 55, loss = 0.72851418\n",
      "Iteration 56, loss = 0.74304205\n",
      "Iteration 57, loss = 0.76100490\n",
      "Iteration 58, loss = 0.72929873\n",
      "Iteration 59, loss = 0.72683694\n",
      "Iteration 60, loss = 0.77838449\n",
      "Iteration 61, loss = 0.70939132\n",
      "Iteration 62, loss = 0.77213971\n",
      "Iteration 63, loss = 0.73065844\n",
      "Iteration 64, loss = 0.77169731\n",
      "Iteration 65, loss = 0.73275047\n",
      "Iteration 66, loss = 0.77062328\n",
      "Iteration 67, loss = 0.71683756\n",
      "Iteration 68, loss = 0.71986057\n",
      "Iteration 69, loss = 0.68183165\n",
      "Iteration 70, loss = 0.72232481\n",
      "Iteration 71, loss = 0.72046305\n",
      "Iteration 72, loss = 0.74862400\n",
      "Iteration 73, loss = 0.73353559\n",
      "Iteration 74, loss = 0.67973761\n",
      "Iteration 75, loss = 0.71584896\n",
      "Iteration 76, loss = 0.71955501\n",
      "Iteration 77, loss = 0.75359710\n",
      "Iteration 78, loss = 0.71301419\n",
      "Iteration 79, loss = 0.69764351\n",
      "Iteration 80, loss = 0.72109613\n",
      "Iteration 81, loss = 0.71036552\n",
      "Iteration 82, loss = 0.71063928\n",
      "Iteration 83, loss = 0.72062468\n",
      "Iteration 84, loss = 0.69919681\n",
      "Iteration 85, loss = 0.66976273\n",
      "Iteration 86, loss = 0.75248480\n",
      "Iteration 71, loss = 0.72046305\n",
      "Iteration 72, loss = 0.74862400\n",
      "Iteration 73, loss = 0.73353559\n",
      "Iteration 74, loss = 0.67973761\n",
      "Iteration 75, loss = 0.71584896\n",
      "Iteration 76, loss = 0.71955501\n",
      "Iteration 77, loss = 0.75359710\n",
      "Iteration 78, loss = 0.71301419\n",
      "Iteration 79, loss = 0.69764351\n",
      "Iteration 80, loss = 0.72109613\n",
      "Iteration 81, loss = 0.71036552\n",
      "Iteration 82, loss = 0.71063928\n",
      "Iteration 83, loss = 0.72062468\n",
      "Iteration 84, loss = 0.69919681\n",
      "Iteration 85, loss = 0.66976273\n",
      "Iteration 86, loss = 0.75248480\n",
      "Iteration 87, loss = 0.70943812\n",
      "Iteration 88, loss = 0.68488919\n",
      "Iteration 89, loss = 0.66830257\n",
      "Iteration 90, loss = 0.66949251\n",
      "Iteration 91, loss = 0.67105126\n",
      "Iteration 92, loss = 0.64975208\n",
      "Iteration 93, loss = 0.66711001\n",
      "Iteration 94, loss = 0.71144191\n",
      "Iteration 95, loss = 0.69919619\n",
      "Iteration 96, loss = 0.65769281\n",
      "Iteration 97, loss = 0.64463402\n",
      "Iteration 98, loss = 0.66590095\n",
      "Iteration 99, loss = 0.73663296\n",
      "Iteration 100, loss = 0.67176405\n",
      "Iteration 1, loss = 1.19288628\n",
      "Iteration 87, loss = 0.70943812\n",
      "Iteration 88, loss = 0.68488919\n",
      "Iteration 89, loss = 0.66830257\n",
      "Iteration 90, loss = 0.66949251\n",
      "Iteration 91, loss = 0.67105126\n",
      "Iteration 92, loss = 0.64975208\n",
      "Iteration 93, loss = 0.66711001\n",
      "Iteration 94, loss = 0.71144191\n",
      "Iteration 95, loss = 0.69919619\n",
      "Iteration 96, loss = 0.65769281\n",
      "Iteration 97, loss = 0.64463402\n",
      "Iteration 98, loss = 0.66590095\n",
      "Iteration 99, loss = 0.73663296\n",
      "Iteration 100, loss = 0.67176405\n",
      "Iteration 1, loss = 1.19288628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.02887090\n",
      "Iteration 3, loss = 0.98398798\n",
      "Iteration 4, loss = 0.97042978\n",
      "Iteration 5, loss = 0.97733353\n",
      "Iteration 6, loss = 0.93007778\n",
      "Iteration 7, loss = 0.96055653\n",
      "Iteration 8, loss = 0.91924604\n",
      "Iteration 9, loss = 0.94858516\n",
      "Iteration 10, loss = 0.94911522\n",
      "Iteration 11, loss = 0.90715823\n",
      "Iteration 12, loss = 0.93699733\n",
      "Iteration 13, loss = 0.93171192\n",
      "Iteration 2, loss = 1.02887090\n",
      "Iteration 3, loss = 0.98398798\n",
      "Iteration 4, loss = 0.97042978\n",
      "Iteration 5, loss = 0.97733353\n",
      "Iteration 6, loss = 0.93007778\n",
      "Iteration 7, loss = 0.96055653\n",
      "Iteration 8, loss = 0.91924604\n",
      "Iteration 9, loss = 0.94858516\n",
      "Iteration 10, loss = 0.94911522\n",
      "Iteration 11, loss = 0.90715823\n",
      "Iteration 12, loss = 0.93699733\n",
      "Iteration 13, loss = 0.93171192\n",
      "Iteration 14, loss = 0.91781646\n",
      "Iteration 15, loss = 0.91728076\n",
      "Iteration 16, loss = 0.92368265\n",
      "Iteration 17, loss = 0.91305583\n",
      "Iteration 18, loss = 0.89549308\n",
      "Iteration 19, loss = 0.90330529\n",
      "Iteration 20, loss = 0.89478533\n",
      "Iteration 21, loss = 0.88886083\n",
      "Iteration 22, loss = 0.89538565\n",
      "Iteration 23, loss = 0.87430683\n",
      "Iteration 24, loss = 0.90249104\n",
      "Iteration 25, loss = 0.86707125\n",
      "Iteration 26, loss = 0.91254180\n",
      "Iteration 27, loss = 0.89974522\n",
      "Iteration 28, loss = 0.86010106\n",
      "Iteration 14, loss = 0.91781646\n",
      "Iteration 15, loss = 0.91728076\n",
      "Iteration 16, loss = 0.92368265\n",
      "Iteration 17, loss = 0.91305583\n",
      "Iteration 18, loss = 0.89549308\n",
      "Iteration 19, loss = 0.90330529\n",
      "Iteration 20, loss = 0.89478533\n",
      "Iteration 21, loss = 0.88886083\n",
      "Iteration 22, loss = 0.89538565\n",
      "Iteration 23, loss = 0.87430683\n",
      "Iteration 24, loss = 0.90249104\n",
      "Iteration 25, loss = 0.86707125\n",
      "Iteration 26, loss = 0.91254180\n",
      "Iteration 27, loss = 0.89974522\n",
      "Iteration 28, loss = 0.86010106\n",
      "Iteration 29, loss = 0.87864469\n",
      "Iteration 30, loss = 0.83395264\n",
      "Iteration 31, loss = 0.85262813\n",
      "Iteration 32, loss = 0.88050266\n",
      "Iteration 33, loss = 0.90861897\n",
      "Iteration 34, loss = 0.83310108\n",
      "Iteration 35, loss = 0.82131241\n",
      "Iteration 36, loss = 0.89156800\n",
      "Iteration 37, loss = 0.88119757\n",
      "Iteration 38, loss = 0.86776508\n",
      "Iteration 39, loss = 0.84860047\n",
      "Iteration 40, loss = 0.86862020\n",
      "Iteration 41, loss = 0.86290878\n",
      "Iteration 42, loss = 0.88911616\n",
      "Iteration 43, loss = 0.82893983\n",
      "Iteration 29, loss = 0.87864469\n",
      "Iteration 30, loss = 0.83395264\n",
      "Iteration 31, loss = 0.85262813\n",
      "Iteration 32, loss = 0.88050266\n",
      "Iteration 33, loss = 0.90861897\n",
      "Iteration 34, loss = 0.83310108\n",
      "Iteration 35, loss = 0.82131241\n",
      "Iteration 36, loss = 0.89156800\n",
      "Iteration 37, loss = 0.88119757\n",
      "Iteration 38, loss = 0.86776508\n",
      "Iteration 39, loss = 0.84860047\n",
      "Iteration 40, loss = 0.86862020\n",
      "Iteration 41, loss = 0.86290878\n",
      "Iteration 42, loss = 0.88911616\n",
      "Iteration 43, loss = 0.82893983\n",
      "Iteration 44, loss = 0.85501731\n",
      "Iteration 45, loss = 0.81570603\n",
      "Iteration 46, loss = 0.77575498\n",
      "Iteration 47, loss = 0.85790528\n",
      "Iteration 48, loss = 0.81951452\n",
      "Iteration 49, loss = 0.81814681\n",
      "Iteration 50, loss = 0.81160966\n",
      "Iteration 51, loss = 0.80987555\n",
      "Iteration 52, loss = 0.81409623\n",
      "Iteration 53, loss = 0.79344727\n",
      "Iteration 54, loss = 0.77582147\n",
      "Iteration 55, loss = 0.79516465\n",
      "Iteration 56, loss = 0.83073826\n",
      "Iteration 57, loss = 0.78374791\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20237473\n",
      "Iteration 2, loss = 1.04907491\n",
      "Iteration 44, loss = 0.85501731\n",
      "Iteration 45, loss = 0.81570603\n",
      "Iteration 46, loss = 0.77575498\n",
      "Iteration 47, loss = 0.85790528\n",
      "Iteration 48, loss = 0.81951452\n",
      "Iteration 49, loss = 0.81814681\n",
      "Iteration 50, loss = 0.81160966\n",
      "Iteration 51, loss = 0.80987555\n",
      "Iteration 52, loss = 0.81409623\n",
      "Iteration 53, loss = 0.79344727\n",
      "Iteration 54, loss = 0.77582147\n",
      "Iteration 55, loss = 0.79516465\n",
      "Iteration 56, loss = 0.83073826\n",
      "Iteration 57, loss = 0.78374791\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20237473\n",
      "Iteration 2, loss = 1.04907491\n",
      "Iteration 3, loss = 1.01172096\n",
      "Iteration 4, loss = 0.97361034\n",
      "Iteration 5, loss = 0.96783666\n",
      "Iteration 6, loss = 0.96599106\n",
      "Iteration 7, loss = 1.01136884\n",
      "Iteration 8, loss = 0.95997167\n",
      "Iteration 9, loss = 0.95509894\n",
      "Iteration 10, loss = 0.96117072\n",
      "Iteration 11, loss = 0.93598114\n",
      "Iteration 12, loss = 0.95072850\n",
      "Iteration 13, loss = 0.95028537\n",
      "Iteration 14, loss = 0.93831089\n",
      "Iteration 15, loss = 0.94748112\n",
      "Iteration 16, loss = 0.90360845\n",
      "Iteration 17, loss = 0.92691140\n",
      "Iteration 3, loss = 1.01172096\n",
      "Iteration 4, loss = 0.97361034\n",
      "Iteration 5, loss = 0.96783666\n",
      "Iteration 6, loss = 0.96599106\n",
      "Iteration 7, loss = 1.01136884\n",
      "Iteration 8, loss = 0.95997167\n",
      "Iteration 9, loss = 0.95509894\n",
      "Iteration 10, loss = 0.96117072\n",
      "Iteration 11, loss = 0.93598114\n",
      "Iteration 12, loss = 0.95072850\n",
      "Iteration 13, loss = 0.95028537\n",
      "Iteration 14, loss = 0.93831089\n",
      "Iteration 15, loss = 0.94748112\n",
      "Iteration 16, loss = 0.90360845\n",
      "Iteration 17, loss = 0.92691140\n",
      "Iteration 18, loss = 0.90323397\n",
      "Iteration 19, loss = 0.86829531\n",
      "Iteration 20, loss = 0.90770280\n",
      "Iteration 21, loss = 0.89217483\n",
      "Iteration 22, loss = 0.89359987\n",
      "Iteration 23, loss = 0.87688420\n",
      "Iteration 24, loss = 0.90161152\n",
      "Iteration 25, loss = 0.88305125\n",
      "Iteration 26, loss = 0.92627240\n",
      "Iteration 27, loss = 0.93168295\n",
      "Iteration 28, loss = 0.87300948\n",
      "Iteration 29, loss = 0.88377921\n",
      "Iteration 30, loss = 0.85062646\n",
      "Iteration 31, loss = 0.85859233\n",
      "Iteration 18, loss = 0.90323397\n",
      "Iteration 19, loss = 0.86829531\n",
      "Iteration 20, loss = 0.90770280\n",
      "Iteration 21, loss = 0.89217483\n",
      "Iteration 22, loss = 0.89359987\n",
      "Iteration 23, loss = 0.87688420\n",
      "Iteration 24, loss = 0.90161152\n",
      "Iteration 25, loss = 0.88305125\n",
      "Iteration 26, loss = 0.92627240\n",
      "Iteration 27, loss = 0.93168295\n",
      "Iteration 28, loss = 0.87300948\n",
      "Iteration 29, loss = 0.88377921\n",
      "Iteration 30, loss = 0.85062646\n",
      "Iteration 31, loss = 0.85859233\n",
      "Iteration 32, loss = 0.88128167\n",
      "Iteration 33, loss = 0.89362108\n",
      "Iteration 34, loss = 0.83721384\n",
      "Iteration 35, loss = 0.85579093\n",
      "Iteration 36, loss = 0.82591341\n",
      "Iteration 37, loss = 0.86117186\n",
      "Iteration 38, loss = 0.87563597\n",
      "Iteration 39, loss = 0.84888886\n",
      "Iteration 40, loss = 0.83499682\n",
      "Iteration 41, loss = 0.85893071\n",
      "Iteration 42, loss = 0.84321137\n",
      "Iteration 43, loss = 0.87605909\n",
      "Iteration 44, loss = 0.83349970\n",
      "Iteration 45, loss = 0.81235522\n",
      "Iteration 46, loss = 0.80468081\n",
      "Iteration 32, loss = 0.88128167\n",
      "Iteration 33, loss = 0.89362108\n",
      "Iteration 34, loss = 0.83721384\n",
      "Iteration 35, loss = 0.85579093\n",
      "Iteration 36, loss = 0.82591341\n",
      "Iteration 37, loss = 0.86117186\n",
      "Iteration 38, loss = 0.87563597\n",
      "Iteration 39, loss = 0.84888886\n",
      "Iteration 40, loss = 0.83499682\n",
      "Iteration 41, loss = 0.85893071\n",
      "Iteration 42, loss = 0.84321137\n",
      "Iteration 43, loss = 0.87605909\n",
      "Iteration 44, loss = 0.83349970\n",
      "Iteration 45, loss = 0.81235522\n",
      "Iteration 46, loss = 0.80468081\n",
      "Iteration 47, loss = 0.81813944\n",
      "Iteration 48, loss = 0.82517946\n",
      "Iteration 49, loss = 0.81177892\n",
      "Iteration 50, loss = 0.83041327\n",
      "Iteration 51, loss = 0.81027942\n",
      "Iteration 52, loss = 0.80176671\n",
      "Iteration 53, loss = 0.79277700\n",
      "Iteration 54, loss = 0.80492641\n",
      "Iteration 55, loss = 0.81002628\n",
      "Iteration 56, loss = 0.83994912\n",
      "Iteration 57, loss = 0.86742096\n",
      "Iteration 58, loss = 0.82009147\n",
      "Iteration 59, loss = 0.79247580\n",
      "Iteration 60, loss = 0.84010933\n",
      "Iteration 61, loss = 0.79114448\n",
      "Iteration 47, loss = 0.81813944\n",
      "Iteration 48, loss = 0.82517946\n",
      "Iteration 49, loss = 0.81177892\n",
      "Iteration 50, loss = 0.83041327\n",
      "Iteration 51, loss = 0.81027942\n",
      "Iteration 52, loss = 0.80176671\n",
      "Iteration 53, loss = 0.79277700\n",
      "Iteration 54, loss = 0.80492641\n",
      "Iteration 55, loss = 0.81002628\n",
      "Iteration 56, loss = 0.83994912\n",
      "Iteration 57, loss = 0.86742096\n",
      "Iteration 58, loss = 0.82009147\n",
      "Iteration 59, loss = 0.79247580\n",
      "Iteration 60, loss = 0.84010933\n",
      "Iteration 61, loss = 0.79114448\n",
      "Iteration 62, loss = 0.80122129\n",
      "Iteration 63, loss = 0.76689843\n",
      "Iteration 64, loss = 0.82076015\n",
      "Iteration 65, loss = 0.79794265\n",
      "Iteration 66, loss = 0.79405074\n",
      "Iteration 67, loss = 0.79090320\n",
      "Iteration 68, loss = 0.82859258\n",
      "Iteration 69, loss = 0.77748812\n",
      "Iteration 70, loss = 0.79543358\n",
      "Iteration 71, loss = 0.77417584\n",
      "Iteration 72, loss = 0.78647605\n",
      "Iteration 73, loss = 0.78363164\n",
      "Iteration 74, loss = 0.78109288\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20641789\n",
      "Iteration 2, loss = 1.04456298\n",
      "Iteration 62, loss = 0.80122129\n",
      "Iteration 63, loss = 0.76689843\n",
      "Iteration 64, loss = 0.82076015\n",
      "Iteration 65, loss = 0.79794265\n",
      "Iteration 66, loss = 0.79405074\n",
      "Iteration 67, loss = 0.79090320\n",
      "Iteration 68, loss = 0.82859258\n",
      "Iteration 69, loss = 0.77748812\n",
      "Iteration 70, loss = 0.79543358\n",
      "Iteration 71, loss = 0.77417584\n",
      "Iteration 72, loss = 0.78647605\n",
      "Iteration 73, loss = 0.78363164\n",
      "Iteration 74, loss = 0.78109288\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20641789\n",
      "Iteration 2, loss = 1.04456298\n",
      "Iteration 3, loss = 0.97964097\n",
      "Iteration 4, loss = 0.96684960\n",
      "Iteration 5, loss = 0.94673037\n",
      "Iteration 6, loss = 0.96814658\n",
      "Iteration 7, loss = 0.93870950\n",
      "Iteration 8, loss = 0.95152821\n",
      "Iteration 9, loss = 0.92391371\n",
      "Iteration 10, loss = 0.92351438\n",
      "Iteration 11, loss = 0.88665117\n",
      "Iteration 12, loss = 0.94922560\n",
      "Iteration 13, loss = 0.94594287\n",
      "Iteration 14, loss = 0.91975559\n",
      "Iteration 15, loss = 0.91585731\n",
      "Iteration 16, loss = 0.87290430\n",
      "Iteration 3, loss = 0.97964097\n",
      "Iteration 4, loss = 0.96684960\n",
      "Iteration 5, loss = 0.94673037\n",
      "Iteration 6, loss = 0.96814658\n",
      "Iteration 7, loss = 0.93870950\n",
      "Iteration 8, loss = 0.95152821\n",
      "Iteration 9, loss = 0.92391371\n",
      "Iteration 10, loss = 0.92351438\n",
      "Iteration 11, loss = 0.88665117\n",
      "Iteration 12, loss = 0.94922560\n",
      "Iteration 13, loss = 0.94594287\n",
      "Iteration 14, loss = 0.91975559\n",
      "Iteration 15, loss = 0.91585731\n",
      "Iteration 16, loss = 0.87290430\n",
      "Iteration 17, loss = 0.90854226\n",
      "Iteration 18, loss = 0.88194110\n",
      "Iteration 19, loss = 0.88434550\n",
      "Iteration 20, loss = 0.90513390\n",
      "Iteration 21, loss = 0.90702026\n",
      "Iteration 22, loss = 0.90003003\n",
      "Iteration 23, loss = 0.87104033\n",
      "Iteration 24, loss = 0.91529079\n",
      "Iteration 25, loss = 0.88151774\n",
      "Iteration 26, loss = 0.91156144\n",
      "Iteration 27, loss = 0.86531085\n",
      "Iteration 28, loss = 0.85757990\n",
      "Iteration 29, loss = 0.86685449\n",
      "Iteration 30, loss = 0.83182533\n",
      "Iteration 31, loss = 0.86579647\n",
      "Iteration 17, loss = 0.90854226\n",
      "Iteration 18, loss = 0.88194110\n",
      "Iteration 19, loss = 0.88434550\n",
      "Iteration 20, loss = 0.90513390\n",
      "Iteration 21, loss = 0.90702026\n",
      "Iteration 22, loss = 0.90003003\n",
      "Iteration 23, loss = 0.87104033\n",
      "Iteration 24, loss = 0.91529079\n",
      "Iteration 25, loss = 0.88151774\n",
      "Iteration 26, loss = 0.91156144\n",
      "Iteration 27, loss = 0.86531085\n",
      "Iteration 28, loss = 0.85757990\n",
      "Iteration 29, loss = 0.86685449\n",
      "Iteration 30, loss = 0.83182533\n",
      "Iteration 31, loss = 0.86579647\n",
      "Iteration 32, loss = 0.84502549\n",
      "Iteration 33, loss = 0.85930214\n",
      "Iteration 34, loss = 0.83317873\n",
      "Iteration 35, loss = 0.84005981\n",
      "Iteration 36, loss = 0.83452295\n",
      "Iteration 37, loss = 0.82666397\n",
      "Iteration 38, loss = 0.84982138\n",
      "Iteration 39, loss = 0.81447316\n",
      "Iteration 40, loss = 0.82796761\n",
      "Iteration 41, loss = 0.86940479\n",
      "Iteration 42, loss = 0.84916669\n",
      "Iteration 43, loss = 0.82133330\n",
      "Iteration 44, loss = 0.85284003\n",
      "Iteration 45, loss = 0.81777718\n",
      "Iteration 46, loss = 0.81233303\n",
      "Iteration 47, loss = 0.82493927\n",
      "Iteration 32, loss = 0.84502549\n",
      "Iteration 33, loss = 0.85930214\n",
      "Iteration 34, loss = 0.83317873\n",
      "Iteration 35, loss = 0.84005981\n",
      "Iteration 36, loss = 0.83452295\n",
      "Iteration 37, loss = 0.82666397\n",
      "Iteration 38, loss = 0.84982138\n",
      "Iteration 39, loss = 0.81447316\n",
      "Iteration 40, loss = 0.82796761\n",
      "Iteration 41, loss = 0.86940479\n",
      "Iteration 42, loss = 0.84916669\n",
      "Iteration 43, loss = 0.82133330\n",
      "Iteration 44, loss = 0.85284003\n",
      "Iteration 45, loss = 0.81777718\n",
      "Iteration 46, loss = 0.81233303\n",
      "Iteration 47, loss = 0.82493927\n",
      "Iteration 48, loss = 0.81541447\n",
      "Iteration 49, loss = 0.80500238\n",
      "Iteration 50, loss = 0.77675779\n",
      "Iteration 51, loss = 0.77272252\n",
      "Iteration 52, loss = 0.76486446\n",
      "Iteration 53, loss = 0.77513358\n",
      "Iteration 54, loss = 0.75673764\n",
      "Iteration 55, loss = 0.79012441\n",
      "Iteration 56, loss = 0.75999276\n",
      "Iteration 57, loss = 0.78280135\n",
      "Iteration 58, loss = 0.78882875\n",
      "Iteration 59, loss = 0.78402020\n",
      "Iteration 60, loss = 0.78271720\n",
      "Iteration 61, loss = 0.75827568\n",
      "Iteration 62, loss = 0.74687631\n",
      "Iteration 48, loss = 0.81541447\n",
      "Iteration 49, loss = 0.80500238\n",
      "Iteration 50, loss = 0.77675779\n",
      "Iteration 51, loss = 0.77272252\n",
      "Iteration 52, loss = 0.76486446\n",
      "Iteration 53, loss = 0.77513358\n",
      "Iteration 54, loss = 0.75673764\n",
      "Iteration 55, loss = 0.79012441\n",
      "Iteration 56, loss = 0.75999276\n",
      "Iteration 57, loss = 0.78280135\n",
      "Iteration 58, loss = 0.78882875\n",
      "Iteration 59, loss = 0.78402020\n",
      "Iteration 60, loss = 0.78271720\n",
      "Iteration 61, loss = 0.75827568\n",
      "Iteration 62, loss = 0.74687631\n",
      "Iteration 63, loss = 0.75192805\n",
      "Iteration 64, loss = 0.75699865\n",
      "Iteration 65, loss = 0.79132018\n",
      "Iteration 66, loss = 0.85938048\n",
      "Iteration 67, loss = 0.83587408\n",
      "Iteration 68, loss = 0.77670139\n",
      "Iteration 69, loss = 0.79530152\n",
      "Iteration 70, loss = 0.76889644\n",
      "Iteration 71, loss = 0.79805439\n",
      "Iteration 72, loss = 0.77726865\n",
      "Iteration 73, loss = 0.76281252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17679877\n",
      "Iteration 2, loss = 0.99991435\n",
      "Iteration 3, loss = 1.01033173\n",
      "Iteration 4, loss = 1.01749091\n",
      "Iteration 63, loss = 0.75192805\n",
      "Iteration 64, loss = 0.75699865\n",
      "Iteration 65, loss = 0.79132018\n",
      "Iteration 66, loss = 0.85938048\n",
      "Iteration 67, loss = 0.83587408\n",
      "Iteration 68, loss = 0.77670139\n",
      "Iteration 69, loss = 0.79530152\n",
      "Iteration 70, loss = 0.76889644\n",
      "Iteration 71, loss = 0.79805439\n",
      "Iteration 72, loss = 0.77726865\n",
      "Iteration 73, loss = 0.76281252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17679877\n",
      "Iteration 2, loss = 0.99991435\n",
      "Iteration 3, loss = 1.01033173\n",
      "Iteration 4, loss = 1.01749091\n",
      "Iteration 5, loss = 0.97756105\n",
      "Iteration 6, loss = 1.01087981\n",
      "Iteration 7, loss = 0.99187470\n",
      "Iteration 8, loss = 1.00348453\n",
      "Iteration 9, loss = 0.98006662\n",
      "Iteration 10, loss = 0.99913788\n",
      "Iteration 1, loss = 1.18944625\n",
      "Iteration 2, loss = 1.10508402\n",
      "Iteration 3, loss = 0.99974931\n",
      "Iteration 4, loss = 1.03955348\n",
      "Iteration 5, loss = 0.95725834\n",
      "Iteration 6, loss = 0.92342304\n",
      "Iteration 5, loss = 0.97756105\n",
      "Iteration 6, loss = 1.01087981\n",
      "Iteration 7, loss = 0.99187470\n",
      "Iteration 8, loss = 1.00348453\n",
      "Iteration 9, loss = 0.98006662\n",
      "Iteration 10, loss = 0.99913788\n",
      "Iteration 1, loss = 1.18944625\n",
      "Iteration 2, loss = 1.10508402\n",
      "Iteration 3, loss = 0.99974931\n",
      "Iteration 4, loss = 1.03955348\n",
      "Iteration 5, loss = 0.95725834\n",
      "Iteration 6, loss = 0.92342304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.96714546\n",
      "Iteration 8, loss = 0.93452493\n",
      "Iteration 9, loss = 0.92348592\n",
      "Iteration 10, loss = 0.96582213\n",
      "Iteration 1, loss = 1.23079311\n",
      "Iteration 2, loss = 1.13745750\n",
      "Iteration 3, loss = 1.02028988\n",
      "Iteration 4, loss = 1.00725403\n",
      "Iteration 5, loss = 1.15838090\n",
      "Iteration 6, loss = 1.28399299\n",
      "Iteration 7, loss = 1.25967810\n",
      "Iteration 8, loss = 1.24981769\n",
      "Iteration 7, loss = 0.96714546\n",
      "Iteration 8, loss = 0.93452493\n",
      "Iteration 9, loss = 0.92348592\n",
      "Iteration 10, loss = 0.96582213\n",
      "Iteration 1, loss = 1.23079311\n",
      "Iteration 2, loss = 1.13745750\n",
      "Iteration 3, loss = 1.02028988\n",
      "Iteration 4, loss = 1.00725403\n",
      "Iteration 5, loss = 1.15838090\n",
      "Iteration 6, loss = 1.28399299\n",
      "Iteration 7, loss = 1.25967810\n",
      "Iteration 8, loss = 1.24981769\n",
      "Iteration 9, loss = 1.25829159\n",
      "Iteration 10, loss = 1.25641869\n",
      "Iteration 1, loss = 1.24906414\n",
      "Iteration 2, loss = 1.18118898\n",
      "Iteration 3, loss = 1.05890028\n",
      "Iteration 4, loss = 1.08307277\n",
      "Iteration 5, loss = 1.03702540\n",
      "Iteration 6, loss = 1.03672497\n",
      "Iteration 7, loss = 1.03670031\n",
      "Iteration 8, loss = 1.01489430\n",
      "Iteration 9, loss = 1.02812811\n",
      "Iteration 10, loss = 1.01764198\n",
      "Iteration 1, loss = 1.23715258\n",
      "Iteration 2, loss = 1.10804007\n",
      "Iteration 9, loss = 1.25829159\n",
      "Iteration 10, loss = 1.25641869\n",
      "Iteration 1, loss = 1.24906414\n",
      "Iteration 2, loss = 1.18118898\n",
      "Iteration 3, loss = 1.05890028\n",
      "Iteration 4, loss = 1.08307277\n",
      "Iteration 5, loss = 1.03702540\n",
      "Iteration 6, loss = 1.03672497\n",
      "Iteration 7, loss = 1.03670031\n",
      "Iteration 8, loss = 1.01489430\n",
      "Iteration 9, loss = 1.02812811\n",
      "Iteration 10, loss = 1.01764198\n",
      "Iteration 1, loss = 1.23715258\n",
      "Iteration 2, loss = 1.10804007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.03386482\n",
      "Iteration 4, loss = 1.05879536\n",
      "Iteration 5, loss = 1.07484008\n",
      "Iteration 6, loss = 1.11222745\n",
      "Iteration 7, loss = 1.07624187\n",
      "Iteration 8, loss = 1.05917289\n",
      "Iteration 9, loss = 1.01715626\n",
      "Iteration 10, loss = 1.02768996\n",
      "Iteration 1, loss = 1.17679877\n",
      "Iteration 2, loss = 0.99991435\n",
      "Iteration 3, loss = 1.01033173\n",
      "Iteration 4, loss = 1.01749091\n",
      "Iteration 3, loss = 1.03386482\n",
      "Iteration 4, loss = 1.05879536\n",
      "Iteration 5, loss = 1.07484008\n",
      "Iteration 6, loss = 1.11222745\n",
      "Iteration 7, loss = 1.07624187\n",
      "Iteration 8, loss = 1.05917289\n",
      "Iteration 9, loss = 1.01715626\n",
      "Iteration 10, loss = 1.02768996\n",
      "Iteration 1, loss = 1.17679877\n",
      "Iteration 2, loss = 0.99991435\n",
      "Iteration 3, loss = 1.01033173\n",
      "Iteration 4, loss = 1.01749091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.97756105\n",
      "Iteration 6, loss = 1.01087981\n",
      "Iteration 7, loss = 0.99187470\n",
      "Iteration 8, loss = 1.00348453\n",
      "Iteration 9, loss = 0.98006662\n",
      "Iteration 10, loss = 0.99913788\n",
      "Iteration 11, loss = 0.99594823\n",
      "Iteration 12, loss = 1.00542214\n",
      "Iteration 13, loss = 1.04956098\n",
      "Iteration 14, loss = 1.05380455\n",
      "Iteration 15, loss = 1.03203441\n",
      "Iteration 16, loss = 1.05073534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18944625\n",
      "Iteration 5, loss = 0.97756105\n",
      "Iteration 6, loss = 1.01087981\n",
      "Iteration 7, loss = 0.99187470\n",
      "Iteration 8, loss = 1.00348453\n",
      "Iteration 9, loss = 0.98006662\n",
      "Iteration 10, loss = 0.99913788\n",
      "Iteration 11, loss = 0.99594823\n",
      "Iteration 12, loss = 1.00542214\n",
      "Iteration 13, loss = 1.04956098\n",
      "Iteration 14, loss = 1.05380455\n",
      "Iteration 15, loss = 1.03203441\n",
      "Iteration 16, loss = 1.05073534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18944625\n",
      "Iteration 2, loss = 1.10508402\n",
      "Iteration 3, loss = 0.99974931\n",
      "Iteration 4, loss = 1.03955348\n",
      "Iteration 5, loss = 0.95725834\n",
      "Iteration 6, loss = 0.92342304\n",
      "Iteration 7, loss = 0.96714546\n",
      "Iteration 8, loss = 0.93452493\n",
      "Iteration 9, loss = 0.92348592\n",
      "Iteration 10, loss = 0.96582213\n",
      "Iteration 11, loss = 0.93050446\n",
      "Iteration 12, loss = 0.87948674\n",
      "Iteration 13, loss = 0.96513041\n",
      "Iteration 14, loss = 0.97795390\n",
      "Iteration 2, loss = 1.10508402\n",
      "Iteration 3, loss = 0.99974931\n",
      "Iteration 4, loss = 1.03955348\n",
      "Iteration 5, loss = 0.95725834\n",
      "Iteration 6, loss = 0.92342304\n",
      "Iteration 7, loss = 0.96714546\n",
      "Iteration 8, loss = 0.93452493\n",
      "Iteration 9, loss = 0.92348592\n",
      "Iteration 10, loss = 0.96582213\n",
      "Iteration 11, loss = 0.93050446\n",
      "Iteration 12, loss = 0.87948674\n",
      "Iteration 13, loss = 0.96513041\n",
      "Iteration 14, loss = 0.97795390\n",
      "Iteration 15, loss = 0.92373924\n",
      "Iteration 16, loss = 0.91897734\n",
      "Iteration 17, loss = 0.92661361\n",
      "Iteration 18, loss = 1.02164287\n",
      "Iteration 19, loss = 0.97378076\n",
      "Iteration 20, loss = 0.92573400\n",
      "Iteration 21, loss = 0.94533972\n",
      "Iteration 22, loss = 0.94341924\n",
      "Iteration 23, loss = 0.93552124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23079311\n",
      "Iteration 2, loss = 1.13745750\n",
      "Iteration 3, loss = 1.02028988\n",
      "Iteration 4, loss = 1.00725403\n",
      "Iteration 5, loss = 1.15838090\n",
      "Iteration 15, loss = 0.92373924\n",
      "Iteration 16, loss = 0.91897734\n",
      "Iteration 17, loss = 0.92661361\n",
      "Iteration 18, loss = 1.02164287\n",
      "Iteration 19, loss = 0.97378076\n",
      "Iteration 20, loss = 0.92573400\n",
      "Iteration 21, loss = 0.94533972\n",
      "Iteration 22, loss = 0.94341924\n",
      "Iteration 23, loss = 0.93552124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23079311\n",
      "Iteration 2, loss = 1.13745750\n",
      "Iteration 3, loss = 1.02028988\n",
      "Iteration 4, loss = 1.00725403\n",
      "Iteration 5, loss = 1.15838090\n",
      "Iteration 6, loss = 1.28399299\n",
      "Iteration 7, loss = 1.25967810\n",
      "Iteration 8, loss = 1.24981769\n",
      "Iteration 9, loss = 1.25829159\n",
      "Iteration 10, loss = 1.25641869\n",
      "Iteration 11, loss = 1.25257466\n",
      "Iteration 12, loss = 1.25903691\n",
      "Iteration 13, loss = 1.25358030\n",
      "Iteration 14, loss = 1.25573365\n",
      "Iteration 15, loss = 1.26862538\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24906414\n",
      "Iteration 2, loss = 1.18118898\n",
      "Iteration 3, loss = 1.05890028\n",
      "Iteration 4, loss = 1.08307277\n",
      "Iteration 6, loss = 1.28399299\n",
      "Iteration 7, loss = 1.25967810\n",
      "Iteration 8, loss = 1.24981769\n",
      "Iteration 9, loss = 1.25829159\n",
      "Iteration 10, loss = 1.25641869\n",
      "Iteration 11, loss = 1.25257466\n",
      "Iteration 12, loss = 1.25903691\n",
      "Iteration 13, loss = 1.25358030\n",
      "Iteration 14, loss = 1.25573365\n",
      "Iteration 15, loss = 1.26862538\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24906414\n",
      "Iteration 2, loss = 1.18118898\n",
      "Iteration 3, loss = 1.05890028\n",
      "Iteration 4, loss = 1.08307277\n",
      "Iteration 5, loss = 1.03702540\n",
      "Iteration 6, loss = 1.03672497\n",
      "Iteration 7, loss = 1.03670031\n",
      "Iteration 8, loss = 1.01489430\n",
      "Iteration 9, loss = 1.02812811\n",
      "Iteration 10, loss = 1.01764198\n",
      "Iteration 11, loss = 1.02680843\n",
      "Iteration 12, loss = 1.01791184\n",
      "Iteration 13, loss = 1.00772547\n",
      "Iteration 14, loss = 1.05725046\n",
      "Iteration 15, loss = 1.07119542\n",
      "Iteration 16, loss = 1.03402387\n",
      "Iteration 17, loss = 1.01035969\n",
      "Iteration 18, loss = 1.00629523\n",
      "Iteration 19, loss = 0.98548019\n",
      "Iteration 5, loss = 1.03702540\n",
      "Iteration 6, loss = 1.03672497\n",
      "Iteration 7, loss = 1.03670031\n",
      "Iteration 8, loss = 1.01489430\n",
      "Iteration 9, loss = 1.02812811\n",
      "Iteration 10, loss = 1.01764198\n",
      "Iteration 11, loss = 1.02680843\n",
      "Iteration 12, loss = 1.01791184\n",
      "Iteration 13, loss = 1.00772547\n",
      "Iteration 14, loss = 1.05725046\n",
      "Iteration 15, loss = 1.07119542\n",
      "Iteration 16, loss = 1.03402387\n",
      "Iteration 17, loss = 1.01035969\n",
      "Iteration 18, loss = 1.00629523\n",
      "Iteration 19, loss = 0.98548019\n",
      "Iteration 20, loss = 0.98242574\n",
      "Iteration 21, loss = 0.96377177\n",
      "Iteration 22, loss = 0.96777626\n",
      "Iteration 23, loss = 1.03530827\n",
      "Iteration 24, loss = 1.13289165\n",
      "Iteration 25, loss = 1.02767902\n",
      "Iteration 26, loss = 1.01125308\n",
      "Iteration 27, loss = 0.98527386\n",
      "Iteration 28, loss = 0.98526735\n",
      "Iteration 29, loss = 1.07557790\n",
      "Iteration 30, loss = 1.05862753\n",
      "Iteration 31, loss = 1.01011555\n",
      "Iteration 32, loss = 0.98580246\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23715258\n",
      "Iteration 20, loss = 0.98242574\n",
      "Iteration 21, loss = 0.96377177\n",
      "Iteration 22, loss = 0.96777626\n",
      "Iteration 23, loss = 1.03530827\n",
      "Iteration 24, loss = 1.13289165\n",
      "Iteration 25, loss = 1.02767902\n",
      "Iteration 26, loss = 1.01125308\n",
      "Iteration 27, loss = 0.98527386\n",
      "Iteration 28, loss = 0.98526735\n",
      "Iteration 29, loss = 1.07557790\n",
      "Iteration 30, loss = 1.05862753\n",
      "Iteration 31, loss = 1.01011555\n",
      "Iteration 32, loss = 0.98580246\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23715258\n",
      "Iteration 2, loss = 1.10804007\n",
      "Iteration 3, loss = 1.03386482\n",
      "Iteration 4, loss = 1.05879536\n",
      "Iteration 5, loss = 1.07484008\n",
      "Iteration 6, loss = 1.11222745\n",
      "Iteration 7, loss = 1.07624187\n",
      "Iteration 8, loss = 1.05917289\n",
      "Iteration 9, loss = 1.01715626\n",
      "Iteration 10, loss = 1.02768996\n",
      "Iteration 11, loss = 0.99502101\n",
      "Iteration 12, loss = 1.03667748\n",
      "Iteration 13, loss = 1.00916068\n",
      "Iteration 14, loss = 0.97891876\n",
      "Iteration 15, loss = 1.01849342\n",
      "Iteration 16, loss = 0.96192171\n",
      "Iteration 2, loss = 1.10804007\n",
      "Iteration 3, loss = 1.03386482\n",
      "Iteration 4, loss = 1.05879536\n",
      "Iteration 5, loss = 1.07484008\n",
      "Iteration 6, loss = 1.11222745\n",
      "Iteration 7, loss = 1.07624187\n",
      "Iteration 8, loss = 1.05917289\n",
      "Iteration 9, loss = 1.01715626\n",
      "Iteration 10, loss = 1.02768996\n",
      "Iteration 11, loss = 0.99502101\n",
      "Iteration 12, loss = 1.03667748\n",
      "Iteration 13, loss = 1.00916068\n",
      "Iteration 14, loss = 0.97891876\n",
      "Iteration 15, loss = 1.01849342\n",
      "Iteration 16, loss = 0.96192171\n",
      "Iteration 17, loss = 1.00941178\n",
      "Iteration 18, loss = 0.96538899\n",
      "Iteration 19, loss = 0.97029332\n",
      "Iteration 20, loss = 0.95505276\n",
      "Iteration 21, loss = 0.99331409\n",
      "Iteration 22, loss = 0.99932356\n",
      "Iteration 23, loss = 1.00124400\n",
      "Iteration 24, loss = 1.01014950\n",
      "Iteration 25, loss = 0.96555474\n",
      "Iteration 26, loss = 0.98355330\n",
      "Iteration 27, loss = 0.93890828\n",
      "Iteration 28, loss = 0.98937438\n",
      "Iteration 29, loss = 1.01935217\n",
      "Iteration 30, loss = 0.93437619\n",
      "Iteration 31, loss = 0.97289501\n",
      "Iteration 17, loss = 1.00941178\n",
      "Iteration 18, loss = 0.96538899\n",
      "Iteration 19, loss = 0.97029332\n",
      "Iteration 20, loss = 0.95505276\n",
      "Iteration 21, loss = 0.99331409\n",
      "Iteration 22, loss = 0.99932356\n",
      "Iteration 23, loss = 1.00124400\n",
      "Iteration 24, loss = 1.01014950\n",
      "Iteration 25, loss = 0.96555474\n",
      "Iteration 26, loss = 0.98355330\n",
      "Iteration 27, loss = 0.93890828\n",
      "Iteration 28, loss = 0.98937438\n",
      "Iteration 29, loss = 1.01935217\n",
      "Iteration 30, loss = 0.93437619\n",
      "Iteration 31, loss = 0.97289501\n",
      "Iteration 32, loss = 0.94143160\n",
      "Iteration 33, loss = 0.94988701\n",
      "Iteration 34, loss = 0.95779459\n",
      "Iteration 35, loss = 0.96197043\n",
      "Iteration 36, loss = 0.99498870\n",
      "Iteration 37, loss = 1.02215021\n",
      "Iteration 38, loss = 0.94952297\n",
      "Iteration 39, loss = 0.97016468\n",
      "Iteration 40, loss = 1.01261401\n",
      "Iteration 41, loss = 0.97273781\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17679877\n",
      "Iteration 2, loss = 0.99991435\n",
      "Iteration 3, loss = 1.01033173\n",
      "Iteration 4, loss = 1.01749091\n",
      "Iteration 32, loss = 0.94143160\n",
      "Iteration 33, loss = 0.94988701\n",
      "Iteration 34, loss = 0.95779459\n",
      "Iteration 35, loss = 0.96197043\n",
      "Iteration 36, loss = 0.99498870\n",
      "Iteration 37, loss = 1.02215021\n",
      "Iteration 38, loss = 0.94952297\n",
      "Iteration 39, loss = 0.97016468\n",
      "Iteration 40, loss = 1.01261401\n",
      "Iteration 41, loss = 0.97273781\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17679877\n",
      "Iteration 2, loss = 0.99991435\n",
      "Iteration 3, loss = 1.01033173\n",
      "Iteration 4, loss = 1.01749091\n",
      "Iteration 5, loss = 0.97756105\n",
      "Iteration 6, loss = 1.01087981\n",
      "Iteration 7, loss = 0.99187470\n",
      "Iteration 8, loss = 1.00348453\n",
      "Iteration 9, loss = 0.98006662\n",
      "Iteration 10, loss = 0.99913788\n",
      "Iteration 11, loss = 0.99594823\n",
      "Iteration 12, loss = 1.00542214\n",
      "Iteration 13, loss = 1.04956098\n",
      "Iteration 14, loss = 1.05380455\n",
      "Iteration 15, loss = 1.03203441\n",
      "Iteration 16, loss = 1.05073534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18944625\n",
      "Iteration 2, loss = 1.10508402\n",
      "Iteration 5, loss = 0.97756105\n",
      "Iteration 6, loss = 1.01087981\n",
      "Iteration 7, loss = 0.99187470\n",
      "Iteration 8, loss = 1.00348453\n",
      "Iteration 9, loss = 0.98006662\n",
      "Iteration 10, loss = 0.99913788\n",
      "Iteration 11, loss = 0.99594823\n",
      "Iteration 12, loss = 1.00542214\n",
      "Iteration 13, loss = 1.04956098\n",
      "Iteration 14, loss = 1.05380455\n",
      "Iteration 15, loss = 1.03203441\n",
      "Iteration 16, loss = 1.05073534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18944625\n",
      "Iteration 2, loss = 1.10508402\n",
      "Iteration 3, loss = 0.99974931\n",
      "Iteration 4, loss = 1.03955348\n",
      "Iteration 5, loss = 0.95725834\n",
      "Iteration 6, loss = 0.92342304\n",
      "Iteration 7, loss = 0.96714546\n",
      "Iteration 8, loss = 0.93452493\n",
      "Iteration 9, loss = 0.92348592\n",
      "Iteration 10, loss = 0.96582213\n",
      "Iteration 11, loss = 0.93050446\n",
      "Iteration 12, loss = 0.87948674\n",
      "Iteration 13, loss = 0.96513041\n",
      "Iteration 14, loss = 0.97795390\n",
      "Iteration 15, loss = 0.92373924\n",
      "Iteration 16, loss = 0.91897734\n",
      "Iteration 3, loss = 0.99974931\n",
      "Iteration 4, loss = 1.03955348\n",
      "Iteration 5, loss = 0.95725834\n",
      "Iteration 6, loss = 0.92342304\n",
      "Iteration 7, loss = 0.96714546\n",
      "Iteration 8, loss = 0.93452493\n",
      "Iteration 9, loss = 0.92348592\n",
      "Iteration 10, loss = 0.96582213\n",
      "Iteration 11, loss = 0.93050446\n",
      "Iteration 12, loss = 0.87948674\n",
      "Iteration 13, loss = 0.96513041\n",
      "Iteration 14, loss = 0.97795390\n",
      "Iteration 15, loss = 0.92373924\n",
      "Iteration 16, loss = 0.91897734\n",
      "Iteration 17, loss = 0.92661361\n",
      "Iteration 18, loss = 1.02164287\n",
      "Iteration 19, loss = 0.97378076\n",
      "Iteration 20, loss = 0.92573400\n",
      "Iteration 21, loss = 0.94533972\n",
      "Iteration 22, loss = 0.94341924\n",
      "Iteration 23, loss = 0.93552124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23079311\n",
      "Iteration 2, loss = 1.13745750\n",
      "Iteration 3, loss = 1.02028988\n",
      "Iteration 4, loss = 1.00725403\n",
      "Iteration 5, loss = 1.15838090\n",
      "Iteration 6, loss = 1.28399299\n",
      "Iteration 7, loss = 1.25967810\n",
      "Iteration 8, loss = 1.24981769\n",
      "Iteration 17, loss = 0.92661361\n",
      "Iteration 18, loss = 1.02164287\n",
      "Iteration 19, loss = 0.97378076\n",
      "Iteration 20, loss = 0.92573400\n",
      "Iteration 21, loss = 0.94533972\n",
      "Iteration 22, loss = 0.94341924\n",
      "Iteration 23, loss = 0.93552124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23079311\n",
      "Iteration 2, loss = 1.13745750\n",
      "Iteration 3, loss = 1.02028988\n",
      "Iteration 4, loss = 1.00725403\n",
      "Iteration 5, loss = 1.15838090\n",
      "Iteration 6, loss = 1.28399299\n",
      "Iteration 7, loss = 1.25967810\n",
      "Iteration 8, loss = 1.24981769\n",
      "Iteration 9, loss = 1.25829159\n",
      "Iteration 10, loss = 1.25641869\n",
      "Iteration 11, loss = 1.25257466\n",
      "Iteration 12, loss = 1.25903691\n",
      "Iteration 13, loss = 1.25358030\n",
      "Iteration 14, loss = 1.25573365\n",
      "Iteration 15, loss = 1.26862538\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24906414\n",
      "Iteration 2, loss = 1.18118898\n",
      "Iteration 3, loss = 1.05890028\n",
      "Iteration 4, loss = 1.08307277\n",
      "Iteration 5, loss = 1.03702540\n",
      "Iteration 9, loss = 1.25829159\n",
      "Iteration 10, loss = 1.25641869\n",
      "Iteration 11, loss = 1.25257466\n",
      "Iteration 12, loss = 1.25903691\n",
      "Iteration 13, loss = 1.25358030\n",
      "Iteration 14, loss = 1.25573365\n",
      "Iteration 15, loss = 1.26862538\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24906414\n",
      "Iteration 2, loss = 1.18118898\n",
      "Iteration 3, loss = 1.05890028\n",
      "Iteration 4, loss = 1.08307277\n",
      "Iteration 5, loss = 1.03702540\n",
      "Iteration 6, loss = 1.03672497\n",
      "Iteration 7, loss = 1.03670031\n",
      "Iteration 8, loss = 1.01489430\n",
      "Iteration 9, loss = 1.02812811\n",
      "Iteration 10, loss = 1.01764198\n",
      "Iteration 11, loss = 1.02680843\n",
      "Iteration 12, loss = 1.01791184\n",
      "Iteration 13, loss = 1.00772547\n",
      "Iteration 14, loss = 1.05725046\n",
      "Iteration 15, loss = 1.07119542\n",
      "Iteration 16, loss = 1.03402387\n",
      "Iteration 17, loss = 1.01035969\n",
      "Iteration 18, loss = 1.00629523\n",
      "Iteration 19, loss = 0.98548019\n",
      "Iteration 20, loss = 0.98242574\n",
      "Iteration 6, loss = 1.03672497\n",
      "Iteration 7, loss = 1.03670031\n",
      "Iteration 8, loss = 1.01489430\n",
      "Iteration 9, loss = 1.02812811\n",
      "Iteration 10, loss = 1.01764198\n",
      "Iteration 11, loss = 1.02680843\n",
      "Iteration 12, loss = 1.01791184\n",
      "Iteration 13, loss = 1.00772547\n",
      "Iteration 14, loss = 1.05725046\n",
      "Iteration 15, loss = 1.07119542\n",
      "Iteration 16, loss = 1.03402387\n",
      "Iteration 17, loss = 1.01035969\n",
      "Iteration 18, loss = 1.00629523\n",
      "Iteration 19, loss = 0.98548019\n",
      "Iteration 20, loss = 0.98242574\n",
      "Iteration 21, loss = 0.96377177\n",
      "Iteration 22, loss = 0.96777626\n",
      "Iteration 23, loss = 1.03530827\n",
      "Iteration 24, loss = 1.13289165\n",
      "Iteration 25, loss = 1.02767902\n",
      "Iteration 26, loss = 1.01125308\n",
      "Iteration 27, loss = 0.98527386\n",
      "Iteration 28, loss = 0.98526735\n",
      "Iteration 29, loss = 1.07557790\n",
      "Iteration 30, loss = 1.05862753\n",
      "Iteration 31, loss = 1.01011555\n",
      "Iteration 32, loss = 0.98580246\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23715258\n",
      "Iteration 2, loss = 1.10804007\n",
      "Iteration 21, loss = 0.96377177\n",
      "Iteration 22, loss = 0.96777626\n",
      "Iteration 23, loss = 1.03530827\n",
      "Iteration 24, loss = 1.13289165\n",
      "Iteration 25, loss = 1.02767902\n",
      "Iteration 26, loss = 1.01125308\n",
      "Iteration 27, loss = 0.98527386\n",
      "Iteration 28, loss = 0.98526735\n",
      "Iteration 29, loss = 1.07557790\n",
      "Iteration 30, loss = 1.05862753\n",
      "Iteration 31, loss = 1.01011555\n",
      "Iteration 32, loss = 0.98580246\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23715258\n",
      "Iteration 2, loss = 1.10804007\n",
      "Iteration 3, loss = 1.03386482\n",
      "Iteration 4, loss = 1.05879536\n",
      "Iteration 5, loss = 1.07484008\n",
      "Iteration 6, loss = 1.11222745\n",
      "Iteration 7, loss = 1.07624187\n",
      "Iteration 8, loss = 1.05917289\n",
      "Iteration 9, loss = 1.01715626\n",
      "Iteration 10, loss = 1.02768996\n",
      "Iteration 11, loss = 0.99502101\n",
      "Iteration 12, loss = 1.03667748\n",
      "Iteration 13, loss = 1.00916068\n",
      "Iteration 14, loss = 0.97891876\n",
      "Iteration 15, loss = 1.01849342\n",
      "Iteration 16, loss = 0.96192171\n",
      "Iteration 3, loss = 1.03386482\n",
      "Iteration 4, loss = 1.05879536\n",
      "Iteration 5, loss = 1.07484008\n",
      "Iteration 6, loss = 1.11222745\n",
      "Iteration 7, loss = 1.07624187\n",
      "Iteration 8, loss = 1.05917289\n",
      "Iteration 9, loss = 1.01715626\n",
      "Iteration 10, loss = 1.02768996\n",
      "Iteration 11, loss = 0.99502101\n",
      "Iteration 12, loss = 1.03667748\n",
      "Iteration 13, loss = 1.00916068\n",
      "Iteration 14, loss = 0.97891876\n",
      "Iteration 15, loss = 1.01849342\n",
      "Iteration 16, loss = 0.96192171\n",
      "Iteration 17, loss = 1.00941178\n",
      "Iteration 18, loss = 0.96538899\n",
      "Iteration 19, loss = 0.97029332\n",
      "Iteration 20, loss = 0.95505276\n",
      "Iteration 21, loss = 0.99331409\n",
      "Iteration 22, loss = 0.99932356\n",
      "Iteration 23, loss = 1.00124400\n",
      "Iteration 24, loss = 1.01014950\n",
      "Iteration 25, loss = 0.96555474\n",
      "Iteration 26, loss = 0.98355330\n",
      "Iteration 27, loss = 0.93890828\n",
      "Iteration 28, loss = 0.98937438\n",
      "Iteration 29, loss = 1.01935217\n",
      "Iteration 30, loss = 0.93437619\n",
      "Iteration 31, loss = 0.97289501\n",
      "Iteration 32, loss = 0.94143160\n",
      "Iteration 17, loss = 1.00941178\n",
      "Iteration 18, loss = 0.96538899\n",
      "Iteration 19, loss = 0.97029332\n",
      "Iteration 20, loss = 0.95505276\n",
      "Iteration 21, loss = 0.99331409\n",
      "Iteration 22, loss = 0.99932356\n",
      "Iteration 23, loss = 1.00124400\n",
      "Iteration 24, loss = 1.01014950\n",
      "Iteration 25, loss = 0.96555474\n",
      "Iteration 26, loss = 0.98355330\n",
      "Iteration 27, loss = 0.93890828\n",
      "Iteration 28, loss = 0.98937438\n",
      "Iteration 29, loss = 1.01935217\n",
      "Iteration 30, loss = 0.93437619\n",
      "Iteration 31, loss = 0.97289501\n",
      "Iteration 32, loss = 0.94143160\n",
      "Iteration 33, loss = 0.94988701\n",
      "Iteration 34, loss = 0.95779459\n",
      "Iteration 35, loss = 0.96197043\n",
      "Iteration 36, loss = 0.99498870\n",
      "Iteration 37, loss = 1.02215021\n",
      "Iteration 38, loss = 0.94952297\n",
      "Iteration 39, loss = 0.97016468\n",
      "Iteration 40, loss = 1.01261401\n",
      "Iteration 41, loss = 0.97273781\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21304427\n",
      "Iteration 2, loss = 1.05593133\n",
      "Iteration 3, loss = 1.11199016\n",
      "Iteration 4, loss = 1.03023997\n",
      "Iteration 5, loss = 0.98365817\n",
      "Iteration 33, loss = 0.94988701\n",
      "Iteration 34, loss = 0.95779459\n",
      "Iteration 35, loss = 0.96197043\n",
      "Iteration 36, loss = 0.99498870\n",
      "Iteration 37, loss = 1.02215021\n",
      "Iteration 38, loss = 0.94952297\n",
      "Iteration 39, loss = 0.97016468\n",
      "Iteration 40, loss = 1.01261401\n",
      "Iteration 41, loss = 0.97273781\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21304427\n",
      "Iteration 2, loss = 1.05593133\n",
      "Iteration 3, loss = 1.11199016\n",
      "Iteration 4, loss = 1.03023997\n",
      "Iteration 5, loss = 0.98365817\n",
      "Iteration 6, loss = 1.03722702\n",
      "Iteration 7, loss = 1.00540126\n",
      "Iteration 8, loss = 0.99564247\n",
      "Iteration 9, loss = 0.98194401\n",
      "Iteration 10, loss = 0.98068943\n",
      "Iteration 1, loss = 1.23496404\n",
      "Iteration 2, loss = 1.25595308\n",
      "Iteration 3, loss = 1.25890670\n",
      "Iteration 4, loss = 1.25313328\n",
      "Iteration 5, loss = 1.23770571\n",
      "Iteration 6, loss = 1.23621642\n",
      "Iteration 7, loss = 1.24328229\n",
      "Iteration 8, loss = 1.23920950\n",
      "Iteration 9, loss = 1.24057937\n",
      "Iteration 6, loss = 1.03722702\n",
      "Iteration 7, loss = 1.00540126\n",
      "Iteration 8, loss = 0.99564247\n",
      "Iteration 9, loss = 0.98194401\n",
      "Iteration 10, loss = 0.98068943\n",
      "Iteration 1, loss = 1.23496404\n",
      "Iteration 2, loss = 1.25595308\n",
      "Iteration 3, loss = 1.25890670\n",
      "Iteration 4, loss = 1.25313328\n",
      "Iteration 5, loss = 1.23770571\n",
      "Iteration 6, loss = 1.23621642\n",
      "Iteration 7, loss = 1.24328229\n",
      "Iteration 8, loss = 1.23920950\n",
      "Iteration 9, loss = 1.24057937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.24250594\n",
      "Iteration 1, loss = 1.26101190\n",
      "Iteration 2, loss = 1.18698361\n",
      "Iteration 3, loss = 1.07827176\n",
      "Iteration 4, loss = 1.06016274\n",
      "Iteration 5, loss = 1.04799752\n",
      "Iteration 6, loss = 1.00114564\n",
      "Iteration 7, loss = 1.01625477\n",
      "Iteration 8, loss = 0.97981312\n",
      "Iteration 9, loss = 0.98891897\n",
      "Iteration 10, loss = 0.98687291\n",
      "Iteration 1, loss = 1.25337913\n",
      "Iteration 10, loss = 1.24250594\n",
      "Iteration 1, loss = 1.26101190\n",
      "Iteration 2, loss = 1.18698361\n",
      "Iteration 3, loss = 1.07827176\n",
      "Iteration 4, loss = 1.06016274\n",
      "Iteration 5, loss = 1.04799752\n",
      "Iteration 6, loss = 1.00114564\n",
      "Iteration 7, loss = 1.01625477\n",
      "Iteration 8, loss = 0.97981312\n",
      "Iteration 9, loss = 0.98891897\n",
      "Iteration 10, loss = 0.98687291\n",
      "Iteration 1, loss = 1.25337913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.25507991\n",
      "Iteration 3, loss = 1.24776359\n",
      "Iteration 4, loss = 1.26339164\n",
      "Iteration 5, loss = 1.24506893\n",
      "Iteration 6, loss = 1.22514659\n",
      "Iteration 7, loss = 1.17982219\n",
      "Iteration 8, loss = 1.13131339\n",
      "Iteration 9, loss = 1.07655815\n",
      "Iteration 10, loss = 1.05004374\n",
      "Iteration 1, loss = 1.25913297\n",
      "Iteration 2, loss = 1.27751255\n",
      "Iteration 3, loss = 1.27515918\n",
      "Iteration 2, loss = 1.25507991\n",
      "Iteration 3, loss = 1.24776359\n",
      "Iteration 4, loss = 1.26339164\n",
      "Iteration 5, loss = 1.24506893\n",
      "Iteration 6, loss = 1.22514659\n",
      "Iteration 7, loss = 1.17982219\n",
      "Iteration 8, loss = 1.13131339\n",
      "Iteration 9, loss = 1.07655815\n",
      "Iteration 10, loss = 1.05004374\n",
      "Iteration 1, loss = 1.25913297\n",
      "Iteration 2, loss = 1.27751255\n",
      "Iteration 3, loss = 1.27515918\n",
      "Iteration 4, loss = 1.25889672\n",
      "Iteration 5, loss = 1.26082683\n",
      "Iteration 6, loss = 1.25624083\n",
      "Iteration 7, loss = 1.27535866\n",
      "Iteration 8, loss = 1.26065747\n",
      "Iteration 9, loss = 1.25635541\n",
      "Iteration 10, loss = 1.26831678\n",
      "Iteration 1, loss = 1.21304427\n",
      "Iteration 2, loss = 1.05593133\n",
      "Iteration 3, loss = 1.11199016\n",
      "Iteration 4, loss = 1.03023997\n",
      "Iteration 5, loss = 0.98365817\n",
      "Iteration 6, loss = 1.03722702\n",
      "Iteration 7, loss = 1.00540126\n",
      "Iteration 8, loss = 0.99564247\n",
      "Iteration 4, loss = 1.25889672\n",
      "Iteration 5, loss = 1.26082683\n",
      "Iteration 6, loss = 1.25624083\n",
      "Iteration 7, loss = 1.27535866\n",
      "Iteration 8, loss = 1.26065747\n",
      "Iteration 9, loss = 1.25635541\n",
      "Iteration 10, loss = 1.26831678\n",
      "Iteration 1, loss = 1.21304427\n",
      "Iteration 2, loss = 1.05593133\n",
      "Iteration 3, loss = 1.11199016\n",
      "Iteration 4, loss = 1.03023997\n",
      "Iteration 5, loss = 0.98365817\n",
      "Iteration 6, loss = 1.03722702\n",
      "Iteration 7, loss = 1.00540126\n",
      "Iteration 8, loss = 0.99564247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.98194401\n",
      "Iteration 10, loss = 0.98068943\n",
      "Iteration 11, loss = 0.96638166\n",
      "Iteration 12, loss = 0.97806925\n",
      "Iteration 13, loss = 1.00188178\n",
      "Iteration 14, loss = 0.96551263\n",
      "Iteration 15, loss = 0.97461145\n",
      "Iteration 16, loss = 0.97172119\n",
      "Iteration 17, loss = 0.97250058\n",
      "Iteration 18, loss = 0.99889697\n",
      "Iteration 19, loss = 0.97297722\n",
      "Iteration 20, loss = 1.05092203\n",
      "Iteration 21, loss = 1.19358558\n",
      "Iteration 22, loss = 1.17264590\n",
      "Iteration 9, loss = 0.98194401\n",
      "Iteration 10, loss = 0.98068943\n",
      "Iteration 11, loss = 0.96638166\n",
      "Iteration 12, loss = 0.97806925\n",
      "Iteration 13, loss = 1.00188178\n",
      "Iteration 14, loss = 0.96551263\n",
      "Iteration 15, loss = 0.97461145\n",
      "Iteration 16, loss = 0.97172119\n",
      "Iteration 17, loss = 0.97250058\n",
      "Iteration 18, loss = 0.99889697\n",
      "Iteration 19, loss = 0.97297722\n",
      "Iteration 20, loss = 1.05092203\n",
      "Iteration 21, loss = 1.19358558\n",
      "Iteration 22, loss = 1.17264590\n",
      "Iteration 23, loss = 0.98676406\n",
      "Iteration 24, loss = 0.99729380\n",
      "Iteration 25, loss = 1.03360321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23496404\n",
      "Iteration 2, loss = 1.25595308\n",
      "Iteration 3, loss = 1.25890670\n",
      "Iteration 4, loss = 1.25313328\n",
      "Iteration 5, loss = 1.23770571\n",
      "Iteration 6, loss = 1.23621642\n",
      "Iteration 7, loss = 1.24328229\n",
      "Iteration 8, loss = 1.23920950\n",
      "Iteration 9, loss = 1.24057937\n",
      "Iteration 10, loss = 1.24250594\n",
      "Iteration 11, loss = 1.24062318\n",
      "Iteration 23, loss = 0.98676406\n",
      "Iteration 24, loss = 0.99729380\n",
      "Iteration 25, loss = 1.03360321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23496404\n",
      "Iteration 2, loss = 1.25595308\n",
      "Iteration 3, loss = 1.25890670\n",
      "Iteration 4, loss = 1.25313328\n",
      "Iteration 5, loss = 1.23770571\n",
      "Iteration 6, loss = 1.23621642\n",
      "Iteration 7, loss = 1.24328229\n",
      "Iteration 8, loss = 1.23920950\n",
      "Iteration 9, loss = 1.24057937\n",
      "Iteration 10, loss = 1.24250594\n",
      "Iteration 11, loss = 1.24062318\n",
      "Iteration 12, loss = 1.25179369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26101190\n",
      "Iteration 2, loss = 1.18698361\n",
      "Iteration 3, loss = 1.07827176\n",
      "Iteration 4, loss = 1.06016274\n",
      "Iteration 5, loss = 1.04799752\n",
      "Iteration 6, loss = 1.00114564\n",
      "Iteration 7, loss = 1.01625477\n",
      "Iteration 8, loss = 0.97981312\n",
      "Iteration 9, loss = 0.98891897\n",
      "Iteration 10, loss = 0.98687291\n",
      "Iteration 11, loss = 0.96468513\n",
      "Iteration 12, loss = 1.25179369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26101190\n",
      "Iteration 2, loss = 1.18698361\n",
      "Iteration 3, loss = 1.07827176\n",
      "Iteration 4, loss = 1.06016274\n",
      "Iteration 5, loss = 1.04799752\n",
      "Iteration 6, loss = 1.00114564\n",
      "Iteration 7, loss = 1.01625477\n",
      "Iteration 8, loss = 0.97981312\n",
      "Iteration 9, loss = 0.98891897\n",
      "Iteration 10, loss = 0.98687291\n",
      "Iteration 11, loss = 0.96468513\n",
      "Iteration 12, loss = 1.01007300\n",
      "Iteration 13, loss = 0.96423483\n",
      "Iteration 14, loss = 0.95786698\n",
      "Iteration 15, loss = 0.96147144\n",
      "Iteration 16, loss = 0.97938895\n",
      "Iteration 17, loss = 1.01138451\n",
      "Iteration 18, loss = 1.01909316\n",
      "Iteration 19, loss = 0.98212629\n",
      "Iteration 20, loss = 0.95457364\n",
      "Iteration 21, loss = 0.99904095\n",
      "Iteration 22, loss = 0.99936849\n",
      "Iteration 23, loss = 0.98179472\n",
      "Iteration 24, loss = 0.96972616\n",
      "Iteration 25, loss = 0.96450575\n",
      "Iteration 26, loss = 0.98007839\n",
      "Iteration 12, loss = 1.01007300\n",
      "Iteration 13, loss = 0.96423483\n",
      "Iteration 14, loss = 0.95786698\n",
      "Iteration 15, loss = 0.96147144\n",
      "Iteration 16, loss = 0.97938895\n",
      "Iteration 17, loss = 1.01138451\n",
      "Iteration 18, loss = 1.01909316\n",
      "Iteration 19, loss = 0.98212629\n",
      "Iteration 20, loss = 0.95457364\n",
      "Iteration 21, loss = 0.99904095\n",
      "Iteration 22, loss = 0.99936849\n",
      "Iteration 23, loss = 0.98179472\n",
      "Iteration 24, loss = 0.96972616\n",
      "Iteration 25, loss = 0.96450575\n",
      "Iteration 26, loss = 0.98007839\n",
      "Iteration 27, loss = 0.97331801\n",
      "Iteration 28, loss = 0.98246497\n",
      "Iteration 29, loss = 0.97488424\n",
      "Iteration 30, loss = 0.96569258\n",
      "Iteration 31, loss = 0.96722267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25337913\n",
      "Iteration 2, loss = 1.25507991\n",
      "Iteration 3, loss = 1.24776359\n",
      "Iteration 4, loss = 1.26339164\n",
      "Iteration 5, loss = 1.24506893\n",
      "Iteration 6, loss = 1.22514659\n",
      "Iteration 7, loss = 1.17982219\n",
      "Iteration 8, loss = 1.13131339\n",
      "Iteration 9, loss = 1.07655815\n",
      "Iteration 27, loss = 0.97331801\n",
      "Iteration 28, loss = 0.98246497\n",
      "Iteration 29, loss = 0.97488424\n",
      "Iteration 30, loss = 0.96569258\n",
      "Iteration 31, loss = 0.96722267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25337913\n",
      "Iteration 2, loss = 1.25507991\n",
      "Iteration 3, loss = 1.24776359\n",
      "Iteration 4, loss = 1.26339164\n",
      "Iteration 5, loss = 1.24506893\n",
      "Iteration 6, loss = 1.22514659\n",
      "Iteration 7, loss = 1.17982219\n",
      "Iteration 8, loss = 1.13131339\n",
      "Iteration 9, loss = 1.07655815\n",
      "Iteration 10, loss = 1.05004374\n",
      "Iteration 11, loss = 1.07080414\n",
      "Iteration 12, loss = 1.05913482\n",
      "Iteration 13, loss = 1.02193842\n",
      "Iteration 14, loss = 1.01351348\n",
      "Iteration 15, loss = 1.09737563\n",
      "Iteration 16, loss = 1.01690601\n",
      "Iteration 17, loss = 1.01851736\n",
      "Iteration 18, loss = 1.04115640\n",
      "Iteration 19, loss = 0.99980367\n",
      "Iteration 20, loss = 1.01413833\n",
      "Iteration 21, loss = 1.00214425\n",
      "Iteration 22, loss = 1.01911793\n",
      "Iteration 23, loss = 1.00413752\n",
      "Iteration 10, loss = 1.05004374\n",
      "Iteration 11, loss = 1.07080414\n",
      "Iteration 12, loss = 1.05913482\n",
      "Iteration 13, loss = 1.02193842\n",
      "Iteration 14, loss = 1.01351348\n",
      "Iteration 15, loss = 1.09737563\n",
      "Iteration 16, loss = 1.01690601\n",
      "Iteration 17, loss = 1.01851736\n",
      "Iteration 18, loss = 1.04115640\n",
      "Iteration 19, loss = 0.99980367\n",
      "Iteration 20, loss = 1.01413833\n",
      "Iteration 21, loss = 1.00214425\n",
      "Iteration 22, loss = 1.01911793\n",
      "Iteration 23, loss = 1.00413752\n",
      "Iteration 24, loss = 1.02087277\n",
      "Iteration 25, loss = 1.01623066\n",
      "Iteration 26, loss = 1.00053327\n",
      "Iteration 27, loss = 1.04857095\n",
      "Iteration 28, loss = 1.06192788\n",
      "Iteration 29, loss = 1.04964628\n",
      "Iteration 30, loss = 0.99055278\n",
      "Iteration 31, loss = 1.01187079\n",
      "Iteration 32, loss = 0.99981396\n",
      "Iteration 33, loss = 1.02662468\n",
      "Iteration 34, loss = 1.01098150\n",
      "Iteration 35, loss = 0.98123761\n",
      "Iteration 36, loss = 0.99967069\n",
      "Iteration 37, loss = 0.99507126\n",
      "Iteration 38, loss = 0.97524682\n",
      "Iteration 24, loss = 1.02087277\n",
      "Iteration 25, loss = 1.01623066\n",
      "Iteration 26, loss = 1.00053327\n",
      "Iteration 27, loss = 1.04857095\n",
      "Iteration 28, loss = 1.06192788\n",
      "Iteration 29, loss = 1.04964628\n",
      "Iteration 30, loss = 0.99055278\n",
      "Iteration 31, loss = 1.01187079\n",
      "Iteration 32, loss = 0.99981396\n",
      "Iteration 33, loss = 1.02662468\n",
      "Iteration 34, loss = 1.01098150\n",
      "Iteration 35, loss = 0.98123761\n",
      "Iteration 36, loss = 0.99967069\n",
      "Iteration 37, loss = 0.99507126\n",
      "Iteration 38, loss = 0.97524682\n",
      "Iteration 39, loss = 0.99031993\n",
      "Iteration 40, loss = 0.99282328\n",
      "Iteration 41, loss = 0.99491127\n",
      "Iteration 42, loss = 0.96035571\n",
      "Iteration 43, loss = 0.96043172\n",
      "Iteration 44, loss = 0.96519512\n",
      "Iteration 45, loss = 0.97976258\n",
      "Iteration 46, loss = 1.00207005\n",
      "Iteration 47, loss = 0.98707466\n",
      "Iteration 48, loss = 0.98928106\n",
      "Iteration 49, loss = 0.99844687\n",
      "Iteration 50, loss = 1.01219396\n",
      "Iteration 1, loss = 1.25913297\n",
      "Iteration 2, loss = 1.27751255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39, loss = 0.99031993\n",
      "Iteration 40, loss = 0.99282328\n",
      "Iteration 41, loss = 0.99491127\n",
      "Iteration 42, loss = 0.96035571\n",
      "Iteration 43, loss = 0.96043172\n",
      "Iteration 44, loss = 0.96519512\n",
      "Iteration 45, loss = 0.97976258\n",
      "Iteration 46, loss = 1.00207005\n",
      "Iteration 47, loss = 0.98707466\n",
      "Iteration 48, loss = 0.98928106\n",
      "Iteration 49, loss = 0.99844687\n",
      "Iteration 50, loss = 1.01219396\n",
      "Iteration 1, loss = 1.25913297\n",
      "Iteration 2, loss = 1.27751255\n",
      "Iteration 3, loss = 1.27515918\n",
      "Iteration 4, loss = 1.25889672\n",
      "Iteration 5, loss = 1.26082683\n",
      "Iteration 6, loss = 1.25624083\n",
      "Iteration 7, loss = 1.27535866\n",
      "Iteration 8, loss = 1.26065747\n",
      "Iteration 9, loss = 1.25635541\n",
      "Iteration 10, loss = 1.26831678\n",
      "Iteration 11, loss = 1.25714891\n",
      "Iteration 12, loss = 1.25917585\n",
      "Iteration 13, loss = 1.26497636\n",
      "Iteration 14, loss = 1.26790675\n",
      "Iteration 15, loss = 1.27902432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.27515918\n",
      "Iteration 4, loss = 1.25889672\n",
      "Iteration 5, loss = 1.26082683\n",
      "Iteration 6, loss = 1.25624083\n",
      "Iteration 7, loss = 1.27535866\n",
      "Iteration 8, loss = 1.26065747\n",
      "Iteration 9, loss = 1.25635541\n",
      "Iteration 10, loss = 1.26831678\n",
      "Iteration 11, loss = 1.25714891\n",
      "Iteration 12, loss = 1.25917585\n",
      "Iteration 13, loss = 1.26497636\n",
      "Iteration 14, loss = 1.26790675\n",
      "Iteration 15, loss = 1.27902432\n",
      "Iteration 16, loss = 1.26009600\n",
      "Iteration 17, loss = 1.26323322\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21304427\n",
      "Iteration 2, loss = 1.05593133\n",
      "Iteration 3, loss = 1.11199016\n",
      "Iteration 4, loss = 1.03023997\n",
      "Iteration 5, loss = 0.98365817\n",
      "Iteration 6, loss = 1.03722702\n",
      "Iteration 7, loss = 1.00540126\n",
      "Iteration 8, loss = 0.99564247\n",
      "Iteration 9, loss = 0.98194401\n",
      "Iteration 10, loss = 0.98068943\n",
      "Iteration 16, loss = 1.26009600\n",
      "Iteration 17, loss = 1.26323322\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21304427\n",
      "Iteration 2, loss = 1.05593133\n",
      "Iteration 3, loss = 1.11199016\n",
      "Iteration 4, loss = 1.03023997\n",
      "Iteration 5, loss = 0.98365817\n",
      "Iteration 6, loss = 1.03722702\n",
      "Iteration 7, loss = 1.00540126\n",
      "Iteration 8, loss = 0.99564247\n",
      "Iteration 9, loss = 0.98194401\n",
      "Iteration 10, loss = 0.98068943\n",
      "Iteration 11, loss = 0.96638166\n",
      "Iteration 12, loss = 0.97806925\n",
      "Iteration 13, loss = 1.00188178\n",
      "Iteration 14, loss = 0.96551263\n",
      "Iteration 15, loss = 0.97461145\n",
      "Iteration 16, loss = 0.97172119\n",
      "Iteration 17, loss = 0.97250058\n",
      "Iteration 18, loss = 0.99889697\n",
      "Iteration 19, loss = 0.97297722\n",
      "Iteration 20, loss = 1.05092203\n",
      "Iteration 21, loss = 1.19358558\n",
      "Iteration 22, loss = 1.17264590\n",
      "Iteration 23, loss = 0.98676406\n",
      "Iteration 24, loss = 0.99729380\n",
      "Iteration 25, loss = 1.03360321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.96638166\n",
      "Iteration 12, loss = 0.97806925\n",
      "Iteration 13, loss = 1.00188178\n",
      "Iteration 14, loss = 0.96551263\n",
      "Iteration 15, loss = 0.97461145\n",
      "Iteration 16, loss = 0.97172119\n",
      "Iteration 17, loss = 0.97250058\n",
      "Iteration 18, loss = 0.99889697\n",
      "Iteration 19, loss = 0.97297722\n",
      "Iteration 20, loss = 1.05092203\n",
      "Iteration 21, loss = 1.19358558\n",
      "Iteration 22, loss = 1.17264590\n",
      "Iteration 23, loss = 0.98676406\n",
      "Iteration 24, loss = 0.99729380\n",
      "Iteration 25, loss = 1.03360321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23496404\n",
      "Iteration 2, loss = 1.25595308\n",
      "Iteration 3, loss = 1.25890670\n",
      "Iteration 4, loss = 1.25313328\n",
      "Iteration 5, loss = 1.23770571\n",
      "Iteration 6, loss = 1.23621642\n",
      "Iteration 7, loss = 1.24328229\n",
      "Iteration 8, loss = 1.23920950\n",
      "Iteration 9, loss = 1.24057937\n",
      "Iteration 10, loss = 1.24250594\n",
      "Iteration 11, loss = 1.24062318\n",
      "Iteration 12, loss = 1.25179369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26101190\n",
      "Iteration 1, loss = 1.23496404\n",
      "Iteration 2, loss = 1.25595308\n",
      "Iteration 3, loss = 1.25890670\n",
      "Iteration 4, loss = 1.25313328\n",
      "Iteration 5, loss = 1.23770571\n",
      "Iteration 6, loss = 1.23621642\n",
      "Iteration 7, loss = 1.24328229\n",
      "Iteration 8, loss = 1.23920950\n",
      "Iteration 9, loss = 1.24057937\n",
      "Iteration 10, loss = 1.24250594\n",
      "Iteration 11, loss = 1.24062318\n",
      "Iteration 12, loss = 1.25179369\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26101190\n",
      "Iteration 2, loss = 1.18698361\n",
      "Iteration 3, loss = 1.07827176\n",
      "Iteration 4, loss = 1.06016274\n",
      "Iteration 5, loss = 1.04799752\n",
      "Iteration 6, loss = 1.00114564\n",
      "Iteration 7, loss = 1.01625477\n",
      "Iteration 8, loss = 0.97981312\n",
      "Iteration 9, loss = 0.98891897\n",
      "Iteration 10, loss = 0.98687291\n",
      "Iteration 11, loss = 0.96468513\n",
      "Iteration 12, loss = 1.01007300\n",
      "Iteration 13, loss = 0.96423483\n",
      "Iteration 14, loss = 0.95786698\n",
      "Iteration 2, loss = 1.18698361\n",
      "Iteration 3, loss = 1.07827176\n",
      "Iteration 4, loss = 1.06016274\n",
      "Iteration 5, loss = 1.04799752\n",
      "Iteration 6, loss = 1.00114564\n",
      "Iteration 7, loss = 1.01625477\n",
      "Iteration 8, loss = 0.97981312\n",
      "Iteration 9, loss = 0.98891897\n",
      "Iteration 10, loss = 0.98687291\n",
      "Iteration 11, loss = 0.96468513\n",
      "Iteration 12, loss = 1.01007300\n",
      "Iteration 13, loss = 0.96423483\n",
      "Iteration 14, loss = 0.95786698\n",
      "Iteration 15, loss = 0.96147144\n",
      "Iteration 16, loss = 0.97938895\n",
      "Iteration 17, loss = 1.01138451\n",
      "Iteration 18, loss = 1.01909316\n",
      "Iteration 19, loss = 0.98212629\n",
      "Iteration 20, loss = 0.95457364\n",
      "Iteration 21, loss = 0.99904095\n",
      "Iteration 22, loss = 0.99936849\n",
      "Iteration 23, loss = 0.98179472\n",
      "Iteration 24, loss = 0.96972616\n",
      "Iteration 25, loss = 0.96450575\n",
      "Iteration 26, loss = 0.98007839\n",
      "Iteration 27, loss = 0.97331801\n",
      "Iteration 28, loss = 0.98246497\n",
      "Iteration 29, loss = 0.97488424\n",
      "Iteration 30, loss = 0.96569258\n",
      "Iteration 15, loss = 0.96147144\n",
      "Iteration 16, loss = 0.97938895\n",
      "Iteration 17, loss = 1.01138451\n",
      "Iteration 18, loss = 1.01909316\n",
      "Iteration 19, loss = 0.98212629\n",
      "Iteration 20, loss = 0.95457364\n",
      "Iteration 21, loss = 0.99904095\n",
      "Iteration 22, loss = 0.99936849\n",
      "Iteration 23, loss = 0.98179472\n",
      "Iteration 24, loss = 0.96972616\n",
      "Iteration 25, loss = 0.96450575\n",
      "Iteration 26, loss = 0.98007839\n",
      "Iteration 27, loss = 0.97331801\n",
      "Iteration 28, loss = 0.98246497\n",
      "Iteration 29, loss = 0.97488424\n",
      "Iteration 30, loss = 0.96569258\n",
      "Iteration 31, loss = 0.96722267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25337913\n",
      "Iteration 2, loss = 1.25507991\n",
      "Iteration 3, loss = 1.24776359\n",
      "Iteration 4, loss = 1.26339164\n",
      "Iteration 5, loss = 1.24506893\n",
      "Iteration 6, loss = 1.22514659\n",
      "Iteration 7, loss = 1.17982219\n",
      "Iteration 8, loss = 1.13131339\n",
      "Iteration 9, loss = 1.07655815\n",
      "Iteration 10, loss = 1.05004374\n",
      "Iteration 11, loss = 1.07080414\n",
      "Iteration 31, loss = 0.96722267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25337913\n",
      "Iteration 2, loss = 1.25507991\n",
      "Iteration 3, loss = 1.24776359\n",
      "Iteration 4, loss = 1.26339164\n",
      "Iteration 5, loss = 1.24506893\n",
      "Iteration 6, loss = 1.22514659\n",
      "Iteration 7, loss = 1.17982219\n",
      "Iteration 8, loss = 1.13131339\n",
      "Iteration 9, loss = 1.07655815\n",
      "Iteration 10, loss = 1.05004374\n",
      "Iteration 11, loss = 1.07080414\n",
      "Iteration 12, loss = 1.05913482\n",
      "Iteration 13, loss = 1.02193842\n",
      "Iteration 14, loss = 1.01351348\n",
      "Iteration 15, loss = 1.09737563\n",
      "Iteration 16, loss = 1.01690601\n",
      "Iteration 17, loss = 1.01851736\n",
      "Iteration 18, loss = 1.04115640\n",
      "Iteration 19, loss = 0.99980367\n",
      "Iteration 20, loss = 1.01413833\n",
      "Iteration 21, loss = 1.00214425\n",
      "Iteration 22, loss = 1.01911793\n",
      "Iteration 23, loss = 1.00413752\n",
      "Iteration 24, loss = 1.02087277\n",
      "Iteration 25, loss = 1.01623066\n",
      "Iteration 26, loss = 1.00053327\n",
      "Iteration 27, loss = 1.04857095\n",
      "Iteration 12, loss = 1.05913482\n",
      "Iteration 13, loss = 1.02193842\n",
      "Iteration 14, loss = 1.01351348\n",
      "Iteration 15, loss = 1.09737563\n",
      "Iteration 16, loss = 1.01690601\n",
      "Iteration 17, loss = 1.01851736\n",
      "Iteration 18, loss = 1.04115640\n",
      "Iteration 19, loss = 0.99980367\n",
      "Iteration 20, loss = 1.01413833\n",
      "Iteration 21, loss = 1.00214425\n",
      "Iteration 22, loss = 1.01911793\n",
      "Iteration 23, loss = 1.00413752\n",
      "Iteration 24, loss = 1.02087277\n",
      "Iteration 25, loss = 1.01623066\n",
      "Iteration 26, loss = 1.00053327\n",
      "Iteration 27, loss = 1.04857095\n",
      "Iteration 28, loss = 1.06192788\n",
      "Iteration 29, loss = 1.04964628\n",
      "Iteration 30, loss = 0.99055278\n",
      "Iteration 31, loss = 1.01187079\n",
      "Iteration 32, loss = 0.99981396\n",
      "Iteration 33, loss = 1.02662468\n",
      "Iteration 34, loss = 1.01098150\n",
      "Iteration 35, loss = 0.98123761\n",
      "Iteration 36, loss = 0.99967069\n",
      "Iteration 37, loss = 0.99507126\n",
      "Iteration 38, loss = 0.97524682\n",
      "Iteration 39, loss = 0.99031993\n",
      "Iteration 40, loss = 0.99282328\n",
      "Iteration 41, loss = 0.99491127\n",
      "Iteration 42, loss = 0.96035571\n",
      "Iteration 28, loss = 1.06192788\n",
      "Iteration 29, loss = 1.04964628\n",
      "Iteration 30, loss = 0.99055278\n",
      "Iteration 31, loss = 1.01187079\n",
      "Iteration 32, loss = 0.99981396\n",
      "Iteration 33, loss = 1.02662468\n",
      "Iteration 34, loss = 1.01098150\n",
      "Iteration 35, loss = 0.98123761\n",
      "Iteration 36, loss = 0.99967069\n",
      "Iteration 37, loss = 0.99507126\n",
      "Iteration 38, loss = 0.97524682\n",
      "Iteration 39, loss = 0.99031993\n",
      "Iteration 40, loss = 0.99282328\n",
      "Iteration 41, loss = 0.99491127\n",
      "Iteration 42, loss = 0.96035571\n",
      "Iteration 43, loss = 0.96043172\n",
      "Iteration 44, loss = 0.96519512\n",
      "Iteration 45, loss = 0.97976258\n",
      "Iteration 46, loss = 1.00207005\n",
      "Iteration 47, loss = 0.98707466\n",
      "Iteration 48, loss = 0.98928106\n",
      "Iteration 49, loss = 0.99844687\n",
      "Iteration 50, loss = 1.01219396\n",
      "Iteration 51, loss = 0.98740912\n",
      "Iteration 52, loss = 0.98287329\n",
      "Iteration 53, loss = 0.97794623\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25913297\n",
      "Iteration 2, loss = 1.27751255\n",
      "Iteration 3, loss = 1.27515918\n",
      "Iteration 4, loss = 1.25889672\n",
      "Iteration 43, loss = 0.96043172\n",
      "Iteration 44, loss = 0.96519512\n",
      "Iteration 45, loss = 0.97976258\n",
      "Iteration 46, loss = 1.00207005\n",
      "Iteration 47, loss = 0.98707466\n",
      "Iteration 48, loss = 0.98928106\n",
      "Iteration 49, loss = 0.99844687\n",
      "Iteration 50, loss = 1.01219396\n",
      "Iteration 51, loss = 0.98740912\n",
      "Iteration 52, loss = 0.98287329\n",
      "Iteration 53, loss = 0.97794623\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25913297\n",
      "Iteration 2, loss = 1.27751255\n",
      "Iteration 3, loss = 1.27515918\n",
      "Iteration 4, loss = 1.25889672\n",
      "Iteration 5, loss = 1.26082683\n",
      "Iteration 6, loss = 1.25624083\n",
      "Iteration 7, loss = 1.27535866\n",
      "Iteration 8, loss = 1.26065747\n",
      "Iteration 9, loss = 1.25635541\n",
      "Iteration 10, loss = 1.26831678\n",
      "Iteration 11, loss = 1.25714891\n",
      "Iteration 12, loss = 1.25917585\n",
      "Iteration 13, loss = 1.26497636\n",
      "Iteration 14, loss = 1.26790675\n",
      "Iteration 15, loss = 1.27902432\n",
      "Iteration 16, loss = 1.26009600\n",
      "Iteration 17, loss = 1.26323322\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25244326\n",
      "Iteration 5, loss = 1.26082683\n",
      "Iteration 6, loss = 1.25624083\n",
      "Iteration 7, loss = 1.27535866\n",
      "Iteration 8, loss = 1.26065747\n",
      "Iteration 9, loss = 1.25635541\n",
      "Iteration 10, loss = 1.26831678\n",
      "Iteration 11, loss = 1.25714891\n",
      "Iteration 12, loss = 1.25917585\n",
      "Iteration 13, loss = 1.26497636\n",
      "Iteration 14, loss = 1.26790675\n",
      "Iteration 15, loss = 1.27902432\n",
      "Iteration 16, loss = 1.26009600\n",
      "Iteration 17, loss = 1.26323322\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25244326\n",
      "Iteration 2, loss = 1.24578391\n",
      "Iteration 3, loss = 1.24765481\n",
      "Iteration 4, loss = 1.25019701\n",
      "Iteration 5, loss = 1.24312641\n",
      "Iteration 6, loss = 1.24538612\n",
      "Iteration 7, loss = 1.24592375\n",
      "Iteration 8, loss = 1.25872396\n",
      "Iteration 9, loss = 1.24864109\n",
      "Iteration 10, loss = 1.25383203\n",
      "Iteration 1, loss = 1.24120847\n",
      "Iteration 2, loss = 1.15719485\n",
      "Iteration 3, loss = 1.18492967\n",
      "Iteration 4, loss = 1.26066151\n",
      "Iteration 5, loss = 1.24270976\n",
      "Iteration 2, loss = 1.24578391\n",
      "Iteration 3, loss = 1.24765481\n",
      "Iteration 4, loss = 1.25019701\n",
      "Iteration 5, loss = 1.24312641\n",
      "Iteration 6, loss = 1.24538612\n",
      "Iteration 7, loss = 1.24592375\n",
      "Iteration 8, loss = 1.25872396\n",
      "Iteration 9, loss = 1.24864109\n",
      "Iteration 10, loss = 1.25383203\n",
      "Iteration 1, loss = 1.24120847\n",
      "Iteration 2, loss = 1.15719485\n",
      "Iteration 3, loss = 1.18492967\n",
      "Iteration 4, loss = 1.26066151\n",
      "Iteration 5, loss = 1.24270976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.23844410\n",
      "Iteration 7, loss = 1.24935118\n",
      "Iteration 8, loss = 1.24273854\n",
      "Iteration 9, loss = 1.24469302\n",
      "Iteration 10, loss = 1.24821425\n",
      "Iteration 1, loss = 1.27052214\n",
      "Iteration 2, loss = 1.26266351\n",
      "Iteration 3, loss = 1.28938850\n",
      "Iteration 4, loss = 1.27884110\n",
      "Iteration 5, loss = 1.25466548\n",
      "Iteration 6, loss = 1.26652693\n",
      "Iteration 7, loss = 1.26725917\n",
      "Iteration 8, loss = 1.25315228\n",
      "Iteration 6, loss = 1.23844410\n",
      "Iteration 7, loss = 1.24935118\n",
      "Iteration 8, loss = 1.24273854\n",
      "Iteration 9, loss = 1.24469302\n",
      "Iteration 10, loss = 1.24821425\n",
      "Iteration 1, loss = 1.27052214\n",
      "Iteration 2, loss = 1.26266351\n",
      "Iteration 3, loss = 1.28938850\n",
      "Iteration 4, loss = 1.27884110\n",
      "Iteration 5, loss = 1.25466548\n",
      "Iteration 6, loss = 1.26652693\n",
      "Iteration 7, loss = 1.26725917\n",
      "Iteration 8, loss = 1.25315228\n",
      "Iteration 9, loss = 1.26470555\n",
      "Iteration 10, loss = 1.26723766\n",
      "Iteration 1, loss = 1.26136577\n",
      "Iteration 2, loss = 1.26291263\n",
      "Iteration 3, loss = 1.25981739\n",
      "Iteration 4, loss = 1.25275289\n",
      "Iteration 5, loss = 1.24583212\n",
      "Iteration 6, loss = 1.24833956\n",
      "Iteration 7, loss = 1.25827234\n",
      "Iteration 8, loss = 1.25387019\n",
      "Iteration 9, loss = 1.24576262\n",
      "Iteration 10, loss = 1.25254743\n",
      "Iteration 1, loss = 1.29120031\n",
      "Iteration 9, loss = 1.26470555\n",
      "Iteration 10, loss = 1.26723766\n",
      "Iteration 1, loss = 1.26136577\n",
      "Iteration 2, loss = 1.26291263\n",
      "Iteration 3, loss = 1.25981739\n",
      "Iteration 4, loss = 1.25275289\n",
      "Iteration 5, loss = 1.24583212\n",
      "Iteration 6, loss = 1.24833956\n",
      "Iteration 7, loss = 1.25827234\n",
      "Iteration 8, loss = 1.25387019\n",
      "Iteration 9, loss = 1.24576262\n",
      "Iteration 10, loss = 1.25254743\n",
      "Iteration 1, loss = 1.29120031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.25369011\n",
      "Iteration 3, loss = 1.28942173\n",
      "Iteration 4, loss = 1.27203518\n",
      "Iteration 5, loss = 1.27251371\n",
      "Iteration 6, loss = 1.26594220\n",
      "Iteration 7, loss = 1.28955759\n",
      "Iteration 8, loss = 1.27235964\n",
      "Iteration 9, loss = 1.26541039\n",
      "Iteration 10, loss = 1.27832235\n",
      "Iteration 1, loss = 1.25244326\n",
      "Iteration 2, loss = 1.24578391\n",
      "Iteration 3, loss = 1.24765481\n",
      "Iteration 4, loss = 1.25019701\n",
      "Iteration 2, loss = 1.25369011\n",
      "Iteration 3, loss = 1.28942173\n",
      "Iteration 4, loss = 1.27203518\n",
      "Iteration 5, loss = 1.27251371\n",
      "Iteration 6, loss = 1.26594220\n",
      "Iteration 7, loss = 1.28955759\n",
      "Iteration 8, loss = 1.27235964\n",
      "Iteration 9, loss = 1.26541039\n",
      "Iteration 10, loss = 1.27832235\n",
      "Iteration 1, loss = 1.25244326\n",
      "Iteration 2, loss = 1.24578391\n",
      "Iteration 3, loss = 1.24765481\n",
      "Iteration 4, loss = 1.25019701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.24312641\n",
      "Iteration 6, loss = 1.24538612\n",
      "Iteration 7, loss = 1.24592375\n",
      "Iteration 8, loss = 1.25872396\n",
      "Iteration 9, loss = 1.24864109\n",
      "Iteration 10, loss = 1.25383203\n",
      "Iteration 11, loss = 1.24645497\n",
      "Iteration 12, loss = 1.26210705\n",
      "Iteration 13, loss = 1.26033116\n",
      "Iteration 14, loss = 1.24610621\n",
      "Iteration 15, loss = 1.25410813\n",
      "Iteration 16, loss = 1.27558452\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 1.24312641\n",
      "Iteration 6, loss = 1.24538612\n",
      "Iteration 7, loss = 1.24592375\n",
      "Iteration 8, loss = 1.25872396\n",
      "Iteration 9, loss = 1.24864109\n",
      "Iteration 10, loss = 1.25383203\n",
      "Iteration 11, loss = 1.24645497\n",
      "Iteration 12, loss = 1.26210705\n",
      "Iteration 13, loss = 1.26033116\n",
      "Iteration 14, loss = 1.24610621\n",
      "Iteration 15, loss = 1.25410813\n",
      "Iteration 16, loss = 1.27558452\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120847\n",
      "Iteration 2, loss = 1.15719485\n",
      "Iteration 3, loss = 1.18492967\n",
      "Iteration 4, loss = 1.26066151\n",
      "Iteration 5, loss = 1.24270976\n",
      "Iteration 6, loss = 1.23844410\n",
      "Iteration 7, loss = 1.24935118\n",
      "Iteration 8, loss = 1.24273854\n",
      "Iteration 9, loss = 1.24469302\n",
      "Iteration 10, loss = 1.24821425\n",
      "Iteration 11, loss = 1.24406679\n",
      "Iteration 12, loss = 1.25759769\n",
      "Iteration 1, loss = 1.24120847\n",
      "Iteration 2, loss = 1.15719485\n",
      "Iteration 3, loss = 1.18492967\n",
      "Iteration 4, loss = 1.26066151\n",
      "Iteration 5, loss = 1.24270976\n",
      "Iteration 6, loss = 1.23844410\n",
      "Iteration 7, loss = 1.24935118\n",
      "Iteration 8, loss = 1.24273854\n",
      "Iteration 9, loss = 1.24469302\n",
      "Iteration 10, loss = 1.24821425\n",
      "Iteration 11, loss = 1.24406679\n",
      "Iteration 12, loss = 1.25759769\n",
      "Iteration 13, loss = 1.24770018\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27052214\n",
      "Iteration 2, loss = 1.26266351\n",
      "Iteration 3, loss = 1.28938850\n",
      "Iteration 4, loss = 1.27884110\n",
      "Iteration 5, loss = 1.25466548\n",
      "Iteration 6, loss = 1.26652693\n",
      "Iteration 7, loss = 1.26725917\n",
      "Iteration 8, loss = 1.25315228\n",
      "Iteration 9, loss = 1.26470555\n",
      "Iteration 10, loss = 1.26723766\n",
      "Iteration 11, loss = 1.26247475\n",
      "Iteration 12, loss = 1.26012802\n",
      "Iteration 13, loss = 1.25766167\n",
      "Iteration 13, loss = 1.24770018\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27052214\n",
      "Iteration 2, loss = 1.26266351\n",
      "Iteration 3, loss = 1.28938850\n",
      "Iteration 4, loss = 1.27884110\n",
      "Iteration 5, loss = 1.25466548\n",
      "Iteration 6, loss = 1.26652693\n",
      "Iteration 7, loss = 1.26725917\n",
      "Iteration 8, loss = 1.25315228\n",
      "Iteration 9, loss = 1.26470555\n",
      "Iteration 10, loss = 1.26723766\n",
      "Iteration 11, loss = 1.26247475\n",
      "Iteration 12, loss = 1.26012802\n",
      "Iteration 13, loss = 1.25766167\n",
      "Iteration 14, loss = 1.26261532\n",
      "Iteration 15, loss = 1.28957809\n",
      "Iteration 16, loss = 1.25776685\n",
      "Iteration 17, loss = 1.24942137\n",
      "Iteration 18, loss = 1.26120436\n",
      "Iteration 19, loss = 1.28823020\n",
      "Iteration 20, loss = 1.26270091\n",
      "Iteration 21, loss = 1.26826765\n",
      "Iteration 22, loss = 1.25042954\n",
      "Iteration 23, loss = 1.27292532\n",
      "Iteration 24, loss = 1.26535861\n",
      "Iteration 25, loss = 1.26426614\n",
      "Iteration 26, loss = 1.26149916\n",
      "Iteration 27, loss = 1.27674141\n",
      "Iteration 28, loss = 1.27178903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 14, loss = 1.26261532\n",
      "Iteration 15, loss = 1.28957809\n",
      "Iteration 16, loss = 1.25776685\n",
      "Iteration 17, loss = 1.24942137\n",
      "Iteration 18, loss = 1.26120436\n",
      "Iteration 19, loss = 1.28823020\n",
      "Iteration 20, loss = 1.26270091\n",
      "Iteration 21, loss = 1.26826765\n",
      "Iteration 22, loss = 1.25042954\n",
      "Iteration 23, loss = 1.27292532\n",
      "Iteration 24, loss = 1.26535861\n",
      "Iteration 25, loss = 1.26426614\n",
      "Iteration 26, loss = 1.26149916\n",
      "Iteration 27, loss = 1.27674141\n",
      "Iteration 28, loss = 1.27178903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26136577\n",
      "Iteration 2, loss = 1.26291263\n",
      "Iteration 3, loss = 1.25981739\n",
      "Iteration 4, loss = 1.25275289\n",
      "Iteration 5, loss = 1.24583212\n",
      "Iteration 6, loss = 1.24833956\n",
      "Iteration 7, loss = 1.25827234\n",
      "Iteration 8, loss = 1.25387019\n",
      "Iteration 9, loss = 1.24576262\n",
      "Iteration 10, loss = 1.25254743\n",
      "Iteration 11, loss = 1.25900092\n",
      "Iteration 12, loss = 1.25255196\n",
      "Iteration 13, loss = 1.26585481\n",
      "Iteration 1, loss = 1.26136577\n",
      "Iteration 2, loss = 1.26291263\n",
      "Iteration 3, loss = 1.25981739\n",
      "Iteration 4, loss = 1.25275289\n",
      "Iteration 5, loss = 1.24583212\n",
      "Iteration 6, loss = 1.24833956\n",
      "Iteration 7, loss = 1.25827234\n",
      "Iteration 8, loss = 1.25387019\n",
      "Iteration 9, loss = 1.24576262\n",
      "Iteration 10, loss = 1.25254743\n",
      "Iteration 11, loss = 1.25900092\n",
      "Iteration 12, loss = 1.25255196\n",
      "Iteration 13, loss = 1.26585481\n",
      "Iteration 14, loss = 1.25549205\n",
      "Iteration 15, loss = 1.26647080\n",
      "Iteration 16, loss = 1.24809088\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29120031\n",
      "Iteration 2, loss = 1.25369011\n",
      "Iteration 3, loss = 1.28942173\n",
      "Iteration 4, loss = 1.27203518\n",
      "Iteration 5, loss = 1.27251371\n",
      "Iteration 6, loss = 1.26594220\n",
      "Iteration 7, loss = 1.28955759\n",
      "Iteration 8, loss = 1.27235964\n",
      "Iteration 9, loss = 1.26541039\n",
      "Iteration 10, loss = 1.27832235\n",
      "Iteration 14, loss = 1.25549205\n",
      "Iteration 15, loss = 1.26647080\n",
      "Iteration 16, loss = 1.24809088\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29120031\n",
      "Iteration 2, loss = 1.25369011\n",
      "Iteration 3, loss = 1.28942173\n",
      "Iteration 4, loss = 1.27203518\n",
      "Iteration 5, loss = 1.27251371\n",
      "Iteration 6, loss = 1.26594220\n",
      "Iteration 7, loss = 1.28955759\n",
      "Iteration 8, loss = 1.27235964\n",
      "Iteration 9, loss = 1.26541039\n",
      "Iteration 10, loss = 1.27832235\n",
      "Iteration 11, loss = 1.26614187\n",
      "Iteration 12, loss = 1.26712061\n",
      "Iteration 13, loss = 1.27269421\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25244326\n",
      "Iteration 2, loss = 1.24578391\n",
      "Iteration 3, loss = 1.24765481\n",
      "Iteration 4, loss = 1.25019701\n",
      "Iteration 5, loss = 1.24312641\n",
      "Iteration 6, loss = 1.24538612\n",
      "Iteration 7, loss = 1.24592375\n",
      "Iteration 8, loss = 1.25872396\n",
      "Iteration 9, loss = 1.24864109\n",
      "Iteration 10, loss = 1.25383203\n",
      "Iteration 11, loss = 1.26614187\n",
      "Iteration 12, loss = 1.26712061\n",
      "Iteration 13, loss = 1.27269421\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25244326\n",
      "Iteration 2, loss = 1.24578391\n",
      "Iteration 3, loss = 1.24765481\n",
      "Iteration 4, loss = 1.25019701\n",
      "Iteration 5, loss = 1.24312641\n",
      "Iteration 6, loss = 1.24538612\n",
      "Iteration 7, loss = 1.24592375\n",
      "Iteration 8, loss = 1.25872396\n",
      "Iteration 9, loss = 1.24864109\n",
      "Iteration 10, loss = 1.25383203\n",
      "Iteration 11, loss = 1.24645497\n",
      "Iteration 12, loss = 1.26210705\n",
      "Iteration 13, loss = 1.26033116\n",
      "Iteration 14, loss = 1.24610621\n",
      "Iteration 15, loss = 1.25410813\n",
      "Iteration 16, loss = 1.27558452\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120847\n",
      "Iteration 2, loss = 1.15719485\n",
      "Iteration 3, loss = 1.18492967\n",
      "Iteration 4, loss = 1.26066151\n",
      "Iteration 5, loss = 1.24270976\n",
      "Iteration 6, loss = 1.23844410\n",
      "Iteration 7, loss = 1.24935118\n",
      "Iteration 8, loss = 1.24273854\n",
      "Iteration 11, loss = 1.24645497\n",
      "Iteration 12, loss = 1.26210705\n",
      "Iteration 13, loss = 1.26033116\n",
      "Iteration 14, loss = 1.24610621\n",
      "Iteration 15, loss = 1.25410813\n",
      "Iteration 16, loss = 1.27558452\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24120847\n",
      "Iteration 2, loss = 1.15719485\n",
      "Iteration 3, loss = 1.18492967\n",
      "Iteration 4, loss = 1.26066151\n",
      "Iteration 5, loss = 1.24270976\n",
      "Iteration 6, loss = 1.23844410\n",
      "Iteration 7, loss = 1.24935118\n",
      "Iteration 8, loss = 1.24273854\n",
      "Iteration 9, loss = 1.24469302\n",
      "Iteration 10, loss = 1.24821425\n",
      "Iteration 11, loss = 1.24406679\n",
      "Iteration 12, loss = 1.25759769\n",
      "Iteration 13, loss = 1.24770018\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27052214\n",
      "Iteration 2, loss = 1.26266351\n",
      "Iteration 3, loss = 1.28938850\n",
      "Iteration 4, loss = 1.27884110\n",
      "Iteration 5, loss = 1.25466548\n",
      "Iteration 6, loss = 1.26652693\n",
      "Iteration 7, loss = 1.26725917\n",
      "Iteration 8, loss = 1.25315228\n",
      "Iteration 9, loss = 1.26470555\n",
      "Iteration 9, loss = 1.24469302\n",
      "Iteration 10, loss = 1.24821425\n",
      "Iteration 11, loss = 1.24406679\n",
      "Iteration 12, loss = 1.25759769\n",
      "Iteration 13, loss = 1.24770018\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27052214\n",
      "Iteration 2, loss = 1.26266351\n",
      "Iteration 3, loss = 1.28938850\n",
      "Iteration 4, loss = 1.27884110\n",
      "Iteration 5, loss = 1.25466548\n",
      "Iteration 6, loss = 1.26652693\n",
      "Iteration 7, loss = 1.26725917\n",
      "Iteration 8, loss = 1.25315228\n",
      "Iteration 9, loss = 1.26470555\n",
      "Iteration 10, loss = 1.26723766\n",
      "Iteration 11, loss = 1.26247475\n",
      "Iteration 12, loss = 1.26012802\n",
      "Iteration 13, loss = 1.25766167\n",
      "Iteration 14, loss = 1.26261532\n",
      "Iteration 15, loss = 1.28957809\n",
      "Iteration 16, loss = 1.25776685\n",
      "Iteration 17, loss = 1.24942137\n",
      "Iteration 18, loss = 1.26120436\n",
      "Iteration 19, loss = 1.28823020\n",
      "Iteration 20, loss = 1.26270091\n",
      "Iteration 21, loss = 1.26826765\n",
      "Iteration 22, loss = 1.25042954\n",
      "Iteration 23, loss = 1.27292532\n",
      "Iteration 24, loss = 1.26535861\n",
      "Iteration 10, loss = 1.26723766\n",
      "Iteration 11, loss = 1.26247475\n",
      "Iteration 12, loss = 1.26012802\n",
      "Iteration 13, loss = 1.25766167\n",
      "Iteration 14, loss = 1.26261532\n",
      "Iteration 15, loss = 1.28957809\n",
      "Iteration 16, loss = 1.25776685\n",
      "Iteration 17, loss = 1.24942137\n",
      "Iteration 18, loss = 1.26120436\n",
      "Iteration 19, loss = 1.28823020\n",
      "Iteration 20, loss = 1.26270091\n",
      "Iteration 21, loss = 1.26826765\n",
      "Iteration 22, loss = 1.25042954\n",
      "Iteration 23, loss = 1.27292532\n",
      "Iteration 24, loss = 1.26535861\n",
      "Iteration 25, loss = 1.26426614\n",
      "Iteration 26, loss = 1.26149916\n",
      "Iteration 27, loss = 1.27674141\n",
      "Iteration 28, loss = 1.27178903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26136577\n",
      "Iteration 2, loss = 1.26291263\n",
      "Iteration 3, loss = 1.25981739\n",
      "Iteration 4, loss = 1.25275289\n",
      "Iteration 5, loss = 1.24583212\n",
      "Iteration 6, loss = 1.24833956\n",
      "Iteration 7, loss = 1.25827234\n",
      "Iteration 8, loss = 1.25387019\n",
      "Iteration 9, loss = 1.24576262\n",
      "Iteration 10, loss = 1.25254743\n",
      "Iteration 25, loss = 1.26426614\n",
      "Iteration 26, loss = 1.26149916\n",
      "Iteration 27, loss = 1.27674141\n",
      "Iteration 28, loss = 1.27178903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26136577\n",
      "Iteration 2, loss = 1.26291263\n",
      "Iteration 3, loss = 1.25981739\n",
      "Iteration 4, loss = 1.25275289\n",
      "Iteration 5, loss = 1.24583212\n",
      "Iteration 6, loss = 1.24833956\n",
      "Iteration 7, loss = 1.25827234\n",
      "Iteration 8, loss = 1.25387019\n",
      "Iteration 9, loss = 1.24576262\n",
      "Iteration 10, loss = 1.25254743\n",
      "Iteration 11, loss = 1.25900092\n",
      "Iteration 12, loss = 1.25255196\n",
      "Iteration 13, loss = 1.26585481\n",
      "Iteration 14, loss = 1.25549205\n",
      "Iteration 15, loss = 1.26647080\n",
      "Iteration 16, loss = 1.24809088\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29120031\n",
      "Iteration 2, loss = 1.25369011\n",
      "Iteration 3, loss = 1.28942173\n",
      "Iteration 4, loss = 1.27203518\n",
      "Iteration 5, loss = 1.27251371\n",
      "Iteration 6, loss = 1.26594220\n",
      "Iteration 7, loss = 1.28955759\n",
      "Iteration 11, loss = 1.25900092\n",
      "Iteration 12, loss = 1.25255196\n",
      "Iteration 13, loss = 1.26585481\n",
      "Iteration 14, loss = 1.25549205\n",
      "Iteration 15, loss = 1.26647080\n",
      "Iteration 16, loss = 1.24809088\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29120031\n",
      "Iteration 2, loss = 1.25369011\n",
      "Iteration 3, loss = 1.28942173\n",
      "Iteration 4, loss = 1.27203518\n",
      "Iteration 5, loss = 1.27251371\n",
      "Iteration 6, loss = 1.26594220\n",
      "Iteration 7, loss = 1.28955759\n",
      "Iteration 8, loss = 1.27235964\n",
      "Iteration 9, loss = 1.26541039\n",
      "Iteration 10, loss = 1.27832235\n",
      "Iteration 11, loss = 1.26614187\n",
      "Iteration 12, loss = 1.26712061\n",
      "Iteration 13, loss = 1.27269421\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23265653\n",
      "Iteration 2, loss = 1.13619616\n",
      "Iteration 3, loss = 1.04022714\n",
      "Iteration 4, loss = 1.19530921\n",
      "Iteration 5, loss = 1.05012142\n",
      "Iteration 6, loss = 1.03250896\n",
      "Iteration 7, loss = 1.00702798\n",
      "Iteration 8, loss = 1.27235964\n",
      "Iteration 9, loss = 1.26541039\n",
      "Iteration 10, loss = 1.27832235\n",
      "Iteration 11, loss = 1.26614187\n",
      "Iteration 12, loss = 1.26712061\n",
      "Iteration 13, loss = 1.27269421\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23265653\n",
      "Iteration 2, loss = 1.13619616\n",
      "Iteration 3, loss = 1.04022714\n",
      "Iteration 4, loss = 1.19530921\n",
      "Iteration 5, loss = 1.05012142\n",
      "Iteration 6, loss = 1.03250896\n",
      "Iteration 7, loss = 1.00702798\n",
      "Iteration 8, loss = 0.95971598\n",
      "Iteration 9, loss = 0.97850058\n",
      "Iteration 10, loss = 0.98674039\n",
      "Iteration 1, loss = 1.22370373\n",
      "Iteration 2, loss = 1.07951166\n",
      "Iteration 3, loss = 1.03627012\n",
      "Iteration 4, loss = 0.98489934\n",
      "Iteration 5, loss = 0.98784573\n",
      "Iteration 6, loss = 0.97229570\n",
      "Iteration 7, loss = 0.95461452\n",
      "Iteration 8, loss = 0.90778931\n",
      "Iteration 9, loss = 0.90921678\n",
      "Iteration 8, loss = 0.95971598\n",
      "Iteration 9, loss = 0.97850058\n",
      "Iteration 10, loss = 0.98674039\n",
      "Iteration 1, loss = 1.22370373\n",
      "Iteration 2, loss = 1.07951166\n",
      "Iteration 3, loss = 1.03627012\n",
      "Iteration 4, loss = 0.98489934\n",
      "Iteration 5, loss = 0.98784573\n",
      "Iteration 6, loss = 0.97229570\n",
      "Iteration 7, loss = 0.95461452\n",
      "Iteration 8, loss = 0.90778931\n",
      "Iteration 9, loss = 0.90921678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.89877074\n",
      "Iteration 1, loss = 1.29106051\n",
      "Iteration 2, loss = 1.24452013\n",
      "Iteration 3, loss = 1.19639585\n",
      "Iteration 4, loss = 1.06729456\n",
      "Iteration 5, loss = 1.09910115\n",
      "Iteration 6, loss = 1.04377574\n",
      "Iteration 7, loss = 0.98153724\n",
      "Iteration 8, loss = 0.96324246\n",
      "Iteration 9, loss = 0.98665480\n",
      "Iteration 10, loss = 0.95899697\n",
      "Iteration 1, loss = 1.29872901\n",
      "Iteration 2, loss = 1.21872082\n",
      "Iteration 10, loss = 0.89877074\n",
      "Iteration 1, loss = 1.29106051\n",
      "Iteration 2, loss = 1.24452013\n",
      "Iteration 3, loss = 1.19639585\n",
      "Iteration 4, loss = 1.06729456\n",
      "Iteration 5, loss = 1.09910115\n",
      "Iteration 6, loss = 1.04377574\n",
      "Iteration 7, loss = 0.98153724\n",
      "Iteration 8, loss = 0.96324246\n",
      "Iteration 9, loss = 0.98665480\n",
      "Iteration 10, loss = 0.95899697\n",
      "Iteration 1, loss = 1.29872901\n",
      "Iteration 2, loss = 1.21872082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.14096981\n",
      "Iteration 4, loss = 1.07789260\n",
      "Iteration 5, loss = 1.13449938\n",
      "Iteration 6, loss = 1.06252943\n",
      "Iteration 7, loss = 1.03400838\n",
      "Iteration 8, loss = 0.98527092\n",
      "Iteration 9, loss = 0.99023181\n",
      "Iteration 10, loss = 0.94867569\n",
      "Iteration 1, loss = 1.29061403\n",
      "Iteration 2, loss = 1.15598138\n",
      "Iteration 3, loss = 1.08185116\n",
      "Iteration 4, loss = 1.04814181\n",
      "Iteration 3, loss = 1.14096981\n",
      "Iteration 4, loss = 1.07789260\n",
      "Iteration 5, loss = 1.13449938\n",
      "Iteration 6, loss = 1.06252943\n",
      "Iteration 7, loss = 1.03400838\n",
      "Iteration 8, loss = 0.98527092\n",
      "Iteration 9, loss = 0.99023181\n",
      "Iteration 10, loss = 0.94867569\n",
      "Iteration 1, loss = 1.29061403\n",
      "Iteration 2, loss = 1.15598138\n",
      "Iteration 3, loss = 1.08185116\n",
      "Iteration 4, loss = 1.04814181\n",
      "Iteration 5, loss = 1.05086432\n",
      "Iteration 6, loss = 1.02965231\n",
      "Iteration 7, loss = 0.99888325\n",
      "Iteration 8, loss = 0.95423283\n",
      "Iteration 9, loss = 0.96635398\n",
      "Iteration 10, loss = 0.96750229\n",
      "Iteration 1, loss = 1.23265653\n",
      "Iteration 2, loss = 1.13619616\n",
      "Iteration 3, loss = 1.04022714\n",
      "Iteration 4, loss = 1.19530921\n",
      "Iteration 5, loss = 1.05012142\n",
      "Iteration 6, loss = 1.03250896\n",
      "Iteration 5, loss = 1.05086432\n",
      "Iteration 6, loss = 1.02965231\n",
      "Iteration 7, loss = 0.99888325\n",
      "Iteration 8, loss = 0.95423283\n",
      "Iteration 9, loss = 0.96635398\n",
      "Iteration 10, loss = 0.96750229\n",
      "Iteration 1, loss = 1.23265653\n",
      "Iteration 2, loss = 1.13619616\n",
      "Iteration 3, loss = 1.04022714\n",
      "Iteration 4, loss = 1.19530921\n",
      "Iteration 5, loss = 1.05012142\n",
      "Iteration 6, loss = 1.03250896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.00702798\n",
      "Iteration 8, loss = 0.95971598\n",
      "Iteration 9, loss = 0.97850058\n",
      "Iteration 10, loss = 0.98674039\n",
      "Iteration 11, loss = 0.98568069\n",
      "Iteration 12, loss = 0.95317105\n",
      "Iteration 13, loss = 0.94949094\n",
      "Iteration 14, loss = 0.97349654\n",
      "Iteration 15, loss = 0.94181662\n",
      "Iteration 16, loss = 0.94070566\n",
      "Iteration 17, loss = 0.90643786\n",
      "Iteration 18, loss = 0.94157149\n",
      "Iteration 19, loss = 0.90619740\n",
      "Iteration 20, loss = 0.91339644\n",
      "Iteration 7, loss = 1.00702798\n",
      "Iteration 8, loss = 0.95971598\n",
      "Iteration 9, loss = 0.97850058\n",
      "Iteration 10, loss = 0.98674039\n",
      "Iteration 11, loss = 0.98568069\n",
      "Iteration 12, loss = 0.95317105\n",
      "Iteration 13, loss = 0.94949094\n",
      "Iteration 14, loss = 0.97349654\n",
      "Iteration 15, loss = 0.94181662\n",
      "Iteration 16, loss = 0.94070566\n",
      "Iteration 17, loss = 0.90643786\n",
      "Iteration 18, loss = 0.94157149\n",
      "Iteration 19, loss = 0.90619740\n",
      "Iteration 20, loss = 0.91339644\n",
      "Iteration 21, loss = 0.91329444\n",
      "Iteration 22, loss = 0.91432744\n",
      "Iteration 23, loss = 0.91523327\n",
      "Iteration 24, loss = 0.88298341\n",
      "Iteration 25, loss = 0.89913789\n",
      "Iteration 26, loss = 0.87713465\n",
      "Iteration 27, loss = 0.83561156\n",
      "Iteration 28, loss = 0.83838365\n",
      "Iteration 29, loss = 0.90950236\n",
      "Iteration 30, loss = 0.84375274\n",
      "Iteration 31, loss = 0.83265766\n",
      "Iteration 32, loss = 0.92695265\n",
      "Iteration 33, loss = 0.86837232\n",
      "Iteration 34, loss = 0.83968804\n",
      "Iteration 21, loss = 0.91329444\n",
      "Iteration 22, loss = 0.91432744\n",
      "Iteration 23, loss = 0.91523327\n",
      "Iteration 24, loss = 0.88298341\n",
      "Iteration 25, loss = 0.89913789\n",
      "Iteration 26, loss = 0.87713465\n",
      "Iteration 27, loss = 0.83561156\n",
      "Iteration 28, loss = 0.83838365\n",
      "Iteration 29, loss = 0.90950236\n",
      "Iteration 30, loss = 0.84375274\n",
      "Iteration 31, loss = 0.83265766\n",
      "Iteration 32, loss = 0.92695265\n",
      "Iteration 33, loss = 0.86837232\n",
      "Iteration 34, loss = 0.83968804\n",
      "Iteration 35, loss = 0.88802606\n",
      "Iteration 36, loss = 0.82538297\n",
      "Iteration 37, loss = 0.81970190\n",
      "Iteration 38, loss = 0.80547464\n",
      "Iteration 39, loss = 0.84979308\n",
      "Iteration 40, loss = 0.88968530\n",
      "Iteration 41, loss = 0.80746005\n",
      "Iteration 42, loss = 0.80570748\n",
      "Iteration 43, loss = 0.80806595\n",
      "Iteration 44, loss = 0.83560102\n",
      "Iteration 45, loss = 0.78496200\n",
      "Iteration 46, loss = 0.84279513\n",
      "Iteration 47, loss = 0.78720906\n",
      "Iteration 48, loss = 0.80200555\n",
      "Iteration 49, loss = 0.83276835\n",
      "Iteration 50, loss = 0.80521004\n",
      "Iteration 35, loss = 0.88802606\n",
      "Iteration 36, loss = 0.82538297\n",
      "Iteration 37, loss = 0.81970190\n",
      "Iteration 38, loss = 0.80547464\n",
      "Iteration 39, loss = 0.84979308\n",
      "Iteration 40, loss = 0.88968530\n",
      "Iteration 41, loss = 0.80746005\n",
      "Iteration 42, loss = 0.80570748\n",
      "Iteration 43, loss = 0.80806595\n",
      "Iteration 44, loss = 0.83560102\n",
      "Iteration 45, loss = 0.78496200\n",
      "Iteration 46, loss = 0.84279513\n",
      "Iteration 47, loss = 0.78720906\n",
      "Iteration 48, loss = 0.80200555\n",
      "Iteration 49, loss = 0.83276835\n",
      "Iteration 50, loss = 0.80521004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22370373\n",
      "Iteration 2, loss = 1.07951166\n",
      "Iteration 3, loss = 1.03627012\n",
      "Iteration 4, loss = 0.98489934\n",
      "Iteration 5, loss = 0.98784573\n",
      "Iteration 6, loss = 0.97229570\n",
      "Iteration 7, loss = 0.95461452\n",
      "Iteration 8, loss = 0.90778931\n",
      "Iteration 9, loss = 0.90921678\n",
      "Iteration 10, loss = 0.89877074\n",
      "Iteration 11, loss = 0.91459928\n",
      "Iteration 12, loss = 0.89682548\n",
      "Iteration 13, loss = 0.91443453\n",
      "Iteration 1, loss = 1.22370373\n",
      "Iteration 2, loss = 1.07951166\n",
      "Iteration 3, loss = 1.03627012\n",
      "Iteration 4, loss = 0.98489934\n",
      "Iteration 5, loss = 0.98784573\n",
      "Iteration 6, loss = 0.97229570\n",
      "Iteration 7, loss = 0.95461452\n",
      "Iteration 8, loss = 0.90778931\n",
      "Iteration 9, loss = 0.90921678\n",
      "Iteration 10, loss = 0.89877074\n",
      "Iteration 11, loss = 0.91459928\n",
      "Iteration 12, loss = 0.89682548\n",
      "Iteration 13, loss = 0.91443453\n",
      "Iteration 14, loss = 0.88353037\n",
      "Iteration 15, loss = 0.87590607\n",
      "Iteration 16, loss = 0.87333047\n",
      "Iteration 17, loss = 0.84618287\n",
      "Iteration 18, loss = 0.87302871\n",
      "Iteration 19, loss = 0.86012099\n",
      "Iteration 20, loss = 0.84341123\n",
      "Iteration 21, loss = 0.85039190\n",
      "Iteration 22, loss = 0.86774367\n",
      "Iteration 23, loss = 0.84805061\n",
      "Iteration 24, loss = 0.81854703\n",
      "Iteration 25, loss = 0.81939186\n",
      "Iteration 26, loss = 0.84028613\n",
      "Iteration 27, loss = 0.80908872\n",
      "Iteration 14, loss = 0.88353037\n",
      "Iteration 15, loss = 0.87590607\n",
      "Iteration 16, loss = 0.87333047\n",
      "Iteration 17, loss = 0.84618287\n",
      "Iteration 18, loss = 0.87302871\n",
      "Iteration 19, loss = 0.86012099\n",
      "Iteration 20, loss = 0.84341123\n",
      "Iteration 21, loss = 0.85039190\n",
      "Iteration 22, loss = 0.86774367\n",
      "Iteration 23, loss = 0.84805061\n",
      "Iteration 24, loss = 0.81854703\n",
      "Iteration 25, loss = 0.81939186\n",
      "Iteration 26, loss = 0.84028613\n",
      "Iteration 27, loss = 0.80908872\n",
      "Iteration 28, loss = 0.81047550\n",
      "Iteration 29, loss = 0.80779627\n",
      "Iteration 30, loss = 0.81843503\n",
      "Iteration 31, loss = 0.80531403\n",
      "Iteration 32, loss = 0.85965008\n",
      "Iteration 33, loss = 0.77399014\n",
      "Iteration 34, loss = 0.80194084\n",
      "Iteration 35, loss = 0.82028763\n",
      "Iteration 36, loss = 0.81559593\n",
      "Iteration 37, loss = 0.75709888\n",
      "Iteration 38, loss = 0.79882928\n",
      "Iteration 39, loss = 0.78156264\n",
      "Iteration 40, loss = 0.78696804\n",
      "Iteration 41, loss = 0.75775964\n",
      "Iteration 42, loss = 0.74173174\n",
      "Iteration 43, loss = 0.76154519\n",
      "Iteration 28, loss = 0.81047550\n",
      "Iteration 29, loss = 0.80779627\n",
      "Iteration 30, loss = 0.81843503\n",
      "Iteration 31, loss = 0.80531403\n",
      "Iteration 32, loss = 0.85965008\n",
      "Iteration 33, loss = 0.77399014\n",
      "Iteration 34, loss = 0.80194084\n",
      "Iteration 35, loss = 0.82028763\n",
      "Iteration 36, loss = 0.81559593\n",
      "Iteration 37, loss = 0.75709888\n",
      "Iteration 38, loss = 0.79882928\n",
      "Iteration 39, loss = 0.78156264\n",
      "Iteration 40, loss = 0.78696804\n",
      "Iteration 41, loss = 0.75775964\n",
      "Iteration 42, loss = 0.74173174\n",
      "Iteration 43, loss = 0.76154519\n",
      "Iteration 44, loss = 0.73611453\n",
      "Iteration 45, loss = 0.75678934\n",
      "Iteration 46, loss = 0.74448092\n",
      "Iteration 47, loss = 0.74037890\n",
      "Iteration 48, loss = 0.74699239\n",
      "Iteration 49, loss = 0.85371723\n",
      "Iteration 50, loss = 0.76322667\n",
      "Iteration 1, loss = 1.29106051\n",
      "Iteration 2, loss = 1.24452013\n",
      "Iteration 3, loss = 1.19639585\n",
      "Iteration 4, loss = 1.06729456\n",
      "Iteration 5, loss = 1.09910115\n",
      "Iteration 44, loss = 0.73611453\n",
      "Iteration 45, loss = 0.75678934\n",
      "Iteration 46, loss = 0.74448092\n",
      "Iteration 47, loss = 0.74037890\n",
      "Iteration 48, loss = 0.74699239\n",
      "Iteration 49, loss = 0.85371723\n",
      "Iteration 50, loss = 0.76322667\n",
      "Iteration 1, loss = 1.29106051\n",
      "Iteration 2, loss = 1.24452013\n",
      "Iteration 3, loss = 1.19639585\n",
      "Iteration 4, loss = 1.06729456\n",
      "Iteration 5, loss = 1.09910115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.04377574\n",
      "Iteration 7, loss = 0.98153724\n",
      "Iteration 8, loss = 0.96324246\n",
      "Iteration 9, loss = 0.98665480\n",
      "Iteration 10, loss = 0.95899697\n",
      "Iteration 11, loss = 0.94782752\n",
      "Iteration 12, loss = 0.95194582\n",
      "Iteration 13, loss = 0.93924715\n",
      "Iteration 14, loss = 0.94533757\n",
      "Iteration 15, loss = 0.93926460\n",
      "Iteration 16, loss = 0.94331996\n",
      "Iteration 17, loss = 0.95430454\n",
      "Iteration 18, loss = 0.95062603\n",
      "Iteration 19, loss = 0.90402094\n",
      "Iteration 6, loss = 1.04377574\n",
      "Iteration 7, loss = 0.98153724\n",
      "Iteration 8, loss = 0.96324246\n",
      "Iteration 9, loss = 0.98665480\n",
      "Iteration 10, loss = 0.95899697\n",
      "Iteration 11, loss = 0.94782752\n",
      "Iteration 12, loss = 0.95194582\n",
      "Iteration 13, loss = 0.93924715\n",
      "Iteration 14, loss = 0.94533757\n",
      "Iteration 15, loss = 0.93926460\n",
      "Iteration 16, loss = 0.94331996\n",
      "Iteration 17, loss = 0.95430454\n",
      "Iteration 18, loss = 0.95062603\n",
      "Iteration 19, loss = 0.90402094\n",
      "Iteration 20, loss = 0.92932061\n",
      "Iteration 21, loss = 0.92530606\n",
      "Iteration 22, loss = 0.89539827\n",
      "Iteration 23, loss = 0.88722736\n",
      "Iteration 24, loss = 0.90096771\n",
      "Iteration 25, loss = 0.89677748\n",
      "Iteration 26, loss = 0.90735659\n",
      "Iteration 27, loss = 0.87290538\n",
      "Iteration 28, loss = 0.87925283\n",
      "Iteration 29, loss = 0.85510890\n",
      "Iteration 30, loss = 0.91205928\n",
      "Iteration 31, loss = 0.90931855\n",
      "Iteration 32, loss = 0.85609576\n",
      "Iteration 33, loss = 0.85579146\n",
      "Iteration 20, loss = 0.92932061\n",
      "Iteration 21, loss = 0.92530606\n",
      "Iteration 22, loss = 0.89539827\n",
      "Iteration 23, loss = 0.88722736\n",
      "Iteration 24, loss = 0.90096771\n",
      "Iteration 25, loss = 0.89677748\n",
      "Iteration 26, loss = 0.90735659\n",
      "Iteration 27, loss = 0.87290538\n",
      "Iteration 28, loss = 0.87925283\n",
      "Iteration 29, loss = 0.85510890\n",
      "Iteration 30, loss = 0.91205928\n",
      "Iteration 31, loss = 0.90931855\n",
      "Iteration 32, loss = 0.85609576\n",
      "Iteration 33, loss = 0.85579146\n",
      "Iteration 34, loss = 0.88173399\n",
      "Iteration 35, loss = 0.85924541\n",
      "Iteration 36, loss = 0.86502181\n",
      "Iteration 37, loss = 0.80453036\n",
      "Iteration 38, loss = 0.81265624\n",
      "Iteration 39, loss = 0.86282205\n",
      "Iteration 40, loss = 0.87997636\n",
      "Iteration 41, loss = 0.81893377\n",
      "Iteration 42, loss = 0.80587944\n",
      "Iteration 43, loss = 0.78635468\n",
      "Iteration 44, loss = 0.79840396\n",
      "Iteration 45, loss = 0.79259628\n",
      "Iteration 46, loss = 0.83742208\n",
      "Iteration 47, loss = 0.76700842\n",
      "Iteration 34, loss = 0.88173399\n",
      "Iteration 35, loss = 0.85924541\n",
      "Iteration 36, loss = 0.86502181\n",
      "Iteration 37, loss = 0.80453036\n",
      "Iteration 38, loss = 0.81265624\n",
      "Iteration 39, loss = 0.86282205\n",
      "Iteration 40, loss = 0.87997636\n",
      "Iteration 41, loss = 0.81893377\n",
      "Iteration 42, loss = 0.80587944\n",
      "Iteration 43, loss = 0.78635468\n",
      "Iteration 44, loss = 0.79840396\n",
      "Iteration 45, loss = 0.79259628\n",
      "Iteration 46, loss = 0.83742208\n",
      "Iteration 47, loss = 0.76700842\n",
      "Iteration 48, loss = 0.82254597\n",
      "Iteration 49, loss = 0.77849200\n",
      "Iteration 50, loss = 0.79030547\n",
      "Iteration 1, loss = 1.29872901\n",
      "Iteration 2, loss = 1.21872082\n",
      "Iteration 3, loss = 1.14096981\n",
      "Iteration 4, loss = 1.07789260\n",
      "Iteration 5, loss = 1.13449938\n",
      "Iteration 6, loss = 1.06252943\n",
      "Iteration 7, loss = 1.03400838\n",
      "Iteration 8, loss = 0.98527092\n",
      "Iteration 9, loss = 0.99023181\n",
      "Iteration 10, loss = 0.94867569\n",
      "Iteration 11, loss = 0.95482987\n",
      "Iteration 48, loss = 0.82254597\n",
      "Iteration 49, loss = 0.77849200\n",
      "Iteration 50, loss = 0.79030547\n",
      "Iteration 1, loss = 1.29872901\n",
      "Iteration 2, loss = 1.21872082\n",
      "Iteration 3, loss = 1.14096981\n",
      "Iteration 4, loss = 1.07789260\n",
      "Iteration 5, loss = 1.13449938\n",
      "Iteration 6, loss = 1.06252943\n",
      "Iteration 7, loss = 1.03400838\n",
      "Iteration 8, loss = 0.98527092\n",
      "Iteration 9, loss = 0.99023181\n",
      "Iteration 10, loss = 0.94867569\n",
      "Iteration 11, loss = 0.95482987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.96245869\n",
      "Iteration 13, loss = 0.98530923\n",
      "Iteration 14, loss = 0.95819133\n",
      "Iteration 15, loss = 0.94975627\n",
      "Iteration 16, loss = 0.93911096\n",
      "Iteration 17, loss = 0.94463813\n",
      "Iteration 18, loss = 0.93262409\n",
      "Iteration 19, loss = 0.93124831\n",
      "Iteration 20, loss = 0.90606936\n",
      "Iteration 21, loss = 0.91403537\n",
      "Iteration 22, loss = 0.90860341\n",
      "Iteration 23, loss = 0.89724554\n",
      "Iteration 24, loss = 0.95307286\n",
      "Iteration 25, loss = 0.91623779\n",
      "Iteration 12, loss = 0.96245869\n",
      "Iteration 13, loss = 0.98530923\n",
      "Iteration 14, loss = 0.95819133\n",
      "Iteration 15, loss = 0.94975627\n",
      "Iteration 16, loss = 0.93911096\n",
      "Iteration 17, loss = 0.94463813\n",
      "Iteration 18, loss = 0.93262409\n",
      "Iteration 19, loss = 0.93124831\n",
      "Iteration 20, loss = 0.90606936\n",
      "Iteration 21, loss = 0.91403537\n",
      "Iteration 22, loss = 0.90860341\n",
      "Iteration 23, loss = 0.89724554\n",
      "Iteration 24, loss = 0.95307286\n",
      "Iteration 25, loss = 0.91623779\n",
      "Iteration 26, loss = 0.91047509\n",
      "Iteration 27, loss = 0.87397404\n",
      "Iteration 28, loss = 0.88786715\n",
      "Iteration 29, loss = 0.86705634\n",
      "Iteration 30, loss = 0.88620384\n",
      "Iteration 31, loss = 0.87215740\n",
      "Iteration 32, loss = 0.88850043\n",
      "Iteration 33, loss = 0.87212723\n",
      "Iteration 34, loss = 0.86114392\n",
      "Iteration 35, loss = 0.86017942\n",
      "Iteration 36, loss = 0.81790615\n",
      "Iteration 37, loss = 0.77092601\n",
      "Iteration 38, loss = 0.83988164\n",
      "Iteration 39, loss = 0.86056700\n",
      "Iteration 40, loss = 0.88902701\n",
      "Iteration 26, loss = 0.91047509\n",
      "Iteration 27, loss = 0.87397404\n",
      "Iteration 28, loss = 0.88786715\n",
      "Iteration 29, loss = 0.86705634\n",
      "Iteration 30, loss = 0.88620384\n",
      "Iteration 31, loss = 0.87215740\n",
      "Iteration 32, loss = 0.88850043\n",
      "Iteration 33, loss = 0.87212723\n",
      "Iteration 34, loss = 0.86114392\n",
      "Iteration 35, loss = 0.86017942\n",
      "Iteration 36, loss = 0.81790615\n",
      "Iteration 37, loss = 0.77092601\n",
      "Iteration 38, loss = 0.83988164\n",
      "Iteration 39, loss = 0.86056700\n",
      "Iteration 40, loss = 0.88902701\n",
      "Iteration 41, loss = 0.86761414\n",
      "Iteration 42, loss = 0.82074397\n",
      "Iteration 43, loss = 0.79810160\n",
      "Iteration 44, loss = 0.78867049\n",
      "Iteration 45, loss = 0.81540876\n",
      "Iteration 46, loss = 0.77194772\n",
      "Iteration 47, loss = 0.78791427\n",
      "Iteration 48, loss = 0.81575107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29061403\n",
      "Iteration 2, loss = 1.15598138\n",
      "Iteration 3, loss = 1.08185116\n",
      "Iteration 4, loss = 1.04814181\n",
      "Iteration 5, loss = 1.05086432\n",
      "Iteration 6, loss = 1.02965231\n",
      "Iteration 41, loss = 0.86761414\n",
      "Iteration 42, loss = 0.82074397\n",
      "Iteration 43, loss = 0.79810160\n",
      "Iteration 44, loss = 0.78867049\n",
      "Iteration 45, loss = 0.81540876\n",
      "Iteration 46, loss = 0.77194772\n",
      "Iteration 47, loss = 0.78791427\n",
      "Iteration 48, loss = 0.81575107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29061403\n",
      "Iteration 2, loss = 1.15598138\n",
      "Iteration 3, loss = 1.08185116\n",
      "Iteration 4, loss = 1.04814181\n",
      "Iteration 5, loss = 1.05086432\n",
      "Iteration 6, loss = 1.02965231\n",
      "Iteration 7, loss = 0.99888325\n",
      "Iteration 8, loss = 0.95423283\n",
      "Iteration 9, loss = 0.96635398\n",
      "Iteration 10, loss = 0.96750229\n",
      "Iteration 11, loss = 0.96492109\n",
      "Iteration 12, loss = 0.99546134\n",
      "Iteration 13, loss = 0.94496847\n",
      "Iteration 14, loss = 0.92701131\n",
      "Iteration 15, loss = 0.93507673\n",
      "Iteration 16, loss = 0.89737931\n",
      "Iteration 17, loss = 0.90509277\n",
      "Iteration 18, loss = 0.93588314\n",
      "Iteration 7, loss = 0.99888325\n",
      "Iteration 8, loss = 0.95423283\n",
      "Iteration 9, loss = 0.96635398\n",
      "Iteration 10, loss = 0.96750229\n",
      "Iteration 11, loss = 0.96492109\n",
      "Iteration 12, loss = 0.99546134\n",
      "Iteration 13, loss = 0.94496847\n",
      "Iteration 14, loss = 0.92701131\n",
      "Iteration 15, loss = 0.93507673\n",
      "Iteration 16, loss = 0.89737931\n",
      "Iteration 17, loss = 0.90509277\n",
      "Iteration 18, loss = 0.93588314\n",
      "Iteration 19, loss = 0.91303062\n",
      "Iteration 20, loss = 0.91010267\n",
      "Iteration 21, loss = 0.93397134\n",
      "Iteration 22, loss = 0.90129094\n",
      "Iteration 23, loss = 0.87277817\n",
      "Iteration 24, loss = 0.89101352\n",
      "Iteration 25, loss = 0.88592032\n",
      "Iteration 26, loss = 0.87083848\n",
      "Iteration 27, loss = 0.86201443\n",
      "Iteration 28, loss = 0.85255075\n",
      "Iteration 29, loss = 0.83454482\n",
      "Iteration 30, loss = 0.84313064\n",
      "Iteration 31, loss = 0.84359146\n",
      "Iteration 32, loss = 0.86672476\n",
      "Iteration 33, loss = 0.81146041\n",
      "Iteration 19, loss = 0.91303062\n",
      "Iteration 20, loss = 0.91010267\n",
      "Iteration 21, loss = 0.93397134\n",
      "Iteration 22, loss = 0.90129094\n",
      "Iteration 23, loss = 0.87277817\n",
      "Iteration 24, loss = 0.89101352\n",
      "Iteration 25, loss = 0.88592032\n",
      "Iteration 26, loss = 0.87083848\n",
      "Iteration 27, loss = 0.86201443\n",
      "Iteration 28, loss = 0.85255075\n",
      "Iteration 29, loss = 0.83454482\n",
      "Iteration 30, loss = 0.84313064\n",
      "Iteration 31, loss = 0.84359146\n",
      "Iteration 32, loss = 0.86672476\n",
      "Iteration 33, loss = 0.81146041\n",
      "Iteration 34, loss = 0.86855772\n",
      "Iteration 35, loss = 0.87968989\n",
      "Iteration 36, loss = 0.85431634\n",
      "Iteration 37, loss = 0.82975395\n",
      "Iteration 38, loss = 0.80568930\n",
      "Iteration 39, loss = 0.83329208\n",
      "Iteration 40, loss = 0.80602627\n",
      "Iteration 41, loss = 0.80438852\n",
      "Iteration 42, loss = 0.79525273\n",
      "Iteration 43, loss = 0.83028662\n",
      "Iteration 44, loss = 0.78627365\n",
      "Iteration 45, loss = 0.82292383\n",
      "Iteration 46, loss = 0.79920722\n",
      "Iteration 47, loss = 0.77388749\n",
      "Iteration 48, loss = 0.79486516\n",
      "Iteration 34, loss = 0.86855772\n",
      "Iteration 35, loss = 0.87968989\n",
      "Iteration 36, loss = 0.85431634\n",
      "Iteration 37, loss = 0.82975395\n",
      "Iteration 38, loss = 0.80568930\n",
      "Iteration 39, loss = 0.83329208\n",
      "Iteration 40, loss = 0.80602627\n",
      "Iteration 41, loss = 0.80438852\n",
      "Iteration 42, loss = 0.79525273\n",
      "Iteration 43, loss = 0.83028662\n",
      "Iteration 44, loss = 0.78627365\n",
      "Iteration 45, loss = 0.82292383\n",
      "Iteration 46, loss = 0.79920722\n",
      "Iteration 47, loss = 0.77388749\n",
      "Iteration 48, loss = 0.79486516\n",
      "Iteration 49, loss = 0.83773164\n",
      "Iteration 50, loss = 0.80835301\n",
      "Iteration 1, loss = 1.23265653\n",
      "Iteration 2, loss = 1.13619616\n",
      "Iteration 3, loss = 1.04022714\n",
      "Iteration 4, loss = 1.19530921\n",
      "Iteration 5, loss = 1.05012142\n",
      "Iteration 6, loss = 1.03250896\n",
      "Iteration 7, loss = 1.00702798\n",
      "Iteration 8, loss = 0.95971598\n",
      "Iteration 9, loss = 0.97850058\n",
      "Iteration 10, loss = 0.98674039\n",
      "Iteration 11, loss = 0.98568069\n",
      "Iteration 12, loss = 0.95317105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49, loss = 0.83773164\n",
      "Iteration 50, loss = 0.80835301\n",
      "Iteration 1, loss = 1.23265653\n",
      "Iteration 2, loss = 1.13619616\n",
      "Iteration 3, loss = 1.04022714\n",
      "Iteration 4, loss = 1.19530921\n",
      "Iteration 5, loss = 1.05012142\n",
      "Iteration 6, loss = 1.03250896\n",
      "Iteration 7, loss = 1.00702798\n",
      "Iteration 8, loss = 0.95971598\n",
      "Iteration 9, loss = 0.97850058\n",
      "Iteration 10, loss = 0.98674039\n",
      "Iteration 11, loss = 0.98568069\n",
      "Iteration 12, loss = 0.95317105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.94949094\n",
      "Iteration 14, loss = 0.97349654\n",
      "Iteration 15, loss = 0.94181662\n",
      "Iteration 16, loss = 0.94070566\n",
      "Iteration 17, loss = 0.90643786\n",
      "Iteration 18, loss = 0.94157149\n",
      "Iteration 19, loss = 0.90619740\n",
      "Iteration 20, loss = 0.91339644\n",
      "Iteration 21, loss = 0.91329444\n",
      "Iteration 22, loss = 0.91432744\n",
      "Iteration 23, loss = 0.91523327\n",
      "Iteration 24, loss = 0.88298341\n",
      "Iteration 25, loss = 0.89913789\n",
      "Iteration 26, loss = 0.87713465\n",
      "Iteration 13, loss = 0.94949094\n",
      "Iteration 14, loss = 0.97349654\n",
      "Iteration 15, loss = 0.94181662\n",
      "Iteration 16, loss = 0.94070566\n",
      "Iteration 17, loss = 0.90643786\n",
      "Iteration 18, loss = 0.94157149\n",
      "Iteration 19, loss = 0.90619740\n",
      "Iteration 20, loss = 0.91339644\n",
      "Iteration 21, loss = 0.91329444\n",
      "Iteration 22, loss = 0.91432744\n",
      "Iteration 23, loss = 0.91523327\n",
      "Iteration 24, loss = 0.88298341\n",
      "Iteration 25, loss = 0.89913789\n",
      "Iteration 26, loss = 0.87713465\n",
      "Iteration 27, loss = 0.83561156\n",
      "Iteration 28, loss = 0.83838365\n",
      "Iteration 29, loss = 0.90950236\n",
      "Iteration 30, loss = 0.84375274\n",
      "Iteration 31, loss = 0.83265766\n",
      "Iteration 32, loss = 0.92695265\n",
      "Iteration 33, loss = 0.86837232\n",
      "Iteration 34, loss = 0.83968804\n",
      "Iteration 35, loss = 0.88802606\n",
      "Iteration 36, loss = 0.82538297\n",
      "Iteration 37, loss = 0.81970190\n",
      "Iteration 38, loss = 0.80547464\n",
      "Iteration 39, loss = 0.84979308\n",
      "Iteration 40, loss = 0.88968530\n",
      "Iteration 27, loss = 0.83561156\n",
      "Iteration 28, loss = 0.83838365\n",
      "Iteration 29, loss = 0.90950236\n",
      "Iteration 30, loss = 0.84375274\n",
      "Iteration 31, loss = 0.83265766\n",
      "Iteration 32, loss = 0.92695265\n",
      "Iteration 33, loss = 0.86837232\n",
      "Iteration 34, loss = 0.83968804\n",
      "Iteration 35, loss = 0.88802606\n",
      "Iteration 36, loss = 0.82538297\n",
      "Iteration 37, loss = 0.81970190\n",
      "Iteration 38, loss = 0.80547464\n",
      "Iteration 39, loss = 0.84979308\n",
      "Iteration 40, loss = 0.88968530\n",
      "Iteration 41, loss = 0.80746005\n",
      "Iteration 42, loss = 0.80570748\n",
      "Iteration 43, loss = 0.80806595\n",
      "Iteration 44, loss = 0.83560102\n",
      "Iteration 45, loss = 0.78496200\n",
      "Iteration 46, loss = 0.84279513\n",
      "Iteration 47, loss = 0.78720906\n",
      "Iteration 48, loss = 0.80200555\n",
      "Iteration 49, loss = 0.83276835\n",
      "Iteration 50, loss = 0.80521004\n",
      "Iteration 51, loss = 0.79030637\n",
      "Iteration 52, loss = 0.76591234\n",
      "Iteration 53, loss = 0.79655729\n",
      "Iteration 54, loss = 0.77782436\n",
      "Iteration 55, loss = 0.84154442\n",
      "Iteration 41, loss = 0.80746005\n",
      "Iteration 42, loss = 0.80570748\n",
      "Iteration 43, loss = 0.80806595\n",
      "Iteration 44, loss = 0.83560102\n",
      "Iteration 45, loss = 0.78496200\n",
      "Iteration 46, loss = 0.84279513\n",
      "Iteration 47, loss = 0.78720906\n",
      "Iteration 48, loss = 0.80200555\n",
      "Iteration 49, loss = 0.83276835\n",
      "Iteration 50, loss = 0.80521004\n",
      "Iteration 51, loss = 0.79030637\n",
      "Iteration 52, loss = 0.76591234\n",
      "Iteration 53, loss = 0.79655729\n",
      "Iteration 54, loss = 0.77782436\n",
      "Iteration 55, loss = 0.84154442\n",
      "Iteration 56, loss = 0.77834548\n",
      "Iteration 57, loss = 0.76274929\n",
      "Iteration 58, loss = 0.73070880\n",
      "Iteration 59, loss = 0.77585970\n",
      "Iteration 60, loss = 0.76218259\n",
      "Iteration 61, loss = 0.71306448\n",
      "Iteration 62, loss = 0.70576794\n",
      "Iteration 63, loss = 0.71177365\n",
      "Iteration 64, loss = 0.73828481\n",
      "Iteration 65, loss = 0.71291054\n",
      "Iteration 66, loss = 0.71388019\n",
      "Iteration 67, loss = 0.71197782\n",
      "Iteration 68, loss = 0.68882960\n",
      "Iteration 69, loss = 0.67909881\n",
      "Iteration 70, loss = 0.68264818\n",
      "Iteration 56, loss = 0.77834548\n",
      "Iteration 57, loss = 0.76274929\n",
      "Iteration 58, loss = 0.73070880\n",
      "Iteration 59, loss = 0.77585970\n",
      "Iteration 60, loss = 0.76218259\n",
      "Iteration 61, loss = 0.71306448\n",
      "Iteration 62, loss = 0.70576794\n",
      "Iteration 63, loss = 0.71177365\n",
      "Iteration 64, loss = 0.73828481\n",
      "Iteration 65, loss = 0.71291054\n",
      "Iteration 66, loss = 0.71388019\n",
      "Iteration 67, loss = 0.71197782\n",
      "Iteration 68, loss = 0.68882960\n",
      "Iteration 69, loss = 0.67909881\n",
      "Iteration 70, loss = 0.68264818\n",
      "Iteration 71, loss = 0.73360382\n",
      "Iteration 72, loss = 0.71804006\n",
      "Iteration 73, loss = 0.72014102\n",
      "Iteration 74, loss = 0.68712118\n",
      "Iteration 75, loss = 0.71624472\n",
      "Iteration 76, loss = 0.72654239\n",
      "Iteration 77, loss = 0.70690481\n",
      "Iteration 78, loss = 0.69425773\n",
      "Iteration 79, loss = 0.69876403\n",
      "Iteration 80, loss = 0.68849057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22370373\n",
      "Iteration 2, loss = 1.07951166\n",
      "Iteration 3, loss = 1.03627012\n",
      "Iteration 4, loss = 0.98489934\n",
      "Iteration 71, loss = 0.73360382\n",
      "Iteration 72, loss = 0.71804006\n",
      "Iteration 73, loss = 0.72014102\n",
      "Iteration 74, loss = 0.68712118\n",
      "Iteration 75, loss = 0.71624472\n",
      "Iteration 76, loss = 0.72654239\n",
      "Iteration 77, loss = 0.70690481\n",
      "Iteration 78, loss = 0.69425773\n",
      "Iteration 79, loss = 0.69876403\n",
      "Iteration 80, loss = 0.68849057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22370373\n",
      "Iteration 2, loss = 1.07951166\n",
      "Iteration 3, loss = 1.03627012\n",
      "Iteration 4, loss = 0.98489934\n",
      "Iteration 5, loss = 0.98784573\n",
      "Iteration 6, loss = 0.97229570\n",
      "Iteration 7, loss = 0.95461452\n",
      "Iteration 8, loss = 0.90778931\n",
      "Iteration 9, loss = 0.90921678\n",
      "Iteration 10, loss = 0.89877074\n",
      "Iteration 11, loss = 0.91459928\n",
      "Iteration 12, loss = 0.89682548\n",
      "Iteration 13, loss = 0.91443453\n",
      "Iteration 14, loss = 0.88353037\n",
      "Iteration 15, loss = 0.87590607\n",
      "Iteration 16, loss = 0.87333047\n",
      "Iteration 17, loss = 0.84618287\n",
      "Iteration 18, loss = 0.87302871\n",
      "Iteration 5, loss = 0.98784573\n",
      "Iteration 6, loss = 0.97229570\n",
      "Iteration 7, loss = 0.95461452\n",
      "Iteration 8, loss = 0.90778931\n",
      "Iteration 9, loss = 0.90921678\n",
      "Iteration 10, loss = 0.89877074\n",
      "Iteration 11, loss = 0.91459928\n",
      "Iteration 12, loss = 0.89682548\n",
      "Iteration 13, loss = 0.91443453\n",
      "Iteration 14, loss = 0.88353037\n",
      "Iteration 15, loss = 0.87590607\n",
      "Iteration 16, loss = 0.87333047\n",
      "Iteration 17, loss = 0.84618287\n",
      "Iteration 18, loss = 0.87302871\n",
      "Iteration 19, loss = 0.86012099\n",
      "Iteration 20, loss = 0.84341123\n",
      "Iteration 21, loss = 0.85039190\n",
      "Iteration 22, loss = 0.86774367\n",
      "Iteration 23, loss = 0.84805061\n",
      "Iteration 24, loss = 0.81854703\n",
      "Iteration 25, loss = 0.81939186\n",
      "Iteration 26, loss = 0.84028613\n",
      "Iteration 27, loss = 0.80908872\n",
      "Iteration 28, loss = 0.81047550\n",
      "Iteration 29, loss = 0.80779627\n",
      "Iteration 30, loss = 0.81843503\n",
      "Iteration 31, loss = 0.80531403\n",
      "Iteration 32, loss = 0.85965008\n",
      "Iteration 19, loss = 0.86012099\n",
      "Iteration 20, loss = 0.84341123\n",
      "Iteration 21, loss = 0.85039190\n",
      "Iteration 22, loss = 0.86774367\n",
      "Iteration 23, loss = 0.84805061\n",
      "Iteration 24, loss = 0.81854703\n",
      "Iteration 25, loss = 0.81939186\n",
      "Iteration 26, loss = 0.84028613\n",
      "Iteration 27, loss = 0.80908872\n",
      "Iteration 28, loss = 0.81047550\n",
      "Iteration 29, loss = 0.80779627\n",
      "Iteration 30, loss = 0.81843503\n",
      "Iteration 31, loss = 0.80531403\n",
      "Iteration 32, loss = 0.85965008\n",
      "Iteration 33, loss = 0.77399014\n",
      "Iteration 34, loss = 0.80194084\n",
      "Iteration 35, loss = 0.82028763\n",
      "Iteration 36, loss = 0.81559593\n",
      "Iteration 37, loss = 0.75709888\n",
      "Iteration 38, loss = 0.79882928\n",
      "Iteration 39, loss = 0.78156264\n",
      "Iteration 40, loss = 0.78696804\n",
      "Iteration 41, loss = 0.75775964\n",
      "Iteration 42, loss = 0.74173174\n",
      "Iteration 43, loss = 0.76154519\n",
      "Iteration 44, loss = 0.73611453\n",
      "Iteration 45, loss = 0.75678934\n",
      "Iteration 46, loss = 0.74448092\n",
      "Iteration 47, loss = 0.74037890\n",
      "Iteration 33, loss = 0.77399014\n",
      "Iteration 34, loss = 0.80194084\n",
      "Iteration 35, loss = 0.82028763\n",
      "Iteration 36, loss = 0.81559593\n",
      "Iteration 37, loss = 0.75709888\n",
      "Iteration 38, loss = 0.79882928\n",
      "Iteration 39, loss = 0.78156264\n",
      "Iteration 40, loss = 0.78696804\n",
      "Iteration 41, loss = 0.75775964\n",
      "Iteration 42, loss = 0.74173174\n",
      "Iteration 43, loss = 0.76154519\n",
      "Iteration 44, loss = 0.73611453\n",
      "Iteration 45, loss = 0.75678934\n",
      "Iteration 46, loss = 0.74448092\n",
      "Iteration 47, loss = 0.74037890\n",
      "Iteration 48, loss = 0.74699239\n",
      "Iteration 49, loss = 0.85371723\n",
      "Iteration 50, loss = 0.76322667\n",
      "Iteration 51, loss = 0.78462128\n",
      "Iteration 52, loss = 0.73747396\n",
      "Iteration 53, loss = 0.75083158\n",
      "Iteration 54, loss = 0.77904618\n",
      "Iteration 55, loss = 0.69528427\n",
      "Iteration 56, loss = 0.74233906\n",
      "Iteration 57, loss = 0.71757629\n",
      "Iteration 58, loss = 0.69489383\n",
      "Iteration 59, loss = 0.74881460\n",
      "Iteration 60, loss = 0.69432506\n",
      "Iteration 61, loss = 0.70860346\n",
      "Iteration 48, loss = 0.74699239\n",
      "Iteration 49, loss = 0.85371723\n",
      "Iteration 50, loss = 0.76322667\n",
      "Iteration 51, loss = 0.78462128\n",
      "Iteration 52, loss = 0.73747396\n",
      "Iteration 53, loss = 0.75083158\n",
      "Iteration 54, loss = 0.77904618\n",
      "Iteration 55, loss = 0.69528427\n",
      "Iteration 56, loss = 0.74233906\n",
      "Iteration 57, loss = 0.71757629\n",
      "Iteration 58, loss = 0.69489383\n",
      "Iteration 59, loss = 0.74881460\n",
      "Iteration 60, loss = 0.69432506\n",
      "Iteration 61, loss = 0.70860346\n",
      "Iteration 62, loss = 0.75330539\n",
      "Iteration 63, loss = 0.70691793\n",
      "Iteration 64, loss = 0.67043781\n",
      "Iteration 65, loss = 0.75854433\n",
      "Iteration 66, loss = 0.69945119\n",
      "Iteration 67, loss = 0.67845235\n",
      "Iteration 68, loss = 0.70582316\n",
      "Iteration 69, loss = 0.73738989\n",
      "Iteration 70, loss = 0.68174860\n",
      "Iteration 71, loss = 0.65330047\n",
      "Iteration 72, loss = 0.67034473\n",
      "Iteration 73, loss = 0.67853641\n",
      "Iteration 74, loss = 0.70117987\n",
      "Iteration 75, loss = 0.66438776\n",
      "Iteration 62, loss = 0.75330539\n",
      "Iteration 63, loss = 0.70691793\n",
      "Iteration 64, loss = 0.67043781\n",
      "Iteration 65, loss = 0.75854433\n",
      "Iteration 66, loss = 0.69945119\n",
      "Iteration 67, loss = 0.67845235\n",
      "Iteration 68, loss = 0.70582316\n",
      "Iteration 69, loss = 0.73738989\n",
      "Iteration 70, loss = 0.68174860\n",
      "Iteration 71, loss = 0.65330047\n",
      "Iteration 72, loss = 0.67034473\n",
      "Iteration 73, loss = 0.67853641\n",
      "Iteration 74, loss = 0.70117987\n",
      "Iteration 75, loss = 0.66438776\n",
      "Iteration 76, loss = 0.68316115\n",
      "Iteration 77, loss = 0.64576634\n",
      "Iteration 78, loss = 0.65294886\n",
      "Iteration 79, loss = 0.67170689\n",
      "Iteration 80, loss = 0.66744790\n",
      "Iteration 81, loss = 0.63692137\n",
      "Iteration 82, loss = 0.64830197\n",
      "Iteration 83, loss = 0.66166686\n",
      "Iteration 84, loss = 0.68732126\n",
      "Iteration 85, loss = 0.65455120\n",
      "Iteration 86, loss = 0.64002851\n",
      "Iteration 87, loss = 0.65835883\n",
      "Iteration 88, loss = 0.61501724\n",
      "Iteration 89, loss = 0.62104181\n",
      "Iteration 90, loss = 0.61419667\n",
      "Iteration 76, loss = 0.68316115\n",
      "Iteration 77, loss = 0.64576634\n",
      "Iteration 78, loss = 0.65294886\n",
      "Iteration 79, loss = 0.67170689\n",
      "Iteration 80, loss = 0.66744790\n",
      "Iteration 81, loss = 0.63692137\n",
      "Iteration 82, loss = 0.64830197\n",
      "Iteration 83, loss = 0.66166686\n",
      "Iteration 84, loss = 0.68732126\n",
      "Iteration 85, loss = 0.65455120\n",
      "Iteration 86, loss = 0.64002851\n",
      "Iteration 87, loss = 0.65835883\n",
      "Iteration 88, loss = 0.61501724\n",
      "Iteration 89, loss = 0.62104181\n",
      "Iteration 90, loss = 0.61419667\n",
      "Iteration 91, loss = 0.68647485\n",
      "Iteration 92, loss = 0.83331480\n",
      "Iteration 93, loss = 0.72887896\n",
      "Iteration 94, loss = 0.72024652\n",
      "Iteration 95, loss = 0.68277513\n",
      "Iteration 96, loss = 0.64485563\n",
      "Iteration 97, loss = 0.68360667\n",
      "Iteration 98, loss = 0.68574482\n",
      "Iteration 99, loss = 0.63017336\n",
      "Iteration 100, loss = 0.66413598\n",
      "Iteration 1, loss = 1.29106051\n",
      "Iteration 2, loss = 1.24452013\n",
      "Iteration 3, loss = 1.19639585\n",
      "Iteration 91, loss = 0.68647485\n",
      "Iteration 92, loss = 0.83331480\n",
      "Iteration 93, loss = 0.72887896\n",
      "Iteration 94, loss = 0.72024652\n",
      "Iteration 95, loss = 0.68277513\n",
      "Iteration 96, loss = 0.64485563\n",
      "Iteration 97, loss = 0.68360667\n",
      "Iteration 98, loss = 0.68574482\n",
      "Iteration 99, loss = 0.63017336\n",
      "Iteration 100, loss = 0.66413598\n",
      "Iteration 1, loss = 1.29106051\n",
      "Iteration 2, loss = 1.24452013\n",
      "Iteration 3, loss = 1.19639585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.06729456\n",
      "Iteration 5, loss = 1.09910115\n",
      "Iteration 6, loss = 1.04377574\n",
      "Iteration 7, loss = 0.98153724\n",
      "Iteration 8, loss = 0.96324246\n",
      "Iteration 9, loss = 0.98665480\n",
      "Iteration 10, loss = 0.95899697\n",
      "Iteration 11, loss = 0.94782752\n",
      "Iteration 12, loss = 0.95194582\n",
      "Iteration 13, loss = 0.93924715\n",
      "Iteration 14, loss = 0.94533757\n",
      "Iteration 15, loss = 0.93926460\n",
      "Iteration 16, loss = 0.94331996\n",
      "Iteration 4, loss = 1.06729456\n",
      "Iteration 5, loss = 1.09910115\n",
      "Iteration 6, loss = 1.04377574\n",
      "Iteration 7, loss = 0.98153724\n",
      "Iteration 8, loss = 0.96324246\n",
      "Iteration 9, loss = 0.98665480\n",
      "Iteration 10, loss = 0.95899697\n",
      "Iteration 11, loss = 0.94782752\n",
      "Iteration 12, loss = 0.95194582\n",
      "Iteration 13, loss = 0.93924715\n",
      "Iteration 14, loss = 0.94533757\n",
      "Iteration 15, loss = 0.93926460\n",
      "Iteration 16, loss = 0.94331996\n",
      "Iteration 17, loss = 0.95430454\n",
      "Iteration 18, loss = 0.95062603\n",
      "Iteration 19, loss = 0.90402094\n",
      "Iteration 20, loss = 0.92932061\n",
      "Iteration 21, loss = 0.92530606\n",
      "Iteration 22, loss = 0.89539827\n",
      "Iteration 23, loss = 0.88722736\n",
      "Iteration 24, loss = 0.90096771\n",
      "Iteration 25, loss = 0.89677748\n",
      "Iteration 26, loss = 0.90735659\n",
      "Iteration 27, loss = 0.87290538\n",
      "Iteration 28, loss = 0.87925283\n",
      "Iteration 29, loss = 0.85510890\n",
      "Iteration 30, loss = 0.91205928\n",
      "Iteration 31, loss = 0.90931855\n",
      "Iteration 17, loss = 0.95430454\n",
      "Iteration 18, loss = 0.95062603\n",
      "Iteration 19, loss = 0.90402094\n",
      "Iteration 20, loss = 0.92932061\n",
      "Iteration 21, loss = 0.92530606\n",
      "Iteration 22, loss = 0.89539827\n",
      "Iteration 23, loss = 0.88722736\n",
      "Iteration 24, loss = 0.90096771\n",
      "Iteration 25, loss = 0.89677748\n",
      "Iteration 26, loss = 0.90735659\n",
      "Iteration 27, loss = 0.87290538\n",
      "Iteration 28, loss = 0.87925283\n",
      "Iteration 29, loss = 0.85510890\n",
      "Iteration 30, loss = 0.91205928\n",
      "Iteration 31, loss = 0.90931855\n",
      "Iteration 32, loss = 0.85609576\n",
      "Iteration 33, loss = 0.85579146\n",
      "Iteration 34, loss = 0.88173399\n",
      "Iteration 35, loss = 0.85924541\n",
      "Iteration 36, loss = 0.86502181\n",
      "Iteration 37, loss = 0.80453036\n",
      "Iteration 38, loss = 0.81265624\n",
      "Iteration 39, loss = 0.86282205\n",
      "Iteration 40, loss = 0.87997636\n",
      "Iteration 41, loss = 0.81893377\n",
      "Iteration 42, loss = 0.80587944\n",
      "Iteration 43, loss = 0.78635468\n",
      "Iteration 44, loss = 0.79840396\n",
      "Iteration 45, loss = 0.79259628\n",
      "Iteration 32, loss = 0.85609576\n",
      "Iteration 33, loss = 0.85579146\n",
      "Iteration 34, loss = 0.88173399\n",
      "Iteration 35, loss = 0.85924541\n",
      "Iteration 36, loss = 0.86502181\n",
      "Iteration 37, loss = 0.80453036\n",
      "Iteration 38, loss = 0.81265624\n",
      "Iteration 39, loss = 0.86282205\n",
      "Iteration 40, loss = 0.87997636\n",
      "Iteration 41, loss = 0.81893377\n",
      "Iteration 42, loss = 0.80587944\n",
      "Iteration 43, loss = 0.78635468\n",
      "Iteration 44, loss = 0.79840396\n",
      "Iteration 45, loss = 0.79259628\n",
      "Iteration 46, loss = 0.83742208\n",
      "Iteration 47, loss = 0.76700842\n",
      "Iteration 48, loss = 0.82254597\n",
      "Iteration 49, loss = 0.77849200\n",
      "Iteration 50, loss = 0.79030547\n",
      "Iteration 51, loss = 0.80242062\n",
      "Iteration 52, loss = 0.80981144\n",
      "Iteration 53, loss = 0.83564574\n",
      "Iteration 54, loss = 0.80924805\n",
      "Iteration 55, loss = 0.81523651\n",
      "Iteration 56, loss = 0.78937652\n",
      "Iteration 57, loss = 0.86862498\n",
      "Iteration 58, loss = 0.82289184\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29872901\n",
      "Iteration 2, loss = 1.21872082\n",
      "Iteration 46, loss = 0.83742208\n",
      "Iteration 47, loss = 0.76700842\n",
      "Iteration 48, loss = 0.82254597\n",
      "Iteration 49, loss = 0.77849200\n",
      "Iteration 50, loss = 0.79030547\n",
      "Iteration 51, loss = 0.80242062\n",
      "Iteration 52, loss = 0.80981144\n",
      "Iteration 53, loss = 0.83564574\n",
      "Iteration 54, loss = 0.80924805\n",
      "Iteration 55, loss = 0.81523651\n",
      "Iteration 56, loss = 0.78937652\n",
      "Iteration 57, loss = 0.86862498\n",
      "Iteration 58, loss = 0.82289184\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29872901\n",
      "Iteration 2, loss = 1.21872082\n",
      "Iteration 3, loss = 1.14096981\n",
      "Iteration 4, loss = 1.07789260\n",
      "Iteration 5, loss = 1.13449938\n",
      "Iteration 6, loss = 1.06252943\n",
      "Iteration 7, loss = 1.03400838\n",
      "Iteration 8, loss = 0.98527092\n",
      "Iteration 9, loss = 0.99023181\n",
      "Iteration 10, loss = 0.94867569\n",
      "Iteration 11, loss = 0.95482987\n",
      "Iteration 12, loss = 0.96245869\n",
      "Iteration 13, loss = 0.98530923\n",
      "Iteration 14, loss = 0.95819133\n",
      "Iteration 15, loss = 0.94975627\n",
      "Iteration 3, loss = 1.14096981\n",
      "Iteration 4, loss = 1.07789260\n",
      "Iteration 5, loss = 1.13449938\n",
      "Iteration 6, loss = 1.06252943\n",
      "Iteration 7, loss = 1.03400838\n",
      "Iteration 8, loss = 0.98527092\n",
      "Iteration 9, loss = 0.99023181\n",
      "Iteration 10, loss = 0.94867569\n",
      "Iteration 11, loss = 0.95482987\n",
      "Iteration 12, loss = 0.96245869\n",
      "Iteration 13, loss = 0.98530923\n",
      "Iteration 14, loss = 0.95819133\n",
      "Iteration 15, loss = 0.94975627\n",
      "Iteration 16, loss = 0.93911096\n",
      "Iteration 17, loss = 0.94463813\n",
      "Iteration 18, loss = 0.93262409\n",
      "Iteration 19, loss = 0.93124831\n",
      "Iteration 20, loss = 0.90606936\n",
      "Iteration 21, loss = 0.91403537\n",
      "Iteration 22, loss = 0.90860341\n",
      "Iteration 23, loss = 0.89724554\n",
      "Iteration 24, loss = 0.95307286\n",
      "Iteration 25, loss = 0.91623779\n",
      "Iteration 26, loss = 0.91047509\n",
      "Iteration 27, loss = 0.87397404\n",
      "Iteration 28, loss = 0.88786715\n",
      "Iteration 29, loss = 0.86705634\n",
      "Iteration 30, loss = 0.88620384\n",
      "Iteration 31, loss = 0.87215740\n",
      "Iteration 16, loss = 0.93911096\n",
      "Iteration 17, loss = 0.94463813\n",
      "Iteration 18, loss = 0.93262409\n",
      "Iteration 19, loss = 0.93124831\n",
      "Iteration 20, loss = 0.90606936\n",
      "Iteration 21, loss = 0.91403537\n",
      "Iteration 22, loss = 0.90860341\n",
      "Iteration 23, loss = 0.89724554\n",
      "Iteration 24, loss = 0.95307286\n",
      "Iteration 25, loss = 0.91623779\n",
      "Iteration 26, loss = 0.91047509\n",
      "Iteration 27, loss = 0.87397404\n",
      "Iteration 28, loss = 0.88786715\n",
      "Iteration 29, loss = 0.86705634\n",
      "Iteration 30, loss = 0.88620384\n",
      "Iteration 31, loss = 0.87215740\n",
      "Iteration 32, loss = 0.88850043\n",
      "Iteration 33, loss = 0.87212723\n",
      "Iteration 34, loss = 0.86114392\n",
      "Iteration 35, loss = 0.86017942\n",
      "Iteration 36, loss = 0.81790615\n",
      "Iteration 37, loss = 0.77092601\n",
      "Iteration 38, loss = 0.83988164\n",
      "Iteration 39, loss = 0.86056700\n",
      "Iteration 40, loss = 0.88902701\n",
      "Iteration 41, loss = 0.86761414\n",
      "Iteration 42, loss = 0.82074397\n",
      "Iteration 43, loss = 0.79810160\n",
      "Iteration 44, loss = 0.78867049\n",
      "Iteration 45, loss = 0.81540876\n",
      "Iteration 46, loss = 0.77194772\n",
      "Iteration 32, loss = 0.88850043\n",
      "Iteration 33, loss = 0.87212723\n",
      "Iteration 34, loss = 0.86114392\n",
      "Iteration 35, loss = 0.86017942\n",
      "Iteration 36, loss = 0.81790615\n",
      "Iteration 37, loss = 0.77092601\n",
      "Iteration 38, loss = 0.83988164\n",
      "Iteration 39, loss = 0.86056700\n",
      "Iteration 40, loss = 0.88902701\n",
      "Iteration 41, loss = 0.86761414\n",
      "Iteration 42, loss = 0.82074397\n",
      "Iteration 43, loss = 0.79810160\n",
      "Iteration 44, loss = 0.78867049\n",
      "Iteration 45, loss = 0.81540876\n",
      "Iteration 46, loss = 0.77194772\n",
      "Iteration 47, loss = 0.78791427\n",
      "Iteration 48, loss = 0.81575107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29061403\n",
      "Iteration 2, loss = 1.15598138\n",
      "Iteration 3, loss = 1.08185116\n",
      "Iteration 4, loss = 1.04814181\n",
      "Iteration 5, loss = 1.05086432\n",
      "Iteration 6, loss = 1.02965231\n",
      "Iteration 7, loss = 0.99888325\n",
      "Iteration 8, loss = 0.95423283\n",
      "Iteration 9, loss = 0.96635398\n",
      "Iteration 10, loss = 0.96750229\n",
      "Iteration 11, loss = 0.96492109\n",
      "Iteration 47, loss = 0.78791427\n",
      "Iteration 48, loss = 0.81575107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29061403\n",
      "Iteration 2, loss = 1.15598138\n",
      "Iteration 3, loss = 1.08185116\n",
      "Iteration 4, loss = 1.04814181\n",
      "Iteration 5, loss = 1.05086432\n",
      "Iteration 6, loss = 1.02965231\n",
      "Iteration 7, loss = 0.99888325\n",
      "Iteration 8, loss = 0.95423283\n",
      "Iteration 9, loss = 0.96635398\n",
      "Iteration 10, loss = 0.96750229\n",
      "Iteration 11, loss = 0.96492109\n",
      "Iteration 12, loss = 0.99546134\n",
      "Iteration 13, loss = 0.94496847\n",
      "Iteration 14, loss = 0.92701131\n",
      "Iteration 15, loss = 0.93507673\n",
      "Iteration 16, loss = 0.89737931\n",
      "Iteration 17, loss = 0.90509277\n",
      "Iteration 18, loss = 0.93588314\n",
      "Iteration 19, loss = 0.91303062\n",
      "Iteration 20, loss = 0.91010267\n",
      "Iteration 21, loss = 0.93397134\n",
      "Iteration 22, loss = 0.90129094\n",
      "Iteration 23, loss = 0.87277817\n",
      "Iteration 24, loss = 0.89101352\n",
      "Iteration 25, loss = 0.88592032\n",
      "Iteration 26, loss = 0.87083848\n",
      "Iteration 12, loss = 0.99546134\n",
      "Iteration 13, loss = 0.94496847\n",
      "Iteration 14, loss = 0.92701131\n",
      "Iteration 15, loss = 0.93507673\n",
      "Iteration 16, loss = 0.89737931\n",
      "Iteration 17, loss = 0.90509277\n",
      "Iteration 18, loss = 0.93588314\n",
      "Iteration 19, loss = 0.91303062\n",
      "Iteration 20, loss = 0.91010267\n",
      "Iteration 21, loss = 0.93397134\n",
      "Iteration 22, loss = 0.90129094\n",
      "Iteration 23, loss = 0.87277817\n",
      "Iteration 24, loss = 0.89101352\n",
      "Iteration 25, loss = 0.88592032\n",
      "Iteration 26, loss = 0.87083848\n",
      "Iteration 27, loss = 0.86201443\n",
      "Iteration 28, loss = 0.85255075\n",
      "Iteration 29, loss = 0.83454482\n",
      "Iteration 30, loss = 0.84313064\n",
      "Iteration 31, loss = 0.84359146\n",
      "Iteration 32, loss = 0.86672476\n",
      "Iteration 33, loss = 0.81146041\n",
      "Iteration 34, loss = 0.86855772\n",
      "Iteration 35, loss = 0.87968989\n",
      "Iteration 36, loss = 0.85431634\n",
      "Iteration 37, loss = 0.82975395\n",
      "Iteration 38, loss = 0.80568930\n",
      "Iteration 39, loss = 0.83329208\n",
      "Iteration 40, loss = 0.80602627\n",
      "Iteration 41, loss = 0.80438852\n",
      "Iteration 27, loss = 0.86201443\n",
      "Iteration 28, loss = 0.85255075\n",
      "Iteration 29, loss = 0.83454482\n",
      "Iteration 30, loss = 0.84313064\n",
      "Iteration 31, loss = 0.84359146\n",
      "Iteration 32, loss = 0.86672476\n",
      "Iteration 33, loss = 0.81146041\n",
      "Iteration 34, loss = 0.86855772\n",
      "Iteration 35, loss = 0.87968989\n",
      "Iteration 36, loss = 0.85431634\n",
      "Iteration 37, loss = 0.82975395\n",
      "Iteration 38, loss = 0.80568930\n",
      "Iteration 39, loss = 0.83329208\n",
      "Iteration 40, loss = 0.80602627\n",
      "Iteration 41, loss = 0.80438852\n",
      "Iteration 42, loss = 0.79525273\n",
      "Iteration 43, loss = 0.83028662\n",
      "Iteration 44, loss = 0.78627365\n",
      "Iteration 45, loss = 0.82292383\n",
      "Iteration 46, loss = 0.79920722\n",
      "Iteration 47, loss = 0.77388749\n",
      "Iteration 48, loss = 0.79486516\n",
      "Iteration 49, loss = 0.83773164\n",
      "Iteration 50, loss = 0.80835301\n",
      "Iteration 51, loss = 0.80563628\n",
      "Iteration 52, loss = 0.79763254\n",
      "Iteration 53, loss = 0.76920676\n",
      "Iteration 54, loss = 0.79829189\n",
      "Iteration 55, loss = 0.86074554\n",
      "Iteration 56, loss = 0.81511029\n",
      "Iteration 42, loss = 0.79525273\n",
      "Iteration 43, loss = 0.83028662\n",
      "Iteration 44, loss = 0.78627365\n",
      "Iteration 45, loss = 0.82292383\n",
      "Iteration 46, loss = 0.79920722\n",
      "Iteration 47, loss = 0.77388749\n",
      "Iteration 48, loss = 0.79486516\n",
      "Iteration 49, loss = 0.83773164\n",
      "Iteration 50, loss = 0.80835301\n",
      "Iteration 51, loss = 0.80563628\n",
      "Iteration 52, loss = 0.79763254\n",
      "Iteration 53, loss = 0.76920676\n",
      "Iteration 54, loss = 0.79829189\n",
      "Iteration 55, loss = 0.86074554\n",
      "Iteration 56, loss = 0.81511029\n",
      "Iteration 57, loss = 0.78043797\n",
      "Iteration 58, loss = 0.81157605\n",
      "Iteration 59, loss = 0.76813279\n",
      "Iteration 60, loss = 0.77465586\n",
      "Iteration 61, loss = 0.77595948\n",
      "Iteration 62, loss = 0.73645959\n",
      "Iteration 63, loss = 0.79059422\n",
      "Iteration 64, loss = 0.81852364\n",
      "Iteration 65, loss = 0.77475714\n",
      "Iteration 66, loss = 0.75339699\n",
      "Iteration 67, loss = 0.74812840\n",
      "Iteration 68, loss = 0.78381505\n",
      "Iteration 69, loss = 0.74360885\n",
      "Iteration 70, loss = 0.73839291\n",
      "Iteration 71, loss = 0.73512086\n",
      "Iteration 57, loss = 0.78043797\n",
      "Iteration 58, loss = 0.81157605\n",
      "Iteration 59, loss = 0.76813279\n",
      "Iteration 60, loss = 0.77465586\n",
      "Iteration 61, loss = 0.77595948\n",
      "Iteration 62, loss = 0.73645959\n",
      "Iteration 63, loss = 0.79059422\n",
      "Iteration 64, loss = 0.81852364\n",
      "Iteration 65, loss = 0.77475714\n",
      "Iteration 66, loss = 0.75339699\n",
      "Iteration 67, loss = 0.74812840\n",
      "Iteration 68, loss = 0.78381505\n",
      "Iteration 69, loss = 0.74360885\n",
      "Iteration 70, loss = 0.73839291\n",
      "Iteration 71, loss = 0.73512086\n",
      "Iteration 72, loss = 0.74564376\n",
      "Iteration 73, loss = 0.71702244\n",
      "Iteration 74, loss = 0.72161249\n",
      "Iteration 75, loss = 0.75918273\n",
      "Iteration 76, loss = 0.78234610\n",
      "Iteration 77, loss = 0.74607638\n",
      "Iteration 78, loss = 0.80613186\n",
      "Iteration 79, loss = 0.80905304\n",
      "Iteration 80, loss = 0.80371254\n",
      "Iteration 81, loss = 0.77427902\n",
      "Iteration 82, loss = 0.79224410\n",
      "Iteration 83, loss = 0.78781747\n",
      "Iteration 84, loss = 0.81225832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22717654\n",
      "Iteration 72, loss = 0.74564376\n",
      "Iteration 73, loss = 0.71702244\n",
      "Iteration 74, loss = 0.72161249\n",
      "Iteration 75, loss = 0.75918273\n",
      "Iteration 76, loss = 0.78234610\n",
      "Iteration 77, loss = 0.74607638\n",
      "Iteration 78, loss = 0.80613186\n",
      "Iteration 79, loss = 0.80905304\n",
      "Iteration 80, loss = 0.80371254\n",
      "Iteration 81, loss = 0.77427902\n",
      "Iteration 82, loss = 0.79224410\n",
      "Iteration 83, loss = 0.78781747\n",
      "Iteration 84, loss = 0.81225832\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22717654\n",
      "Iteration 2, loss = 1.17236950\n",
      "Iteration 3, loss = 1.07617499\n",
      "Iteration 4, loss = 1.16626769\n",
      "Iteration 5, loss = 1.03432489\n",
      "Iteration 6, loss = 0.99924212\n",
      "Iteration 7, loss = 0.99359713\n",
      "Iteration 8, loss = 1.00876985\n",
      "Iteration 9, loss = 1.00693636\n",
      "Iteration 10, loss = 0.99177687\n",
      "Iteration 1, loss = 1.24964002\n",
      "Iteration 2, loss = 1.18666963\n",
      "Iteration 3, loss = 1.12652941\n",
      "Iteration 4, loss = 1.00688631\n",
      "Iteration 5, loss = 0.98816018\n",
      "Iteration 2, loss = 1.17236950\n",
      "Iteration 3, loss = 1.07617499\n",
      "Iteration 4, loss = 1.16626769\n",
      "Iteration 5, loss = 1.03432489\n",
      "Iteration 6, loss = 0.99924212\n",
      "Iteration 7, loss = 0.99359713\n",
      "Iteration 8, loss = 1.00876985\n",
      "Iteration 9, loss = 1.00693636\n",
      "Iteration 10, loss = 0.99177687\n",
      "Iteration 1, loss = 1.24964002\n",
      "Iteration 2, loss = 1.18666963\n",
      "Iteration 3, loss = 1.12652941\n",
      "Iteration 4, loss = 1.00688631\n",
      "Iteration 5, loss = 0.98816018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.94709229\n",
      "Iteration 7, loss = 0.98486053\n",
      "Iteration 8, loss = 0.98445063\n",
      "Iteration 9, loss = 0.97399436\n",
      "Iteration 10, loss = 1.01685818\n",
      "Iteration 1, loss = 1.28707839\n",
      "Iteration 2, loss = 1.23170844\n",
      "Iteration 3, loss = 1.18916597\n",
      "Iteration 4, loss = 1.06399211\n",
      "Iteration 5, loss = 1.16908554\n",
      "Iteration 6, loss = 1.03419258\n",
      "Iteration 7, loss = 0.98781630\n",
      "Iteration 6, loss = 0.94709229\n",
      "Iteration 7, loss = 0.98486053\n",
      "Iteration 8, loss = 0.98445063\n",
      "Iteration 9, loss = 0.97399436\n",
      "Iteration 10, loss = 1.01685818\n",
      "Iteration 1, loss = 1.28707839\n",
      "Iteration 2, loss = 1.23170844\n",
      "Iteration 3, loss = 1.18916597\n",
      "Iteration 4, loss = 1.06399211\n",
      "Iteration 5, loss = 1.16908554\n",
      "Iteration 6, loss = 1.03419258\n",
      "Iteration 7, loss = 0.98781630\n",
      "Iteration 8, loss = 1.00935713\n",
      "Iteration 9, loss = 1.02558020\n",
      "Iteration 10, loss = 0.97571022\n",
      "Iteration 1, loss = 1.28438887\n",
      "Iteration 2, loss = 1.25851810\n",
      "Iteration 3, loss = 1.24544050\n",
      "Iteration 4, loss = 1.24334842\n",
      "Iteration 5, loss = 1.24563662\n",
      "Iteration 6, loss = 1.24372030\n",
      "Iteration 7, loss = 1.24539567\n",
      "Iteration 8, loss = 1.23836412\n",
      "Iteration 9, loss = 1.26098388\n",
      "Iteration 8, loss = 1.00935713\n",
      "Iteration 9, loss = 1.02558020\n",
      "Iteration 10, loss = 0.97571022\n",
      "Iteration 1, loss = 1.28438887\n",
      "Iteration 2, loss = 1.25851810\n",
      "Iteration 3, loss = 1.24544050\n",
      "Iteration 4, loss = 1.24334842\n",
      "Iteration 5, loss = 1.24563662\n",
      "Iteration 6, loss = 1.24372030\n",
      "Iteration 7, loss = 1.24539567\n",
      "Iteration 8, loss = 1.23836412\n",
      "Iteration 9, loss = 1.26098388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25664328\n",
      "Iteration 1, loss = 1.29772966\n",
      "Iteration 2, loss = 1.22593763\n",
      "Iteration 3, loss = 1.14703240\n",
      "Iteration 4, loss = 1.03764005\n",
      "Iteration 5, loss = 1.02793314\n",
      "Iteration 6, loss = 1.00000792\n",
      "Iteration 7, loss = 1.06758197\n",
      "Iteration 8, loss = 1.03413408\n",
      "Iteration 9, loss = 0.98600744\n",
      "Iteration 10, loss = 0.96753346\n",
      "Iteration 10, loss = 1.25664328\n",
      "Iteration 1, loss = 1.29772966\n",
      "Iteration 2, loss = 1.22593763\n",
      "Iteration 3, loss = 1.14703240\n",
      "Iteration 4, loss = 1.03764005\n",
      "Iteration 5, loss = 1.02793314\n",
      "Iteration 6, loss = 1.00000792\n",
      "Iteration 7, loss = 1.06758197\n",
      "Iteration 8, loss = 1.03413408\n",
      "Iteration 9, loss = 0.98600744\n",
      "Iteration 10, loss = 0.96753346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22717654\n",
      "Iteration 2, loss = 1.17236950\n",
      "Iteration 3, loss = 1.07617499\n",
      "Iteration 4, loss = 1.16626769\n",
      "Iteration 5, loss = 1.03432489\n",
      "Iteration 6, loss = 0.99924212\n",
      "Iteration 7, loss = 0.99359713\n",
      "Iteration 8, loss = 1.00876985\n",
      "Iteration 9, loss = 1.00693636\n",
      "Iteration 10, loss = 0.99177687\n",
      "Iteration 11, loss = 0.99955058\n",
      "Iteration 12, loss = 0.96590781\n",
      "Iteration 1, loss = 1.22717654\n",
      "Iteration 2, loss = 1.17236950\n",
      "Iteration 3, loss = 1.07617499\n",
      "Iteration 4, loss = 1.16626769\n",
      "Iteration 5, loss = 1.03432489\n",
      "Iteration 6, loss = 0.99924212\n",
      "Iteration 7, loss = 0.99359713\n",
      "Iteration 8, loss = 1.00876985\n",
      "Iteration 9, loss = 1.00693636\n",
      "Iteration 10, loss = 0.99177687\n",
      "Iteration 11, loss = 0.99955058\n",
      "Iteration 12, loss = 0.96590781\n",
      "Iteration 13, loss = 0.97808763\n",
      "Iteration 14, loss = 0.96188003\n",
      "Iteration 15, loss = 0.96372540\n",
      "Iteration 16, loss = 0.94738248\n",
      "Iteration 17, loss = 0.96447331\n",
      "Iteration 18, loss = 0.95376324\n",
      "Iteration 19, loss = 0.96544000\n",
      "Iteration 20, loss = 0.97160408\n",
      "Iteration 21, loss = 0.94882828\n",
      "Iteration 22, loss = 0.95725075\n",
      "Iteration 23, loss = 0.95315737\n",
      "Iteration 24, loss = 0.94542412\n",
      "Iteration 25, loss = 1.04379892\n",
      "Iteration 26, loss = 1.07227010\n",
      "Iteration 27, loss = 0.99454060\n",
      "Iteration 13, loss = 0.97808763\n",
      "Iteration 14, loss = 0.96188003\n",
      "Iteration 15, loss = 0.96372540\n",
      "Iteration 16, loss = 0.94738248\n",
      "Iteration 17, loss = 0.96447331\n",
      "Iteration 18, loss = 0.95376324\n",
      "Iteration 19, loss = 0.96544000\n",
      "Iteration 20, loss = 0.97160408\n",
      "Iteration 21, loss = 0.94882828\n",
      "Iteration 22, loss = 0.95725075\n",
      "Iteration 23, loss = 0.95315737\n",
      "Iteration 24, loss = 0.94542412\n",
      "Iteration 25, loss = 1.04379892\n",
      "Iteration 26, loss = 1.07227010\n",
      "Iteration 27, loss = 0.99454060\n",
      "Iteration 28, loss = 0.94783869\n",
      "Iteration 29, loss = 0.96378471\n",
      "Iteration 30, loss = 0.94065987\n",
      "Iteration 31, loss = 0.93898363\n",
      "Iteration 32, loss = 0.93753382\n",
      "Iteration 33, loss = 0.93951654\n",
      "Iteration 34, loss = 0.96780140\n",
      "Iteration 35, loss = 0.96656022\n",
      "Iteration 36, loss = 0.94735541\n",
      "Iteration 37, loss = 0.93413091\n",
      "Iteration 38, loss = 0.95479688\n",
      "Iteration 39, loss = 0.94060398\n",
      "Iteration 40, loss = 0.94721531\n",
      "Iteration 41, loss = 0.94602053\n",
      "Iteration 28, loss = 0.94783869\n",
      "Iteration 29, loss = 0.96378471\n",
      "Iteration 30, loss = 0.94065987\n",
      "Iteration 31, loss = 0.93898363\n",
      "Iteration 32, loss = 0.93753382\n",
      "Iteration 33, loss = 0.93951654\n",
      "Iteration 34, loss = 0.96780140\n",
      "Iteration 35, loss = 0.96656022\n",
      "Iteration 36, loss = 0.94735541\n",
      "Iteration 37, loss = 0.93413091\n",
      "Iteration 38, loss = 0.95479688\n",
      "Iteration 39, loss = 0.94060398\n",
      "Iteration 40, loss = 0.94721531\n",
      "Iteration 41, loss = 0.94602053\n",
      "Iteration 42, loss = 0.93613093\n",
      "Iteration 43, loss = 0.93139180\n",
      "Iteration 44, loss = 0.93566303\n",
      "Iteration 45, loss = 0.94321001\n",
      "Iteration 46, loss = 0.94215658\n",
      "Iteration 47, loss = 0.96492926\n",
      "Iteration 48, loss = 0.94751140\n",
      "Iteration 49, loss = 0.92871340\n",
      "Iteration 50, loss = 0.94673087\n",
      "Iteration 1, loss = 1.24964002\n",
      "Iteration 2, loss = 1.18666963\n",
      "Iteration 3, loss = 1.12652941\n",
      "Iteration 4, loss = 1.00688631\n",
      "Iteration 42, loss = 0.93613093\n",
      "Iteration 43, loss = 0.93139180\n",
      "Iteration 44, loss = 0.93566303\n",
      "Iteration 45, loss = 0.94321001\n",
      "Iteration 46, loss = 0.94215658\n",
      "Iteration 47, loss = 0.96492926\n",
      "Iteration 48, loss = 0.94751140\n",
      "Iteration 49, loss = 0.92871340\n",
      "Iteration 50, loss = 0.94673087\n",
      "Iteration 1, loss = 1.24964002\n",
      "Iteration 2, loss = 1.18666963\n",
      "Iteration 3, loss = 1.12652941\n",
      "Iteration 4, loss = 1.00688631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.98816018\n",
      "Iteration 6, loss = 0.94709229\n",
      "Iteration 7, loss = 0.98486053\n",
      "Iteration 8, loss = 0.98445063\n",
      "Iteration 9, loss = 0.97399436\n",
      "Iteration 10, loss = 1.01685818\n",
      "Iteration 11, loss = 1.01407731\n",
      "Iteration 12, loss = 0.96997531\n",
      "Iteration 13, loss = 0.95831140\n",
      "Iteration 14, loss = 0.95057732\n",
      "Iteration 15, loss = 0.99246906\n",
      "Iteration 16, loss = 0.93058339\n",
      "Iteration 17, loss = 0.93721919\n",
      "Iteration 5, loss = 0.98816018\n",
      "Iteration 6, loss = 0.94709229\n",
      "Iteration 7, loss = 0.98486053\n",
      "Iteration 8, loss = 0.98445063\n",
      "Iteration 9, loss = 0.97399436\n",
      "Iteration 10, loss = 1.01685818\n",
      "Iteration 11, loss = 1.01407731\n",
      "Iteration 12, loss = 0.96997531\n",
      "Iteration 13, loss = 0.95831140\n",
      "Iteration 14, loss = 0.95057732\n",
      "Iteration 15, loss = 0.99246906\n",
      "Iteration 16, loss = 0.93058339\n",
      "Iteration 17, loss = 0.93721919\n",
      "Iteration 18, loss = 0.93819214\n",
      "Iteration 19, loss = 0.93903842\n",
      "Iteration 20, loss = 0.96560655\n",
      "Iteration 21, loss = 0.94728007\n",
      "Iteration 22, loss = 0.95048267\n",
      "Iteration 23, loss = 1.07687469\n",
      "Iteration 24, loss = 0.95505601\n",
      "Iteration 25, loss = 0.94336998\n",
      "Iteration 26, loss = 0.94347578\n",
      "Iteration 27, loss = 0.92870900\n",
      "Iteration 28, loss = 0.90295555\n",
      "Iteration 29, loss = 0.91587610\n",
      "Iteration 30, loss = 0.92240416\n",
      "Iteration 31, loss = 0.93487337\n",
      "Iteration 32, loss = 0.87630793\n",
      "Iteration 18, loss = 0.93819214\n",
      "Iteration 19, loss = 0.93903842\n",
      "Iteration 20, loss = 0.96560655\n",
      "Iteration 21, loss = 0.94728007\n",
      "Iteration 22, loss = 0.95048267\n",
      "Iteration 23, loss = 1.07687469\n",
      "Iteration 24, loss = 0.95505601\n",
      "Iteration 25, loss = 0.94336998\n",
      "Iteration 26, loss = 0.94347578\n",
      "Iteration 27, loss = 0.92870900\n",
      "Iteration 28, loss = 0.90295555\n",
      "Iteration 29, loss = 0.91587610\n",
      "Iteration 30, loss = 0.92240416\n",
      "Iteration 31, loss = 0.93487337\n",
      "Iteration 32, loss = 0.87630793\n",
      "Iteration 33, loss = 0.93842285\n",
      "Iteration 34, loss = 0.89761529\n",
      "Iteration 35, loss = 0.87577639\n",
      "Iteration 36, loss = 0.86109734\n",
      "Iteration 37, loss = 0.83431340\n",
      "Iteration 38, loss = 0.93463080\n",
      "Iteration 39, loss = 0.85461937\n",
      "Iteration 40, loss = 0.99804802\n",
      "Iteration 41, loss = 1.02478950\n",
      "Iteration 42, loss = 0.95033775\n",
      "Iteration 43, loss = 0.90932361\n",
      "Iteration 44, loss = 0.95379149\n",
      "Iteration 45, loss = 0.87017649\n",
      "Iteration 46, loss = 0.93936592\n",
      "Iteration 47, loss = 0.93724264\n",
      "Iteration 33, loss = 0.93842285\n",
      "Iteration 34, loss = 0.89761529\n",
      "Iteration 35, loss = 0.87577639\n",
      "Iteration 36, loss = 0.86109734\n",
      "Iteration 37, loss = 0.83431340\n",
      "Iteration 38, loss = 0.93463080\n",
      "Iteration 39, loss = 0.85461937\n",
      "Iteration 40, loss = 0.99804802\n",
      "Iteration 41, loss = 1.02478950\n",
      "Iteration 42, loss = 0.95033775\n",
      "Iteration 43, loss = 0.90932361\n",
      "Iteration 44, loss = 0.95379149\n",
      "Iteration 45, loss = 0.87017649\n",
      "Iteration 46, loss = 0.93936592\n",
      "Iteration 47, loss = 0.93724264\n",
      "Iteration 48, loss = 0.93644072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28707839\n",
      "Iteration 2, loss = 1.23170844\n",
      "Iteration 3, loss = 1.18916597\n",
      "Iteration 4, loss = 1.06399211\n",
      "Iteration 5, loss = 1.16908554\n",
      "Iteration 6, loss = 1.03419258\n",
      "Iteration 7, loss = 0.98781630\n",
      "Iteration 8, loss = 1.00935713\n",
      "Iteration 9, loss = 1.02558020\n",
      "Iteration 10, loss = 0.97571022\n",
      "Iteration 48, loss = 0.93644072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28707839\n",
      "Iteration 2, loss = 1.23170844\n",
      "Iteration 3, loss = 1.18916597\n",
      "Iteration 4, loss = 1.06399211\n",
      "Iteration 5, loss = 1.16908554\n",
      "Iteration 6, loss = 1.03419258\n",
      "Iteration 7, loss = 0.98781630\n",
      "Iteration 8, loss = 1.00935713\n",
      "Iteration 9, loss = 1.02558020\n",
      "Iteration 10, loss = 0.97571022\n",
      "Iteration 11, loss = 0.95440222\n",
      "Iteration 12, loss = 0.96184327\n",
      "Iteration 13, loss = 0.98533559\n",
      "Iteration 14, loss = 1.01081374\n",
      "Iteration 15, loss = 0.99364779\n",
      "Iteration 16, loss = 0.97903140\n",
      "Iteration 17, loss = 0.93440902\n",
      "Iteration 18, loss = 0.95851851\n",
      "Iteration 19, loss = 0.94754478\n",
      "Iteration 20, loss = 0.99980386\n",
      "Iteration 21, loss = 0.97161055\n",
      "Iteration 22, loss = 0.94233125\n",
      "Iteration 23, loss = 0.90392405\n",
      "Iteration 24, loss = 0.94547062\n",
      "Iteration 11, loss = 0.95440222\n",
      "Iteration 12, loss = 0.96184327\n",
      "Iteration 13, loss = 0.98533559\n",
      "Iteration 14, loss = 1.01081374\n",
      "Iteration 15, loss = 0.99364779\n",
      "Iteration 16, loss = 0.97903140\n",
      "Iteration 17, loss = 0.93440902\n",
      "Iteration 18, loss = 0.95851851\n",
      "Iteration 19, loss = 0.94754478\n",
      "Iteration 20, loss = 0.99980386\n",
      "Iteration 21, loss = 0.97161055\n",
      "Iteration 22, loss = 0.94233125\n",
      "Iteration 23, loss = 0.90392405\n",
      "Iteration 24, loss = 0.94547062\n",
      "Iteration 25, loss = 0.95021689\n",
      "Iteration 26, loss = 0.95673462\n",
      "Iteration 27, loss = 0.90633328\n",
      "Iteration 28, loss = 0.94138769\n",
      "Iteration 29, loss = 0.95228499\n",
      "Iteration 30, loss = 0.96743540\n",
      "Iteration 31, loss = 1.02984794\n",
      "Iteration 32, loss = 0.95108600\n",
      "Iteration 33, loss = 0.93559087\n",
      "Iteration 34, loss = 0.90700470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28438887\n",
      "Iteration 2, loss = 1.25851810\n",
      "Iteration 25, loss = 0.95021689\n",
      "Iteration 26, loss = 0.95673462\n",
      "Iteration 27, loss = 0.90633328\n",
      "Iteration 28, loss = 0.94138769\n",
      "Iteration 29, loss = 0.95228499\n",
      "Iteration 30, loss = 0.96743540\n",
      "Iteration 31, loss = 1.02984794\n",
      "Iteration 32, loss = 0.95108600\n",
      "Iteration 33, loss = 0.93559087\n",
      "Iteration 34, loss = 0.90700470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28438887\n",
      "Iteration 2, loss = 1.25851810\n",
      "Iteration 3, loss = 1.24544050\n",
      "Iteration 4, loss = 1.24334842\n",
      "Iteration 5, loss = 1.24563662\n",
      "Iteration 6, loss = 1.24372030\n",
      "Iteration 7, loss = 1.24539567\n",
      "Iteration 8, loss = 1.23836412\n",
      "Iteration 9, loss = 1.26098388\n",
      "Iteration 10, loss = 1.25664328\n",
      "Iteration 11, loss = 1.24660571\n",
      "Iteration 12, loss = 1.24489624\n",
      "Iteration 13, loss = 1.25362006\n",
      "Iteration 3, loss = 1.24544050\n",
      "Iteration 4, loss = 1.24334842\n",
      "Iteration 5, loss = 1.24563662\n",
      "Iteration 6, loss = 1.24372030\n",
      "Iteration 7, loss = 1.24539567\n",
      "Iteration 8, loss = 1.23836412\n",
      "Iteration 9, loss = 1.26098388\n",
      "Iteration 10, loss = 1.25664328\n",
      "Iteration 11, loss = 1.24660571\n",
      "Iteration 12, loss = 1.24489624\n",
      "Iteration 13, loss = 1.25362006\n",
      "Iteration 14, loss = 1.24969676\n",
      "Iteration 15, loss = 1.24956932\n",
      "Iteration 16, loss = 1.25046449\n",
      "Iteration 17, loss = 1.24338779\n",
      "Iteration 18, loss = 1.24074894\n",
      "Iteration 19, loss = 1.24700683\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29772966\n",
      "Iteration 2, loss = 1.22593763\n",
      "Iteration 3, loss = 1.14703240\n",
      "Iteration 4, loss = 1.03764005\n",
      "Iteration 5, loss = 1.02793314\n",
      "Iteration 6, loss = 1.00000792\n",
      "Iteration 14, loss = 1.24969676\n",
      "Iteration 15, loss = 1.24956932\n",
      "Iteration 16, loss = 1.25046449\n",
      "Iteration 17, loss = 1.24338779\n",
      "Iteration 18, loss = 1.24074894\n",
      "Iteration 19, loss = 1.24700683\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29772966\n",
      "Iteration 2, loss = 1.22593763\n",
      "Iteration 3, loss = 1.14703240\n",
      "Iteration 4, loss = 1.03764005\n",
      "Iteration 5, loss = 1.02793314\n",
      "Iteration 6, loss = 1.00000792\n",
      "Iteration 7, loss = 1.06758197\n",
      "Iteration 8, loss = 1.03413408\n",
      "Iteration 9, loss = 0.98600744\n",
      "Iteration 10, loss = 0.96753346\n",
      "Iteration 11, loss = 0.94476309\n",
      "Iteration 12, loss = 0.95928413\n",
      "Iteration 13, loss = 1.03065956\n",
      "Iteration 14, loss = 1.01415493\n",
      "Iteration 15, loss = 1.04410690\n",
      "Iteration 16, loss = 1.01023190\n",
      "Iteration 17, loss = 0.98992737\n",
      "Iteration 18, loss = 1.01336092\n",
      "Iteration 19, loss = 0.97021775\n",
      "Iteration 7, loss = 1.06758197\n",
      "Iteration 8, loss = 1.03413408\n",
      "Iteration 9, loss = 0.98600744\n",
      "Iteration 10, loss = 0.96753346\n",
      "Iteration 11, loss = 0.94476309\n",
      "Iteration 12, loss = 0.95928413\n",
      "Iteration 13, loss = 1.03065956\n",
      "Iteration 14, loss = 1.01415493\n",
      "Iteration 15, loss = 1.04410690\n",
      "Iteration 16, loss = 1.01023190\n",
      "Iteration 17, loss = 0.98992737\n",
      "Iteration 18, loss = 1.01336092\n",
      "Iteration 19, loss = 0.97021775\n",
      "Iteration 20, loss = 1.00301207\n",
      "Iteration 21, loss = 0.98730562\n",
      "Iteration 22, loss = 0.96873154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22717654\n",
      "Iteration 2, loss = 1.17236950\n",
      "Iteration 3, loss = 1.07617499\n",
      "Iteration 4, loss = 1.16626769\n",
      "Iteration 5, loss = 1.03432489\n",
      "Iteration 6, loss = 0.99924212\n",
      "Iteration 7, loss = 0.99359713\n",
      "Iteration 8, loss = 1.00876985\n",
      "Iteration 9, loss = 1.00693636\n",
      "Iteration 20, loss = 1.00301207\n",
      "Iteration 21, loss = 0.98730562\n",
      "Iteration 22, loss = 0.96873154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22717654\n",
      "Iteration 2, loss = 1.17236950\n",
      "Iteration 3, loss = 1.07617499\n",
      "Iteration 4, loss = 1.16626769\n",
      "Iteration 5, loss = 1.03432489\n",
      "Iteration 6, loss = 0.99924212\n",
      "Iteration 7, loss = 0.99359713\n",
      "Iteration 8, loss = 1.00876985\n",
      "Iteration 9, loss = 1.00693636\n",
      "Iteration 10, loss = 0.99177687\n",
      "Iteration 11, loss = 0.99955058\n",
      "Iteration 12, loss = 0.96590781\n",
      "Iteration 13, loss = 0.97808763\n",
      "Iteration 14, loss = 0.96188003\n",
      "Iteration 15, loss = 0.96372540\n",
      "Iteration 16, loss = 0.94738248\n",
      "Iteration 17, loss = 0.96447331\n",
      "Iteration 18, loss = 0.95376324\n",
      "Iteration 19, loss = 0.96544000\n",
      "Iteration 20, loss = 0.97160408\n",
      "Iteration 21, loss = 0.94882828\n",
      "Iteration 22, loss = 0.95725075\n",
      "Iteration 23, loss = 0.95315737\n",
      "Iteration 10, loss = 0.99177687\n",
      "Iteration 11, loss = 0.99955058\n",
      "Iteration 12, loss = 0.96590781\n",
      "Iteration 13, loss = 0.97808763\n",
      "Iteration 14, loss = 0.96188003\n",
      "Iteration 15, loss = 0.96372540\n",
      "Iteration 16, loss = 0.94738248\n",
      "Iteration 17, loss = 0.96447331\n",
      "Iteration 18, loss = 0.95376324\n",
      "Iteration 19, loss = 0.96544000\n",
      "Iteration 20, loss = 0.97160408\n",
      "Iteration 21, loss = 0.94882828\n",
      "Iteration 22, loss = 0.95725075\n",
      "Iteration 23, loss = 0.95315737\n",
      "Iteration 24, loss = 0.94542412\n",
      "Iteration 25, loss = 1.04379892\n",
      "Iteration 26, loss = 1.07227010\n",
      "Iteration 27, loss = 0.99454060\n",
      "Iteration 28, loss = 0.94783869\n",
      "Iteration 29, loss = 0.96378471\n",
      "Iteration 30, loss = 0.94065987\n",
      "Iteration 31, loss = 0.93898363\n",
      "Iteration 32, loss = 0.93753382\n",
      "Iteration 33, loss = 0.93951654\n",
      "Iteration 34, loss = 0.96780140\n",
      "Iteration 35, loss = 0.96656022\n",
      "Iteration 36, loss = 0.94735541\n",
      "Iteration 37, loss = 0.93413091\n",
      "Iteration 24, loss = 0.94542412\n",
      "Iteration 25, loss = 1.04379892\n",
      "Iteration 26, loss = 1.07227010\n",
      "Iteration 27, loss = 0.99454060\n",
      "Iteration 28, loss = 0.94783869\n",
      "Iteration 29, loss = 0.96378471\n",
      "Iteration 30, loss = 0.94065987\n",
      "Iteration 31, loss = 0.93898363\n",
      "Iteration 32, loss = 0.93753382\n",
      "Iteration 33, loss = 0.93951654\n",
      "Iteration 34, loss = 0.96780140\n",
      "Iteration 35, loss = 0.96656022\n",
      "Iteration 36, loss = 0.94735541\n",
      "Iteration 37, loss = 0.93413091\n",
      "Iteration 38, loss = 0.95479688\n",
      "Iteration 39, loss = 0.94060398\n",
      "Iteration 40, loss = 0.94721531\n",
      "Iteration 41, loss = 0.94602053\n",
      "Iteration 42, loss = 0.93613093\n",
      "Iteration 43, loss = 0.93139180\n",
      "Iteration 44, loss = 0.93566303\n",
      "Iteration 45, loss = 0.94321001\n",
      "Iteration 46, loss = 0.94215658\n",
      "Iteration 47, loss = 0.96492926\n",
      "Iteration 48, loss = 0.94751140\n",
      "Iteration 49, loss = 0.92871340\n",
      "Iteration 50, loss = 0.94673087\n",
      "Iteration 51, loss = 0.93634399\n",
      "Iteration 52, loss = 0.92989347\n",
      "Iteration 38, loss = 0.95479688\n",
      "Iteration 39, loss = 0.94060398\n",
      "Iteration 40, loss = 0.94721531\n",
      "Iteration 41, loss = 0.94602053\n",
      "Iteration 42, loss = 0.93613093\n",
      "Iteration 43, loss = 0.93139180\n",
      "Iteration 44, loss = 0.93566303\n",
      "Iteration 45, loss = 0.94321001\n",
      "Iteration 46, loss = 0.94215658\n",
      "Iteration 47, loss = 0.96492926\n",
      "Iteration 48, loss = 0.94751140\n",
      "Iteration 49, loss = 0.92871340\n",
      "Iteration 50, loss = 0.94673087\n",
      "Iteration 51, loss = 0.93634399\n",
      "Iteration 52, loss = 0.92989347\n",
      "Iteration 53, loss = 0.92813203\n",
      "Iteration 54, loss = 0.93700642\n",
      "Iteration 55, loss = 0.97282029\n",
      "Iteration 56, loss = 0.93979348\n",
      "Iteration 57, loss = 0.94123642\n",
      "Iteration 58, loss = 0.92322352\n",
      "Iteration 59, loss = 0.92681831\n",
      "Iteration 60, loss = 0.91931949\n",
      "Iteration 61, loss = 0.92395646\n",
      "Iteration 62, loss = 0.92934742\n",
      "Iteration 63, loss = 0.93914304\n",
      "Iteration 64, loss = 0.95730377\n",
      "Iteration 65, loss = 0.93118518\n",
      "Iteration 66, loss = 0.92661357\n",
      "Iteration 67, loss = 0.93242852\n",
      "Iteration 53, loss = 0.92813203\n",
      "Iteration 54, loss = 0.93700642\n",
      "Iteration 55, loss = 0.97282029\n",
      "Iteration 56, loss = 0.93979348\n",
      "Iteration 57, loss = 0.94123642\n",
      "Iteration 58, loss = 0.92322352\n",
      "Iteration 59, loss = 0.92681831\n",
      "Iteration 60, loss = 0.91931949\n",
      "Iteration 61, loss = 0.92395646\n",
      "Iteration 62, loss = 0.92934742\n",
      "Iteration 63, loss = 0.93914304\n",
      "Iteration 64, loss = 0.95730377\n",
      "Iteration 65, loss = 0.93118518\n",
      "Iteration 66, loss = 0.92661357\n",
      "Iteration 67, loss = 0.93242852\n",
      "Iteration 68, loss = 0.92624389\n",
      "Iteration 69, loss = 0.93308601\n",
      "Iteration 70, loss = 0.93267187\n",
      "Iteration 71, loss = 0.91602110\n",
      "Iteration 72, loss = 0.91688908\n",
      "Iteration 73, loss = 0.92347475\n",
      "Iteration 74, loss = 0.95919483\n",
      "Iteration 75, loss = 0.96127017\n",
      "Iteration 76, loss = 0.92920086\n",
      "Iteration 77, loss = 0.92608607\n",
      "Iteration 78, loss = 0.92257161\n",
      "Iteration 79, loss = 0.92022542\n",
      "Iteration 80, loss = 0.92013910\n",
      "Iteration 81, loss = 0.92715483\n",
      "Iteration 82, loss = 0.91990134\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 68, loss = 0.92624389\n",
      "Iteration 69, loss = 0.93308601\n",
      "Iteration 70, loss = 0.93267187\n",
      "Iteration 71, loss = 0.91602110\n",
      "Iteration 72, loss = 0.91688908\n",
      "Iteration 73, loss = 0.92347475\n",
      "Iteration 74, loss = 0.95919483\n",
      "Iteration 75, loss = 0.96127017\n",
      "Iteration 76, loss = 0.92920086\n",
      "Iteration 77, loss = 0.92608607\n",
      "Iteration 78, loss = 0.92257161\n",
      "Iteration 79, loss = 0.92022542\n",
      "Iteration 80, loss = 0.92013910\n",
      "Iteration 81, loss = 0.92715483\n",
      "Iteration 82, loss = 0.91990134\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24964002\n",
      "Iteration 2, loss = 1.18666963\n",
      "Iteration 3, loss = 1.12652941\n",
      "Iteration 4, loss = 1.00688631\n",
      "Iteration 5, loss = 0.98816018\n",
      "Iteration 6, loss = 0.94709229\n",
      "Iteration 7, loss = 0.98486053\n",
      "Iteration 8, loss = 0.98445063\n",
      "Iteration 9, loss = 0.97399436\n",
      "Iteration 10, loss = 1.01685818\n",
      "Iteration 11, loss = 1.01407731\n",
      "Iteration 12, loss = 0.96997531\n",
      "Iteration 1, loss = 1.24964002\n",
      "Iteration 2, loss = 1.18666963\n",
      "Iteration 3, loss = 1.12652941\n",
      "Iteration 4, loss = 1.00688631\n",
      "Iteration 5, loss = 0.98816018\n",
      "Iteration 6, loss = 0.94709229\n",
      "Iteration 7, loss = 0.98486053\n",
      "Iteration 8, loss = 0.98445063\n",
      "Iteration 9, loss = 0.97399436\n",
      "Iteration 10, loss = 1.01685818\n",
      "Iteration 11, loss = 1.01407731\n",
      "Iteration 12, loss = 0.96997531\n",
      "Iteration 13, loss = 0.95831140\n",
      "Iteration 14, loss = 0.95057732\n",
      "Iteration 15, loss = 0.99246906\n",
      "Iteration 16, loss = 0.93058339\n",
      "Iteration 17, loss = 0.93721919\n",
      "Iteration 18, loss = 0.93819214\n",
      "Iteration 19, loss = 0.93903842\n",
      "Iteration 20, loss = 0.96560655\n",
      "Iteration 21, loss = 0.94728007\n",
      "Iteration 22, loss = 0.95048267\n",
      "Iteration 23, loss = 1.07687469\n",
      "Iteration 24, loss = 0.95505601\n",
      "Iteration 25, loss = 0.94336998\n",
      "Iteration 26, loss = 0.94347578\n",
      "Iteration 27, loss = 0.92870900\n",
      "Iteration 13, loss = 0.95831140\n",
      "Iteration 14, loss = 0.95057732\n",
      "Iteration 15, loss = 0.99246906\n",
      "Iteration 16, loss = 0.93058339\n",
      "Iteration 17, loss = 0.93721919\n",
      "Iteration 18, loss = 0.93819214\n",
      "Iteration 19, loss = 0.93903842\n",
      "Iteration 20, loss = 0.96560655\n",
      "Iteration 21, loss = 0.94728007\n",
      "Iteration 22, loss = 0.95048267\n",
      "Iteration 23, loss = 1.07687469\n",
      "Iteration 24, loss = 0.95505601\n",
      "Iteration 25, loss = 0.94336998\n",
      "Iteration 26, loss = 0.94347578\n",
      "Iteration 27, loss = 0.92870900\n",
      "Iteration 28, loss = 0.90295555\n",
      "Iteration 29, loss = 0.91587610\n",
      "Iteration 30, loss = 0.92240416\n",
      "Iteration 31, loss = 0.93487337\n",
      "Iteration 32, loss = 0.87630793\n",
      "Iteration 33, loss = 0.93842285\n",
      "Iteration 34, loss = 0.89761529\n",
      "Iteration 35, loss = 0.87577639\n",
      "Iteration 36, loss = 0.86109734\n",
      "Iteration 37, loss = 0.83431340\n",
      "Iteration 38, loss = 0.93463080\n",
      "Iteration 39, loss = 0.85461937\n",
      "Iteration 40, loss = 0.99804802\n",
      "Iteration 41, loss = 1.02478950\n",
      "Iteration 42, loss = 0.95033775\n",
      "Iteration 28, loss = 0.90295555\n",
      "Iteration 29, loss = 0.91587610\n",
      "Iteration 30, loss = 0.92240416\n",
      "Iteration 31, loss = 0.93487337\n",
      "Iteration 32, loss = 0.87630793\n",
      "Iteration 33, loss = 0.93842285\n",
      "Iteration 34, loss = 0.89761529\n",
      "Iteration 35, loss = 0.87577639\n",
      "Iteration 36, loss = 0.86109734\n",
      "Iteration 37, loss = 0.83431340\n",
      "Iteration 38, loss = 0.93463080\n",
      "Iteration 39, loss = 0.85461937\n",
      "Iteration 40, loss = 0.99804802\n",
      "Iteration 41, loss = 1.02478950\n",
      "Iteration 42, loss = 0.95033775\n",
      "Iteration 43, loss = 0.90932361\n",
      "Iteration 44, loss = 0.95379149\n",
      "Iteration 45, loss = 0.87017649\n",
      "Iteration 46, loss = 0.93936592\n",
      "Iteration 47, loss = 0.93724264\n",
      "Iteration 48, loss = 0.93644072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28707839\n",
      "Iteration 2, loss = 1.23170844\n",
      "Iteration 3, loss = 1.18916597\n",
      "Iteration 4, loss = 1.06399211\n",
      "Iteration 5, loss = 1.16908554\n",
      "Iteration 6, loss = 1.03419258\n",
      "Iteration 7, loss = 0.98781630\n",
      "Iteration 43, loss = 0.90932361\n",
      "Iteration 44, loss = 0.95379149\n",
      "Iteration 45, loss = 0.87017649\n",
      "Iteration 46, loss = 0.93936592\n",
      "Iteration 47, loss = 0.93724264\n",
      "Iteration 48, loss = 0.93644072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28707839\n",
      "Iteration 2, loss = 1.23170844\n",
      "Iteration 3, loss = 1.18916597\n",
      "Iteration 4, loss = 1.06399211\n",
      "Iteration 5, loss = 1.16908554\n",
      "Iteration 6, loss = 1.03419258\n",
      "Iteration 7, loss = 0.98781630\n",
      "Iteration 8, loss = 1.00935713\n",
      "Iteration 9, loss = 1.02558020\n",
      "Iteration 10, loss = 0.97571022\n",
      "Iteration 11, loss = 0.95440222\n",
      "Iteration 12, loss = 0.96184327\n",
      "Iteration 13, loss = 0.98533559\n",
      "Iteration 14, loss = 1.01081374\n",
      "Iteration 15, loss = 0.99364779\n",
      "Iteration 16, loss = 0.97903140\n",
      "Iteration 17, loss = 0.93440902\n",
      "Iteration 18, loss = 0.95851851\n",
      "Iteration 19, loss = 0.94754478\n",
      "Iteration 20, loss = 0.99980386\n",
      "Iteration 21, loss = 0.97161055\n",
      "Iteration 8, loss = 1.00935713\n",
      "Iteration 9, loss = 1.02558020\n",
      "Iteration 10, loss = 0.97571022\n",
      "Iteration 11, loss = 0.95440222\n",
      "Iteration 12, loss = 0.96184327\n",
      "Iteration 13, loss = 0.98533559\n",
      "Iteration 14, loss = 1.01081374\n",
      "Iteration 15, loss = 0.99364779\n",
      "Iteration 16, loss = 0.97903140\n",
      "Iteration 17, loss = 0.93440902\n",
      "Iteration 18, loss = 0.95851851\n",
      "Iteration 19, loss = 0.94754478\n",
      "Iteration 20, loss = 0.99980386\n",
      "Iteration 21, loss = 0.97161055\n",
      "Iteration 22, loss = 0.94233125\n",
      "Iteration 23, loss = 0.90392405\n",
      "Iteration 24, loss = 0.94547062\n",
      "Iteration 25, loss = 0.95021689\n",
      "Iteration 26, loss = 0.95673462\n",
      "Iteration 27, loss = 0.90633328\n",
      "Iteration 28, loss = 0.94138769\n",
      "Iteration 29, loss = 0.95228499\n",
      "Iteration 30, loss = 0.96743540\n",
      "Iteration 31, loss = 1.02984794\n",
      "Iteration 32, loss = 0.95108600\n",
      "Iteration 33, loss = 0.93559087\n",
      "Iteration 34, loss = 0.90700470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28438887\n",
      "Iteration 22, loss = 0.94233125\n",
      "Iteration 23, loss = 0.90392405\n",
      "Iteration 24, loss = 0.94547062\n",
      "Iteration 25, loss = 0.95021689\n",
      "Iteration 26, loss = 0.95673462\n",
      "Iteration 27, loss = 0.90633328\n",
      "Iteration 28, loss = 0.94138769\n",
      "Iteration 29, loss = 0.95228499\n",
      "Iteration 30, loss = 0.96743540\n",
      "Iteration 31, loss = 1.02984794\n",
      "Iteration 32, loss = 0.95108600\n",
      "Iteration 33, loss = 0.93559087\n",
      "Iteration 34, loss = 0.90700470\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28438887\n",
      "Iteration 2, loss = 1.25851810\n",
      "Iteration 3, loss = 1.24544050\n",
      "Iteration 4, loss = 1.24334842\n",
      "Iteration 5, loss = 1.24563662\n",
      "Iteration 6, loss = 1.24372030\n",
      "Iteration 7, loss = 1.24539567\n",
      "Iteration 8, loss = 1.23836412\n",
      "Iteration 9, loss = 1.26098388\n",
      "Iteration 10, loss = 1.25664328\n",
      "Iteration 11, loss = 1.24660571\n",
      "Iteration 12, loss = 1.24489624\n",
      "Iteration 13, loss = 1.25362006\n",
      "Iteration 14, loss = 1.24969676\n",
      "Iteration 15, loss = 1.24956932\n",
      "Iteration 2, loss = 1.25851810\n",
      "Iteration 3, loss = 1.24544050\n",
      "Iteration 4, loss = 1.24334842\n",
      "Iteration 5, loss = 1.24563662\n",
      "Iteration 6, loss = 1.24372030\n",
      "Iteration 7, loss = 1.24539567\n",
      "Iteration 8, loss = 1.23836412\n",
      "Iteration 9, loss = 1.26098388\n",
      "Iteration 10, loss = 1.25664328\n",
      "Iteration 11, loss = 1.24660571\n",
      "Iteration 12, loss = 1.24489624\n",
      "Iteration 13, loss = 1.25362006\n",
      "Iteration 14, loss = 1.24969676\n",
      "Iteration 15, loss = 1.24956932\n",
      "Iteration 16, loss = 1.25046449\n",
      "Iteration 17, loss = 1.24338779\n",
      "Iteration 18, loss = 1.24074894\n",
      "Iteration 19, loss = 1.24700683\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29772966\n",
      "Iteration 2, loss = 1.22593763\n",
      "Iteration 3, loss = 1.14703240\n",
      "Iteration 4, loss = 1.03764005\n",
      "Iteration 5, loss = 1.02793314\n",
      "Iteration 6, loss = 1.00000792\n",
      "Iteration 7, loss = 1.06758197\n",
      "Iteration 8, loss = 1.03413408\n",
      "Iteration 16, loss = 1.25046449\n",
      "Iteration 17, loss = 1.24338779\n",
      "Iteration 18, loss = 1.24074894\n",
      "Iteration 19, loss = 1.24700683\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29772966\n",
      "Iteration 2, loss = 1.22593763\n",
      "Iteration 3, loss = 1.14703240\n",
      "Iteration 4, loss = 1.03764005\n",
      "Iteration 5, loss = 1.02793314\n",
      "Iteration 6, loss = 1.00000792\n",
      "Iteration 7, loss = 1.06758197\n",
      "Iteration 8, loss = 1.03413408\n",
      "Iteration 9, loss = 0.98600744\n",
      "Iteration 10, loss = 0.96753346\n",
      "Iteration 11, loss = 0.94476309\n",
      "Iteration 12, loss = 0.95928413\n",
      "Iteration 13, loss = 1.03065956\n",
      "Iteration 14, loss = 1.01415493\n",
      "Iteration 15, loss = 1.04410690\n",
      "Iteration 16, loss = 1.01023190\n",
      "Iteration 17, loss = 0.98992737\n",
      "Iteration 18, loss = 1.01336092\n",
      "Iteration 19, loss = 0.97021775\n",
      "Iteration 20, loss = 1.00301207\n",
      "Iteration 21, loss = 0.98730562\n",
      "Iteration 22, loss = 0.96873154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26146749\n",
      "Iteration 9, loss = 0.98600744\n",
      "Iteration 10, loss = 0.96753346\n",
      "Iteration 11, loss = 0.94476309\n",
      "Iteration 12, loss = 0.95928413\n",
      "Iteration 13, loss = 1.03065956\n",
      "Iteration 14, loss = 1.01415493\n",
      "Iteration 15, loss = 1.04410690\n",
      "Iteration 16, loss = 1.01023190\n",
      "Iteration 17, loss = 0.98992737\n",
      "Iteration 18, loss = 1.01336092\n",
      "Iteration 19, loss = 0.97021775\n",
      "Iteration 20, loss = 1.00301207\n",
      "Iteration 21, loss = 0.98730562\n",
      "Iteration 22, loss = 0.96873154\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26146749\n",
      "Iteration 2, loss = 1.24355860\n",
      "Iteration 3, loss = 1.24303546\n",
      "Iteration 4, loss = 1.24515698\n",
      "Iteration 5, loss = 1.25192208\n",
      "Iteration 6, loss = 1.23999805\n",
      "Iteration 7, loss = 1.22508550\n",
      "Iteration 8, loss = 1.25480965\n",
      "Iteration 9, loss = 1.24517505\n",
      "Iteration 10, loss = 1.25302172\n",
      "Iteration 1, loss = 1.25500426\n",
      "Iteration 2, loss = 1.20390357\n",
      "Iteration 3, loss = 1.15566741\n",
      "Iteration 4, loss = 1.03410826\n",
      "Iteration 5, loss = 1.04005626\n",
      "Iteration 2, loss = 1.24355860\n",
      "Iteration 3, loss = 1.24303546\n",
      "Iteration 4, loss = 1.24515698\n",
      "Iteration 5, loss = 1.25192208\n",
      "Iteration 6, loss = 1.23999805\n",
      "Iteration 7, loss = 1.22508550\n",
      "Iteration 8, loss = 1.25480965\n",
      "Iteration 9, loss = 1.24517505\n",
      "Iteration 10, loss = 1.25302172\n",
      "Iteration 1, loss = 1.25500426\n",
      "Iteration 2, loss = 1.20390357\n",
      "Iteration 3, loss = 1.15566741\n",
      "Iteration 4, loss = 1.03410826\n",
      "Iteration 5, loss = 1.04005626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 1.05182581\n",
      "Iteration 7, loss = 1.23124858\n",
      "Iteration 8, loss = 1.17072051\n",
      "Iteration 9, loss = 0.98492188\n",
      "Iteration 10, loss = 1.23991104\n",
      "Iteration 1, loss = 1.28514258\n",
      "Iteration 2, loss = 1.22747038\n",
      "Iteration 3, loss = 1.11634798\n",
      "Iteration 4, loss = 1.25530592\n",
      "Iteration 5, loss = 1.26124677\n",
      "Iteration 6, loss = 1.25885623\n",
      "Iteration 7, loss = 1.26017474\n",
      "Iteration 8, loss = 1.25784807\n",
      "Iteration 6, loss = 1.05182581\n",
      "Iteration 7, loss = 1.23124858\n",
      "Iteration 8, loss = 1.17072051\n",
      "Iteration 9, loss = 0.98492188\n",
      "Iteration 10, loss = 1.23991104\n",
      "Iteration 1, loss = 1.28514258\n",
      "Iteration 2, loss = 1.22747038\n",
      "Iteration 3, loss = 1.11634798\n",
      "Iteration 4, loss = 1.25530592\n",
      "Iteration 5, loss = 1.26124677\n",
      "Iteration 6, loss = 1.25885623\n",
      "Iteration 7, loss = 1.26017474\n",
      "Iteration 8, loss = 1.25784807\n",
      "Iteration 9, loss = 1.28453859\n",
      "Iteration 10, loss = 1.26710432\n",
      "Iteration 1, loss = 1.28085272\n",
      "Iteration 2, loss = 1.22493565\n",
      "Iteration 3, loss = 1.22136809\n",
      "Iteration 4, loss = 1.17484763\n",
      "Iteration 5, loss = 1.13650379\n",
      "Iteration 6, loss = 1.12503633\n",
      "Iteration 7, loss = 1.27323890\n",
      "Iteration 8, loss = 1.24385833\n",
      "Iteration 9, loss = 1.26817031\n",
      "Iteration 10, loss = 1.27396065\n",
      "Iteration 1, loss = 1.28933029\n",
      "Iteration 9, loss = 1.28453859\n",
      "Iteration 10, loss = 1.26710432\n",
      "Iteration 1, loss = 1.28085272\n",
      "Iteration 2, loss = 1.22493565\n",
      "Iteration 3, loss = 1.22136809\n",
      "Iteration 4, loss = 1.17484763\n",
      "Iteration 5, loss = 1.13650379\n",
      "Iteration 6, loss = 1.12503633\n",
      "Iteration 7, loss = 1.27323890\n",
      "Iteration 8, loss = 1.24385833\n",
      "Iteration 9, loss = 1.26817031\n",
      "Iteration 10, loss = 1.27396065\n",
      "Iteration 1, loss = 1.28933029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.26172361\n",
      "Iteration 3, loss = 1.26370761\n",
      "Iteration 4, loss = 1.24311404\n",
      "Iteration 5, loss = 1.26397810\n",
      "Iteration 6, loss = 1.17660318\n",
      "Iteration 7, loss = 1.12066143\n",
      "Iteration 8, loss = 1.13747910\n",
      "Iteration 9, loss = 1.28083056\n",
      "Iteration 10, loss = 1.27668244\n",
      "Iteration 1, loss = 1.26146749\n",
      "Iteration 2, loss = 1.24355860\n",
      "Iteration 3, loss = 1.24303546\n",
      "Iteration 2, loss = 1.26172361\n",
      "Iteration 3, loss = 1.26370761\n",
      "Iteration 4, loss = 1.24311404\n",
      "Iteration 5, loss = 1.26397810\n",
      "Iteration 6, loss = 1.17660318\n",
      "Iteration 7, loss = 1.12066143\n",
      "Iteration 8, loss = 1.13747910\n",
      "Iteration 9, loss = 1.28083056\n",
      "Iteration 10, loss = 1.27668244\n",
      "Iteration 1, loss = 1.26146749\n",
      "Iteration 2, loss = 1.24355860\n",
      "Iteration 3, loss = 1.24303546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.24515698\n",
      "Iteration 5, loss = 1.25192208\n",
      "Iteration 6, loss = 1.23999805\n",
      "Iteration 7, loss = 1.22508550\n",
      "Iteration 8, loss = 1.25480965\n",
      "Iteration 9, loss = 1.24517505\n",
      "Iteration 10, loss = 1.25302172\n",
      "Iteration 11, loss = 1.24095610\n",
      "Iteration 12, loss = 1.25516229\n",
      "Iteration 13, loss = 1.25567758\n",
      "Iteration 14, loss = 1.25628775\n",
      "Iteration 15, loss = 1.24670301\n",
      "Iteration 16, loss = 1.24666835\n",
      "Iteration 17, loss = 1.25499330\n",
      "Iteration 4, loss = 1.24515698\n",
      "Iteration 5, loss = 1.25192208\n",
      "Iteration 6, loss = 1.23999805\n",
      "Iteration 7, loss = 1.22508550\n",
      "Iteration 8, loss = 1.25480965\n",
      "Iteration 9, loss = 1.24517505\n",
      "Iteration 10, loss = 1.25302172\n",
      "Iteration 11, loss = 1.24095610\n",
      "Iteration 12, loss = 1.25516229\n",
      "Iteration 13, loss = 1.25567758\n",
      "Iteration 14, loss = 1.25628775\n",
      "Iteration 15, loss = 1.24670301\n",
      "Iteration 16, loss = 1.24666835\n",
      "Iteration 17, loss = 1.25499330\n",
      "Iteration 18, loss = 1.24419870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25500426\n",
      "Iteration 2, loss = 1.20390357\n",
      "Iteration 3, loss = 1.15566741\n",
      "Iteration 4, loss = 1.03410826\n",
      "Iteration 5, loss = 1.04005626\n",
      "Iteration 6, loss = 1.05182581\n",
      "Iteration 7, loss = 1.23124858\n",
      "Iteration 8, loss = 1.17072051\n",
      "Iteration 9, loss = 0.98492188\n",
      "Iteration 10, loss = 1.23991104\n",
      "Iteration 11, loss = 1.24170231\n",
      "Iteration 18, loss = 1.24419870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25500426\n",
      "Iteration 2, loss = 1.20390357\n",
      "Iteration 3, loss = 1.15566741\n",
      "Iteration 4, loss = 1.03410826\n",
      "Iteration 5, loss = 1.04005626\n",
      "Iteration 6, loss = 1.05182581\n",
      "Iteration 7, loss = 1.23124858\n",
      "Iteration 8, loss = 1.17072051\n",
      "Iteration 9, loss = 0.98492188\n",
      "Iteration 10, loss = 1.23991104\n",
      "Iteration 11, loss = 1.24170231\n",
      "Iteration 12, loss = 1.25017576\n",
      "Iteration 13, loss = 1.26562332\n",
      "Iteration 14, loss = 1.24026701\n",
      "Iteration 15, loss = 1.26407530\n",
      "Iteration 16, loss = 1.24213892\n",
      "Iteration 17, loss = 1.25796695\n",
      "Iteration 18, loss = 1.24770388\n",
      "Iteration 19, loss = 1.23722128\n",
      "Iteration 20, loss = 1.24617943\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28514258\n",
      "Iteration 2, loss = 1.22747038\n",
      "Iteration 3, loss = 1.11634798\n",
      "Iteration 4, loss = 1.25530592\n",
      "Iteration 5, loss = 1.26124677\n",
      "Iteration 12, loss = 1.25017576\n",
      "Iteration 13, loss = 1.26562332\n",
      "Iteration 14, loss = 1.24026701\n",
      "Iteration 15, loss = 1.26407530\n",
      "Iteration 16, loss = 1.24213892\n",
      "Iteration 17, loss = 1.25796695\n",
      "Iteration 18, loss = 1.24770388\n",
      "Iteration 19, loss = 1.23722128\n",
      "Iteration 20, loss = 1.24617943\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28514258\n",
      "Iteration 2, loss = 1.22747038\n",
      "Iteration 3, loss = 1.11634798\n",
      "Iteration 4, loss = 1.25530592\n",
      "Iteration 5, loss = 1.26124677\n",
      "Iteration 6, loss = 1.25885623\n",
      "Iteration 7, loss = 1.26017474\n",
      "Iteration 8, loss = 1.25784807\n",
      "Iteration 9, loss = 1.28453859\n",
      "Iteration 10, loss = 1.26710432\n",
      "Iteration 11, loss = 1.26329254\n",
      "Iteration 12, loss = 1.25649863\n",
      "Iteration 13, loss = 1.26982755\n",
      "Iteration 14, loss = 1.26550778\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28085272\n",
      "Iteration 2, loss = 1.22493565\n",
      "Iteration 3, loss = 1.22136809\n",
      "Iteration 6, loss = 1.25885623\n",
      "Iteration 7, loss = 1.26017474\n",
      "Iteration 8, loss = 1.25784807\n",
      "Iteration 9, loss = 1.28453859\n",
      "Iteration 10, loss = 1.26710432\n",
      "Iteration 11, loss = 1.26329254\n",
      "Iteration 12, loss = 1.25649863\n",
      "Iteration 13, loss = 1.26982755\n",
      "Iteration 14, loss = 1.26550778\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28085272\n",
      "Iteration 2, loss = 1.22493565\n",
      "Iteration 3, loss = 1.22136809\n",
      "Iteration 4, loss = 1.17484763\n",
      "Iteration 5, loss = 1.13650379\n",
      "Iteration 6, loss = 1.12503633\n",
      "Iteration 7, loss = 1.27323890\n",
      "Iteration 8, loss = 1.24385833\n",
      "Iteration 9, loss = 1.26817031\n",
      "Iteration 10, loss = 1.27396065\n",
      "Iteration 11, loss = 1.25784520\n",
      "Iteration 12, loss = 1.25027592\n",
      "Iteration 13, loss = 1.26497854\n",
      "Iteration 14, loss = 1.25932811\n",
      "Iteration 15, loss = 1.26539385\n",
      "Iteration 16, loss = 1.26298554\n",
      "Iteration 17, loss = 1.25089106\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 1.17484763\n",
      "Iteration 5, loss = 1.13650379\n",
      "Iteration 6, loss = 1.12503633\n",
      "Iteration 7, loss = 1.27323890\n",
      "Iteration 8, loss = 1.24385833\n",
      "Iteration 9, loss = 1.26817031\n",
      "Iteration 10, loss = 1.27396065\n",
      "Iteration 11, loss = 1.25784520\n",
      "Iteration 12, loss = 1.25027592\n",
      "Iteration 13, loss = 1.26497854\n",
      "Iteration 14, loss = 1.25932811\n",
      "Iteration 15, loss = 1.26539385\n",
      "Iteration 16, loss = 1.26298554\n",
      "Iteration 17, loss = 1.25089106\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28933029\n",
      "Iteration 2, loss = 1.26172361\n",
      "Iteration 3, loss = 1.26370761\n",
      "Iteration 4, loss = 1.24311404\n",
      "Iteration 5, loss = 1.26397810\n",
      "Iteration 6, loss = 1.17660318\n",
      "Iteration 7, loss = 1.12066143\n",
      "Iteration 8, loss = 1.13747910\n",
      "Iteration 9, loss = 1.28083056\n",
      "Iteration 10, loss = 1.27668244\n",
      "Iteration 11, loss = 1.26588716\n",
      "Iteration 12, loss = 1.26838402\n",
      "Iteration 13, loss = 1.26711457\n",
      "Iteration 1, loss = 1.28933029\n",
      "Iteration 2, loss = 1.26172361\n",
      "Iteration 3, loss = 1.26370761\n",
      "Iteration 4, loss = 1.24311404\n",
      "Iteration 5, loss = 1.26397810\n",
      "Iteration 6, loss = 1.17660318\n",
      "Iteration 7, loss = 1.12066143\n",
      "Iteration 8, loss = 1.13747910\n",
      "Iteration 9, loss = 1.28083056\n",
      "Iteration 10, loss = 1.27668244\n",
      "Iteration 11, loss = 1.26588716\n",
      "Iteration 12, loss = 1.26838402\n",
      "Iteration 13, loss = 1.26711457\n",
      "Iteration 14, loss = 1.26602019\n",
      "Iteration 15, loss = 1.27689437\n",
      "Iteration 16, loss = 1.26633578\n",
      "Iteration 17, loss = 1.26362161\n",
      "Iteration 18, loss = 1.26548151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26146749\n",
      "Iteration 2, loss = 1.24355860\n",
      "Iteration 3, loss = 1.24303546\n",
      "Iteration 4, loss = 1.24515698\n",
      "Iteration 5, loss = 1.25192208\n",
      "Iteration 6, loss = 1.23999805\n",
      "Iteration 7, loss = 1.22508550\n",
      "Iteration 14, loss = 1.26602019\n",
      "Iteration 15, loss = 1.27689437\n",
      "Iteration 16, loss = 1.26633578\n",
      "Iteration 17, loss = 1.26362161\n",
      "Iteration 18, loss = 1.26548151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26146749\n",
      "Iteration 2, loss = 1.24355860\n",
      "Iteration 3, loss = 1.24303546\n",
      "Iteration 4, loss = 1.24515698\n",
      "Iteration 5, loss = 1.25192208\n",
      "Iteration 6, loss = 1.23999805\n",
      "Iteration 7, loss = 1.22508550\n",
      "Iteration 8, loss = 1.25480965\n",
      "Iteration 9, loss = 1.24517505\n",
      "Iteration 10, loss = 1.25302172\n",
      "Iteration 11, loss = 1.24095610\n",
      "Iteration 12, loss = 1.25516229\n",
      "Iteration 13, loss = 1.25567758\n",
      "Iteration 14, loss = 1.25628775\n",
      "Iteration 15, loss = 1.24670301\n",
      "Iteration 16, loss = 1.24666835\n",
      "Iteration 17, loss = 1.25499330\n",
      "Iteration 18, loss = 1.24419870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25500426\n",
      "Iteration 2, loss = 1.20390357\n",
      "Iteration 8, loss = 1.25480965\n",
      "Iteration 9, loss = 1.24517505\n",
      "Iteration 10, loss = 1.25302172\n",
      "Iteration 11, loss = 1.24095610\n",
      "Iteration 12, loss = 1.25516229\n",
      "Iteration 13, loss = 1.25567758\n",
      "Iteration 14, loss = 1.25628775\n",
      "Iteration 15, loss = 1.24670301\n",
      "Iteration 16, loss = 1.24666835\n",
      "Iteration 17, loss = 1.25499330\n",
      "Iteration 18, loss = 1.24419870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25500426\n",
      "Iteration 2, loss = 1.20390357\n",
      "Iteration 3, loss = 1.15566741\n",
      "Iteration 4, loss = 1.03410826\n",
      "Iteration 5, loss = 1.04005626\n",
      "Iteration 6, loss = 1.05182581\n",
      "Iteration 7, loss = 1.23124858\n",
      "Iteration 8, loss = 1.17072051\n",
      "Iteration 9, loss = 0.98492188\n",
      "Iteration 10, loss = 1.23991104\n",
      "Iteration 11, loss = 1.24170231\n",
      "Iteration 12, loss = 1.25017576\n",
      "Iteration 13, loss = 1.26562332\n",
      "Iteration 14, loss = 1.24026701\n",
      "Iteration 15, loss = 1.26407530\n",
      "Iteration 16, loss = 1.24213892\n",
      "Iteration 3, loss = 1.15566741\n",
      "Iteration 4, loss = 1.03410826\n",
      "Iteration 5, loss = 1.04005626\n",
      "Iteration 6, loss = 1.05182581\n",
      "Iteration 7, loss = 1.23124858\n",
      "Iteration 8, loss = 1.17072051\n",
      "Iteration 9, loss = 0.98492188\n",
      "Iteration 10, loss = 1.23991104\n",
      "Iteration 11, loss = 1.24170231\n",
      "Iteration 12, loss = 1.25017576\n",
      "Iteration 13, loss = 1.26562332\n",
      "Iteration 14, loss = 1.24026701\n",
      "Iteration 15, loss = 1.26407530\n",
      "Iteration 16, loss = 1.24213892\n",
      "Iteration 17, loss = 1.25796695\n",
      "Iteration 18, loss = 1.24770388\n",
      "Iteration 19, loss = 1.23722128\n",
      "Iteration 20, loss = 1.24617943\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28514258\n",
      "Iteration 2, loss = 1.22747038\n",
      "Iteration 3, loss = 1.11634798\n",
      "Iteration 4, loss = 1.25530592\n",
      "Iteration 5, loss = 1.26124677\n",
      "Iteration 6, loss = 1.25885623\n",
      "Iteration 7, loss = 1.26017474\n",
      "Iteration 8, loss = 1.25784807\n",
      "Iteration 9, loss = 1.28453859\n",
      "Iteration 10, loss = 1.26710432\n",
      "Iteration 17, loss = 1.25796695\n",
      "Iteration 18, loss = 1.24770388\n",
      "Iteration 19, loss = 1.23722128\n",
      "Iteration 20, loss = 1.24617943\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28514258\n",
      "Iteration 2, loss = 1.22747038\n",
      "Iteration 3, loss = 1.11634798\n",
      "Iteration 4, loss = 1.25530592\n",
      "Iteration 5, loss = 1.26124677\n",
      "Iteration 6, loss = 1.25885623\n",
      "Iteration 7, loss = 1.26017474\n",
      "Iteration 8, loss = 1.25784807\n",
      "Iteration 9, loss = 1.28453859\n",
      "Iteration 10, loss = 1.26710432\n",
      "Iteration 11, loss = 1.26329254\n",
      "Iteration 12, loss = 1.25649863\n",
      "Iteration 13, loss = 1.26982755\n",
      "Iteration 14, loss = 1.26550778\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28085272\n",
      "Iteration 2, loss = 1.22493565\n",
      "Iteration 3, loss = 1.22136809\n",
      "Iteration 4, loss = 1.17484763\n",
      "Iteration 5, loss = 1.13650379\n",
      "Iteration 6, loss = 1.12503633\n",
      "Iteration 7, loss = 1.27323890\n",
      "Iteration 8, loss = 1.24385833\n",
      "Iteration 9, loss = 1.26817031\n",
      "Iteration 11, loss = 1.26329254\n",
      "Iteration 12, loss = 1.25649863\n",
      "Iteration 13, loss = 1.26982755\n",
      "Iteration 14, loss = 1.26550778\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28085272\n",
      "Iteration 2, loss = 1.22493565\n",
      "Iteration 3, loss = 1.22136809\n",
      "Iteration 4, loss = 1.17484763\n",
      "Iteration 5, loss = 1.13650379\n",
      "Iteration 6, loss = 1.12503633\n",
      "Iteration 7, loss = 1.27323890\n",
      "Iteration 8, loss = 1.24385833\n",
      "Iteration 9, loss = 1.26817031\n",
      "Iteration 10, loss = 1.27396065\n",
      "Iteration 11, loss = 1.25784520\n",
      "Iteration 12, loss = 1.25027592\n",
      "Iteration 13, loss = 1.26497854\n",
      "Iteration 14, loss = 1.25932811\n",
      "Iteration 15, loss = 1.26539385\n",
      "Iteration 16, loss = 1.26298554\n",
      "Iteration 17, loss = 1.25089106\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28933029\n",
      "Iteration 2, loss = 1.26172361\n",
      "Iteration 3, loss = 1.26370761\n",
      "Iteration 4, loss = 1.24311404\n",
      "Iteration 5, loss = 1.26397810\n",
      "Iteration 10, loss = 1.27396065\n",
      "Iteration 11, loss = 1.25784520\n",
      "Iteration 12, loss = 1.25027592\n",
      "Iteration 13, loss = 1.26497854\n",
      "Iteration 14, loss = 1.25932811\n",
      "Iteration 15, loss = 1.26539385\n",
      "Iteration 16, loss = 1.26298554\n",
      "Iteration 17, loss = 1.25089106\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28933029\n",
      "Iteration 2, loss = 1.26172361\n",
      "Iteration 3, loss = 1.26370761\n",
      "Iteration 4, loss = 1.24311404\n",
      "Iteration 5, loss = 1.26397810\n",
      "Iteration 6, loss = 1.17660318\n",
      "Iteration 7, loss = 1.12066143\n",
      "Iteration 8, loss = 1.13747910\n",
      "Iteration 9, loss = 1.28083056\n",
      "Iteration 10, loss = 1.27668244\n",
      "Iteration 11, loss = 1.26588716\n",
      "Iteration 12, loss = 1.26838402\n",
      "Iteration 13, loss = 1.26711457\n",
      "Iteration 14, loss = 1.26602019\n",
      "Iteration 15, loss = 1.27689437\n",
      "Iteration 16, loss = 1.26633578\n",
      "Iteration 17, loss = 1.26362161\n",
      "Iteration 18, loss = 1.26548151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26277104\n",
      "Iteration 6, loss = 1.17660318\n",
      "Iteration 7, loss = 1.12066143\n",
      "Iteration 8, loss = 1.13747910\n",
      "Iteration 9, loss = 1.28083056\n",
      "Iteration 10, loss = 1.27668244\n",
      "Iteration 11, loss = 1.26588716\n",
      "Iteration 12, loss = 1.26838402\n",
      "Iteration 13, loss = 1.26711457\n",
      "Iteration 14, loss = 1.26602019\n",
      "Iteration 15, loss = 1.27689437\n",
      "Iteration 16, loss = 1.26633578\n",
      "Iteration 17, loss = 1.26362161\n",
      "Iteration 18, loss = 1.26548151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26277104\n",
      "Iteration 2, loss = 1.25617450\n",
      "Iteration 3, loss = 1.24561679\n",
      "Iteration 4, loss = 1.24635729\n",
      "Iteration 5, loss = 1.26054131\n",
      "Iteration 6, loss = 1.24223598\n",
      "Iteration 7, loss = 1.25112550\n",
      "Iteration 8, loss = 1.24524163\n",
      "Iteration 9, loss = 1.25101335\n",
      "Iteration 10, loss = 1.25686687\n",
      "Iteration 1, loss = 1.27192057\n",
      "Iteration 2, loss = 1.25495411\n",
      "Iteration 3, loss = 1.24599131\n",
      "Iteration 2, loss = 1.25617450\n",
      "Iteration 3, loss = 1.24561679\n",
      "Iteration 4, loss = 1.24635729\n",
      "Iteration 5, loss = 1.26054131\n",
      "Iteration 6, loss = 1.24223598\n",
      "Iteration 7, loss = 1.25112550\n",
      "Iteration 8, loss = 1.24524163\n",
      "Iteration 9, loss = 1.25101335\n",
      "Iteration 10, loss = 1.25686687\n",
      "Iteration 1, loss = 1.27192057\n",
      "Iteration 2, loss = 1.25495411\n",
      "Iteration 3, loss = 1.24599131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.25533971\n",
      "Iteration 5, loss = 1.24187606\n",
      "Iteration 6, loss = 1.24352541\n",
      "Iteration 7, loss = 1.24841854\n",
      "Iteration 8, loss = 1.23584073\n",
      "Iteration 9, loss = 1.24564364\n",
      "Iteration 10, loss = 1.26149497\n",
      "Iteration 1, loss = 1.30196522\n",
      "Iteration 2, loss = 1.26655225\n",
      "Iteration 3, loss = 1.26820112\n",
      "Iteration 4, loss = 1.25857231\n",
      "Iteration 5, loss = 1.25877914\n",
      "Iteration 4, loss = 1.25533971\n",
      "Iteration 5, loss = 1.24187606\n",
      "Iteration 6, loss = 1.24352541\n",
      "Iteration 7, loss = 1.24841854\n",
      "Iteration 8, loss = 1.23584073\n",
      "Iteration 9, loss = 1.24564364\n",
      "Iteration 10, loss = 1.26149497\n",
      "Iteration 1, loss = 1.30196522\n",
      "Iteration 2, loss = 1.26655225\n",
      "Iteration 3, loss = 1.26820112\n",
      "Iteration 4, loss = 1.25857231\n",
      "Iteration 5, loss = 1.25877914\n",
      "Iteration 6, loss = 1.25901259\n",
      "Iteration 7, loss = 1.25811337\n",
      "Iteration 8, loss = 1.25248259\n",
      "Iteration 9, loss = 1.28444386\n",
      "Iteration 10, loss = 1.26985058\n",
      "Iteration 1, loss = 1.29647251\n",
      "Iteration 2, loss = 1.26698880\n",
      "Iteration 3, loss = 1.25469254\n",
      "Iteration 4, loss = 1.25039911\n",
      "Iteration 5, loss = 1.25214783\n",
      "Iteration 6, loss = 1.25106607\n",
      "Iteration 7, loss = 1.24972342\n",
      "Iteration 8, loss = 1.24309921\n",
      "Iteration 6, loss = 1.25901259\n",
      "Iteration 7, loss = 1.25811337\n",
      "Iteration 8, loss = 1.25248259\n",
      "Iteration 9, loss = 1.28444386\n",
      "Iteration 10, loss = 1.26985058\n",
      "Iteration 1, loss = 1.29647251\n",
      "Iteration 2, loss = 1.26698880\n",
      "Iteration 3, loss = 1.25469254\n",
      "Iteration 4, loss = 1.25039911\n",
      "Iteration 5, loss = 1.25214783\n",
      "Iteration 6, loss = 1.25106607\n",
      "Iteration 7, loss = 1.24972342\n",
      "Iteration 8, loss = 1.24309921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 1.26442880\n",
      "Iteration 10, loss = 1.27720496\n",
      "Iteration 1, loss = 1.28866785\n",
      "Iteration 2, loss = 1.26580919\n",
      "Iteration 3, loss = 1.27025042\n",
      "Iteration 4, loss = 1.26582168\n",
      "Iteration 5, loss = 1.26367897\n",
      "Iteration 6, loss = 1.25697644\n",
      "Iteration 7, loss = 1.28252195\n",
      "Iteration 8, loss = 1.25164132\n",
      "Iteration 9, loss = 1.27867107\n",
      "Iteration 10, loss = 1.27896220\n",
      "Iteration 9, loss = 1.26442880\n",
      "Iteration 10, loss = 1.27720496\n",
      "Iteration 1, loss = 1.28866785\n",
      "Iteration 2, loss = 1.26580919\n",
      "Iteration 3, loss = 1.27025042\n",
      "Iteration 4, loss = 1.26582168\n",
      "Iteration 5, loss = 1.26367897\n",
      "Iteration 6, loss = 1.25697644\n",
      "Iteration 7, loss = 1.28252195\n",
      "Iteration 8, loss = 1.25164132\n",
      "Iteration 9, loss = 1.27867107\n",
      "Iteration 10, loss = 1.27896220\n",
      "Iteration 1, loss = 1.26277104\n",
      "Iteration 2, loss = 1.25617450\n",
      "Iteration 3, loss = 1.24561679\n",
      "Iteration 4, loss = 1.24635729\n",
      "Iteration 5, loss = 1.26054131\n",
      "Iteration 6, loss = 1.24223598\n",
      "Iteration 7, loss = 1.25112550\n",
      "Iteration 8, loss = 1.24524163\n",
      "Iteration 9, loss = 1.25101335\n",
      "Iteration 10, loss = 1.25686687\n",
      "Iteration 11, loss = 1.24146521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.26277104\n",
      "Iteration 2, loss = 1.25617450\n",
      "Iteration 3, loss = 1.24561679\n",
      "Iteration 4, loss = 1.24635729\n",
      "Iteration 5, loss = 1.26054131\n",
      "Iteration 6, loss = 1.24223598\n",
      "Iteration 7, loss = 1.25112550\n",
      "Iteration 8, loss = 1.24524163\n",
      "Iteration 9, loss = 1.25101335\n",
      "Iteration 10, loss = 1.25686687\n",
      "Iteration 11, loss = 1.24146521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 1.25995185\n",
      "Iteration 13, loss = 1.26206497\n",
      "Iteration 14, loss = 1.26488419\n",
      "Iteration 15, loss = 1.25020504\n",
      "Iteration 16, loss = 1.24906144\n",
      "Iteration 17, loss = 1.25888396\n",
      "Iteration 18, loss = 1.25200200\n",
      "Iteration 19, loss = 1.23646399\n",
      "Iteration 20, loss = 1.24216408\n",
      "Iteration 21, loss = 1.26731071\n",
      "Iteration 22, loss = 1.25361493\n",
      "Iteration 23, loss = 1.26813966\n",
      "Iteration 24, loss = 1.24150603\n",
      "Iteration 25, loss = 1.24661209\n",
      "Iteration 12, loss = 1.25995185\n",
      "Iteration 13, loss = 1.26206497\n",
      "Iteration 14, loss = 1.26488419\n",
      "Iteration 15, loss = 1.25020504\n",
      "Iteration 16, loss = 1.24906144\n",
      "Iteration 17, loss = 1.25888396\n",
      "Iteration 18, loss = 1.25200200\n",
      "Iteration 19, loss = 1.23646399\n",
      "Iteration 20, loss = 1.24216408\n",
      "Iteration 21, loss = 1.26731071\n",
      "Iteration 22, loss = 1.25361493\n",
      "Iteration 23, loss = 1.26813966\n",
      "Iteration 24, loss = 1.24150603\n",
      "Iteration 25, loss = 1.24661209\n",
      "Iteration 26, loss = 1.26114676\n",
      "Iteration 27, loss = 1.24679890\n",
      "Iteration 28, loss = 1.23980265\n",
      "Iteration 29, loss = 1.26218626\n",
      "Iteration 30, loss = 1.24038626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27192057\n",
      "Iteration 2, loss = 1.25495411\n",
      "Iteration 3, loss = 1.24599131\n",
      "Iteration 4, loss = 1.25533971\n",
      "Iteration 5, loss = 1.24187606\n",
      "Iteration 6, loss = 1.24352541\n",
      "Iteration 7, loss = 1.24841854\n",
      "Iteration 26, loss = 1.26114676\n",
      "Iteration 27, loss = 1.24679890\n",
      "Iteration 28, loss = 1.23980265\n",
      "Iteration 29, loss = 1.26218626\n",
      "Iteration 30, loss = 1.24038626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27192057\n",
      "Iteration 2, loss = 1.25495411\n",
      "Iteration 3, loss = 1.24599131\n",
      "Iteration 4, loss = 1.25533971\n",
      "Iteration 5, loss = 1.24187606\n",
      "Iteration 6, loss = 1.24352541\n",
      "Iteration 7, loss = 1.24841854\n",
      "Iteration 8, loss = 1.23584073\n",
      "Iteration 9, loss = 1.24564364\n",
      "Iteration 10, loss = 1.26149497\n",
      "Iteration 11, loss = 1.24025217\n",
      "Iteration 12, loss = 1.24599328\n",
      "Iteration 13, loss = 1.26670991\n",
      "Iteration 14, loss = 1.23983298\n",
      "Iteration 15, loss = 1.25342958\n",
      "Iteration 16, loss = 1.23763593\n",
      "Iteration 17, loss = 1.25285257\n",
      "Iteration 18, loss = 1.24909126\n",
      "Iteration 19, loss = 1.23021615\n",
      "Iteration 20, loss = 1.24530675\n",
      "Iteration 21, loss = 1.24796466\n",
      "Iteration 22, loss = 1.23449708\n",
      "Iteration 23, loss = 1.25391029\n",
      "Iteration 8, loss = 1.23584073\n",
      "Iteration 9, loss = 1.24564364\n",
      "Iteration 10, loss = 1.26149497\n",
      "Iteration 11, loss = 1.24025217\n",
      "Iteration 12, loss = 1.24599328\n",
      "Iteration 13, loss = 1.26670991\n",
      "Iteration 14, loss = 1.23983298\n",
      "Iteration 15, loss = 1.25342958\n",
      "Iteration 16, loss = 1.23763593\n",
      "Iteration 17, loss = 1.25285257\n",
      "Iteration 18, loss = 1.24909126\n",
      "Iteration 19, loss = 1.23021615\n",
      "Iteration 20, loss = 1.24530675\n",
      "Iteration 21, loss = 1.24796466\n",
      "Iteration 22, loss = 1.23449708\n",
      "Iteration 23, loss = 1.25391029\n",
      "Iteration 24, loss = 1.23528433\n",
      "Iteration 25, loss = 1.24947605\n",
      "Iteration 26, loss = 1.25279369\n",
      "Iteration 27, loss = 1.24590362\n",
      "Iteration 28, loss = 1.22875184\n",
      "Iteration 29, loss = 1.25326014\n",
      "Iteration 30, loss = 1.23706152\n",
      "Iteration 31, loss = 1.23963211\n",
      "Iteration 32, loss = 1.23801885\n",
      "Iteration 33, loss = 1.23958823\n",
      "Iteration 34, loss = 1.25372831\n",
      "Iteration 35, loss = 1.23656038\n",
      "Iteration 36, loss = 1.24566385\n",
      "Iteration 37, loss = 1.22892380\n",
      "Iteration 24, loss = 1.23528433\n",
      "Iteration 25, loss = 1.24947605\n",
      "Iteration 26, loss = 1.25279369\n",
      "Iteration 27, loss = 1.24590362\n",
      "Iteration 28, loss = 1.22875184\n",
      "Iteration 29, loss = 1.25326014\n",
      "Iteration 30, loss = 1.23706152\n",
      "Iteration 31, loss = 1.23963211\n",
      "Iteration 32, loss = 1.23801885\n",
      "Iteration 33, loss = 1.23958823\n",
      "Iteration 34, loss = 1.25372831\n",
      "Iteration 35, loss = 1.23656038\n",
      "Iteration 36, loss = 1.24566385\n",
      "Iteration 37, loss = 1.22892380\n",
      "Iteration 38, loss = 1.24552325\n",
      "Iteration 39, loss = 1.24758926\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30196522\n",
      "Iteration 2, loss = 1.26655225\n",
      "Iteration 3, loss = 1.26820112\n",
      "Iteration 4, loss = 1.25857231\n",
      "Iteration 5, loss = 1.25877914\n",
      "Iteration 6, loss = 1.25901259\n",
      "Iteration 7, loss = 1.25811337\n",
      "Iteration 8, loss = 1.25248259\n",
      "Iteration 9, loss = 1.28444386\n",
      "Iteration 10, loss = 1.26985058\n",
      "Iteration 11, loss = 1.26715971\n",
      "Iteration 38, loss = 1.24552325\n",
      "Iteration 39, loss = 1.24758926\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30196522\n",
      "Iteration 2, loss = 1.26655225\n",
      "Iteration 3, loss = 1.26820112\n",
      "Iteration 4, loss = 1.25857231\n",
      "Iteration 5, loss = 1.25877914\n",
      "Iteration 6, loss = 1.25901259\n",
      "Iteration 7, loss = 1.25811337\n",
      "Iteration 8, loss = 1.25248259\n",
      "Iteration 9, loss = 1.28444386\n",
      "Iteration 10, loss = 1.26985058\n",
      "Iteration 11, loss = 1.26715971\n",
      "Iteration 12, loss = 1.25981719\n",
      "Iteration 13, loss = 1.27015709\n",
      "Iteration 14, loss = 1.26862685\n",
      "Iteration 15, loss = 1.27272708\n",
      "Iteration 16, loss = 1.25418381\n",
      "Iteration 17, loss = 1.26884982\n",
      "Iteration 18, loss = 1.26562634\n",
      "Iteration 19, loss = 1.25521669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29647251\n",
      "Iteration 2, loss = 1.26698880\n",
      "Iteration 3, loss = 1.25469254\n",
      "Iteration 4, loss = 1.25039911\n",
      "Iteration 5, loss = 1.25214783\n",
      "Iteration 12, loss = 1.25981719\n",
      "Iteration 13, loss = 1.27015709\n",
      "Iteration 14, loss = 1.26862685\n",
      "Iteration 15, loss = 1.27272708\n",
      "Iteration 16, loss = 1.25418381\n",
      "Iteration 17, loss = 1.26884982\n",
      "Iteration 18, loss = 1.26562634\n",
      "Iteration 19, loss = 1.25521669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29647251\n",
      "Iteration 2, loss = 1.26698880\n",
      "Iteration 3, loss = 1.25469254\n",
      "Iteration 4, loss = 1.25039911\n",
      "Iteration 5, loss = 1.25214783\n",
      "Iteration 6, loss = 1.25106607\n",
      "Iteration 7, loss = 1.24972342\n",
      "Iteration 8, loss = 1.24309921\n",
      "Iteration 9, loss = 1.26442880\n",
      "Iteration 10, loss = 1.27720496\n",
      "Iteration 11, loss = 1.25995719\n",
      "Iteration 12, loss = 1.24692661\n",
      "Iteration 13, loss = 1.26500172\n",
      "Iteration 14, loss = 1.25667480\n",
      "Iteration 15, loss = 1.26619663\n",
      "Iteration 16, loss = 1.26406424\n",
      "Iteration 17, loss = 1.25113454\n",
      "Iteration 6, loss = 1.25106607\n",
      "Iteration 7, loss = 1.24972342\n",
      "Iteration 8, loss = 1.24309921\n",
      "Iteration 9, loss = 1.26442880\n",
      "Iteration 10, loss = 1.27720496\n",
      "Iteration 11, loss = 1.25995719\n",
      "Iteration 12, loss = 1.24692661\n",
      "Iteration 13, loss = 1.26500172\n",
      "Iteration 14, loss = 1.25667480\n",
      "Iteration 15, loss = 1.26619663\n",
      "Iteration 16, loss = 1.26406424\n",
      "Iteration 17, loss = 1.25113454\n",
      "Iteration 18, loss = 1.24608667\n",
      "Iteration 19, loss = 1.25217600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28866785\n",
      "Iteration 2, loss = 1.26580919\n",
      "Iteration 3, loss = 1.27025042\n",
      "Iteration 4, loss = 1.26582168\n",
      "Iteration 5, loss = 1.26367897\n",
      "Iteration 6, loss = 1.25697644\n",
      "Iteration 7, loss = 1.28252195\n",
      "Iteration 8, loss = 1.25164132\n",
      "Iteration 9, loss = 1.27867107\n",
      "Iteration 10, loss = 1.27896220\n",
      "Iteration 11, loss = 1.26349618\n",
      "Iteration 18, loss = 1.24608667\n",
      "Iteration 19, loss = 1.25217600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28866785\n",
      "Iteration 2, loss = 1.26580919\n",
      "Iteration 3, loss = 1.27025042\n",
      "Iteration 4, loss = 1.26582168\n",
      "Iteration 5, loss = 1.26367897\n",
      "Iteration 6, loss = 1.25697644\n",
      "Iteration 7, loss = 1.28252195\n",
      "Iteration 8, loss = 1.25164132\n",
      "Iteration 9, loss = 1.27867107\n",
      "Iteration 10, loss = 1.27896220\n",
      "Iteration 11, loss = 1.26349618\n",
      "Iteration 12, loss = 1.26445755\n",
      "Iteration 13, loss = 1.26408737\n",
      "Iteration 14, loss = 1.26449467\n",
      "Iteration 15, loss = 1.27810982\n",
      "Iteration 16, loss = 1.26605170\n",
      "Iteration 17, loss = 1.25651755\n",
      "Iteration 18, loss = 1.25898463\n",
      "Iteration 19, loss = 1.27096887\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26277104\n",
      "Iteration 2, loss = 1.25617450\n",
      "Iteration 3, loss = 1.24561679\n",
      "Iteration 4, loss = 1.24635729\n",
      "Iteration 5, loss = 1.26054131\n",
      "Iteration 12, loss = 1.26445755\n",
      "Iteration 13, loss = 1.26408737\n",
      "Iteration 14, loss = 1.26449467\n",
      "Iteration 15, loss = 1.27810982\n",
      "Iteration 16, loss = 1.26605170\n",
      "Iteration 17, loss = 1.25651755\n",
      "Iteration 18, loss = 1.25898463\n",
      "Iteration 19, loss = 1.27096887\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26277104\n",
      "Iteration 2, loss = 1.25617450\n",
      "Iteration 3, loss = 1.24561679\n",
      "Iteration 4, loss = 1.24635729\n",
      "Iteration 5, loss = 1.26054131\n",
      "Iteration 6, loss = 1.24223598\n",
      "Iteration 7, loss = 1.25112550\n",
      "Iteration 8, loss = 1.24524163\n",
      "Iteration 9, loss = 1.25101335\n",
      "Iteration 10, loss = 1.25686687\n",
      "Iteration 11, loss = 1.24146521\n",
      "Iteration 12, loss = 1.25995185\n",
      "Iteration 13, loss = 1.26206497\n",
      "Iteration 14, loss = 1.26488419\n",
      "Iteration 15, loss = 1.25020504\n",
      "Iteration 16, loss = 1.24906144\n",
      "Iteration 17, loss = 1.25888396\n",
      "Iteration 18, loss = 1.25200200\n",
      "Iteration 19, loss = 1.23646399\n",
      "Iteration 6, loss = 1.24223598\n",
      "Iteration 7, loss = 1.25112550\n",
      "Iteration 8, loss = 1.24524163\n",
      "Iteration 9, loss = 1.25101335\n",
      "Iteration 10, loss = 1.25686687\n",
      "Iteration 11, loss = 1.24146521\n",
      "Iteration 12, loss = 1.25995185\n",
      "Iteration 13, loss = 1.26206497\n",
      "Iteration 14, loss = 1.26488419\n",
      "Iteration 15, loss = 1.25020504\n",
      "Iteration 16, loss = 1.24906144\n",
      "Iteration 17, loss = 1.25888396\n",
      "Iteration 18, loss = 1.25200200\n",
      "Iteration 19, loss = 1.23646399\n",
      "Iteration 20, loss = 1.24216408\n",
      "Iteration 21, loss = 1.26731071\n",
      "Iteration 22, loss = 1.25361493\n",
      "Iteration 23, loss = 1.26813966\n",
      "Iteration 24, loss = 1.24150603\n",
      "Iteration 25, loss = 1.24661209\n",
      "Iteration 26, loss = 1.26114676\n",
      "Iteration 27, loss = 1.24679890\n",
      "Iteration 28, loss = 1.23980265\n",
      "Iteration 29, loss = 1.26218626\n",
      "Iteration 30, loss = 1.24038626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27192057\n",
      "Iteration 2, loss = 1.25495411\n",
      "Iteration 3, loss = 1.24599131\n",
      "Iteration 20, loss = 1.24216408\n",
      "Iteration 21, loss = 1.26731071\n",
      "Iteration 22, loss = 1.25361493\n",
      "Iteration 23, loss = 1.26813966\n",
      "Iteration 24, loss = 1.24150603\n",
      "Iteration 25, loss = 1.24661209\n",
      "Iteration 26, loss = 1.26114676\n",
      "Iteration 27, loss = 1.24679890\n",
      "Iteration 28, loss = 1.23980265\n",
      "Iteration 29, loss = 1.26218626\n",
      "Iteration 30, loss = 1.24038626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27192057\n",
      "Iteration 2, loss = 1.25495411\n",
      "Iteration 3, loss = 1.24599131\n",
      "Iteration 4, loss = 1.25533971\n",
      "Iteration 5, loss = 1.24187606\n",
      "Iteration 6, loss = 1.24352541\n",
      "Iteration 7, loss = 1.24841854\n",
      "Iteration 8, loss = 1.23584073\n",
      "Iteration 9, loss = 1.24564364\n",
      "Iteration 10, loss = 1.26149497\n",
      "Iteration 11, loss = 1.24025217\n",
      "Iteration 12, loss = 1.24599328\n",
      "Iteration 13, loss = 1.26670991\n",
      "Iteration 14, loss = 1.23983298\n",
      "Iteration 15, loss = 1.25342958\n",
      "Iteration 16, loss = 1.23763593\n",
      "Iteration 17, loss = 1.25285257\n",
      "Iteration 4, loss = 1.25533971\n",
      "Iteration 5, loss = 1.24187606\n",
      "Iteration 6, loss = 1.24352541\n",
      "Iteration 7, loss = 1.24841854\n",
      "Iteration 8, loss = 1.23584073\n",
      "Iteration 9, loss = 1.24564364\n",
      "Iteration 10, loss = 1.26149497\n",
      "Iteration 11, loss = 1.24025217\n",
      "Iteration 12, loss = 1.24599328\n",
      "Iteration 13, loss = 1.26670991\n",
      "Iteration 14, loss = 1.23983298\n",
      "Iteration 15, loss = 1.25342958\n",
      "Iteration 16, loss = 1.23763593\n",
      "Iteration 17, loss = 1.25285257\n",
      "Iteration 18, loss = 1.24909126\n",
      "Iteration 19, loss = 1.23021615\n",
      "Iteration 20, loss = 1.24530675\n",
      "Iteration 21, loss = 1.24796466\n",
      "Iteration 22, loss = 1.23449708\n",
      "Iteration 23, loss = 1.25391029\n",
      "Iteration 24, loss = 1.23528433\n",
      "Iteration 25, loss = 1.24947605\n",
      "Iteration 26, loss = 1.25279369\n",
      "Iteration 27, loss = 1.24590362\n",
      "Iteration 28, loss = 1.22875184\n",
      "Iteration 29, loss = 1.25326014\n",
      "Iteration 30, loss = 1.23706152\n",
      "Iteration 31, loss = 1.23963211\n",
      "Iteration 32, loss = 1.23801885\n",
      "Iteration 18, loss = 1.24909126\n",
      "Iteration 19, loss = 1.23021615\n",
      "Iteration 20, loss = 1.24530675\n",
      "Iteration 21, loss = 1.24796466\n",
      "Iteration 22, loss = 1.23449708\n",
      "Iteration 23, loss = 1.25391029\n",
      "Iteration 24, loss = 1.23528433\n",
      "Iteration 25, loss = 1.24947605\n",
      "Iteration 26, loss = 1.25279369\n",
      "Iteration 27, loss = 1.24590362\n",
      "Iteration 28, loss = 1.22875184\n",
      "Iteration 29, loss = 1.25326014\n",
      "Iteration 30, loss = 1.23706152\n",
      "Iteration 31, loss = 1.23963211\n",
      "Iteration 32, loss = 1.23801885\n",
      "Iteration 33, loss = 1.23958823\n",
      "Iteration 34, loss = 1.25372831\n",
      "Iteration 35, loss = 1.23656038\n",
      "Iteration 36, loss = 1.24566385\n",
      "Iteration 37, loss = 1.22892380\n",
      "Iteration 38, loss = 1.24552325\n",
      "Iteration 39, loss = 1.24758926\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30196522\n",
      "Iteration 2, loss = 1.26655225\n",
      "Iteration 3, loss = 1.26820112\n",
      "Iteration 4, loss = 1.25857231\n",
      "Iteration 5, loss = 1.25877914\n",
      "Iteration 6, loss = 1.25901259\n",
      "Iteration 33, loss = 1.23958823\n",
      "Iteration 34, loss = 1.25372831\n",
      "Iteration 35, loss = 1.23656038\n",
      "Iteration 36, loss = 1.24566385\n",
      "Iteration 37, loss = 1.22892380\n",
      "Iteration 38, loss = 1.24552325\n",
      "Iteration 39, loss = 1.24758926\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30196522\n",
      "Iteration 2, loss = 1.26655225\n",
      "Iteration 3, loss = 1.26820112\n",
      "Iteration 4, loss = 1.25857231\n",
      "Iteration 5, loss = 1.25877914\n",
      "Iteration 6, loss = 1.25901259\n",
      "Iteration 7, loss = 1.25811337\n",
      "Iteration 8, loss = 1.25248259\n",
      "Iteration 9, loss = 1.28444386\n",
      "Iteration 10, loss = 1.26985058\n",
      "Iteration 11, loss = 1.26715971\n",
      "Iteration 12, loss = 1.25981719\n",
      "Iteration 13, loss = 1.27015709\n",
      "Iteration 14, loss = 1.26862685\n",
      "Iteration 15, loss = 1.27272708\n",
      "Iteration 16, loss = 1.25418381\n",
      "Iteration 17, loss = 1.26884982\n",
      "Iteration 18, loss = 1.26562634\n",
      "Iteration 19, loss = 1.25521669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29647251\n",
      "Iteration 7, loss = 1.25811337\n",
      "Iteration 8, loss = 1.25248259\n",
      "Iteration 9, loss = 1.28444386\n",
      "Iteration 10, loss = 1.26985058\n",
      "Iteration 11, loss = 1.26715971\n",
      "Iteration 12, loss = 1.25981719\n",
      "Iteration 13, loss = 1.27015709\n",
      "Iteration 14, loss = 1.26862685\n",
      "Iteration 15, loss = 1.27272708\n",
      "Iteration 16, loss = 1.25418381\n",
      "Iteration 17, loss = 1.26884982\n",
      "Iteration 18, loss = 1.26562634\n",
      "Iteration 19, loss = 1.25521669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29647251\n",
      "Iteration 2, loss = 1.26698880\n",
      "Iteration 3, loss = 1.25469254\n",
      "Iteration 4, loss = 1.25039911\n",
      "Iteration 5, loss = 1.25214783\n",
      "Iteration 6, loss = 1.25106607\n",
      "Iteration 7, loss = 1.24972342\n",
      "Iteration 8, loss = 1.24309921\n",
      "Iteration 9, loss = 1.26442880\n",
      "Iteration 10, loss = 1.27720496\n",
      "Iteration 11, loss = 1.25995719\n",
      "Iteration 12, loss = 1.24692661\n",
      "Iteration 2, loss = 1.26698880\n",
      "Iteration 3, loss = 1.25469254\n",
      "Iteration 4, loss = 1.25039911\n",
      "Iteration 5, loss = 1.25214783\n",
      "Iteration 6, loss = 1.25106607\n",
      "Iteration 7, loss = 1.24972342\n",
      "Iteration 8, loss = 1.24309921\n",
      "Iteration 9, loss = 1.26442880\n",
      "Iteration 10, loss = 1.27720496\n",
      "Iteration 11, loss = 1.25995719\n",
      "Iteration 12, loss = 1.24692661\n",
      "Iteration 13, loss = 1.26500172\n",
      "Iteration 14, loss = 1.25667480\n",
      "Iteration 15, loss = 1.26619663\n",
      "Iteration 16, loss = 1.26406424\n",
      "Iteration 17, loss = 1.25113454\n",
      "Iteration 18, loss = 1.24608667\n",
      "Iteration 19, loss = 1.25217600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28866785\n",
      "Iteration 2, loss = 1.26580919\n",
      "Iteration 3, loss = 1.27025042\n",
      "Iteration 4, loss = 1.26582168\n",
      "Iteration 13, loss = 1.26500172\n",
      "Iteration 14, loss = 1.25667480\n",
      "Iteration 15, loss = 1.26619663\n",
      "Iteration 16, loss = 1.26406424\n",
      "Iteration 17, loss = 1.25113454\n",
      "Iteration 18, loss = 1.24608667\n",
      "Iteration 19, loss = 1.25217600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28866785\n",
      "Iteration 2, loss = 1.26580919\n",
      "Iteration 3, loss = 1.27025042\n",
      "Iteration 4, loss = 1.26582168\n",
      "Iteration 5, loss = 1.26367897\n",
      "Iteration 6, loss = 1.25697644\n",
      "Iteration 7, loss = 1.28252195\n",
      "Iteration 8, loss = 1.25164132\n",
      "Iteration 9, loss = 1.27867107\n",
      "Iteration 10, loss = 1.27896220\n",
      "Iteration 11, loss = 1.26349618\n",
      "Iteration 12, loss = 1.26445755\n",
      "Iteration 13, loss = 1.26408737\n",
      "Iteration 14, loss = 1.26449467\n",
      "Iteration 15, loss = 1.27810982\n",
      "Iteration 16, loss = 1.26605170\n",
      "Iteration 17, loss = 1.25651755\n",
      "Iteration 5, loss = 1.26367897\n",
      "Iteration 6, loss = 1.25697644\n",
      "Iteration 7, loss = 1.28252195\n",
      "Iteration 8, loss = 1.25164132\n",
      "Iteration 9, loss = 1.27867107\n",
      "Iteration 10, loss = 1.27896220\n",
      "Iteration 11, loss = 1.26349618\n",
      "Iteration 12, loss = 1.26445755\n",
      "Iteration 13, loss = 1.26408737\n",
      "Iteration 14, loss = 1.26449467\n",
      "Iteration 15, loss = 1.27810982\n",
      "Iteration 16, loss = 1.26605170\n",
      "Iteration 17, loss = 1.25651755\n",
      "Iteration 18, loss = 1.25898463\n",
      "Iteration 19, loss = 1.27096887\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15215098\n",
      "Iteration 2, loss = 1.05902376\n",
      "Iteration 3, loss = 1.01617352\n",
      "Iteration 4, loss = 0.98744133\n",
      "Iteration 5, loss = 1.00905866\n",
      "Iteration 6, loss = 0.95321433\n",
      "Iteration 7, loss = 0.98483932\n",
      "Iteration 8, loss = 0.98694833\n",
      "Iteration 9, loss = 0.99788177\n",
      "Iteration 18, loss = 1.25898463\n",
      "Iteration 19, loss = 1.27096887\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15215098\n",
      "Iteration 2, loss = 1.05902376\n",
      "Iteration 3, loss = 1.01617352\n",
      "Iteration 4, loss = 0.98744133\n",
      "Iteration 5, loss = 1.00905866\n",
      "Iteration 6, loss = 0.95321433\n",
      "Iteration 7, loss = 0.98483932\n",
      "Iteration 8, loss = 0.98694833\n",
      "Iteration 9, loss = 0.99788177\n",
      "Iteration 10, loss = 0.94202262\n",
      "Iteration 1, loss = 1.15474165\n",
      "Iteration 2, loss = 0.99458393\n",
      "Iteration 3, loss = 0.98702664\n",
      "Iteration 4, loss = 0.92141462\n",
      "Iteration 5, loss = 0.93099045\n",
      "Iteration 6, loss = 0.89760020\n",
      "Iteration 7, loss = 0.91664807\n",
      "Iteration 8, loss = 0.89606759\n",
      "Iteration 9, loss = 0.92287971\n",
      "Iteration 10, loss = 0.87749846\n",
      "Iteration 10, loss = 0.94202262\n",
      "Iteration 1, loss = 1.15474165\n",
      "Iteration 2, loss = 0.99458393\n",
      "Iteration 3, loss = 0.98702664\n",
      "Iteration 4, loss = 0.92141462\n",
      "Iteration 5, loss = 0.93099045\n",
      "Iteration 6, loss = 0.89760020\n",
      "Iteration 7, loss = 0.91664807\n",
      "Iteration 8, loss = 0.89606759\n",
      "Iteration 9, loss = 0.92287971\n",
      "Iteration 10, loss = 0.87749846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.17645811\n",
      "Iteration 2, loss = 1.01901515\n",
      "Iteration 3, loss = 1.03596691\n",
      "Iteration 4, loss = 0.98752694\n",
      "Iteration 5, loss = 0.98634849\n",
      "Iteration 6, loss = 0.94388389\n",
      "Iteration 7, loss = 0.93004457\n",
      "Iteration 8, loss = 0.93641801\n",
      "Iteration 9, loss = 0.94719307\n",
      "Iteration 10, loss = 0.93307659\n",
      "Iteration 1, loss = 1.20413729\n",
      "Iteration 2, loss = 1.06032540\n",
      "Iteration 3, loss = 1.04612262\n",
      "Iteration 1, loss = 1.17645811\n",
      "Iteration 2, loss = 1.01901515\n",
      "Iteration 3, loss = 1.03596691\n",
      "Iteration 4, loss = 0.98752694\n",
      "Iteration 5, loss = 0.98634849\n",
      "Iteration 6, loss = 0.94388389\n",
      "Iteration 7, loss = 0.93004457\n",
      "Iteration 8, loss = 0.93641801\n",
      "Iteration 9, loss = 0.94719307\n",
      "Iteration 10, loss = 0.93307659\n",
      "Iteration 1, loss = 1.20413729\n",
      "Iteration 2, loss = 1.06032540\n",
      "Iteration 3, loss = 1.04612262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.97408036\n",
      "Iteration 5, loss = 1.02038100\n",
      "Iteration 6, loss = 0.96744344\n",
      "Iteration 7, loss = 0.93521408\n",
      "Iteration 8, loss = 0.96848100\n",
      "Iteration 9, loss = 0.95967247\n",
      "Iteration 10, loss = 0.93317776\n",
      "Iteration 1, loss = 1.18494747\n",
      "Iteration 2, loss = 1.06046800\n",
      "Iteration 4, loss = 0.97408036\n",
      "Iteration 5, loss = 1.02038100\n",
      "Iteration 6, loss = 0.96744344\n",
      "Iteration 7, loss = 0.93521408\n",
      "Iteration 8, loss = 0.96848100\n",
      "Iteration 9, loss = 0.95967247\n",
      "Iteration 10, loss = 0.93317776\n",
      "Iteration 1, loss = 1.18494747\n",
      "Iteration 2, loss = 1.06046800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 1.03577015\n",
      "Iteration 4, loss = 0.99223511\n",
      "Iteration 5, loss = 0.97521174\n",
      "Iteration 6, loss = 0.99535383\n",
      "Iteration 7, loss = 0.94451501\n",
      "Iteration 8, loss = 1.00859762\n",
      "Iteration 9, loss = 0.96847217\n",
      "Iteration 10, loss = 0.92647260\n",
      "Iteration 1, loss = 1.15215098\n",
      "Iteration 2, loss = 1.05902376\n",
      "Iteration 3, loss = 1.01617352\n",
      "Iteration 4, loss = 0.98744133\n",
      "Iteration 5, loss = 1.00905866\n",
      "Iteration 3, loss = 1.03577015\n",
      "Iteration 4, loss = 0.99223511\n",
      "Iteration 5, loss = 0.97521174\n",
      "Iteration 6, loss = 0.99535383\n",
      "Iteration 7, loss = 0.94451501\n",
      "Iteration 8, loss = 1.00859762\n",
      "Iteration 9, loss = 0.96847217\n",
      "Iteration 10, loss = 0.92647260\n",
      "Iteration 1, loss = 1.15215098\n",
      "Iteration 2, loss = 1.05902376\n",
      "Iteration 3, loss = 1.01617352\n",
      "Iteration 4, loss = 0.98744133\n",
      "Iteration 5, loss = 1.00905866\n",
      "Iteration 6, loss = 0.95321433\n",
      "Iteration 7, loss = 0.98483932\n",
      "Iteration 8, loss = 0.98694833\n",
      "Iteration 9, loss = 0.99788177\n",
      "Iteration 10, loss = 0.94202262\n",
      "Iteration 11, loss = 0.95242591\n",
      "Iteration 12, loss = 0.95667916\n",
      "Iteration 13, loss = 0.93562682\n",
      "Iteration 14, loss = 0.93727177\n",
      "Iteration 15, loss = 0.92597915\n",
      "Iteration 16, loss = 0.91275972\n",
      "Iteration 17, loss = 0.90536224\n",
      "Iteration 18, loss = 0.91624375\n",
      "Iteration 6, loss = 0.95321433\n",
      "Iteration 7, loss = 0.98483932\n",
      "Iteration 8, loss = 0.98694833\n",
      "Iteration 9, loss = 0.99788177\n",
      "Iteration 10, loss = 0.94202262\n",
      "Iteration 11, loss = 0.95242591\n",
      "Iteration 12, loss = 0.95667916\n",
      "Iteration 13, loss = 0.93562682\n",
      "Iteration 14, loss = 0.93727177\n",
      "Iteration 15, loss = 0.92597915\n",
      "Iteration 16, loss = 0.91275972\n",
      "Iteration 17, loss = 0.90536224\n",
      "Iteration 18, loss = 0.91624375\n",
      "Iteration 19, loss = 0.92715813\n",
      "Iteration 20, loss = 0.95367839\n",
      "Iteration 21, loss = 0.91091329\n",
      "Iteration 22, loss = 0.89177190\n",
      "Iteration 23, loss = 0.87536312\n",
      "Iteration 24, loss = 0.86809853\n",
      "Iteration 25, loss = 0.86612740\n",
      "Iteration 26, loss = 0.85361915\n",
      "Iteration 27, loss = 0.86284730\n",
      "Iteration 28, loss = 0.89548398\n",
      "Iteration 29, loss = 0.89792438\n",
      "Iteration 30, loss = 0.87543761\n",
      "Iteration 31, loss = 0.86857106\n",
      "Iteration 19, loss = 0.92715813\n",
      "Iteration 20, loss = 0.95367839\n",
      "Iteration 21, loss = 0.91091329\n",
      "Iteration 22, loss = 0.89177190\n",
      "Iteration 23, loss = 0.87536312\n",
      "Iteration 24, loss = 0.86809853\n",
      "Iteration 25, loss = 0.86612740\n",
      "Iteration 26, loss = 0.85361915\n",
      "Iteration 27, loss = 0.86284730\n",
      "Iteration 28, loss = 0.89548398\n",
      "Iteration 29, loss = 0.89792438\n",
      "Iteration 30, loss = 0.87543761\n",
      "Iteration 31, loss = 0.86857106\n",
      "Iteration 32, loss = 0.84915800\n",
      "Iteration 33, loss = 0.87236429\n",
      "Iteration 34, loss = 0.84161285\n",
      "Iteration 35, loss = 0.84037367\n",
      "Iteration 36, loss = 0.79374316\n",
      "Iteration 37, loss = 0.81943805\n",
      "Iteration 38, loss = 0.82132463\n",
      "Iteration 39, loss = 0.86041271\n",
      "Iteration 40, loss = 0.81906144\n",
      "Iteration 41, loss = 0.82446676\n",
      "Iteration 42, loss = 0.78233584\n",
      "Iteration 43, loss = 0.79207004\n",
      "Iteration 44, loss = 0.81055536\n",
      "Iteration 32, loss = 0.84915800\n",
      "Iteration 33, loss = 0.87236429\n",
      "Iteration 34, loss = 0.84161285\n",
      "Iteration 35, loss = 0.84037367\n",
      "Iteration 36, loss = 0.79374316\n",
      "Iteration 37, loss = 0.81943805\n",
      "Iteration 38, loss = 0.82132463\n",
      "Iteration 39, loss = 0.86041271\n",
      "Iteration 40, loss = 0.81906144\n",
      "Iteration 41, loss = 0.82446676\n",
      "Iteration 42, loss = 0.78233584\n",
      "Iteration 43, loss = 0.79207004\n",
      "Iteration 44, loss = 0.81055536\n",
      "Iteration 45, loss = 0.86111707\n",
      "Iteration 46, loss = 0.78153003\n",
      "Iteration 47, loss = 0.77410789\n",
      "Iteration 48, loss = 0.77676129\n",
      "Iteration 49, loss = 0.79382386\n",
      "Iteration 50, loss = 0.76079878\n",
      "Iteration 1, loss = 1.15474165\n",
      "Iteration 2, loss = 0.99458393\n",
      "Iteration 3, loss = 0.98702664\n",
      "Iteration 4, loss = 0.92141462\n",
      "Iteration 5, loss = 0.93099045\n",
      "Iteration 6, loss = 0.89760020\n",
      "Iteration 7, loss = 0.91664807\n",
      "Iteration 8, loss = 0.89606759\n",
      "Iteration 45, loss = 0.86111707\n",
      "Iteration 46, loss = 0.78153003\n",
      "Iteration 47, loss = 0.77410789\n",
      "Iteration 48, loss = 0.77676129\n",
      "Iteration 49, loss = 0.79382386\n",
      "Iteration 50, loss = 0.76079878\n",
      "Iteration 1, loss = 1.15474165\n",
      "Iteration 2, loss = 0.99458393\n",
      "Iteration 3, loss = 0.98702664\n",
      "Iteration 4, loss = 0.92141462\n",
      "Iteration 5, loss = 0.93099045\n",
      "Iteration 6, loss = 0.89760020\n",
      "Iteration 7, loss = 0.91664807\n",
      "Iteration 8, loss = 0.89606759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.92287971\n",
      "Iteration 10, loss = 0.87749846\n",
      "Iteration 11, loss = 0.93932324\n",
      "Iteration 12, loss = 0.90566796\n",
      "Iteration 13, loss = 0.89235014\n",
      "Iteration 14, loss = 0.92450634\n",
      "Iteration 15, loss = 0.85187506\n",
      "Iteration 16, loss = 0.90707440\n",
      "Iteration 17, loss = 0.86661669\n",
      "Iteration 18, loss = 0.84384630\n",
      "Iteration 19, loss = 0.85118292\n",
      "Iteration 20, loss = 0.86421713\n",
      "Iteration 21, loss = 0.85616798\n",
      "Iteration 22, loss = 0.85535333\n",
      "Iteration 23, loss = 0.82456022\n",
      "Iteration 9, loss = 0.92287971\n",
      "Iteration 10, loss = 0.87749846\n",
      "Iteration 11, loss = 0.93932324\n",
      "Iteration 12, loss = 0.90566796\n",
      "Iteration 13, loss = 0.89235014\n",
      "Iteration 14, loss = 0.92450634\n",
      "Iteration 15, loss = 0.85187506\n",
      "Iteration 16, loss = 0.90707440\n",
      "Iteration 17, loss = 0.86661669\n",
      "Iteration 18, loss = 0.84384630\n",
      "Iteration 19, loss = 0.85118292\n",
      "Iteration 20, loss = 0.86421713\n",
      "Iteration 21, loss = 0.85616798\n",
      "Iteration 22, loss = 0.85535333\n",
      "Iteration 23, loss = 0.82456022\n",
      "Iteration 24, loss = 0.81869800\n",
      "Iteration 25, loss = 0.80700280\n",
      "Iteration 26, loss = 0.80947770\n",
      "Iteration 27, loss = 0.80947894\n",
      "Iteration 28, loss = 0.79552188\n",
      "Iteration 29, loss = 0.85068701\n",
      "Iteration 30, loss = 0.82702709\n",
      "Iteration 31, loss = 0.78942499\n",
      "Iteration 32, loss = 0.80345761\n",
      "Iteration 33, loss = 0.80762076\n",
      "Iteration 34, loss = 0.83841806\n",
      "Iteration 35, loss = 0.83966483\n",
      "Iteration 24, loss = 0.81869800\n",
      "Iteration 25, loss = 0.80700280\n",
      "Iteration 26, loss = 0.80947770\n",
      "Iteration 27, loss = 0.80947894\n",
      "Iteration 28, loss = 0.79552188\n",
      "Iteration 29, loss = 0.85068701\n",
      "Iteration 30, loss = 0.82702709\n",
      "Iteration 31, loss = 0.78942499\n",
      "Iteration 32, loss = 0.80345761\n",
      "Iteration 33, loss = 0.80762076\n",
      "Iteration 34, loss = 0.83841806\n",
      "Iteration 35, loss = 0.83966483\n",
      "Iteration 36, loss = 0.77825829\n",
      "Iteration 37, loss = 0.77559605\n",
      "Iteration 38, loss = 0.75276144\n",
      "Iteration 39, loss = 0.79096125\n",
      "Iteration 40, loss = 0.77427837\n",
      "Iteration 41, loss = 0.76649117\n",
      "Iteration 42, loss = 0.76304823\n",
      "Iteration 43, loss = 0.76040796\n",
      "Iteration 44, loss = 0.77253966\n",
      "Iteration 45, loss = 0.75460058\n",
      "Iteration 46, loss = 0.76528323\n",
      "Iteration 47, loss = 0.70956908\n",
      "Iteration 48, loss = 0.70552123\n",
      "Iteration 49, loss = 0.70299828\n",
      "Iteration 50, loss = 0.72842656\n",
      "Iteration 36, loss = 0.77825829\n",
      "Iteration 37, loss = 0.77559605\n",
      "Iteration 38, loss = 0.75276144\n",
      "Iteration 39, loss = 0.79096125\n",
      "Iteration 40, loss = 0.77427837\n",
      "Iteration 41, loss = 0.76649117\n",
      "Iteration 42, loss = 0.76304823\n",
      "Iteration 43, loss = 0.76040796\n",
      "Iteration 44, loss = 0.77253966\n",
      "Iteration 45, loss = 0.75460058\n",
      "Iteration 46, loss = 0.76528323\n",
      "Iteration 47, loss = 0.70956908\n",
      "Iteration 48, loss = 0.70552123\n",
      "Iteration 49, loss = 0.70299828\n",
      "Iteration 50, loss = 0.72842656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.17645811\n",
      "Iteration 2, loss = 1.01901515\n",
      "Iteration 3, loss = 1.03596691\n",
      "Iteration 4, loss = 0.98752694\n",
      "Iteration 5, loss = 0.98634849\n",
      "Iteration 6, loss = 0.94388389\n",
      "Iteration 7, loss = 0.93004457\n",
      "Iteration 8, loss = 0.93641801\n",
      "Iteration 9, loss = 0.94719307\n",
      "Iteration 10, loss = 0.93307659\n",
      "Iteration 11, loss = 0.95002681\n",
      "Iteration 12, loss = 0.92178089\n",
      "Iteration 13, loss = 0.90953876\n",
      "Iteration 1, loss = 1.17645811\n",
      "Iteration 2, loss = 1.01901515\n",
      "Iteration 3, loss = 1.03596691\n",
      "Iteration 4, loss = 0.98752694\n",
      "Iteration 5, loss = 0.98634849\n",
      "Iteration 6, loss = 0.94388389\n",
      "Iteration 7, loss = 0.93004457\n",
      "Iteration 8, loss = 0.93641801\n",
      "Iteration 9, loss = 0.94719307\n",
      "Iteration 10, loss = 0.93307659\n",
      "Iteration 11, loss = 0.95002681\n",
      "Iteration 12, loss = 0.92178089\n",
      "Iteration 13, loss = 0.90953876\n",
      "Iteration 14, loss = 0.99512424\n",
      "Iteration 15, loss = 0.93092580\n",
      "Iteration 16, loss = 0.92376847\n",
      "Iteration 17, loss = 0.89008727\n",
      "Iteration 18, loss = 0.89827297\n",
      "Iteration 19, loss = 0.92613349\n",
      "Iteration 20, loss = 0.91368277\n",
      "Iteration 21, loss = 0.93331449\n",
      "Iteration 22, loss = 0.89486016\n",
      "Iteration 23, loss = 0.90282245\n",
      "Iteration 24, loss = 0.88421013\n",
      "Iteration 25, loss = 0.88876862\n",
      "Iteration 26, loss = 0.89987058\n",
      "Iteration 27, loss = 0.88614119\n",
      "Iteration 28, loss = 0.89028424\n",
      "Iteration 14, loss = 0.99512424\n",
      "Iteration 15, loss = 0.93092580\n",
      "Iteration 16, loss = 0.92376847\n",
      "Iteration 17, loss = 0.89008727\n",
      "Iteration 18, loss = 0.89827297\n",
      "Iteration 19, loss = 0.92613349\n",
      "Iteration 20, loss = 0.91368277\n",
      "Iteration 21, loss = 0.93331449\n",
      "Iteration 22, loss = 0.89486016\n",
      "Iteration 23, loss = 0.90282245\n",
      "Iteration 24, loss = 0.88421013\n",
      "Iteration 25, loss = 0.88876862\n",
      "Iteration 26, loss = 0.89987058\n",
      "Iteration 27, loss = 0.88614119\n",
      "Iteration 28, loss = 0.89028424\n",
      "Iteration 29, loss = 0.93231369\n",
      "Iteration 30, loss = 0.88085553\n",
      "Iteration 31, loss = 0.85928612\n",
      "Iteration 32, loss = 0.86693520\n",
      "Iteration 33, loss = 0.87172046\n",
      "Iteration 34, loss = 0.86286867\n",
      "Iteration 35, loss = 0.86237070\n",
      "Iteration 36, loss = 0.85123801\n",
      "Iteration 37, loss = 0.87102370\n",
      "Iteration 38, loss = 0.84229273\n",
      "Iteration 39, loss = 0.86576470\n",
      "Iteration 40, loss = 0.84425238\n",
      "Iteration 29, loss = 0.93231369\n",
      "Iteration 30, loss = 0.88085553\n",
      "Iteration 31, loss = 0.85928612\n",
      "Iteration 32, loss = 0.86693520\n",
      "Iteration 33, loss = 0.87172046\n",
      "Iteration 34, loss = 0.86286867\n",
      "Iteration 35, loss = 0.86237070\n",
      "Iteration 36, loss = 0.85123801\n",
      "Iteration 37, loss = 0.87102370\n",
      "Iteration 38, loss = 0.84229273\n",
      "Iteration 39, loss = 0.86576470\n",
      "Iteration 40, loss = 0.84425238\n",
      "Iteration 41, loss = 0.81582544\n",
      "Iteration 42, loss = 0.82503677\n",
      "Iteration 43, loss = 0.83215941\n",
      "Iteration 44, loss = 0.81753491\n",
      "Iteration 45, loss = 0.81616688\n",
      "Iteration 46, loss = 0.89794650\n",
      "Iteration 47, loss = 0.82353104\n",
      "Iteration 48, loss = 0.83250078\n",
      "Iteration 49, loss = 0.81611325\n",
      "Iteration 50, loss = 0.82277439\n",
      "Iteration 1, loss = 1.20413729\n",
      "Iteration 2, loss = 1.06032540\n",
      "Iteration 3, loss = 1.04612262\n",
      "Iteration 41, loss = 0.81582544\n",
      "Iteration 42, loss = 0.82503677\n",
      "Iteration 43, loss = 0.83215941\n",
      "Iteration 44, loss = 0.81753491\n",
      "Iteration 45, loss = 0.81616688\n",
      "Iteration 46, loss = 0.89794650\n",
      "Iteration 47, loss = 0.82353104\n",
      "Iteration 48, loss = 0.83250078\n",
      "Iteration 49, loss = 0.81611325\n",
      "Iteration 50, loss = 0.82277439\n",
      "Iteration 1, loss = 1.20413729\n",
      "Iteration 2, loss = 1.06032540\n",
      "Iteration 3, loss = 1.04612262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.97408036\n",
      "Iteration 5, loss = 1.02038100\n",
      "Iteration 6, loss = 0.96744344\n",
      "Iteration 7, loss = 0.93521408\n",
      "Iteration 8, loss = 0.96848100\n",
      "Iteration 9, loss = 0.95967247\n",
      "Iteration 10, loss = 0.93317776\n",
      "Iteration 11, loss = 0.95407366\n",
      "Iteration 12, loss = 0.94987579\n",
      "Iteration 13, loss = 0.94949322\n",
      "Iteration 14, loss = 0.92937095\n",
      "Iteration 15, loss = 0.92563217\n",
      "Iteration 4, loss = 0.97408036\n",
      "Iteration 5, loss = 1.02038100\n",
      "Iteration 6, loss = 0.96744344\n",
      "Iteration 7, loss = 0.93521408\n",
      "Iteration 8, loss = 0.96848100\n",
      "Iteration 9, loss = 0.95967247\n",
      "Iteration 10, loss = 0.93317776\n",
      "Iteration 11, loss = 0.95407366\n",
      "Iteration 12, loss = 0.94987579\n",
      "Iteration 13, loss = 0.94949322\n",
      "Iteration 14, loss = 0.92937095\n",
      "Iteration 15, loss = 0.92563217\n",
      "Iteration 16, loss = 0.93355862\n",
      "Iteration 17, loss = 0.93685920\n",
      "Iteration 18, loss = 0.88214683\n",
      "Iteration 19, loss = 0.94857283\n",
      "Iteration 20, loss = 0.89685780\n",
      "Iteration 21, loss = 0.88075935\n",
      "Iteration 22, loss = 0.89900345\n",
      "Iteration 23, loss = 0.89532613\n",
      "Iteration 24, loss = 0.89808524\n",
      "Iteration 25, loss = 0.88150513\n",
      "Iteration 26, loss = 0.87792428\n",
      "Iteration 27, loss = 0.84528897\n",
      "Iteration 28, loss = 0.85792636\n",
      "Iteration 29, loss = 0.92886960\n",
      "Iteration 16, loss = 0.93355862\n",
      "Iteration 17, loss = 0.93685920\n",
      "Iteration 18, loss = 0.88214683\n",
      "Iteration 19, loss = 0.94857283\n",
      "Iteration 20, loss = 0.89685780\n",
      "Iteration 21, loss = 0.88075935\n",
      "Iteration 22, loss = 0.89900345\n",
      "Iteration 23, loss = 0.89532613\n",
      "Iteration 24, loss = 0.89808524\n",
      "Iteration 25, loss = 0.88150513\n",
      "Iteration 26, loss = 0.87792428\n",
      "Iteration 27, loss = 0.84528897\n",
      "Iteration 28, loss = 0.85792636\n",
      "Iteration 29, loss = 0.92886960\n",
      "Iteration 30, loss = 0.85470250\n",
      "Iteration 31, loss = 0.82378875\n",
      "Iteration 32, loss = 0.82734958\n",
      "Iteration 33, loss = 0.82120252\n",
      "Iteration 34, loss = 0.83775664\n",
      "Iteration 35, loss = 0.87458163\n",
      "Iteration 36, loss = 0.81476225\n",
      "Iteration 37, loss = 0.84815817\n",
      "Iteration 38, loss = 0.81890505\n",
      "Iteration 39, loss = 0.85093056\n",
      "Iteration 40, loss = 0.84702992\n",
      "Iteration 41, loss = 0.84161494\n",
      "Iteration 30, loss = 0.85470250\n",
      "Iteration 31, loss = 0.82378875\n",
      "Iteration 32, loss = 0.82734958\n",
      "Iteration 33, loss = 0.82120252\n",
      "Iteration 34, loss = 0.83775664\n",
      "Iteration 35, loss = 0.87458163\n",
      "Iteration 36, loss = 0.81476225\n",
      "Iteration 37, loss = 0.84815817\n",
      "Iteration 38, loss = 0.81890505\n",
      "Iteration 39, loss = 0.85093056\n",
      "Iteration 40, loss = 0.84702992\n",
      "Iteration 41, loss = 0.84161494\n",
      "Iteration 42, loss = 0.81693363\n",
      "Iteration 43, loss = 0.79307287\n",
      "Iteration 44, loss = 0.79822644\n",
      "Iteration 45, loss = 0.81598386\n",
      "Iteration 46, loss = 0.79051386\n",
      "Iteration 47, loss = 0.83534408\n",
      "Iteration 48, loss = 0.80557360\n",
      "Iteration 49, loss = 0.77961238\n",
      "Iteration 50, loss = 0.74504447\n",
      "Iteration 1, loss = 1.18494747\n",
      "Iteration 2, loss = 1.06046800\n",
      "Iteration 3, loss = 1.03577015\n",
      "Iteration 4, loss = 0.99223511\n",
      "Iteration 5, loss = 0.97521174\n",
      "Iteration 42, loss = 0.81693363\n",
      "Iteration 43, loss = 0.79307287\n",
      "Iteration 44, loss = 0.79822644\n",
      "Iteration 45, loss = 0.81598386\n",
      "Iteration 46, loss = 0.79051386\n",
      "Iteration 47, loss = 0.83534408\n",
      "Iteration 48, loss = 0.80557360\n",
      "Iteration 49, loss = 0.77961238\n",
      "Iteration 50, loss = 0.74504447\n",
      "Iteration 1, loss = 1.18494747\n",
      "Iteration 2, loss = 1.06046800\n",
      "Iteration 3, loss = 1.03577015\n",
      "Iteration 4, loss = 0.99223511\n",
      "Iteration 5, loss = 0.97521174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.99535383\n",
      "Iteration 7, loss = 0.94451501\n",
      "Iteration 8, loss = 1.00859762\n",
      "Iteration 9, loss = 0.96847217\n",
      "Iteration 10, loss = 0.92647260\n",
      "Iteration 11, loss = 0.91276372\n",
      "Iteration 12, loss = 0.92777261\n",
      "Iteration 13, loss = 0.91023268\n",
      "Iteration 14, loss = 0.92940828\n",
      "Iteration 6, loss = 0.99535383\n",
      "Iteration 7, loss = 0.94451501\n",
      "Iteration 8, loss = 1.00859762\n",
      "Iteration 9, loss = 0.96847217\n",
      "Iteration 10, loss = 0.92647260\n",
      "Iteration 11, loss = 0.91276372\n",
      "Iteration 12, loss = 0.92777261\n",
      "Iteration 13, loss = 0.91023268\n",
      "Iteration 14, loss = 0.92940828\n",
      "Iteration 15, loss = 0.88457039\n",
      "Iteration 16, loss = 0.93610067\n",
      "Iteration 17, loss = 0.91544968\n",
      "Iteration 18, loss = 0.92344546\n",
      "Iteration 19, loss = 0.90412974\n",
      "Iteration 20, loss = 0.88608990\n",
      "Iteration 21, loss = 0.91038073\n",
      "Iteration 22, loss = 0.90183278\n",
      "Iteration 23, loss = 0.86760457\n",
      "Iteration 24, loss = 0.91234124\n",
      "Iteration 25, loss = 0.89830648\n",
      "Iteration 26, loss = 0.87415950\n",
      "Iteration 27, loss = 0.86980768\n",
      "Iteration 28, loss = 0.87216545\n",
      "Iteration 15, loss = 0.88457039\n",
      "Iteration 16, loss = 0.93610067\n",
      "Iteration 17, loss = 0.91544968\n",
      "Iteration 18, loss = 0.92344546\n",
      "Iteration 19, loss = 0.90412974\n",
      "Iteration 20, loss = 0.88608990\n",
      "Iteration 21, loss = 0.91038073\n",
      "Iteration 22, loss = 0.90183278\n",
      "Iteration 23, loss = 0.86760457\n",
      "Iteration 24, loss = 0.91234124\n",
      "Iteration 25, loss = 0.89830648\n",
      "Iteration 26, loss = 0.87415950\n",
      "Iteration 27, loss = 0.86980768\n",
      "Iteration 28, loss = 0.87216545\n",
      "Iteration 29, loss = 0.85998809\n",
      "Iteration 30, loss = 0.81857090\n",
      "Iteration 31, loss = 0.83454112\n",
      "Iteration 32, loss = 0.89131055\n",
      "Iteration 33, loss = 0.85256859\n",
      "Iteration 34, loss = 0.82989455\n",
      "Iteration 35, loss = 0.83872004\n",
      "Iteration 36, loss = 0.81852657\n",
      "Iteration 37, loss = 0.84123589\n",
      "Iteration 38, loss = 0.84153477\n",
      "Iteration 39, loss = 0.82688495\n",
      "Iteration 40, loss = 0.81203543\n",
      "Iteration 41, loss = 0.78141286\n",
      "Iteration 42, loss = 0.84099622\n",
      "Iteration 43, loss = 0.81106288\n",
      "Iteration 29, loss = 0.85998809\n",
      "Iteration 30, loss = 0.81857090\n",
      "Iteration 31, loss = 0.83454112\n",
      "Iteration 32, loss = 0.89131055\n",
      "Iteration 33, loss = 0.85256859\n",
      "Iteration 34, loss = 0.82989455\n",
      "Iteration 35, loss = 0.83872004\n",
      "Iteration 36, loss = 0.81852657\n",
      "Iteration 37, loss = 0.84123589\n",
      "Iteration 38, loss = 0.84153477\n",
      "Iteration 39, loss = 0.82688495\n",
      "Iteration 40, loss = 0.81203543\n",
      "Iteration 41, loss = 0.78141286\n",
      "Iteration 42, loss = 0.84099622\n",
      "Iteration 43, loss = 0.81106288\n",
      "Iteration 44, loss = 0.81505175\n",
      "Iteration 45, loss = 0.84914289\n",
      "Iteration 46, loss = 0.81010063\n",
      "Iteration 47, loss = 0.80779536\n",
      "Iteration 48, loss = 0.79901200\n",
      "Iteration 49, loss = 0.80448209\n",
      "Iteration 50, loss = 0.79405457\n",
      "Iteration 1, loss = 1.15215098\n",
      "Iteration 2, loss = 1.05902376\n",
      "Iteration 3, loss = 1.01617352\n",
      "Iteration 4, loss = 0.98744133\n",
      "Iteration 5, loss = 1.00905866\n",
      "Iteration 6, loss = 0.95321433\n",
      "Iteration 7, loss = 0.98483932\n",
      "Iteration 44, loss = 0.81505175\n",
      "Iteration 45, loss = 0.84914289\n",
      "Iteration 46, loss = 0.81010063\n",
      "Iteration 47, loss = 0.80779536\n",
      "Iteration 48, loss = 0.79901200\n",
      "Iteration 49, loss = 0.80448209\n",
      "Iteration 50, loss = 0.79405457\n",
      "Iteration 1, loss = 1.15215098\n",
      "Iteration 2, loss = 1.05902376\n",
      "Iteration 3, loss = 1.01617352\n",
      "Iteration 4, loss = 0.98744133\n",
      "Iteration 5, loss = 1.00905866\n",
      "Iteration 6, loss = 0.95321433\n",
      "Iteration 7, loss = 0.98483932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.98694833\n",
      "Iteration 9, loss = 0.99788177\n",
      "Iteration 10, loss = 0.94202262\n",
      "Iteration 11, loss = 0.95242591\n",
      "Iteration 12, loss = 0.95667916\n",
      "Iteration 13, loss = 0.93562682\n",
      "Iteration 14, loss = 0.93727177\n",
      "Iteration 15, loss = 0.92597915\n",
      "Iteration 16, loss = 0.91275972\n",
      "Iteration 17, loss = 0.90536224\n",
      "Iteration 18, loss = 0.91624375\n",
      "Iteration 19, loss = 0.92715813\n",
      "Iteration 20, loss = 0.95367839\n",
      "Iteration 21, loss = 0.91091329\n",
      "Iteration 8, loss = 0.98694833\n",
      "Iteration 9, loss = 0.99788177\n",
      "Iteration 10, loss = 0.94202262\n",
      "Iteration 11, loss = 0.95242591\n",
      "Iteration 12, loss = 0.95667916\n",
      "Iteration 13, loss = 0.93562682\n",
      "Iteration 14, loss = 0.93727177\n",
      "Iteration 15, loss = 0.92597915\n",
      "Iteration 16, loss = 0.91275972\n",
      "Iteration 17, loss = 0.90536224\n",
      "Iteration 18, loss = 0.91624375\n",
      "Iteration 19, loss = 0.92715813\n",
      "Iteration 20, loss = 0.95367839\n",
      "Iteration 21, loss = 0.91091329\n",
      "Iteration 22, loss = 0.89177190\n",
      "Iteration 23, loss = 0.87536312\n",
      "Iteration 24, loss = 0.86809853\n",
      "Iteration 25, loss = 0.86612740\n",
      "Iteration 26, loss = 0.85361915\n",
      "Iteration 27, loss = 0.86284730\n",
      "Iteration 28, loss = 0.89548398\n",
      "Iteration 29, loss = 0.89792438\n",
      "Iteration 30, loss = 0.87543761\n",
      "Iteration 31, loss = 0.86857106\n",
      "Iteration 32, loss = 0.84915800\n",
      "Iteration 33, loss = 0.87236429\n",
      "Iteration 34, loss = 0.84161285\n",
      "Iteration 35, loss = 0.84037367\n",
      "Iteration 22, loss = 0.89177190\n",
      "Iteration 23, loss = 0.87536312\n",
      "Iteration 24, loss = 0.86809853\n",
      "Iteration 25, loss = 0.86612740\n",
      "Iteration 26, loss = 0.85361915\n",
      "Iteration 27, loss = 0.86284730\n",
      "Iteration 28, loss = 0.89548398\n",
      "Iteration 29, loss = 0.89792438\n",
      "Iteration 30, loss = 0.87543761\n",
      "Iteration 31, loss = 0.86857106\n",
      "Iteration 32, loss = 0.84915800\n",
      "Iteration 33, loss = 0.87236429\n",
      "Iteration 34, loss = 0.84161285\n",
      "Iteration 35, loss = 0.84037367\n",
      "Iteration 36, loss = 0.79374316\n",
      "Iteration 37, loss = 0.81943805\n",
      "Iteration 38, loss = 0.82132463\n",
      "Iteration 39, loss = 0.86041271\n",
      "Iteration 40, loss = 0.81906144\n",
      "Iteration 41, loss = 0.82446676\n",
      "Iteration 42, loss = 0.78233584\n",
      "Iteration 43, loss = 0.79207004\n",
      "Iteration 44, loss = 0.81055536\n",
      "Iteration 45, loss = 0.86111707\n",
      "Iteration 46, loss = 0.78153003\n",
      "Iteration 47, loss = 0.77410789\n",
      "Iteration 48, loss = 0.77676129\n",
      "Iteration 49, loss = 0.79382386\n",
      "Iteration 36, loss = 0.79374316\n",
      "Iteration 37, loss = 0.81943805\n",
      "Iteration 38, loss = 0.82132463\n",
      "Iteration 39, loss = 0.86041271\n",
      "Iteration 40, loss = 0.81906144\n",
      "Iteration 41, loss = 0.82446676\n",
      "Iteration 42, loss = 0.78233584\n",
      "Iteration 43, loss = 0.79207004\n",
      "Iteration 44, loss = 0.81055536\n",
      "Iteration 45, loss = 0.86111707\n",
      "Iteration 46, loss = 0.78153003\n",
      "Iteration 47, loss = 0.77410789\n",
      "Iteration 48, loss = 0.77676129\n",
      "Iteration 49, loss = 0.79382386\n",
      "Iteration 50, loss = 0.76079878\n",
      "Iteration 51, loss = 0.78975083\n",
      "Iteration 52, loss = 0.77271752\n",
      "Iteration 53, loss = 0.76585555\n",
      "Iteration 54, loss = 0.72489850\n",
      "Iteration 55, loss = 0.76761155\n",
      "Iteration 56, loss = 0.73248462\n",
      "Iteration 57, loss = 0.81570999\n",
      "Iteration 58, loss = 0.78250225\n",
      "Iteration 59, loss = 0.77054465\n",
      "Iteration 60, loss = 0.71886021\n",
      "Iteration 61, loss = 0.71236339\n",
      "Iteration 62, loss = 0.71162015\n",
      "Iteration 63, loss = 0.73400627\n",
      "Iteration 50, loss = 0.76079878\n",
      "Iteration 51, loss = 0.78975083\n",
      "Iteration 52, loss = 0.77271752\n",
      "Iteration 53, loss = 0.76585555\n",
      "Iteration 54, loss = 0.72489850\n",
      "Iteration 55, loss = 0.76761155\n",
      "Iteration 56, loss = 0.73248462\n",
      "Iteration 57, loss = 0.81570999\n",
      "Iteration 58, loss = 0.78250225\n",
      "Iteration 59, loss = 0.77054465\n",
      "Iteration 60, loss = 0.71886021\n",
      "Iteration 61, loss = 0.71236339\n",
      "Iteration 62, loss = 0.71162015\n",
      "Iteration 63, loss = 0.73400627\n",
      "Iteration 64, loss = 0.76179931\n",
      "Iteration 65, loss = 0.73183616\n",
      "Iteration 66, loss = 0.72296064\n",
      "Iteration 67, loss = 0.70760817\n",
      "Iteration 68, loss = 0.74376031\n",
      "Iteration 69, loss = 0.70999386\n",
      "Iteration 70, loss = 0.72939269\n",
      "Iteration 71, loss = 0.68174029\n",
      "Iteration 72, loss = 0.67598711\n",
      "Iteration 73, loss = 0.70196001\n",
      "Iteration 74, loss = 0.76435564\n",
      "Iteration 75, loss = 0.71238400\n",
      "Iteration 76, loss = 0.71613863\n",
      "Iteration 77, loss = 0.71371332\n",
      "Iteration 78, loss = 0.72634899\n",
      "Iteration 79, loss = 0.70077079\n",
      "Iteration 64, loss = 0.76179931\n",
      "Iteration 65, loss = 0.73183616\n",
      "Iteration 66, loss = 0.72296064\n",
      "Iteration 67, loss = 0.70760817\n",
      "Iteration 68, loss = 0.74376031\n",
      "Iteration 69, loss = 0.70999386\n",
      "Iteration 70, loss = 0.72939269\n",
      "Iteration 71, loss = 0.68174029\n",
      "Iteration 72, loss = 0.67598711\n",
      "Iteration 73, loss = 0.70196001\n",
      "Iteration 74, loss = 0.76435564\n",
      "Iteration 75, loss = 0.71238400\n",
      "Iteration 76, loss = 0.71613863\n",
      "Iteration 77, loss = 0.71371332\n",
      "Iteration 78, loss = 0.72634899\n",
      "Iteration 79, loss = 0.70077079\n",
      "Iteration 80, loss = 0.72551807\n",
      "Iteration 81, loss = 0.72266822\n",
      "Iteration 82, loss = 0.71794714\n",
      "Iteration 83, loss = 0.71718965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15474165\n",
      "Iteration 2, loss = 0.99458393\n",
      "Iteration 3, loss = 0.98702664\n",
      "Iteration 4, loss = 0.92141462\n",
      "Iteration 5, loss = 0.93099045\n",
      "Iteration 6, loss = 0.89760020\n",
      "Iteration 7, loss = 0.91664807\n",
      "Iteration 8, loss = 0.89606759\n",
      "Iteration 9, loss = 0.92287971\n",
      "Iteration 80, loss = 0.72551807\n",
      "Iteration 81, loss = 0.72266822\n",
      "Iteration 82, loss = 0.71794714\n",
      "Iteration 83, loss = 0.71718965\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15474165\n",
      "Iteration 2, loss = 0.99458393\n",
      "Iteration 3, loss = 0.98702664\n",
      "Iteration 4, loss = 0.92141462\n",
      "Iteration 5, loss = 0.93099045\n",
      "Iteration 6, loss = 0.89760020\n",
      "Iteration 7, loss = 0.91664807\n",
      "Iteration 8, loss = 0.89606759\n",
      "Iteration 9, loss = 0.92287971\n",
      "Iteration 10, loss = 0.87749846\n",
      "Iteration 11, loss = 0.93932324\n",
      "Iteration 12, loss = 0.90566796\n",
      "Iteration 13, loss = 0.89235014\n",
      "Iteration 14, loss = 0.92450634\n",
      "Iteration 15, loss = 0.85187506\n",
      "Iteration 16, loss = 0.90707440\n",
      "Iteration 17, loss = 0.86661669\n",
      "Iteration 18, loss = 0.84384630\n",
      "Iteration 19, loss = 0.85118292\n",
      "Iteration 20, loss = 0.86421713\n",
      "Iteration 21, loss = 0.85616798\n",
      "Iteration 22, loss = 0.85535333\n",
      "Iteration 23, loss = 0.82456022\n",
      "Iteration 10, loss = 0.87749846\n",
      "Iteration 11, loss = 0.93932324\n",
      "Iteration 12, loss = 0.90566796\n",
      "Iteration 13, loss = 0.89235014\n",
      "Iteration 14, loss = 0.92450634\n",
      "Iteration 15, loss = 0.85187506\n",
      "Iteration 16, loss = 0.90707440\n",
      "Iteration 17, loss = 0.86661669\n",
      "Iteration 18, loss = 0.84384630\n",
      "Iteration 19, loss = 0.85118292\n",
      "Iteration 20, loss = 0.86421713\n",
      "Iteration 21, loss = 0.85616798\n",
      "Iteration 22, loss = 0.85535333\n",
      "Iteration 23, loss = 0.82456022\n",
      "Iteration 24, loss = 0.81869800\n",
      "Iteration 25, loss = 0.80700280\n",
      "Iteration 26, loss = 0.80947770\n",
      "Iteration 27, loss = 0.80947894\n",
      "Iteration 28, loss = 0.79552188\n",
      "Iteration 29, loss = 0.85068701\n",
      "Iteration 30, loss = 0.82702709\n",
      "Iteration 31, loss = 0.78942499\n",
      "Iteration 32, loss = 0.80345761\n",
      "Iteration 33, loss = 0.80762076\n",
      "Iteration 34, loss = 0.83841806\n",
      "Iteration 35, loss = 0.83966483\n",
      "Iteration 36, loss = 0.77825829\n",
      "Iteration 37, loss = 0.77559605\n",
      "Iteration 38, loss = 0.75276144\n",
      "Iteration 24, loss = 0.81869800\n",
      "Iteration 25, loss = 0.80700280\n",
      "Iteration 26, loss = 0.80947770\n",
      "Iteration 27, loss = 0.80947894\n",
      "Iteration 28, loss = 0.79552188\n",
      "Iteration 29, loss = 0.85068701\n",
      "Iteration 30, loss = 0.82702709\n",
      "Iteration 31, loss = 0.78942499\n",
      "Iteration 32, loss = 0.80345761\n",
      "Iteration 33, loss = 0.80762076\n",
      "Iteration 34, loss = 0.83841806\n",
      "Iteration 35, loss = 0.83966483\n",
      "Iteration 36, loss = 0.77825829\n",
      "Iteration 37, loss = 0.77559605\n",
      "Iteration 38, loss = 0.75276144\n",
      "Iteration 39, loss = 0.79096125\n",
      "Iteration 40, loss = 0.77427837\n",
      "Iteration 41, loss = 0.76649117\n",
      "Iteration 42, loss = 0.76304823\n",
      "Iteration 43, loss = 0.76040796\n",
      "Iteration 44, loss = 0.77253966\n",
      "Iteration 45, loss = 0.75460058\n",
      "Iteration 46, loss = 0.76528323\n",
      "Iteration 47, loss = 0.70956908\n",
      "Iteration 48, loss = 0.70552123\n",
      "Iteration 49, loss = 0.70299828\n",
      "Iteration 50, loss = 0.72842656\n",
      "Iteration 51, loss = 0.72384728\n",
      "Iteration 52, loss = 0.75387693\n",
      "Iteration 39, loss = 0.79096125\n",
      "Iteration 40, loss = 0.77427837\n",
      "Iteration 41, loss = 0.76649117\n",
      "Iteration 42, loss = 0.76304823\n",
      "Iteration 43, loss = 0.76040796\n",
      "Iteration 44, loss = 0.77253966\n",
      "Iteration 45, loss = 0.75460058\n",
      "Iteration 46, loss = 0.76528323\n",
      "Iteration 47, loss = 0.70956908\n",
      "Iteration 48, loss = 0.70552123\n",
      "Iteration 49, loss = 0.70299828\n",
      "Iteration 50, loss = 0.72842656\n",
      "Iteration 51, loss = 0.72384728\n",
      "Iteration 52, loss = 0.75387693\n",
      "Iteration 53, loss = 0.73563820\n",
      "Iteration 54, loss = 0.72059153\n",
      "Iteration 55, loss = 0.69856204\n",
      "Iteration 56, loss = 0.69711733\n",
      "Iteration 57, loss = 0.70225001\n",
      "Iteration 58, loss = 0.70107742\n",
      "Iteration 59, loss = 0.76543856\n",
      "Iteration 60, loss = 0.72406354\n",
      "Iteration 61, loss = 0.70872982\n",
      "Iteration 62, loss = 0.69513849\n",
      "Iteration 63, loss = 0.67948653\n",
      "Iteration 64, loss = 0.69434882\n",
      "Iteration 65, loss = 0.74120934\n",
      "Iteration 66, loss = 0.68277384\n",
      "Iteration 67, loss = 0.68506542\n",
      "Iteration 53, loss = 0.73563820\n",
      "Iteration 54, loss = 0.72059153\n",
      "Iteration 55, loss = 0.69856204\n",
      "Iteration 56, loss = 0.69711733\n",
      "Iteration 57, loss = 0.70225001\n",
      "Iteration 58, loss = 0.70107742\n",
      "Iteration 59, loss = 0.76543856\n",
      "Iteration 60, loss = 0.72406354\n",
      "Iteration 61, loss = 0.70872982\n",
      "Iteration 62, loss = 0.69513849\n",
      "Iteration 63, loss = 0.67948653\n",
      "Iteration 64, loss = 0.69434882\n",
      "Iteration 65, loss = 0.74120934\n",
      "Iteration 66, loss = 0.68277384\n",
      "Iteration 67, loss = 0.68506542\n",
      "Iteration 68, loss = 0.68480804\n",
      "Iteration 69, loss = 0.70764093\n",
      "Iteration 70, loss = 0.70519222\n",
      "Iteration 71, loss = 0.77972261\n",
      "Iteration 72, loss = 0.70455688\n",
      "Iteration 73, loss = 0.68252007\n",
      "Iteration 74, loss = 0.66456184\n",
      "Iteration 75, loss = 0.67219194\n",
      "Iteration 76, loss = 0.66859792\n",
      "Iteration 77, loss = 0.66875692\n",
      "Iteration 78, loss = 0.67680532\n",
      "Iteration 79, loss = 0.70893338\n",
      "Iteration 80, loss = 0.67660044\n",
      "Iteration 81, loss = 0.67418376\n",
      "Iteration 82, loss = 0.64257585\n",
      "Iteration 68, loss = 0.68480804\n",
      "Iteration 69, loss = 0.70764093\n",
      "Iteration 70, loss = 0.70519222\n",
      "Iteration 71, loss = 0.77972261\n",
      "Iteration 72, loss = 0.70455688\n",
      "Iteration 73, loss = 0.68252007\n",
      "Iteration 74, loss = 0.66456184\n",
      "Iteration 75, loss = 0.67219194\n",
      "Iteration 76, loss = 0.66859792\n",
      "Iteration 77, loss = 0.66875692\n",
      "Iteration 78, loss = 0.67680532\n",
      "Iteration 79, loss = 0.70893338\n",
      "Iteration 80, loss = 0.67660044\n",
      "Iteration 81, loss = 0.67418376\n",
      "Iteration 82, loss = 0.64257585\n",
      "Iteration 83, loss = 0.65424876\n",
      "Iteration 84, loss = 0.65766896\n",
      "Iteration 85, loss = 0.65082142\n",
      "Iteration 86, loss = 0.65605316\n",
      "Iteration 87, loss = 0.64914526\n",
      "Iteration 88, loss = 0.64762077\n",
      "Iteration 89, loss = 0.63642078\n",
      "Iteration 90, loss = 0.68724030\n",
      "Iteration 91, loss = 0.65781556\n",
      "Iteration 92, loss = 0.66875009\n",
      "Iteration 93, loss = 0.65585759\n",
      "Iteration 94, loss = 0.69428697\n",
      "Iteration 95, loss = 0.72856950\n",
      "Iteration 96, loss = 0.72643495\n",
      "Iteration 83, loss = 0.65424876\n",
      "Iteration 84, loss = 0.65766896\n",
      "Iteration 85, loss = 0.65082142\n",
      "Iteration 86, loss = 0.65605316\n",
      "Iteration 87, loss = 0.64914526\n",
      "Iteration 88, loss = 0.64762077\n",
      "Iteration 89, loss = 0.63642078\n",
      "Iteration 90, loss = 0.68724030\n",
      "Iteration 91, loss = 0.65781556\n",
      "Iteration 92, loss = 0.66875009\n",
      "Iteration 93, loss = 0.65585759\n",
      "Iteration 94, loss = 0.69428697\n",
      "Iteration 95, loss = 0.72856950\n",
      "Iteration 96, loss = 0.72643495\n",
      "Iteration 97, loss = 0.69919166\n",
      "Iteration 98, loss = 0.70986700\n",
      "Iteration 99, loss = 0.67345927\n",
      "Iteration 100, loss = 0.67247567\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17645811\n",
      "Iteration 2, loss = 1.01901515\n",
      "Iteration 3, loss = 1.03596691\n",
      "Iteration 4, loss = 0.98752694\n",
      "Iteration 5, loss = 0.98634849\n",
      "Iteration 6, loss = 0.94388389\n",
      "Iteration 7, loss = 0.93004457\n",
      "Iteration 8, loss = 0.93641801\n",
      "Iteration 9, loss = 0.94719307\n",
      "Iteration 97, loss = 0.69919166\n",
      "Iteration 98, loss = 0.70986700\n",
      "Iteration 99, loss = 0.67345927\n",
      "Iteration 100, loss = 0.67247567\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17645811\n",
      "Iteration 2, loss = 1.01901515\n",
      "Iteration 3, loss = 1.03596691\n",
      "Iteration 4, loss = 0.98752694\n",
      "Iteration 5, loss = 0.98634849\n",
      "Iteration 6, loss = 0.94388389\n",
      "Iteration 7, loss = 0.93004457\n",
      "Iteration 8, loss = 0.93641801\n",
      "Iteration 9, loss = 0.94719307\n",
      "Iteration 10, loss = 0.93307659\n",
      "Iteration 11, loss = 0.95002681\n",
      "Iteration 12, loss = 0.92178089\n",
      "Iteration 13, loss = 0.90953876\n",
      "Iteration 14, loss = 0.99512424\n",
      "Iteration 15, loss = 0.93092580\n",
      "Iteration 16, loss = 0.92376847\n",
      "Iteration 17, loss = 0.89008727\n",
      "Iteration 18, loss = 0.89827297\n",
      "Iteration 19, loss = 0.92613349\n",
      "Iteration 20, loss = 0.91368277\n",
      "Iteration 21, loss = 0.93331449\n",
      "Iteration 22, loss = 0.89486016\n",
      "Iteration 10, loss = 0.93307659\n",
      "Iteration 11, loss = 0.95002681\n",
      "Iteration 12, loss = 0.92178089\n",
      "Iteration 13, loss = 0.90953876\n",
      "Iteration 14, loss = 0.99512424\n",
      "Iteration 15, loss = 0.93092580\n",
      "Iteration 16, loss = 0.92376847\n",
      "Iteration 17, loss = 0.89008727\n",
      "Iteration 18, loss = 0.89827297\n",
      "Iteration 19, loss = 0.92613349\n",
      "Iteration 20, loss = 0.91368277\n",
      "Iteration 21, loss = 0.93331449\n",
      "Iteration 22, loss = 0.89486016\n",
      "Iteration 23, loss = 0.90282245\n",
      "Iteration 24, loss = 0.88421013\n",
      "Iteration 25, loss = 0.88876862\n",
      "Iteration 26, loss = 0.89987058\n",
      "Iteration 27, loss = 0.88614119\n",
      "Iteration 28, loss = 0.89028424\n",
      "Iteration 29, loss = 0.93231369\n",
      "Iteration 30, loss = 0.88085553\n",
      "Iteration 31, loss = 0.85928612\n",
      "Iteration 32, loss = 0.86693520\n",
      "Iteration 33, loss = 0.87172046\n",
      "Iteration 34, loss = 0.86286867\n",
      "Iteration 35, loss = 0.86237070\n",
      "Iteration 36, loss = 0.85123801\n",
      "Iteration 37, loss = 0.87102370\n",
      "Iteration 23, loss = 0.90282245\n",
      "Iteration 24, loss = 0.88421013\n",
      "Iteration 25, loss = 0.88876862\n",
      "Iteration 26, loss = 0.89987058\n",
      "Iteration 27, loss = 0.88614119\n",
      "Iteration 28, loss = 0.89028424\n",
      "Iteration 29, loss = 0.93231369\n",
      "Iteration 30, loss = 0.88085553\n",
      "Iteration 31, loss = 0.85928612\n",
      "Iteration 32, loss = 0.86693520\n",
      "Iteration 33, loss = 0.87172046\n",
      "Iteration 34, loss = 0.86286867\n",
      "Iteration 35, loss = 0.86237070\n",
      "Iteration 36, loss = 0.85123801\n",
      "Iteration 37, loss = 0.87102370\n",
      "Iteration 38, loss = 0.84229273\n",
      "Iteration 39, loss = 0.86576470\n",
      "Iteration 40, loss = 0.84425238\n",
      "Iteration 41, loss = 0.81582544\n",
      "Iteration 42, loss = 0.82503677\n",
      "Iteration 43, loss = 0.83215941\n",
      "Iteration 44, loss = 0.81753491\n",
      "Iteration 45, loss = 0.81616688\n",
      "Iteration 46, loss = 0.89794650\n",
      "Iteration 47, loss = 0.82353104\n",
      "Iteration 48, loss = 0.83250078\n",
      "Iteration 49, loss = 0.81611325\n",
      "Iteration 50, loss = 0.82277439\n",
      "Iteration 51, loss = 0.82213694\n",
      "Iteration 38, loss = 0.84229273\n",
      "Iteration 39, loss = 0.86576470\n",
      "Iteration 40, loss = 0.84425238\n",
      "Iteration 41, loss = 0.81582544\n",
      "Iteration 42, loss = 0.82503677\n",
      "Iteration 43, loss = 0.83215941\n",
      "Iteration 44, loss = 0.81753491\n",
      "Iteration 45, loss = 0.81616688\n",
      "Iteration 46, loss = 0.89794650\n",
      "Iteration 47, loss = 0.82353104\n",
      "Iteration 48, loss = 0.83250078\n",
      "Iteration 49, loss = 0.81611325\n",
      "Iteration 50, loss = 0.82277439\n",
      "Iteration 51, loss = 0.82213694\n",
      "Iteration 52, loss = 0.76671885\n",
      "Iteration 53, loss = 0.79847830\n",
      "Iteration 54, loss = 0.81507662\n",
      "Iteration 55, loss = 0.76743419\n",
      "Iteration 56, loss = 0.78240386\n",
      "Iteration 57, loss = 0.83313451\n",
      "Iteration 58, loss = 0.77605510\n",
      "Iteration 59, loss = 0.80952148\n",
      "Iteration 60, loss = 0.79458918\n",
      "Iteration 61, loss = 0.76793271\n",
      "Iteration 62, loss = 0.80343884\n",
      "Iteration 63, loss = 0.77916449\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20413729\n",
      "Iteration 52, loss = 0.76671885\n",
      "Iteration 53, loss = 0.79847830\n",
      "Iteration 54, loss = 0.81507662\n",
      "Iteration 55, loss = 0.76743419\n",
      "Iteration 56, loss = 0.78240386\n",
      "Iteration 57, loss = 0.83313451\n",
      "Iteration 58, loss = 0.77605510\n",
      "Iteration 59, loss = 0.80952148\n",
      "Iteration 60, loss = 0.79458918\n",
      "Iteration 61, loss = 0.76793271\n",
      "Iteration 62, loss = 0.80343884\n",
      "Iteration 63, loss = 0.77916449\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20413729\n",
      "Iteration 2, loss = 1.06032540\n",
      "Iteration 3, loss = 1.04612262\n",
      "Iteration 4, loss = 0.97408036\n",
      "Iteration 5, loss = 1.02038100\n",
      "Iteration 6, loss = 0.96744344\n",
      "Iteration 7, loss = 0.93521408\n",
      "Iteration 8, loss = 0.96848100\n",
      "Iteration 9, loss = 0.95967247\n",
      "Iteration 10, loss = 0.93317776\n",
      "Iteration 11, loss = 0.95407366\n",
      "Iteration 12, loss = 0.94987579\n",
      "Iteration 13, loss = 0.94949322\n",
      "Iteration 14, loss = 0.92937095\n",
      "Iteration 2, loss = 1.06032540\n",
      "Iteration 3, loss = 1.04612262\n",
      "Iteration 4, loss = 0.97408036\n",
      "Iteration 5, loss = 1.02038100\n",
      "Iteration 6, loss = 0.96744344\n",
      "Iteration 7, loss = 0.93521408\n",
      "Iteration 8, loss = 0.96848100\n",
      "Iteration 9, loss = 0.95967247\n",
      "Iteration 10, loss = 0.93317776\n",
      "Iteration 11, loss = 0.95407366\n",
      "Iteration 12, loss = 0.94987579\n",
      "Iteration 13, loss = 0.94949322\n",
      "Iteration 14, loss = 0.92937095\n",
      "Iteration 15, loss = 0.92563217\n",
      "Iteration 16, loss = 0.93355862\n",
      "Iteration 17, loss = 0.93685920\n",
      "Iteration 18, loss = 0.88214683\n",
      "Iteration 19, loss = 0.94857283\n",
      "Iteration 20, loss = 0.89685780\n",
      "Iteration 21, loss = 0.88075935\n",
      "Iteration 22, loss = 0.89900345\n",
      "Iteration 23, loss = 0.89532613\n",
      "Iteration 24, loss = 0.89808524\n",
      "Iteration 25, loss = 0.88150513\n",
      "Iteration 26, loss = 0.87792428\n",
      "Iteration 27, loss = 0.84528897\n",
      "Iteration 28, loss = 0.85792636\n",
      "Iteration 15, loss = 0.92563217\n",
      "Iteration 16, loss = 0.93355862\n",
      "Iteration 17, loss = 0.93685920\n",
      "Iteration 18, loss = 0.88214683\n",
      "Iteration 19, loss = 0.94857283\n",
      "Iteration 20, loss = 0.89685780\n",
      "Iteration 21, loss = 0.88075935\n",
      "Iteration 22, loss = 0.89900345\n",
      "Iteration 23, loss = 0.89532613\n",
      "Iteration 24, loss = 0.89808524\n",
      "Iteration 25, loss = 0.88150513\n",
      "Iteration 26, loss = 0.87792428\n",
      "Iteration 27, loss = 0.84528897\n",
      "Iteration 28, loss = 0.85792636\n",
      "Iteration 29, loss = 0.92886960\n",
      "Iteration 30, loss = 0.85470250\n",
      "Iteration 31, loss = 0.82378875\n",
      "Iteration 32, loss = 0.82734958\n",
      "Iteration 33, loss = 0.82120252\n",
      "Iteration 34, loss = 0.83775664\n",
      "Iteration 35, loss = 0.87458163\n",
      "Iteration 36, loss = 0.81476225\n",
      "Iteration 37, loss = 0.84815817\n",
      "Iteration 38, loss = 0.81890505\n",
      "Iteration 39, loss = 0.85093056\n",
      "Iteration 40, loss = 0.84702992\n",
      "Iteration 41, loss = 0.84161494\n",
      "Iteration 42, loss = 0.81693363\n",
      "Iteration 43, loss = 0.79307287\n",
      "Iteration 29, loss = 0.92886960\n",
      "Iteration 30, loss = 0.85470250\n",
      "Iteration 31, loss = 0.82378875\n",
      "Iteration 32, loss = 0.82734958\n",
      "Iteration 33, loss = 0.82120252\n",
      "Iteration 34, loss = 0.83775664\n",
      "Iteration 35, loss = 0.87458163\n",
      "Iteration 36, loss = 0.81476225\n",
      "Iteration 37, loss = 0.84815817\n",
      "Iteration 38, loss = 0.81890505\n",
      "Iteration 39, loss = 0.85093056\n",
      "Iteration 40, loss = 0.84702992\n",
      "Iteration 41, loss = 0.84161494\n",
      "Iteration 42, loss = 0.81693363\n",
      "Iteration 43, loss = 0.79307287\n",
      "Iteration 44, loss = 0.79822644\n",
      "Iteration 45, loss = 0.81598386\n",
      "Iteration 46, loss = 0.79051386\n",
      "Iteration 47, loss = 0.83534408\n",
      "Iteration 48, loss = 0.80557360\n",
      "Iteration 49, loss = 0.77961238\n",
      "Iteration 50, loss = 0.74504447\n",
      "Iteration 51, loss = 0.77086548\n",
      "Iteration 52, loss = 0.75447644\n",
      "Iteration 53, loss = 0.77999563\n",
      "Iteration 54, loss = 0.75563876\n",
      "Iteration 55, loss = 0.73573958\n",
      "Iteration 56, loss = 0.73701133\n",
      "Iteration 57, loss = 0.72004371\n",
      "Iteration 58, loss = 0.74369399\n",
      "Iteration 44, loss = 0.79822644\n",
      "Iteration 45, loss = 0.81598386\n",
      "Iteration 46, loss = 0.79051386\n",
      "Iteration 47, loss = 0.83534408\n",
      "Iteration 48, loss = 0.80557360\n",
      "Iteration 49, loss = 0.77961238\n",
      "Iteration 50, loss = 0.74504447\n",
      "Iteration 51, loss = 0.77086548\n",
      "Iteration 52, loss = 0.75447644\n",
      "Iteration 53, loss = 0.77999563\n",
      "Iteration 54, loss = 0.75563876\n",
      "Iteration 55, loss = 0.73573958\n",
      "Iteration 56, loss = 0.73701133\n",
      "Iteration 57, loss = 0.72004371\n",
      "Iteration 58, loss = 0.74369399\n",
      "Iteration 59, loss = 0.77044978\n",
      "Iteration 60, loss = 0.71990714\n",
      "Iteration 61, loss = 0.68945464\n",
      "Iteration 62, loss = 0.88872056\n",
      "Iteration 63, loss = 0.74462412\n",
      "Iteration 64, loss = 0.73007080\n",
      "Iteration 65, loss = 0.75087548\n",
      "Iteration 66, loss = 0.71253978\n",
      "Iteration 67, loss = 0.72404014\n",
      "Iteration 68, loss = 0.73903211\n",
      "Iteration 69, loss = 0.71233038\n",
      "Iteration 70, loss = 0.73650559\n",
      "Iteration 71, loss = 0.71991576\n",
      "Iteration 72, loss = 0.73264728\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 59, loss = 0.77044978\n",
      "Iteration 60, loss = 0.71990714\n",
      "Iteration 61, loss = 0.68945464\n",
      "Iteration 62, loss = 0.88872056\n",
      "Iteration 63, loss = 0.74462412\n",
      "Iteration 64, loss = 0.73007080\n",
      "Iteration 65, loss = 0.75087548\n",
      "Iteration 66, loss = 0.71253978\n",
      "Iteration 67, loss = 0.72404014\n",
      "Iteration 68, loss = 0.73903211\n",
      "Iteration 69, loss = 0.71233038\n",
      "Iteration 70, loss = 0.73650559\n",
      "Iteration 71, loss = 0.71991576\n",
      "Iteration 72, loss = 0.73264728\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18494747\n",
      "Iteration 2, loss = 1.06046800\n",
      "Iteration 3, loss = 1.03577015\n",
      "Iteration 4, loss = 0.99223511\n",
      "Iteration 5, loss = 0.97521174\n",
      "Iteration 6, loss = 0.99535383\n",
      "Iteration 7, loss = 0.94451501\n",
      "Iteration 8, loss = 1.00859762\n",
      "Iteration 9, loss = 0.96847217\n",
      "Iteration 10, loss = 0.92647260\n",
      "Iteration 11, loss = 0.91276372\n",
      "Iteration 12, loss = 0.92777261\n",
      "Iteration 13, loss = 0.91023268\n",
      "Iteration 14, loss = 0.92940828\n",
      "Iteration 1, loss = 1.18494747\n",
      "Iteration 2, loss = 1.06046800\n",
      "Iteration 3, loss = 1.03577015\n",
      "Iteration 4, loss = 0.99223511\n",
      "Iteration 5, loss = 0.97521174\n",
      "Iteration 6, loss = 0.99535383\n",
      "Iteration 7, loss = 0.94451501\n",
      "Iteration 8, loss = 1.00859762\n",
      "Iteration 9, loss = 0.96847217\n",
      "Iteration 10, loss = 0.92647260\n",
      "Iteration 11, loss = 0.91276372\n",
      "Iteration 12, loss = 0.92777261\n",
      "Iteration 13, loss = 0.91023268\n",
      "Iteration 14, loss = 0.92940828\n",
      "Iteration 15, loss = 0.88457039\n",
      "Iteration 16, loss = 0.93610067\n",
      "Iteration 17, loss = 0.91544968\n",
      "Iteration 18, loss = 0.92344546\n",
      "Iteration 19, loss = 0.90412974\n",
      "Iteration 20, loss = 0.88608990\n",
      "Iteration 21, loss = 0.91038073\n",
      "Iteration 22, loss = 0.90183278\n",
      "Iteration 23, loss = 0.86760457\n",
      "Iteration 24, loss = 0.91234124\n",
      "Iteration 25, loss = 0.89830648\n",
      "Iteration 26, loss = 0.87415950\n",
      "Iteration 27, loss = 0.86980768\n",
      "Iteration 28, loss = 0.87216545\n",
      "Iteration 15, loss = 0.88457039\n",
      "Iteration 16, loss = 0.93610067\n",
      "Iteration 17, loss = 0.91544968\n",
      "Iteration 18, loss = 0.92344546\n",
      "Iteration 19, loss = 0.90412974\n",
      "Iteration 20, loss = 0.88608990\n",
      "Iteration 21, loss = 0.91038073\n",
      "Iteration 22, loss = 0.90183278\n",
      "Iteration 23, loss = 0.86760457\n",
      "Iteration 24, loss = 0.91234124\n",
      "Iteration 25, loss = 0.89830648\n",
      "Iteration 26, loss = 0.87415950\n",
      "Iteration 27, loss = 0.86980768\n",
      "Iteration 28, loss = 0.87216545\n",
      "Iteration 29, loss = 0.85998809\n",
      "Iteration 30, loss = 0.81857090\n",
      "Iteration 31, loss = 0.83454112\n",
      "Iteration 32, loss = 0.89131055\n",
      "Iteration 33, loss = 0.85256859\n",
      "Iteration 34, loss = 0.82989455\n",
      "Iteration 35, loss = 0.83872004\n",
      "Iteration 36, loss = 0.81852657\n",
      "Iteration 37, loss = 0.84123589\n",
      "Iteration 38, loss = 0.84153477\n",
      "Iteration 39, loss = 0.82688495\n",
      "Iteration 40, loss = 0.81203543\n",
      "Iteration 41, loss = 0.78141286\n",
      "Iteration 42, loss = 0.84099622\n",
      "Iteration 43, loss = 0.81106288\n",
      "Iteration 29, loss = 0.85998809\n",
      "Iteration 30, loss = 0.81857090\n",
      "Iteration 31, loss = 0.83454112\n",
      "Iteration 32, loss = 0.89131055\n",
      "Iteration 33, loss = 0.85256859\n",
      "Iteration 34, loss = 0.82989455\n",
      "Iteration 35, loss = 0.83872004\n",
      "Iteration 36, loss = 0.81852657\n",
      "Iteration 37, loss = 0.84123589\n",
      "Iteration 38, loss = 0.84153477\n",
      "Iteration 39, loss = 0.82688495\n",
      "Iteration 40, loss = 0.81203543\n",
      "Iteration 41, loss = 0.78141286\n",
      "Iteration 42, loss = 0.84099622\n",
      "Iteration 43, loss = 0.81106288\n",
      "Iteration 44, loss = 0.81505175\n",
      "Iteration 45, loss = 0.84914289\n",
      "Iteration 46, loss = 0.81010063\n",
      "Iteration 47, loss = 0.80779536\n",
      "Iteration 48, loss = 0.79901200\n",
      "Iteration 49, loss = 0.80448209\n",
      "Iteration 50, loss = 0.79405457\n",
      "Iteration 51, loss = 0.74687978\n",
      "Iteration 52, loss = 0.81731657\n",
      "Iteration 53, loss = 0.82120404\n",
      "Iteration 54, loss = 0.79415786\n",
      "Iteration 55, loss = 0.84684574\n",
      "Iteration 56, loss = 0.90089508\n",
      "Iteration 57, loss = 0.86916960\n",
      "Iteration 58, loss = 0.79039561\n",
      "Iteration 44, loss = 0.81505175\n",
      "Iteration 45, loss = 0.84914289\n",
      "Iteration 46, loss = 0.81010063\n",
      "Iteration 47, loss = 0.80779536\n",
      "Iteration 48, loss = 0.79901200\n",
      "Iteration 49, loss = 0.80448209\n",
      "Iteration 50, loss = 0.79405457\n",
      "Iteration 51, loss = 0.74687978\n",
      "Iteration 52, loss = 0.81731657\n",
      "Iteration 53, loss = 0.82120404\n",
      "Iteration 54, loss = 0.79415786\n",
      "Iteration 55, loss = 0.84684574\n",
      "Iteration 56, loss = 0.90089508\n",
      "Iteration 57, loss = 0.86916960\n",
      "Iteration 58, loss = 0.79039561\n",
      "Iteration 59, loss = 0.79132001\n",
      "Iteration 60, loss = 0.78861532\n",
      "Iteration 61, loss = 0.74550734\n",
      "Iteration 62, loss = 0.77603094\n",
      "Iteration 63, loss = 0.82641299\n",
      "Iteration 64, loss = 0.79117877\n",
      "Iteration 65, loss = 0.77794732\n",
      "Iteration 66, loss = 0.80923994\n",
      "Iteration 67, loss = 0.79144063\n",
      "Iteration 68, loss = 0.76041851\n",
      "Iteration 69, loss = 0.77731833\n",
      "Iteration 70, loss = 0.74849003\n",
      "Iteration 71, loss = 0.77570345\n",
      "Iteration 59, loss = 0.79132001\n",
      "Iteration 60, loss = 0.78861532\n",
      "Iteration 61, loss = 0.74550734\n",
      "Iteration 62, loss = 0.77603094\n",
      "Iteration 63, loss = 0.82641299\n",
      "Iteration 64, loss = 0.79117877\n",
      "Iteration 65, loss = 0.77794732\n",
      "Iteration 66, loss = 0.80923994\n",
      "Iteration 67, loss = 0.79144063\n",
      "Iteration 68, loss = 0.76041851\n",
      "Iteration 69, loss = 0.77731833\n",
      "Iteration 70, loss = 0.74849003\n",
      "Iteration 71, loss = 0.77570345\n",
      "Iteration 72, loss = 0.75937629\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17152280\n",
      "Iteration 2, loss = 1.13389529\n",
      "Iteration 3, loss = 0.99588971\n",
      "Iteration 4, loss = 0.99337551\n",
      "Iteration 5, loss = 1.05065138\n",
      "Iteration 6, loss = 1.00765456\n",
      "Iteration 7, loss = 1.03801894\n",
      "Iteration 8, loss = 1.00976351\n",
      "Iteration 9, loss = 1.01360264\n",
      "Iteration 10, loss = 1.00132804\n",
      "Iteration 1, loss = 1.23265771\n",
      "Iteration 2, loss = 1.02444022\n",
      "Iteration 72, loss = 0.75937629\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.17152280\n",
      "Iteration 2, loss = 1.13389529\n",
      "Iteration 3, loss = 0.99588971\n",
      "Iteration 4, loss = 0.99337551\n",
      "Iteration 5, loss = 1.05065138\n",
      "Iteration 6, loss = 1.00765456\n",
      "Iteration 7, loss = 1.03801894\n",
      "Iteration 8, loss = 1.00976351\n",
      "Iteration 9, loss = 1.01360264\n",
      "Iteration 10, loss = 1.00132804\n",
      "Iteration 1, loss = 1.23265771\n",
      "Iteration 2, loss = 1.02444022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.99592404\n",
      "Iteration 4, loss = 0.93054195\n",
      "Iteration 5, loss = 0.95878147\n",
      "Iteration 6, loss = 0.91574666\n",
      "Iteration 7, loss = 0.95656622\n",
      "Iteration 8, loss = 0.91306738\n",
      "Iteration 9, loss = 0.95178273\n",
      "Iteration 10, loss = 0.92675678\n",
      "Iteration 1, loss = 1.21745615\n",
      "Iteration 2, loss = 1.09299875\n",
      "Iteration 3, loss = 1.11788078\n",
      "Iteration 4, loss = 1.05505725\n",
      "Iteration 3, loss = 0.99592404\n",
      "Iteration 4, loss = 0.93054195\n",
      "Iteration 5, loss = 0.95878147\n",
      "Iteration 6, loss = 0.91574666\n",
      "Iteration 7, loss = 0.95656622\n",
      "Iteration 8, loss = 0.91306738\n",
      "Iteration 9, loss = 0.95178273\n",
      "Iteration 10, loss = 0.92675678\n",
      "Iteration 1, loss = 1.21745615\n",
      "Iteration 2, loss = 1.09299875\n",
      "Iteration 3, loss = 1.11788078\n",
      "Iteration 4, loss = 1.05505725\n",
      "Iteration 5, loss = 1.00615236\n",
      "Iteration 6, loss = 1.01880439\n",
      "Iteration 7, loss = 0.97462252\n",
      "Iteration 8, loss = 0.95473290\n",
      "Iteration 9, loss = 0.96336396\n",
      "Iteration 10, loss = 0.95769218\n",
      "Iteration 1, loss = 1.23623299\n",
      "Iteration 2, loss = 1.07609280\n",
      "Iteration 3, loss = 1.06885153\n",
      "Iteration 4, loss = 1.03343154\n",
      "Iteration 5, loss = 1.08316702\n",
      "Iteration 6, loss = 1.00479281\n",
      "Iteration 5, loss = 1.00615236\n",
      "Iteration 6, loss = 1.01880439\n",
      "Iteration 7, loss = 0.97462252\n",
      "Iteration 8, loss = 0.95473290\n",
      "Iteration 9, loss = 0.96336396\n",
      "Iteration 10, loss = 0.95769218\n",
      "Iteration 1, loss = 1.23623299\n",
      "Iteration 2, loss = 1.07609280\n",
      "Iteration 3, loss = 1.06885153\n",
      "Iteration 4, loss = 1.03343154\n",
      "Iteration 5, loss = 1.08316702\n",
      "Iteration 6, loss = 1.00479281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.95210327\n",
      "Iteration 8, loss = 1.00709137\n",
      "Iteration 9, loss = 0.99833658\n",
      "Iteration 10, loss = 0.97196058\n",
      "Iteration 1, loss = 1.20234794\n",
      "Iteration 2, loss = 1.10104869\n",
      "Iteration 3, loss = 1.10704601\n",
      "Iteration 4, loss = 1.08291323\n",
      "Iteration 5, loss = 1.05781381\n",
      "Iteration 6, loss = 1.12372702\n",
      "Iteration 7, loss = 0.96670410\n",
      "Iteration 8, loss = 0.99437456\n",
      "Iteration 9, loss = 1.00032436\n",
      "Iteration 7, loss = 0.95210327\n",
      "Iteration 8, loss = 1.00709137\n",
      "Iteration 9, loss = 0.99833658\n",
      "Iteration 10, loss = 0.97196058\n",
      "Iteration 1, loss = 1.20234794\n",
      "Iteration 2, loss = 1.10104869\n",
      "Iteration 3, loss = 1.10704601\n",
      "Iteration 4, loss = 1.08291323\n",
      "Iteration 5, loss = 1.05781381\n",
      "Iteration 6, loss = 1.12372702\n",
      "Iteration 7, loss = 0.96670410\n",
      "Iteration 8, loss = 0.99437456\n",
      "Iteration 9, loss = 1.00032436\n",
      "Iteration 10, loss = 1.05513347\n",
      "Iteration 1, loss = 1.17152280\n",
      "Iteration 2, loss = 1.13389529\n",
      "Iteration 3, loss = 0.99588971\n",
      "Iteration 4, loss = 0.99337551\n",
      "Iteration 5, loss = 1.05065138\n",
      "Iteration 6, loss = 1.00765456\n",
      "Iteration 7, loss = 1.03801894\n",
      "Iteration 8, loss = 1.00976351\n",
      "Iteration 9, loss = 1.01360264\n",
      "Iteration 10, loss = 1.00132804\n",
      "Iteration 11, loss = 0.99219069\n",
      "Iteration 12, loss = 0.97336457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.05513347\n",
      "Iteration 1, loss = 1.17152280\n",
      "Iteration 2, loss = 1.13389529\n",
      "Iteration 3, loss = 0.99588971\n",
      "Iteration 4, loss = 0.99337551\n",
      "Iteration 5, loss = 1.05065138\n",
      "Iteration 6, loss = 1.00765456\n",
      "Iteration 7, loss = 1.03801894\n",
      "Iteration 8, loss = 1.00976351\n",
      "Iteration 9, loss = 1.01360264\n",
      "Iteration 10, loss = 1.00132804\n",
      "Iteration 11, loss = 0.99219069\n",
      "Iteration 12, loss = 0.97336457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 1.01950502\n",
      "Iteration 14, loss = 0.97638569\n",
      "Iteration 15, loss = 1.00915415\n",
      "Iteration 16, loss = 0.98766040\n",
      "Iteration 17, loss = 0.97628844\n",
      "Iteration 18, loss = 0.98106211\n",
      "Iteration 19, loss = 0.98630764\n",
      "Iteration 20, loss = 0.95554336\n",
      "Iteration 21, loss = 0.96649088\n",
      "Iteration 22, loss = 0.96504903\n",
      "Iteration 23, loss = 0.98109111\n",
      "Iteration 24, loss = 0.94311322\n",
      "Iteration 25, loss = 0.94718785\n",
      "Iteration 26, loss = 0.96048983\n",
      "Iteration 13, loss = 1.01950502\n",
      "Iteration 14, loss = 0.97638569\n",
      "Iteration 15, loss = 1.00915415\n",
      "Iteration 16, loss = 0.98766040\n",
      "Iteration 17, loss = 0.97628844\n",
      "Iteration 18, loss = 0.98106211\n",
      "Iteration 19, loss = 0.98630764\n",
      "Iteration 20, loss = 0.95554336\n",
      "Iteration 21, loss = 0.96649088\n",
      "Iteration 22, loss = 0.96504903\n",
      "Iteration 23, loss = 0.98109111\n",
      "Iteration 24, loss = 0.94311322\n",
      "Iteration 25, loss = 0.94718785\n",
      "Iteration 26, loss = 0.96048983\n",
      "Iteration 27, loss = 0.95790952\n",
      "Iteration 28, loss = 0.95355535\n",
      "Iteration 29, loss = 0.95953396\n",
      "Iteration 30, loss = 0.95148470\n",
      "Iteration 31, loss = 1.00212414\n",
      "Iteration 32, loss = 0.93736586\n",
      "Iteration 33, loss = 0.93655888\n",
      "Iteration 34, loss = 0.94627827\n",
      "Iteration 35, loss = 0.95209909\n",
      "Iteration 36, loss = 0.92644539\n",
      "Iteration 37, loss = 0.93522973\n",
      "Iteration 38, loss = 0.95354515\n",
      "Iteration 39, loss = 1.05355673\n",
      "Iteration 40, loss = 1.01425270\n",
      "Iteration 41, loss = 0.96898778\n",
      "Iteration 27, loss = 0.95790952\n",
      "Iteration 28, loss = 0.95355535\n",
      "Iteration 29, loss = 0.95953396\n",
      "Iteration 30, loss = 0.95148470\n",
      "Iteration 31, loss = 1.00212414\n",
      "Iteration 32, loss = 0.93736586\n",
      "Iteration 33, loss = 0.93655888\n",
      "Iteration 34, loss = 0.94627827\n",
      "Iteration 35, loss = 0.95209909\n",
      "Iteration 36, loss = 0.92644539\n",
      "Iteration 37, loss = 0.93522973\n",
      "Iteration 38, loss = 0.95354515\n",
      "Iteration 39, loss = 1.05355673\n",
      "Iteration 40, loss = 1.01425270\n",
      "Iteration 41, loss = 0.96898778\n",
      "Iteration 42, loss = 0.94193583\n",
      "Iteration 43, loss = 0.95419439\n",
      "Iteration 44, loss = 0.94921195\n",
      "Iteration 45, loss = 0.95586333\n",
      "Iteration 46, loss = 0.95028555\n",
      "Iteration 47, loss = 0.94683412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23265771\n",
      "Iteration 2, loss = 1.02444022\n",
      "Iteration 3, loss = 0.99592404\n",
      "Iteration 4, loss = 0.93054195\n",
      "Iteration 5, loss = 0.95878147\n",
      "Iteration 6, loss = 0.91574666\n",
      "Iteration 7, loss = 0.95656622\n",
      "Iteration 8, loss = 0.91306738\n",
      "Iteration 42, loss = 0.94193583\n",
      "Iteration 43, loss = 0.95419439\n",
      "Iteration 44, loss = 0.94921195\n",
      "Iteration 45, loss = 0.95586333\n",
      "Iteration 46, loss = 0.95028555\n",
      "Iteration 47, loss = 0.94683412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23265771\n",
      "Iteration 2, loss = 1.02444022\n",
      "Iteration 3, loss = 0.99592404\n",
      "Iteration 4, loss = 0.93054195\n",
      "Iteration 5, loss = 0.95878147\n",
      "Iteration 6, loss = 0.91574666\n",
      "Iteration 7, loss = 0.95656622\n",
      "Iteration 8, loss = 0.91306738\n",
      "Iteration 9, loss = 0.95178273\n",
      "Iteration 10, loss = 0.92675678\n",
      "Iteration 11, loss = 0.97483455\n",
      "Iteration 12, loss = 0.92350830\n",
      "Iteration 13, loss = 0.97797100\n",
      "Iteration 14, loss = 0.97937520\n",
      "Iteration 15, loss = 0.88343854\n",
      "Iteration 16, loss = 1.00269666\n",
      "Iteration 17, loss = 0.91922722\n",
      "Iteration 18, loss = 0.92977166\n",
      "Iteration 19, loss = 0.93736938\n",
      "Iteration 20, loss = 0.97688062\n",
      "Iteration 21, loss = 0.97421602\n",
      "Iteration 22, loss = 0.92918082\n",
      "Iteration 9, loss = 0.95178273\n",
      "Iteration 10, loss = 0.92675678\n",
      "Iteration 11, loss = 0.97483455\n",
      "Iteration 12, loss = 0.92350830\n",
      "Iteration 13, loss = 0.97797100\n",
      "Iteration 14, loss = 0.97937520\n",
      "Iteration 15, loss = 0.88343854\n",
      "Iteration 16, loss = 1.00269666\n",
      "Iteration 17, loss = 0.91922722\n",
      "Iteration 18, loss = 0.92977166\n",
      "Iteration 19, loss = 0.93736938\n",
      "Iteration 20, loss = 0.97688062\n",
      "Iteration 21, loss = 0.97421602\n",
      "Iteration 22, loss = 0.92918082\n",
      "Iteration 23, loss = 0.90589565\n",
      "Iteration 24, loss = 0.89801371\n",
      "Iteration 25, loss = 0.87893649\n",
      "Iteration 26, loss = 0.88917708\n",
      "Iteration 27, loss = 0.94442877\n",
      "Iteration 28, loss = 0.89693594\n",
      "Iteration 29, loss = 0.89146594\n",
      "Iteration 30, loss = 0.95863098\n",
      "Iteration 31, loss = 0.91332362\n",
      "Iteration 32, loss = 0.89775186\n",
      "Iteration 33, loss = 0.89800846\n",
      "Iteration 34, loss = 0.91752854\n",
      "Iteration 35, loss = 0.98061206\n",
      "Iteration 36, loss = 0.87608874\n",
      "Iteration 23, loss = 0.90589565\n",
      "Iteration 24, loss = 0.89801371\n",
      "Iteration 25, loss = 0.87893649\n",
      "Iteration 26, loss = 0.88917708\n",
      "Iteration 27, loss = 0.94442877\n",
      "Iteration 28, loss = 0.89693594\n",
      "Iteration 29, loss = 0.89146594\n",
      "Iteration 30, loss = 0.95863098\n",
      "Iteration 31, loss = 0.91332362\n",
      "Iteration 32, loss = 0.89775186\n",
      "Iteration 33, loss = 0.89800846\n",
      "Iteration 34, loss = 0.91752854\n",
      "Iteration 35, loss = 0.98061206\n",
      "Iteration 36, loss = 0.87608874\n",
      "Iteration 37, loss = 0.88006313\n",
      "Iteration 38, loss = 0.85391785\n",
      "Iteration 39, loss = 0.91329125\n",
      "Iteration 40, loss = 0.88490494\n",
      "Iteration 41, loss = 0.85934002\n",
      "Iteration 42, loss = 0.83589767\n",
      "Iteration 43, loss = 0.87197768\n",
      "Iteration 44, loss = 0.88385675\n",
      "Iteration 45, loss = 0.89200016\n",
      "Iteration 46, loss = 0.87413610\n",
      "Iteration 47, loss = 0.86001430\n",
      "Iteration 48, loss = 0.87919133\n",
      "Iteration 49, loss = 0.89814725\n",
      "Iteration 50, loss = 0.93090665\n",
      "Iteration 37, loss = 0.88006313\n",
      "Iteration 38, loss = 0.85391785\n",
      "Iteration 39, loss = 0.91329125\n",
      "Iteration 40, loss = 0.88490494\n",
      "Iteration 41, loss = 0.85934002\n",
      "Iteration 42, loss = 0.83589767\n",
      "Iteration 43, loss = 0.87197768\n",
      "Iteration 44, loss = 0.88385675\n",
      "Iteration 45, loss = 0.89200016\n",
      "Iteration 46, loss = 0.87413610\n",
      "Iteration 47, loss = 0.86001430\n",
      "Iteration 48, loss = 0.87919133\n",
      "Iteration 49, loss = 0.89814725\n",
      "Iteration 50, loss = 0.93090665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21745615\n",
      "Iteration 2, loss = 1.09299875\n",
      "Iteration 3, loss = 1.11788078\n",
      "Iteration 4, loss = 1.05505725\n",
      "Iteration 5, loss = 1.00615236\n",
      "Iteration 6, loss = 1.01880439\n",
      "Iteration 7, loss = 0.97462252\n",
      "Iteration 8, loss = 0.95473290\n",
      "Iteration 9, loss = 0.96336396\n",
      "Iteration 10, loss = 0.95769218\n",
      "Iteration 11, loss = 1.00654931\n",
      "Iteration 12, loss = 0.96773883\n",
      "Iteration 1, loss = 1.21745615\n",
      "Iteration 2, loss = 1.09299875\n",
      "Iteration 3, loss = 1.11788078\n",
      "Iteration 4, loss = 1.05505725\n",
      "Iteration 5, loss = 1.00615236\n",
      "Iteration 6, loss = 1.01880439\n",
      "Iteration 7, loss = 0.97462252\n",
      "Iteration 8, loss = 0.95473290\n",
      "Iteration 9, loss = 0.96336396\n",
      "Iteration 10, loss = 0.95769218\n",
      "Iteration 11, loss = 1.00654931\n",
      "Iteration 12, loss = 0.96773883\n",
      "Iteration 13, loss = 0.95912044\n",
      "Iteration 14, loss = 1.03625164\n",
      "Iteration 15, loss = 0.97557922\n",
      "Iteration 16, loss = 0.95084254\n",
      "Iteration 17, loss = 0.97221120\n",
      "Iteration 18, loss = 0.97666691\n",
      "Iteration 19, loss = 0.98676547\n",
      "Iteration 20, loss = 0.96853624\n",
      "Iteration 21, loss = 0.95439317\n",
      "Iteration 22, loss = 0.97555654\n",
      "Iteration 23, loss = 0.92826109\n",
      "Iteration 24, loss = 0.95364035\n",
      "Iteration 25, loss = 0.93340506\n",
      "Iteration 26, loss = 0.96381878\n",
      "Iteration 27, loss = 0.94543446\n",
      "Iteration 28, loss = 0.93406931\n",
      "Iteration 13, loss = 0.95912044\n",
      "Iteration 14, loss = 1.03625164\n",
      "Iteration 15, loss = 0.97557922\n",
      "Iteration 16, loss = 0.95084254\n",
      "Iteration 17, loss = 0.97221120\n",
      "Iteration 18, loss = 0.97666691\n",
      "Iteration 19, loss = 0.98676547\n",
      "Iteration 20, loss = 0.96853624\n",
      "Iteration 21, loss = 0.95439317\n",
      "Iteration 22, loss = 0.97555654\n",
      "Iteration 23, loss = 0.92826109\n",
      "Iteration 24, loss = 0.95364035\n",
      "Iteration 25, loss = 0.93340506\n",
      "Iteration 26, loss = 0.96381878\n",
      "Iteration 27, loss = 0.94543446\n",
      "Iteration 28, loss = 0.93406931\n",
      "Iteration 29, loss = 0.95586047\n",
      "Iteration 30, loss = 0.96084730\n",
      "Iteration 31, loss = 0.95584257\n",
      "Iteration 32, loss = 0.89602234\n",
      "Iteration 33, loss = 1.01536751\n",
      "Iteration 34, loss = 0.97008216\n",
      "Iteration 35, loss = 0.94848762\n",
      "Iteration 36, loss = 0.91525614\n",
      "Iteration 37, loss = 0.92238521\n",
      "Iteration 38, loss = 0.95489261\n",
      "Iteration 39, loss = 0.92723123\n",
      "Iteration 40, loss = 0.91033003\n",
      "Iteration 41, loss = 0.89915284\n",
      "Iteration 42, loss = 0.92561082\n",
      "Iteration 29, loss = 0.95586047\n",
      "Iteration 30, loss = 0.96084730\n",
      "Iteration 31, loss = 0.95584257\n",
      "Iteration 32, loss = 0.89602234\n",
      "Iteration 33, loss = 1.01536751\n",
      "Iteration 34, loss = 0.97008216\n",
      "Iteration 35, loss = 0.94848762\n",
      "Iteration 36, loss = 0.91525614\n",
      "Iteration 37, loss = 0.92238521\n",
      "Iteration 38, loss = 0.95489261\n",
      "Iteration 39, loss = 0.92723123\n",
      "Iteration 40, loss = 0.91033003\n",
      "Iteration 41, loss = 0.89915284\n",
      "Iteration 42, loss = 0.92561082\n",
      "Iteration 43, loss = 0.93480765\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23623299\n",
      "Iteration 2, loss = 1.07609280\n",
      "Iteration 3, loss = 1.06885153\n",
      "Iteration 4, loss = 1.03343154\n",
      "Iteration 5, loss = 1.08316702\n",
      "Iteration 6, loss = 1.00479281\n",
      "Iteration 7, loss = 0.95210327\n",
      "Iteration 8, loss = 1.00709137\n",
      "Iteration 9, loss = 0.99833658\n",
      "Iteration 10, loss = 0.97196058\n",
      "Iteration 11, loss = 0.99143630\n",
      "Iteration 43, loss = 0.93480765\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23623299\n",
      "Iteration 2, loss = 1.07609280\n",
      "Iteration 3, loss = 1.06885153\n",
      "Iteration 4, loss = 1.03343154\n",
      "Iteration 5, loss = 1.08316702\n",
      "Iteration 6, loss = 1.00479281\n",
      "Iteration 7, loss = 0.95210327\n",
      "Iteration 8, loss = 1.00709137\n",
      "Iteration 9, loss = 0.99833658\n",
      "Iteration 10, loss = 0.97196058\n",
      "Iteration 11, loss = 0.99143630\n",
      "Iteration 12, loss = 0.96585212\n",
      "Iteration 13, loss = 1.00713308\n",
      "Iteration 14, loss = 1.04963401\n",
      "Iteration 15, loss = 1.00736300\n",
      "Iteration 16, loss = 1.01926963\n",
      "Iteration 17, loss = 1.01789931\n",
      "Iteration 18, loss = 1.05151478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20234794\n",
      "Iteration 2, loss = 1.10104869\n",
      "Iteration 3, loss = 1.10704601\n",
      "Iteration 4, loss = 1.08291323\n",
      "Iteration 5, loss = 1.05781381\n",
      "Iteration 12, loss = 0.96585212\n",
      "Iteration 13, loss = 1.00713308\n",
      "Iteration 14, loss = 1.04963401\n",
      "Iteration 15, loss = 1.00736300\n",
      "Iteration 16, loss = 1.01926963\n",
      "Iteration 17, loss = 1.01789931\n",
      "Iteration 18, loss = 1.05151478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20234794\n",
      "Iteration 2, loss = 1.10104869\n",
      "Iteration 3, loss = 1.10704601\n",
      "Iteration 4, loss = 1.08291323\n",
      "Iteration 5, loss = 1.05781381\n",
      "Iteration 6, loss = 1.12372702\n",
      "Iteration 7, loss = 0.96670410\n",
      "Iteration 8, loss = 0.99437456\n",
      "Iteration 9, loss = 1.00032436\n",
      "Iteration 10, loss = 1.05513347\n",
      "Iteration 11, loss = 1.04439004\n",
      "Iteration 12, loss = 1.00295117\n",
      "Iteration 13, loss = 0.97956460\n",
      "Iteration 14, loss = 1.00657682\n",
      "Iteration 15, loss = 0.96446968\n",
      "Iteration 16, loss = 1.02255037\n",
      "Iteration 17, loss = 0.96031411\n",
      "Iteration 18, loss = 0.96137467\n",
      "Iteration 6, loss = 1.12372702\n",
      "Iteration 7, loss = 0.96670410\n",
      "Iteration 8, loss = 0.99437456\n",
      "Iteration 9, loss = 1.00032436\n",
      "Iteration 10, loss = 1.05513347\n",
      "Iteration 11, loss = 1.04439004\n",
      "Iteration 12, loss = 1.00295117\n",
      "Iteration 13, loss = 0.97956460\n",
      "Iteration 14, loss = 1.00657682\n",
      "Iteration 15, loss = 0.96446968\n",
      "Iteration 16, loss = 1.02255037\n",
      "Iteration 17, loss = 0.96031411\n",
      "Iteration 18, loss = 0.96137467\n",
      "Iteration 19, loss = 0.99310278\n",
      "Iteration 20, loss = 0.99222022\n",
      "Iteration 21, loss = 1.02529155\n",
      "Iteration 22, loss = 0.99757475\n",
      "Iteration 23, loss = 0.98955862\n",
      "Iteration 24, loss = 0.99826708\n",
      "Iteration 25, loss = 0.96390635\n",
      "Iteration 26, loss = 0.97496804\n",
      "Iteration 27, loss = 1.02761077\n",
      "Iteration 28, loss = 0.94148724\n",
      "Iteration 29, loss = 0.93692136\n",
      "Iteration 30, loss = 0.98880170\n",
      "Iteration 31, loss = 0.91830194\n",
      "Iteration 32, loss = 1.03377087\n",
      "Iteration 33, loss = 1.05020398\n",
      "Iteration 34, loss = 0.94828524\n",
      "Iteration 19, loss = 0.99310278\n",
      "Iteration 20, loss = 0.99222022\n",
      "Iteration 21, loss = 1.02529155\n",
      "Iteration 22, loss = 0.99757475\n",
      "Iteration 23, loss = 0.98955862\n",
      "Iteration 24, loss = 0.99826708\n",
      "Iteration 25, loss = 0.96390635\n",
      "Iteration 26, loss = 0.97496804\n",
      "Iteration 27, loss = 1.02761077\n",
      "Iteration 28, loss = 0.94148724\n",
      "Iteration 29, loss = 0.93692136\n",
      "Iteration 30, loss = 0.98880170\n",
      "Iteration 31, loss = 0.91830194\n",
      "Iteration 32, loss = 1.03377087\n",
      "Iteration 33, loss = 1.05020398\n",
      "Iteration 34, loss = 0.94828524\n",
      "Iteration 35, loss = 1.03503267\n",
      "Iteration 36, loss = 0.98485679\n",
      "Iteration 37, loss = 0.97215870\n",
      "Iteration 38, loss = 0.94875624\n",
      "Iteration 39, loss = 0.95195463\n",
      "Iteration 40, loss = 0.95509849\n",
      "Iteration 41, loss = 0.93835324\n",
      "Iteration 42, loss = 0.91347683\n",
      "Iteration 43, loss = 0.91656404\n",
      "Iteration 44, loss = 0.88088612\n",
      "Iteration 45, loss = 0.88078622\n",
      "Iteration 46, loss = 0.91308783\n",
      "Iteration 47, loss = 0.93672313\n",
      "Iteration 48, loss = 0.91058544\n",
      "Iteration 49, loss = 0.96178541\n",
      "Iteration 35, loss = 1.03503267\n",
      "Iteration 36, loss = 0.98485679\n",
      "Iteration 37, loss = 0.97215870\n",
      "Iteration 38, loss = 0.94875624\n",
      "Iteration 39, loss = 0.95195463\n",
      "Iteration 40, loss = 0.95509849\n",
      "Iteration 41, loss = 0.93835324\n",
      "Iteration 42, loss = 0.91347683\n",
      "Iteration 43, loss = 0.91656404\n",
      "Iteration 44, loss = 0.88088612\n",
      "Iteration 45, loss = 0.88078622\n",
      "Iteration 46, loss = 0.91308783\n",
      "Iteration 47, loss = 0.93672313\n",
      "Iteration 48, loss = 0.91058544\n",
      "Iteration 49, loss = 0.96178541\n",
      "Iteration 50, loss = 0.93107017\n",
      "Iteration 1, loss = 1.17152280\n",
      "Iteration 2, loss = 1.13389529\n",
      "Iteration 3, loss = 0.99588971\n",
      "Iteration 4, loss = 0.99337551\n",
      "Iteration 5, loss = 1.05065138\n",
      "Iteration 6, loss = 1.00765456\n",
      "Iteration 7, loss = 1.03801894\n",
      "Iteration 8, loss = 1.00976351\n",
      "Iteration 9, loss = 1.01360264\n",
      "Iteration 10, loss = 1.00132804\n",
      "Iteration 11, loss = 0.99219069\n",
      "Iteration 50, loss = 0.93107017\n",
      "Iteration 1, loss = 1.17152280\n",
      "Iteration 2, loss = 1.13389529\n",
      "Iteration 3, loss = 0.99588971\n",
      "Iteration 4, loss = 0.99337551\n",
      "Iteration 5, loss = 1.05065138\n",
      "Iteration 6, loss = 1.00765456\n",
      "Iteration 7, loss = 1.03801894\n",
      "Iteration 8, loss = 1.00976351\n",
      "Iteration 9, loss = 1.01360264\n",
      "Iteration 10, loss = 1.00132804\n",
      "Iteration 11, loss = 0.99219069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.97336457\n",
      "Iteration 13, loss = 1.01950502\n",
      "Iteration 14, loss = 0.97638569\n",
      "Iteration 15, loss = 1.00915415\n",
      "Iteration 16, loss = 0.98766040\n",
      "Iteration 17, loss = 0.97628844\n",
      "Iteration 18, loss = 0.98106211\n",
      "Iteration 19, loss = 0.98630764\n",
      "Iteration 20, loss = 0.95554336\n",
      "Iteration 21, loss = 0.96649088\n",
      "Iteration 22, loss = 0.96504903\n",
      "Iteration 23, loss = 0.98109111\n",
      "Iteration 24, loss = 0.94311322\n",
      "Iteration 25, loss = 0.94718785\n",
      "Iteration 12, loss = 0.97336457\n",
      "Iteration 13, loss = 1.01950502\n",
      "Iteration 14, loss = 0.97638569\n",
      "Iteration 15, loss = 1.00915415\n",
      "Iteration 16, loss = 0.98766040\n",
      "Iteration 17, loss = 0.97628844\n",
      "Iteration 18, loss = 0.98106211\n",
      "Iteration 19, loss = 0.98630764\n",
      "Iteration 20, loss = 0.95554336\n",
      "Iteration 21, loss = 0.96649088\n",
      "Iteration 22, loss = 0.96504903\n",
      "Iteration 23, loss = 0.98109111\n",
      "Iteration 24, loss = 0.94311322\n",
      "Iteration 25, loss = 0.94718785\n",
      "Iteration 26, loss = 0.96048983\n",
      "Iteration 27, loss = 0.95790952\n",
      "Iteration 28, loss = 0.95355535\n",
      "Iteration 29, loss = 0.95953396\n",
      "Iteration 30, loss = 0.95148470\n",
      "Iteration 31, loss = 1.00212414\n",
      "Iteration 32, loss = 0.93736586\n",
      "Iteration 33, loss = 0.93655888\n",
      "Iteration 34, loss = 0.94627827\n",
      "Iteration 35, loss = 0.95209909\n",
      "Iteration 36, loss = 0.92644539\n",
      "Iteration 37, loss = 0.93522973\n",
      "Iteration 38, loss = 0.95354515\n",
      "Iteration 39, loss = 1.05355673\n",
      "Iteration 26, loss = 0.96048983\n",
      "Iteration 27, loss = 0.95790952\n",
      "Iteration 28, loss = 0.95355535\n",
      "Iteration 29, loss = 0.95953396\n",
      "Iteration 30, loss = 0.95148470\n",
      "Iteration 31, loss = 1.00212414\n",
      "Iteration 32, loss = 0.93736586\n",
      "Iteration 33, loss = 0.93655888\n",
      "Iteration 34, loss = 0.94627827\n",
      "Iteration 35, loss = 0.95209909\n",
      "Iteration 36, loss = 0.92644539\n",
      "Iteration 37, loss = 0.93522973\n",
      "Iteration 38, loss = 0.95354515\n",
      "Iteration 39, loss = 1.05355673\n",
      "Iteration 40, loss = 1.01425270\n",
      "Iteration 41, loss = 0.96898778\n",
      "Iteration 42, loss = 0.94193583\n",
      "Iteration 43, loss = 0.95419439\n",
      "Iteration 44, loss = 0.94921195\n",
      "Iteration 45, loss = 0.95586333\n",
      "Iteration 46, loss = 0.95028555\n",
      "Iteration 47, loss = 0.94683412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23265771\n",
      "Iteration 2, loss = 1.02444022\n",
      "Iteration 3, loss = 0.99592404\n",
      "Iteration 4, loss = 0.93054195\n",
      "Iteration 5, loss = 0.95878147\n",
      "Iteration 6, loss = 0.91574666\n",
      "Iteration 7, loss = 0.95656622\n",
      "Iteration 40, loss = 1.01425270\n",
      "Iteration 41, loss = 0.96898778\n",
      "Iteration 42, loss = 0.94193583\n",
      "Iteration 43, loss = 0.95419439\n",
      "Iteration 44, loss = 0.94921195\n",
      "Iteration 45, loss = 0.95586333\n",
      "Iteration 46, loss = 0.95028555\n",
      "Iteration 47, loss = 0.94683412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23265771\n",
      "Iteration 2, loss = 1.02444022\n",
      "Iteration 3, loss = 0.99592404\n",
      "Iteration 4, loss = 0.93054195\n",
      "Iteration 5, loss = 0.95878147\n",
      "Iteration 6, loss = 0.91574666\n",
      "Iteration 7, loss = 0.95656622\n",
      "Iteration 8, loss = 0.91306738\n",
      "Iteration 9, loss = 0.95178273\n",
      "Iteration 10, loss = 0.92675678\n",
      "Iteration 11, loss = 0.97483455\n",
      "Iteration 12, loss = 0.92350830\n",
      "Iteration 13, loss = 0.97797100\n",
      "Iteration 14, loss = 0.97937520\n",
      "Iteration 15, loss = 0.88343854\n",
      "Iteration 16, loss = 1.00269666\n",
      "Iteration 17, loss = 0.91922722\n",
      "Iteration 18, loss = 0.92977166\n",
      "Iteration 19, loss = 0.93736938\n",
      "Iteration 20, loss = 0.97688062\n",
      "Iteration 21, loss = 0.97421602\n",
      "Iteration 22, loss = 0.92918082\n",
      "Iteration 8, loss = 0.91306738\n",
      "Iteration 9, loss = 0.95178273\n",
      "Iteration 10, loss = 0.92675678\n",
      "Iteration 11, loss = 0.97483455\n",
      "Iteration 12, loss = 0.92350830\n",
      "Iteration 13, loss = 0.97797100\n",
      "Iteration 14, loss = 0.97937520\n",
      "Iteration 15, loss = 0.88343854\n",
      "Iteration 16, loss = 1.00269666\n",
      "Iteration 17, loss = 0.91922722\n",
      "Iteration 18, loss = 0.92977166\n",
      "Iteration 19, loss = 0.93736938\n",
      "Iteration 20, loss = 0.97688062\n",
      "Iteration 21, loss = 0.97421602\n",
      "Iteration 22, loss = 0.92918082\n",
      "Iteration 23, loss = 0.90589565\n",
      "Iteration 24, loss = 0.89801371\n",
      "Iteration 25, loss = 0.87893649\n",
      "Iteration 26, loss = 0.88917708\n",
      "Iteration 27, loss = 0.94442877\n",
      "Iteration 28, loss = 0.89693594\n",
      "Iteration 29, loss = 0.89146594\n",
      "Iteration 30, loss = 0.95863098\n",
      "Iteration 31, loss = 0.91332362\n",
      "Iteration 32, loss = 0.89775186\n",
      "Iteration 33, loss = 0.89800846\n",
      "Iteration 34, loss = 0.91752854\n",
      "Iteration 35, loss = 0.98061206\n",
      "Iteration 36, loss = 0.87608874\n",
      "Iteration 37, loss = 0.88006313\n",
      "Iteration 23, loss = 0.90589565\n",
      "Iteration 24, loss = 0.89801371\n",
      "Iteration 25, loss = 0.87893649\n",
      "Iteration 26, loss = 0.88917708\n",
      "Iteration 27, loss = 0.94442877\n",
      "Iteration 28, loss = 0.89693594\n",
      "Iteration 29, loss = 0.89146594\n",
      "Iteration 30, loss = 0.95863098\n",
      "Iteration 31, loss = 0.91332362\n",
      "Iteration 32, loss = 0.89775186\n",
      "Iteration 33, loss = 0.89800846\n",
      "Iteration 34, loss = 0.91752854\n",
      "Iteration 35, loss = 0.98061206\n",
      "Iteration 36, loss = 0.87608874\n",
      "Iteration 37, loss = 0.88006313\n",
      "Iteration 38, loss = 0.85391785\n",
      "Iteration 39, loss = 0.91329125\n",
      "Iteration 40, loss = 0.88490494\n",
      "Iteration 41, loss = 0.85934002\n",
      "Iteration 42, loss = 0.83589767\n",
      "Iteration 43, loss = 0.87197768\n",
      "Iteration 44, loss = 0.88385675\n",
      "Iteration 45, loss = 0.89200016\n",
      "Iteration 46, loss = 0.87413610\n",
      "Iteration 47, loss = 0.86001430\n",
      "Iteration 48, loss = 0.87919133\n",
      "Iteration 49, loss = 0.89814725\n",
      "Iteration 50, loss = 0.93090665\n",
      "Iteration 51, loss = 0.88662466\n",
      "Iteration 52, loss = 0.85304866\n",
      "Iteration 38, loss = 0.85391785\n",
      "Iteration 39, loss = 0.91329125\n",
      "Iteration 40, loss = 0.88490494\n",
      "Iteration 41, loss = 0.85934002\n",
      "Iteration 42, loss = 0.83589767\n",
      "Iteration 43, loss = 0.87197768\n",
      "Iteration 44, loss = 0.88385675\n",
      "Iteration 45, loss = 0.89200016\n",
      "Iteration 46, loss = 0.87413610\n",
      "Iteration 47, loss = 0.86001430\n",
      "Iteration 48, loss = 0.87919133\n",
      "Iteration 49, loss = 0.89814725\n",
      "Iteration 50, loss = 0.93090665\n",
      "Iteration 51, loss = 0.88662466\n",
      "Iteration 52, loss = 0.85304866\n",
      "Iteration 53, loss = 0.85603321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21745615\n",
      "Iteration 2, loss = 1.09299875\n",
      "Iteration 3, loss = 1.11788078\n",
      "Iteration 4, loss = 1.05505725\n",
      "Iteration 5, loss = 1.00615236\n",
      "Iteration 6, loss = 1.01880439\n",
      "Iteration 7, loss = 0.97462252\n",
      "Iteration 8, loss = 0.95473290\n",
      "Iteration 9, loss = 0.96336396\n",
      "Iteration 10, loss = 0.95769218\n",
      "Iteration 11, loss = 1.00654931\n",
      "Iteration 12, loss = 0.96773883\n",
      "Iteration 53, loss = 0.85603321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21745615\n",
      "Iteration 2, loss = 1.09299875\n",
      "Iteration 3, loss = 1.11788078\n",
      "Iteration 4, loss = 1.05505725\n",
      "Iteration 5, loss = 1.00615236\n",
      "Iteration 6, loss = 1.01880439\n",
      "Iteration 7, loss = 0.97462252\n",
      "Iteration 8, loss = 0.95473290\n",
      "Iteration 9, loss = 0.96336396\n",
      "Iteration 10, loss = 0.95769218\n",
      "Iteration 11, loss = 1.00654931\n",
      "Iteration 12, loss = 0.96773883\n",
      "Iteration 13, loss = 0.95912044\n",
      "Iteration 14, loss = 1.03625164\n",
      "Iteration 15, loss = 0.97557922\n",
      "Iteration 16, loss = 0.95084254\n",
      "Iteration 17, loss = 0.97221120\n",
      "Iteration 18, loss = 0.97666691\n",
      "Iteration 19, loss = 0.98676547\n",
      "Iteration 20, loss = 0.96853624\n",
      "Iteration 21, loss = 0.95439317\n",
      "Iteration 22, loss = 0.97555654\n",
      "Iteration 23, loss = 0.92826109\n",
      "Iteration 24, loss = 0.95364035\n",
      "Iteration 25, loss = 0.93340506\n",
      "Iteration 26, loss = 0.96381878\n",
      "Iteration 27, loss = 0.94543446\n",
      "Iteration 13, loss = 0.95912044\n",
      "Iteration 14, loss = 1.03625164\n",
      "Iteration 15, loss = 0.97557922\n",
      "Iteration 16, loss = 0.95084254\n",
      "Iteration 17, loss = 0.97221120\n",
      "Iteration 18, loss = 0.97666691\n",
      "Iteration 19, loss = 0.98676547\n",
      "Iteration 20, loss = 0.96853624\n",
      "Iteration 21, loss = 0.95439317\n",
      "Iteration 22, loss = 0.97555654\n",
      "Iteration 23, loss = 0.92826109\n",
      "Iteration 24, loss = 0.95364035\n",
      "Iteration 25, loss = 0.93340506\n",
      "Iteration 26, loss = 0.96381878\n",
      "Iteration 27, loss = 0.94543446\n",
      "Iteration 28, loss = 0.93406931\n",
      "Iteration 29, loss = 0.95586047\n",
      "Iteration 30, loss = 0.96084730\n",
      "Iteration 31, loss = 0.95584257\n",
      "Iteration 32, loss = 0.89602234\n",
      "Iteration 33, loss = 1.01536751\n",
      "Iteration 34, loss = 0.97008216\n",
      "Iteration 35, loss = 0.94848762\n",
      "Iteration 36, loss = 0.91525614\n",
      "Iteration 37, loss = 0.92238521\n",
      "Iteration 38, loss = 0.95489261\n",
      "Iteration 39, loss = 0.92723123\n",
      "Iteration 40, loss = 0.91033003\n",
      "Iteration 41, loss = 0.89915284\n",
      "Iteration 28, loss = 0.93406931\n",
      "Iteration 29, loss = 0.95586047\n",
      "Iteration 30, loss = 0.96084730\n",
      "Iteration 31, loss = 0.95584257\n",
      "Iteration 32, loss = 0.89602234\n",
      "Iteration 33, loss = 1.01536751\n",
      "Iteration 34, loss = 0.97008216\n",
      "Iteration 35, loss = 0.94848762\n",
      "Iteration 36, loss = 0.91525614\n",
      "Iteration 37, loss = 0.92238521\n",
      "Iteration 38, loss = 0.95489261\n",
      "Iteration 39, loss = 0.92723123\n",
      "Iteration 40, loss = 0.91033003\n",
      "Iteration 41, loss = 0.89915284\n",
      "Iteration 42, loss = 0.92561082\n",
      "Iteration 43, loss = 0.93480765\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23623299\n",
      "Iteration 2, loss = 1.07609280\n",
      "Iteration 3, loss = 1.06885153\n",
      "Iteration 4, loss = 1.03343154\n",
      "Iteration 5, loss = 1.08316702\n",
      "Iteration 6, loss = 1.00479281\n",
      "Iteration 7, loss = 0.95210327\n",
      "Iteration 8, loss = 1.00709137\n",
      "Iteration 9, loss = 0.99833658\n",
      "Iteration 10, loss = 0.97196058\n",
      "Iteration 11, loss = 0.99143630\n",
      "Iteration 12, loss = 0.96585212\n",
      "Iteration 42, loss = 0.92561082\n",
      "Iteration 43, loss = 0.93480765\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.23623299\n",
      "Iteration 2, loss = 1.07609280\n",
      "Iteration 3, loss = 1.06885153\n",
      "Iteration 4, loss = 1.03343154\n",
      "Iteration 5, loss = 1.08316702\n",
      "Iteration 6, loss = 1.00479281\n",
      "Iteration 7, loss = 0.95210327\n",
      "Iteration 8, loss = 1.00709137\n",
      "Iteration 9, loss = 0.99833658\n",
      "Iteration 10, loss = 0.97196058\n",
      "Iteration 11, loss = 0.99143630\n",
      "Iteration 12, loss = 0.96585212\n",
      "Iteration 13, loss = 1.00713308\n",
      "Iteration 14, loss = 1.04963401\n",
      "Iteration 15, loss = 1.00736300\n",
      "Iteration 16, loss = 1.01926963\n",
      "Iteration 17, loss = 1.01789931\n",
      "Iteration 18, loss = 1.05151478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20234794\n",
      "Iteration 2, loss = 1.10104869\n",
      "Iteration 3, loss = 1.10704601\n",
      "Iteration 4, loss = 1.08291323\n",
      "Iteration 5, loss = 1.05781381\n",
      "Iteration 6, loss = 1.12372702\n",
      "Iteration 7, loss = 0.96670410\n",
      "Iteration 8, loss = 0.99437456\n",
      "Iteration 13, loss = 1.00713308\n",
      "Iteration 14, loss = 1.04963401\n",
      "Iteration 15, loss = 1.00736300\n",
      "Iteration 16, loss = 1.01926963\n",
      "Iteration 17, loss = 1.01789931\n",
      "Iteration 18, loss = 1.05151478\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20234794\n",
      "Iteration 2, loss = 1.10104869\n",
      "Iteration 3, loss = 1.10704601\n",
      "Iteration 4, loss = 1.08291323\n",
      "Iteration 5, loss = 1.05781381\n",
      "Iteration 6, loss = 1.12372702\n",
      "Iteration 7, loss = 0.96670410\n",
      "Iteration 8, loss = 0.99437456\n",
      "Iteration 9, loss = 1.00032436\n",
      "Iteration 10, loss = 1.05513347\n",
      "Iteration 11, loss = 1.04439004\n",
      "Iteration 12, loss = 1.00295117\n",
      "Iteration 13, loss = 0.97956460\n",
      "Iteration 14, loss = 1.00657682\n",
      "Iteration 15, loss = 0.96446968\n",
      "Iteration 16, loss = 1.02255037\n",
      "Iteration 17, loss = 0.96031411\n",
      "Iteration 18, loss = 0.96137467\n",
      "Iteration 19, loss = 0.99310278\n",
      "Iteration 20, loss = 0.99222022\n",
      "Iteration 21, loss = 1.02529155\n",
      "Iteration 22, loss = 0.99757475\n",
      "Iteration 9, loss = 1.00032436\n",
      "Iteration 10, loss = 1.05513347\n",
      "Iteration 11, loss = 1.04439004\n",
      "Iteration 12, loss = 1.00295117\n",
      "Iteration 13, loss = 0.97956460\n",
      "Iteration 14, loss = 1.00657682\n",
      "Iteration 15, loss = 0.96446968\n",
      "Iteration 16, loss = 1.02255037\n",
      "Iteration 17, loss = 0.96031411\n",
      "Iteration 18, loss = 0.96137467\n",
      "Iteration 19, loss = 0.99310278\n",
      "Iteration 20, loss = 0.99222022\n",
      "Iteration 21, loss = 1.02529155\n",
      "Iteration 22, loss = 0.99757475\n",
      "Iteration 23, loss = 0.98955862\n",
      "Iteration 24, loss = 0.99826708\n",
      "Iteration 25, loss = 0.96390635\n",
      "Iteration 26, loss = 0.97496804\n",
      "Iteration 27, loss = 1.02761077\n",
      "Iteration 28, loss = 0.94148724\n",
      "Iteration 29, loss = 0.93692136\n",
      "Iteration 30, loss = 0.98880170\n",
      "Iteration 31, loss = 0.91830194\n",
      "Iteration 32, loss = 1.03377087\n",
      "Iteration 33, loss = 1.05020398\n",
      "Iteration 34, loss = 0.94828524\n",
      "Iteration 35, loss = 1.03503267\n",
      "Iteration 36, loss = 0.98485679\n",
      "Iteration 37, loss = 0.97215870\n",
      "Iteration 23, loss = 0.98955862\n",
      "Iteration 24, loss = 0.99826708\n",
      "Iteration 25, loss = 0.96390635\n",
      "Iteration 26, loss = 0.97496804\n",
      "Iteration 27, loss = 1.02761077\n",
      "Iteration 28, loss = 0.94148724\n",
      "Iteration 29, loss = 0.93692136\n",
      "Iteration 30, loss = 0.98880170\n",
      "Iteration 31, loss = 0.91830194\n",
      "Iteration 32, loss = 1.03377087\n",
      "Iteration 33, loss = 1.05020398\n",
      "Iteration 34, loss = 0.94828524\n",
      "Iteration 35, loss = 1.03503267\n",
      "Iteration 36, loss = 0.98485679\n",
      "Iteration 37, loss = 0.97215870\n",
      "Iteration 38, loss = 0.94875624\n",
      "Iteration 39, loss = 0.95195463\n",
      "Iteration 40, loss = 0.95509849\n",
      "Iteration 41, loss = 0.93835324\n",
      "Iteration 42, loss = 0.91347683\n",
      "Iteration 43, loss = 0.91656404\n",
      "Iteration 44, loss = 0.88088612\n",
      "Iteration 45, loss = 0.88078622\n",
      "Iteration 46, loss = 0.91308783\n",
      "Iteration 47, loss = 0.93672313\n",
      "Iteration 48, loss = 0.91058544\n",
      "Iteration 49, loss = 0.96178541\n",
      "Iteration 50, loss = 0.93107017\n",
      "Iteration 51, loss = 0.89357043\n",
      "Iteration 52, loss = 0.90165045\n",
      "Iteration 38, loss = 0.94875624\n",
      "Iteration 39, loss = 0.95195463\n",
      "Iteration 40, loss = 0.95509849\n",
      "Iteration 41, loss = 0.93835324\n",
      "Iteration 42, loss = 0.91347683\n",
      "Iteration 43, loss = 0.91656404\n",
      "Iteration 44, loss = 0.88088612\n",
      "Iteration 45, loss = 0.88078622\n",
      "Iteration 46, loss = 0.91308783\n",
      "Iteration 47, loss = 0.93672313\n",
      "Iteration 48, loss = 0.91058544\n",
      "Iteration 49, loss = 0.96178541\n",
      "Iteration 50, loss = 0.93107017\n",
      "Iteration 51, loss = 0.89357043\n",
      "Iteration 52, loss = 0.90165045\n",
      "Iteration 53, loss = 0.88565210\n",
      "Iteration 54, loss = 0.85851375\n",
      "Iteration 55, loss = 0.85522059\n",
      "Iteration 56, loss = 0.91375730\n",
      "Iteration 57, loss = 0.91918407\n",
      "Iteration 58, loss = 0.90502184\n",
      "Iteration 59, loss = 0.88513097\n",
      "Iteration 60, loss = 0.90839309\n",
      "Iteration 61, loss = 0.85758094\n",
      "Iteration 62, loss = 0.89602407\n",
      "Iteration 63, loss = 0.92057297\n",
      "Iteration 64, loss = 0.87733621\n",
      "Iteration 65, loss = 0.85783923\n",
      "Iteration 66, loss = 0.85748312\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 53, loss = 0.88565210\n",
      "Iteration 54, loss = 0.85851375\n",
      "Iteration 55, loss = 0.85522059\n",
      "Iteration 56, loss = 0.91375730\n",
      "Iteration 57, loss = 0.91918407\n",
      "Iteration 58, loss = 0.90502184\n",
      "Iteration 59, loss = 0.88513097\n",
      "Iteration 60, loss = 0.90839309\n",
      "Iteration 61, loss = 0.85758094\n",
      "Iteration 62, loss = 0.89602407\n",
      "Iteration 63, loss = 0.92057297\n",
      "Iteration 64, loss = 0.87733621\n",
      "Iteration 65, loss = 0.85783923\n",
      "Iteration 66, loss = 0.85748312\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29144097\n",
      "Iteration 2, loss = 1.17288308\n",
      "Iteration 3, loss = 1.07655925\n",
      "Iteration 4, loss = 1.05052743\n",
      "Iteration 5, loss = 1.05847414\n",
      "Iteration 6, loss = 1.06745631\n",
      "Iteration 7, loss = 1.08007384\n",
      "Iteration 8, loss = 1.05425390\n",
      "Iteration 9, loss = 1.06206760\n",
      "Iteration 10, loss = 1.02181012\n",
      "Iteration 1, loss = 1.31592730\n",
      "Iteration 2, loss = 1.25870380\n",
      "Iteration 3, loss = 1.24310274\n",
      "Iteration 1, loss = 1.29144097\n",
      "Iteration 2, loss = 1.17288308\n",
      "Iteration 3, loss = 1.07655925\n",
      "Iteration 4, loss = 1.05052743\n",
      "Iteration 5, loss = 1.05847414\n",
      "Iteration 6, loss = 1.06745631\n",
      "Iteration 7, loss = 1.08007384\n",
      "Iteration 8, loss = 1.05425390\n",
      "Iteration 9, loss = 1.06206760\n",
      "Iteration 10, loss = 1.02181012\n",
      "Iteration 1, loss = 1.31592730\n",
      "Iteration 2, loss = 1.25870380\n",
      "Iteration 3, loss = 1.24310274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.25605611\n",
      "Iteration 5, loss = 1.26863339\n",
      "Iteration 6, loss = 1.23345619\n",
      "Iteration 7, loss = 1.25470443\n",
      "Iteration 8, loss = 1.24156098\n",
      "Iteration 9, loss = 1.23989022\n",
      "Iteration 10, loss = 1.25490678\n",
      "Iteration 1, loss = 1.31897575\n",
      "Iteration 2, loss = 1.15809847\n",
      "Iteration 3, loss = 1.05712457\n",
      "Iteration 4, loss = 1.04458758\n",
      "Iteration 4, loss = 1.25605611\n",
      "Iteration 5, loss = 1.26863339\n",
      "Iteration 6, loss = 1.23345619\n",
      "Iteration 7, loss = 1.25470443\n",
      "Iteration 8, loss = 1.24156098\n",
      "Iteration 9, loss = 1.23989022\n",
      "Iteration 10, loss = 1.25490678\n",
      "Iteration 1, loss = 1.31897575\n",
      "Iteration 2, loss = 1.15809847\n",
      "Iteration 3, loss = 1.05712457\n",
      "Iteration 4, loss = 1.04458758\n",
      "Iteration 5, loss = 0.99869599\n",
      "Iteration 6, loss = 1.01943835\n",
      "Iteration 7, loss = 0.99829286\n",
      "Iteration 8, loss = 0.97714839\n",
      "Iteration 9, loss = 0.96968237\n",
      "Iteration 10, loss = 1.01149618\n",
      "Iteration 1, loss = 1.31589787\n",
      "Iteration 2, loss = 1.14728571\n",
      "Iteration 3, loss = 1.08802175\n",
      "Iteration 4, loss = 1.27326207\n",
      "Iteration 5, loss = 1.26835742\n",
      "Iteration 6, loss = 1.25862359\n",
      "Iteration 7, loss = 1.25242657\n",
      "Iteration 8, loss = 1.25202386\n",
      "Iteration 9, loss = 1.25216910\n",
      "Iteration 5, loss = 0.99869599\n",
      "Iteration 6, loss = 1.01943835\n",
      "Iteration 7, loss = 0.99829286\n",
      "Iteration 8, loss = 0.97714839\n",
      "Iteration 9, loss = 0.96968237\n",
      "Iteration 10, loss = 1.01149618\n",
      "Iteration 1, loss = 1.31589787\n",
      "Iteration 2, loss = 1.14728571\n",
      "Iteration 3, loss = 1.08802175\n",
      "Iteration 4, loss = 1.27326207\n",
      "Iteration 5, loss = 1.26835742\n",
      "Iteration 6, loss = 1.25862359\n",
      "Iteration 7, loss = 1.25242657\n",
      "Iteration 8, loss = 1.25202386\n",
      "Iteration 9, loss = 1.25216910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.25583023\n",
      "Iteration 1, loss = 1.24915325\n",
      "Iteration 2, loss = 1.12416211\n",
      "Iteration 3, loss = 1.06140434\n",
      "Iteration 4, loss = 1.12947571\n",
      "Iteration 5, loss = 1.21027768\n",
      "Iteration 6, loss = 1.22101220\n",
      "Iteration 7, loss = 1.06955414\n",
      "Iteration 8, loss = 1.01975512\n",
      "Iteration 9, loss = 1.09374752\n",
      "Iteration 10, loss = 1.04777909\n",
      "Iteration 10, loss = 1.25583023\n",
      "Iteration 1, loss = 1.24915325\n",
      "Iteration 2, loss = 1.12416211\n",
      "Iteration 3, loss = 1.06140434\n",
      "Iteration 4, loss = 1.12947571\n",
      "Iteration 5, loss = 1.21027768\n",
      "Iteration 6, loss = 1.22101220\n",
      "Iteration 7, loss = 1.06955414\n",
      "Iteration 8, loss = 1.01975512\n",
      "Iteration 9, loss = 1.09374752\n",
      "Iteration 10, loss = 1.04777909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.29144097\n",
      "Iteration 2, loss = 1.17288308\n",
      "Iteration 3, loss = 1.07655925\n",
      "Iteration 4, loss = 1.05052743\n",
      "Iteration 5, loss = 1.05847414\n",
      "Iteration 6, loss = 1.06745631\n",
      "Iteration 7, loss = 1.08007384\n",
      "Iteration 8, loss = 1.05425390\n",
      "Iteration 9, loss = 1.06206760\n",
      "Iteration 10, loss = 1.02181012\n",
      "Iteration 11, loss = 0.98178183\n",
      "Iteration 12, loss = 0.97321240\n",
      "Iteration 13, loss = 0.99146405\n",
      "Iteration 14, loss = 1.01094590\n",
      "Iteration 15, loss = 0.97020139\n",
      "Iteration 1, loss = 1.29144097\n",
      "Iteration 2, loss = 1.17288308\n",
      "Iteration 3, loss = 1.07655925\n",
      "Iteration 4, loss = 1.05052743\n",
      "Iteration 5, loss = 1.05847414\n",
      "Iteration 6, loss = 1.06745631\n",
      "Iteration 7, loss = 1.08007384\n",
      "Iteration 8, loss = 1.05425390\n",
      "Iteration 9, loss = 1.06206760\n",
      "Iteration 10, loss = 1.02181012\n",
      "Iteration 11, loss = 0.98178183\n",
      "Iteration 12, loss = 0.97321240\n",
      "Iteration 13, loss = 0.99146405\n",
      "Iteration 14, loss = 1.01094590\n",
      "Iteration 15, loss = 0.97020139\n",
      "Iteration 16, loss = 1.00621264\n",
      "Iteration 17, loss = 0.99498468\n",
      "Iteration 18, loss = 1.13826016\n",
      "Iteration 19, loss = 1.09306863\n",
      "Iteration 20, loss = 0.99054476\n",
      "Iteration 21, loss = 0.98473210\n",
      "Iteration 22, loss = 0.97358897\n",
      "Iteration 23, loss = 0.98918589\n",
      "Iteration 24, loss = 0.96264542\n",
      "Iteration 25, loss = 0.98571790\n",
      "Iteration 26, loss = 0.99768340\n",
      "Iteration 27, loss = 1.14769732\n",
      "Iteration 28, loss = 1.07194126\n",
      "Iteration 29, loss = 0.99847120\n",
      "Iteration 30, loss = 0.98377881\n",
      "Iteration 16, loss = 1.00621264\n",
      "Iteration 17, loss = 0.99498468\n",
      "Iteration 18, loss = 1.13826016\n",
      "Iteration 19, loss = 1.09306863\n",
      "Iteration 20, loss = 0.99054476\n",
      "Iteration 21, loss = 0.98473210\n",
      "Iteration 22, loss = 0.97358897\n",
      "Iteration 23, loss = 0.98918589\n",
      "Iteration 24, loss = 0.96264542\n",
      "Iteration 25, loss = 0.98571790\n",
      "Iteration 26, loss = 0.99768340\n",
      "Iteration 27, loss = 1.14769732\n",
      "Iteration 28, loss = 1.07194126\n",
      "Iteration 29, loss = 0.99847120\n",
      "Iteration 30, loss = 0.98377881\n",
      "Iteration 31, loss = 1.01732636\n",
      "Iteration 32, loss = 0.98497797\n",
      "Iteration 33, loss = 0.97391823\n",
      "Iteration 34, loss = 0.98322341\n",
      "Iteration 35, loss = 0.99568102\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31592730\n",
      "Iteration 2, loss = 1.25870380\n",
      "Iteration 3, loss = 1.24310274\n",
      "Iteration 4, loss = 1.25605611\n",
      "Iteration 5, loss = 1.26863339\n",
      "Iteration 6, loss = 1.23345619\n",
      "Iteration 7, loss = 1.25470443\n",
      "Iteration 31, loss = 1.01732636\n",
      "Iteration 32, loss = 0.98497797\n",
      "Iteration 33, loss = 0.97391823\n",
      "Iteration 34, loss = 0.98322341\n",
      "Iteration 35, loss = 0.99568102\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31592730\n",
      "Iteration 2, loss = 1.25870380\n",
      "Iteration 3, loss = 1.24310274\n",
      "Iteration 4, loss = 1.25605611\n",
      "Iteration 5, loss = 1.26863339\n",
      "Iteration 6, loss = 1.23345619\n",
      "Iteration 7, loss = 1.25470443\n",
      "Iteration 8, loss = 1.24156098\n",
      "Iteration 9, loss = 1.23989022\n",
      "Iteration 10, loss = 1.25490678\n",
      "Iteration 11, loss = 1.24937767\n",
      "Iteration 12, loss = 1.26128842\n",
      "Iteration 13, loss = 1.26488854\n",
      "Iteration 14, loss = 1.26076104\n",
      "Iteration 15, loss = 1.24102229\n",
      "Iteration 16, loss = 1.25150327\n",
      "Iteration 17, loss = 1.23678590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31897575\n",
      "Iteration 2, loss = 1.15809847\n",
      "Iteration 3, loss = 1.05712457\n",
      "Iteration 8, loss = 1.24156098\n",
      "Iteration 9, loss = 1.23989022\n",
      "Iteration 10, loss = 1.25490678\n",
      "Iteration 11, loss = 1.24937767\n",
      "Iteration 12, loss = 1.26128842\n",
      "Iteration 13, loss = 1.26488854\n",
      "Iteration 14, loss = 1.26076104\n",
      "Iteration 15, loss = 1.24102229\n",
      "Iteration 16, loss = 1.25150327\n",
      "Iteration 17, loss = 1.23678590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31897575\n",
      "Iteration 2, loss = 1.15809847\n",
      "Iteration 3, loss = 1.05712457\n",
      "Iteration 4, loss = 1.04458758\n",
      "Iteration 5, loss = 0.99869599\n",
      "Iteration 6, loss = 1.01943835\n",
      "Iteration 7, loss = 0.99829286\n",
      "Iteration 8, loss = 0.97714839\n",
      "Iteration 9, loss = 0.96968237\n",
      "Iteration 10, loss = 1.01149618\n",
      "Iteration 11, loss = 1.24582231\n",
      "Iteration 12, loss = 1.27295314\n",
      "Iteration 13, loss = 1.28936351\n",
      "Iteration 14, loss = 1.29642403\n",
      "Iteration 15, loss = 1.26511931\n",
      "Iteration 16, loss = 1.28525335\n",
      "Iteration 4, loss = 1.04458758\n",
      "Iteration 5, loss = 0.99869599\n",
      "Iteration 6, loss = 1.01943835\n",
      "Iteration 7, loss = 0.99829286\n",
      "Iteration 8, loss = 0.97714839\n",
      "Iteration 9, loss = 0.96968237\n",
      "Iteration 10, loss = 1.01149618\n",
      "Iteration 11, loss = 1.24582231\n",
      "Iteration 12, loss = 1.27295314\n",
      "Iteration 13, loss = 1.28936351\n",
      "Iteration 14, loss = 1.29642403\n",
      "Iteration 15, loss = 1.26511931\n",
      "Iteration 16, loss = 1.28525335\n",
      "Iteration 17, loss = 1.26217352\n",
      "Iteration 18, loss = 1.26969863\n",
      "Iteration 19, loss = 1.30445204\n",
      "Iteration 20, loss = 1.25518083\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31589787\n",
      "Iteration 2, loss = 1.14728571\n",
      "Iteration 3, loss = 1.08802175\n",
      "Iteration 4, loss = 1.27326207\n",
      "Iteration 5, loss = 1.26835742\n",
      "Iteration 6, loss = 1.25862359\n",
      "Iteration 7, loss = 1.25242657\n",
      "Iteration 8, loss = 1.25202386\n",
      "Iteration 9, loss = 1.25216910\n",
      "Iteration 10, loss = 1.25583023\n",
      "Iteration 17, loss = 1.26217352\n",
      "Iteration 18, loss = 1.26969863\n",
      "Iteration 19, loss = 1.30445204\n",
      "Iteration 20, loss = 1.25518083\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31589787\n",
      "Iteration 2, loss = 1.14728571\n",
      "Iteration 3, loss = 1.08802175\n",
      "Iteration 4, loss = 1.27326207\n",
      "Iteration 5, loss = 1.26835742\n",
      "Iteration 6, loss = 1.25862359\n",
      "Iteration 7, loss = 1.25242657\n",
      "Iteration 8, loss = 1.25202386\n",
      "Iteration 9, loss = 1.25216910\n",
      "Iteration 10, loss = 1.25583023\n",
      "Iteration 11, loss = 1.25188039\n",
      "Iteration 12, loss = 1.24359260\n",
      "Iteration 13, loss = 1.26329284\n",
      "Iteration 14, loss = 1.28452430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24915325\n",
      "Iteration 2, loss = 1.12416211\n",
      "Iteration 3, loss = 1.06140434\n",
      "Iteration 4, loss = 1.12947571\n",
      "Iteration 5, loss = 1.21027768\n",
      "Iteration 6, loss = 1.22101220\n",
      "Iteration 7, loss = 1.06955414\n",
      "Iteration 8, loss = 1.01975512\n",
      "Iteration 9, loss = 1.09374752\n",
      "Iteration 11, loss = 1.25188039\n",
      "Iteration 12, loss = 1.24359260\n",
      "Iteration 13, loss = 1.26329284\n",
      "Iteration 14, loss = 1.28452430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24915325\n",
      "Iteration 2, loss = 1.12416211\n",
      "Iteration 3, loss = 1.06140434\n",
      "Iteration 4, loss = 1.12947571\n",
      "Iteration 5, loss = 1.21027768\n",
      "Iteration 6, loss = 1.22101220\n",
      "Iteration 7, loss = 1.06955414\n",
      "Iteration 8, loss = 1.01975512\n",
      "Iteration 9, loss = 1.09374752\n",
      "Iteration 10, loss = 1.04777909\n",
      "Iteration 11, loss = 1.04851338\n",
      "Iteration 12, loss = 1.04985095\n",
      "Iteration 13, loss = 1.06344314\n",
      "Iteration 14, loss = 1.02344031\n",
      "Iteration 15, loss = 1.00778173\n",
      "Iteration 16, loss = 1.05149382\n",
      "Iteration 17, loss = 1.11031014\n",
      "Iteration 18, loss = 1.14316832\n",
      "Iteration 19, loss = 1.16629179\n",
      "Iteration 20, loss = 1.06358766\n",
      "Iteration 21, loss = 1.05857481\n",
      "Iteration 22, loss = 1.07000699\n",
      "Iteration 23, loss = 1.17130707\n",
      "Iteration 10, loss = 1.04777909\n",
      "Iteration 11, loss = 1.04851338\n",
      "Iteration 12, loss = 1.04985095\n",
      "Iteration 13, loss = 1.06344314\n",
      "Iteration 14, loss = 1.02344031\n",
      "Iteration 15, loss = 1.00778173\n",
      "Iteration 16, loss = 1.05149382\n",
      "Iteration 17, loss = 1.11031014\n",
      "Iteration 18, loss = 1.14316832\n",
      "Iteration 19, loss = 1.16629179\n",
      "Iteration 20, loss = 1.06358766\n",
      "Iteration 21, loss = 1.05857481\n",
      "Iteration 22, loss = 1.07000699\n",
      "Iteration 23, loss = 1.17130707\n",
      "Iteration 24, loss = 1.11928785\n",
      "Iteration 25, loss = 1.05103133\n",
      "Iteration 26, loss = 1.14757969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29144097\n",
      "Iteration 2, loss = 1.17288308\n",
      "Iteration 3, loss = 1.07655925\n",
      "Iteration 4, loss = 1.05052743\n",
      "Iteration 5, loss = 1.05847414\n",
      "Iteration 6, loss = 1.06745631\n",
      "Iteration 7, loss = 1.08007384\n",
      "Iteration 8, loss = 1.05425390\n",
      "Iteration 9, loss = 1.06206760\n",
      "Iteration 10, loss = 1.02181012\n",
      "Iteration 11, loss = 0.98178183\n",
      "Iteration 24, loss = 1.11928785\n",
      "Iteration 25, loss = 1.05103133\n",
      "Iteration 26, loss = 1.14757969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.29144097\n",
      "Iteration 2, loss = 1.17288308\n",
      "Iteration 3, loss = 1.07655925\n",
      "Iteration 4, loss = 1.05052743\n",
      "Iteration 5, loss = 1.05847414\n",
      "Iteration 6, loss = 1.06745631\n",
      "Iteration 7, loss = 1.08007384\n",
      "Iteration 8, loss = 1.05425390\n",
      "Iteration 9, loss = 1.06206760\n",
      "Iteration 10, loss = 1.02181012\n",
      "Iteration 11, loss = 0.98178183\n",
      "Iteration 12, loss = 0.97321240\n",
      "Iteration 13, loss = 0.99146405\n",
      "Iteration 14, loss = 1.01094590\n",
      "Iteration 15, loss = 0.97020139\n",
      "Iteration 16, loss = 1.00621264\n",
      "Iteration 17, loss = 0.99498468\n",
      "Iteration 18, loss = 1.13826016\n",
      "Iteration 19, loss = 1.09306863\n",
      "Iteration 20, loss = 0.99054476\n",
      "Iteration 21, loss = 0.98473210\n",
      "Iteration 22, loss = 0.97358897\n",
      "Iteration 23, loss = 0.98918589\n",
      "Iteration 24, loss = 0.96264542\n",
      "Iteration 25, loss = 0.98571790\n",
      "Iteration 12, loss = 0.97321240\n",
      "Iteration 13, loss = 0.99146405\n",
      "Iteration 14, loss = 1.01094590\n",
      "Iteration 15, loss = 0.97020139\n",
      "Iteration 16, loss = 1.00621264\n",
      "Iteration 17, loss = 0.99498468\n",
      "Iteration 18, loss = 1.13826016\n",
      "Iteration 19, loss = 1.09306863\n",
      "Iteration 20, loss = 0.99054476\n",
      "Iteration 21, loss = 0.98473210\n",
      "Iteration 22, loss = 0.97358897\n",
      "Iteration 23, loss = 0.98918589\n",
      "Iteration 24, loss = 0.96264542\n",
      "Iteration 25, loss = 0.98571790\n",
      "Iteration 26, loss = 0.99768340\n",
      "Iteration 27, loss = 1.14769732\n",
      "Iteration 28, loss = 1.07194126\n",
      "Iteration 29, loss = 0.99847120\n",
      "Iteration 30, loss = 0.98377881\n",
      "Iteration 31, loss = 1.01732636\n",
      "Iteration 32, loss = 0.98497797\n",
      "Iteration 33, loss = 0.97391823\n",
      "Iteration 34, loss = 0.98322341\n",
      "Iteration 35, loss = 0.99568102\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31592730\n",
      "Iteration 2, loss = 1.25870380\n",
      "Iteration 3, loss = 1.24310274\n",
      "Iteration 26, loss = 0.99768340\n",
      "Iteration 27, loss = 1.14769732\n",
      "Iteration 28, loss = 1.07194126\n",
      "Iteration 29, loss = 0.99847120\n",
      "Iteration 30, loss = 0.98377881\n",
      "Iteration 31, loss = 1.01732636\n",
      "Iteration 32, loss = 0.98497797\n",
      "Iteration 33, loss = 0.97391823\n",
      "Iteration 34, loss = 0.98322341\n",
      "Iteration 35, loss = 0.99568102\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31592730\n",
      "Iteration 2, loss = 1.25870380\n",
      "Iteration 3, loss = 1.24310274\n",
      "Iteration 4, loss = 1.25605611\n",
      "Iteration 5, loss = 1.26863339\n",
      "Iteration 6, loss = 1.23345619\n",
      "Iteration 7, loss = 1.25470443\n",
      "Iteration 8, loss = 1.24156098\n",
      "Iteration 9, loss = 1.23989022\n",
      "Iteration 10, loss = 1.25490678\n",
      "Iteration 11, loss = 1.24937767\n",
      "Iteration 12, loss = 1.26128842\n",
      "Iteration 13, loss = 1.26488854\n",
      "Iteration 14, loss = 1.26076104\n",
      "Iteration 15, loss = 1.24102229\n",
      "Iteration 16, loss = 1.25150327\n",
      "Iteration 17, loss = 1.23678590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 1.25605611\n",
      "Iteration 5, loss = 1.26863339\n",
      "Iteration 6, loss = 1.23345619\n",
      "Iteration 7, loss = 1.25470443\n",
      "Iteration 8, loss = 1.24156098\n",
      "Iteration 9, loss = 1.23989022\n",
      "Iteration 10, loss = 1.25490678\n",
      "Iteration 11, loss = 1.24937767\n",
      "Iteration 12, loss = 1.26128842\n",
      "Iteration 13, loss = 1.26488854\n",
      "Iteration 14, loss = 1.26076104\n",
      "Iteration 15, loss = 1.24102229\n",
      "Iteration 16, loss = 1.25150327\n",
      "Iteration 17, loss = 1.23678590\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31897575\n",
      "Iteration 2, loss = 1.15809847\n",
      "Iteration 3, loss = 1.05712457\n",
      "Iteration 4, loss = 1.04458758\n",
      "Iteration 5, loss = 0.99869599\n",
      "Iteration 6, loss = 1.01943835\n",
      "Iteration 7, loss = 0.99829286\n",
      "Iteration 8, loss = 0.97714839\n",
      "Iteration 9, loss = 0.96968237\n",
      "Iteration 10, loss = 1.01149618\n",
      "Iteration 11, loss = 1.24582231\n",
      "Iteration 12, loss = 1.27295314\n",
      "Iteration 13, loss = 1.28936351\n",
      "Iteration 14, loss = 1.29642403\n",
      "Iteration 1, loss = 1.31897575\n",
      "Iteration 2, loss = 1.15809847\n",
      "Iteration 3, loss = 1.05712457\n",
      "Iteration 4, loss = 1.04458758\n",
      "Iteration 5, loss = 0.99869599\n",
      "Iteration 6, loss = 1.01943835\n",
      "Iteration 7, loss = 0.99829286\n",
      "Iteration 8, loss = 0.97714839\n",
      "Iteration 9, loss = 0.96968237\n",
      "Iteration 10, loss = 1.01149618\n",
      "Iteration 11, loss = 1.24582231\n",
      "Iteration 12, loss = 1.27295314\n",
      "Iteration 13, loss = 1.28936351\n",
      "Iteration 14, loss = 1.29642403\n",
      "Iteration 15, loss = 1.26511931\n",
      "Iteration 16, loss = 1.28525335\n",
      "Iteration 17, loss = 1.26217352\n",
      "Iteration 18, loss = 1.26969863\n",
      "Iteration 19, loss = 1.30445204\n",
      "Iteration 20, loss = 1.25518083\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31589787\n",
      "Iteration 2, loss = 1.14728571\n",
      "Iteration 3, loss = 1.08802175\n",
      "Iteration 4, loss = 1.27326207\n",
      "Iteration 5, loss = 1.26835742\n",
      "Iteration 6, loss = 1.25862359\n",
      "Iteration 7, loss = 1.25242657\n",
      "Iteration 8, loss = 1.25202386\n",
      "Iteration 15, loss = 1.26511931\n",
      "Iteration 16, loss = 1.28525335\n",
      "Iteration 17, loss = 1.26217352\n",
      "Iteration 18, loss = 1.26969863\n",
      "Iteration 19, loss = 1.30445204\n",
      "Iteration 20, loss = 1.25518083\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31589787\n",
      "Iteration 2, loss = 1.14728571\n",
      "Iteration 3, loss = 1.08802175\n",
      "Iteration 4, loss = 1.27326207\n",
      "Iteration 5, loss = 1.26835742\n",
      "Iteration 6, loss = 1.25862359\n",
      "Iteration 7, loss = 1.25242657\n",
      "Iteration 8, loss = 1.25202386\n",
      "Iteration 9, loss = 1.25216910\n",
      "Iteration 10, loss = 1.25583023\n",
      "Iteration 11, loss = 1.25188039\n",
      "Iteration 12, loss = 1.24359260\n",
      "Iteration 13, loss = 1.26329284\n",
      "Iteration 14, loss = 1.28452430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24915325\n",
      "Iteration 2, loss = 1.12416211\n",
      "Iteration 3, loss = 1.06140434\n",
      "Iteration 4, loss = 1.12947571\n",
      "Iteration 5, loss = 1.21027768\n",
      "Iteration 6, loss = 1.22101220\n",
      "Iteration 9, loss = 1.25216910\n",
      "Iteration 10, loss = 1.25583023\n",
      "Iteration 11, loss = 1.25188039\n",
      "Iteration 12, loss = 1.24359260\n",
      "Iteration 13, loss = 1.26329284\n",
      "Iteration 14, loss = 1.28452430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24915325\n",
      "Iteration 2, loss = 1.12416211\n",
      "Iteration 3, loss = 1.06140434\n",
      "Iteration 4, loss = 1.12947571\n",
      "Iteration 5, loss = 1.21027768\n",
      "Iteration 6, loss = 1.22101220\n",
      "Iteration 7, loss = 1.06955414\n",
      "Iteration 8, loss = 1.01975512\n",
      "Iteration 9, loss = 1.09374752\n",
      "Iteration 10, loss = 1.04777909\n",
      "Iteration 11, loss = 1.04851338\n",
      "Iteration 12, loss = 1.04985095\n",
      "Iteration 13, loss = 1.06344314\n",
      "Iteration 14, loss = 1.02344031\n",
      "Iteration 15, loss = 1.00778173\n",
      "Iteration 16, loss = 1.05149382\n",
      "Iteration 17, loss = 1.11031014\n",
      "Iteration 18, loss = 1.14316832\n",
      "Iteration 19, loss = 1.16629179\n",
      "Iteration 20, loss = 1.06358766\n",
      "Iteration 7, loss = 1.06955414\n",
      "Iteration 8, loss = 1.01975512\n",
      "Iteration 9, loss = 1.09374752\n",
      "Iteration 10, loss = 1.04777909\n",
      "Iteration 11, loss = 1.04851338\n",
      "Iteration 12, loss = 1.04985095\n",
      "Iteration 13, loss = 1.06344314\n",
      "Iteration 14, loss = 1.02344031\n",
      "Iteration 15, loss = 1.00778173\n",
      "Iteration 16, loss = 1.05149382\n",
      "Iteration 17, loss = 1.11031014\n",
      "Iteration 18, loss = 1.14316832\n",
      "Iteration 19, loss = 1.16629179\n",
      "Iteration 20, loss = 1.06358766\n",
      "Iteration 21, loss = 1.05857481\n",
      "Iteration 22, loss = 1.07000699\n",
      "Iteration 23, loss = 1.17130707\n",
      "Iteration 24, loss = 1.11928785\n",
      "Iteration 25, loss = 1.05103133\n",
      "Iteration 26, loss = 1.14757969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30807783\n",
      "Iteration 2, loss = 1.26348594\n",
      "Iteration 3, loss = 1.25342547\n",
      "Iteration 4, loss = 1.24636334\n",
      "Iteration 5, loss = 1.25251179\n",
      "Iteration 6, loss = 1.24246538\n",
      "Iteration 21, loss = 1.05857481\n",
      "Iteration 22, loss = 1.07000699\n",
      "Iteration 23, loss = 1.17130707\n",
      "Iteration 24, loss = 1.11928785\n",
      "Iteration 25, loss = 1.05103133\n",
      "Iteration 26, loss = 1.14757969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30807783\n",
      "Iteration 2, loss = 1.26348594\n",
      "Iteration 3, loss = 1.25342547\n",
      "Iteration 4, loss = 1.24636334\n",
      "Iteration 5, loss = 1.25251179\n",
      "Iteration 6, loss = 1.24246538\n",
      "Iteration 7, loss = 1.25387929\n",
      "Iteration 8, loss = 1.25325425\n",
      "Iteration 9, loss = 1.24780838\n",
      "Iteration 10, loss = 1.24534829\n",
      "Iteration 1, loss = 1.31505089\n",
      "Iteration 2, loss = 1.26412009\n",
      "Iteration 3, loss = 1.24780433\n",
      "Iteration 4, loss = 1.24643235\n",
      "Iteration 5, loss = 1.28472672\n",
      "Iteration 6, loss = 1.23710644\n",
      "Iteration 7, loss = 1.25644793\n",
      "Iteration 8, loss = 1.25152229\n",
      "Iteration 9, loss = 1.24271559\n",
      "Iteration 10, loss = 1.25265171\n",
      "Iteration 7, loss = 1.25387929\n",
      "Iteration 8, loss = 1.25325425\n",
      "Iteration 9, loss = 1.24780838\n",
      "Iteration 10, loss = 1.24534829\n",
      "Iteration 1, loss = 1.31505089\n",
      "Iteration 2, loss = 1.26412009\n",
      "Iteration 3, loss = 1.24780433\n",
      "Iteration 4, loss = 1.24643235\n",
      "Iteration 5, loss = 1.28472672\n",
      "Iteration 6, loss = 1.23710644\n",
      "Iteration 7, loss = 1.25644793\n",
      "Iteration 8, loss = 1.25152229\n",
      "Iteration 9, loss = 1.24271559\n",
      "Iteration 10, loss = 1.25265171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.33585329\n",
      "Iteration 2, loss = 1.13597717\n",
      "Iteration 3, loss = 1.17912563\n",
      "Iteration 4, loss = 1.07942885\n",
      "Iteration 5, loss = 1.09575330\n",
      "Iteration 6, loss = 1.13056703\n",
      "Iteration 7, loss = 1.10085904\n",
      "Iteration 8, loss = 1.20189318\n",
      "Iteration 9, loss = 1.26984896\n",
      "Iteration 10, loss = 1.26707518\n",
      "Iteration 1, loss = 1.33604217\n",
      "Iteration 1, loss = 1.33585329\n",
      "Iteration 2, loss = 1.13597717\n",
      "Iteration 3, loss = 1.17912563\n",
      "Iteration 4, loss = 1.07942885\n",
      "Iteration 5, loss = 1.09575330\n",
      "Iteration 6, loss = 1.13056703\n",
      "Iteration 7, loss = 1.10085904\n",
      "Iteration 8, loss = 1.20189318\n",
      "Iteration 9, loss = 1.26984896\n",
      "Iteration 10, loss = 1.26707518\n",
      "Iteration 1, loss = 1.33604217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.15407285\n",
      "Iteration 3, loss = 1.11499594\n",
      "Iteration 4, loss = 1.10028161\n",
      "Iteration 5, loss = 1.08233168\n",
      "Iteration 6, loss = 1.06906269\n",
      "Iteration 7, loss = 1.13124687\n",
      "Iteration 8, loss = 1.10999087\n",
      "Iteration 9, loss = 1.05654066\n",
      "Iteration 10, loss = 1.04787234\n",
      "Iteration 1, loss = 1.27717928\n",
      "Iteration 2, loss = 1.17336909\n",
      "Iteration 2, loss = 1.15407285\n",
      "Iteration 3, loss = 1.11499594\n",
      "Iteration 4, loss = 1.10028161\n",
      "Iteration 5, loss = 1.08233168\n",
      "Iteration 6, loss = 1.06906269\n",
      "Iteration 7, loss = 1.13124687\n",
      "Iteration 8, loss = 1.10999087\n",
      "Iteration 9, loss = 1.05654066\n",
      "Iteration 10, loss = 1.04787234\n",
      "Iteration 1, loss = 1.27717928\n",
      "Iteration 2, loss = 1.17336909\n",
      "Iteration 3, loss = 1.23107351\n",
      "Iteration 4, loss = 1.16986380\n",
      "Iteration 5, loss = 1.27888720\n",
      "Iteration 6, loss = 1.28645203\n",
      "Iteration 7, loss = 1.24541344\n",
      "Iteration 8, loss = 1.28471810\n",
      "Iteration 9, loss = 1.27504959\n",
      "Iteration 10, loss = 1.27799859\n",
      "Iteration 1, loss = 1.30807783\n",
      "Iteration 2, loss = 1.26348594\n",
      "Iteration 3, loss = 1.25342547\n",
      "Iteration 4, loss = 1.24636334\n",
      "Iteration 3, loss = 1.23107351\n",
      "Iteration 4, loss = 1.16986380\n",
      "Iteration 5, loss = 1.27888720\n",
      "Iteration 6, loss = 1.28645203\n",
      "Iteration 7, loss = 1.24541344\n",
      "Iteration 8, loss = 1.28471810\n",
      "Iteration 9, loss = 1.27504959\n",
      "Iteration 10, loss = 1.27799859\n",
      "Iteration 1, loss = 1.30807783\n",
      "Iteration 2, loss = 1.26348594\n",
      "Iteration 3, loss = 1.25342547\n",
      "Iteration 4, loss = 1.24636334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.25251179\n",
      "Iteration 6, loss = 1.24246538\n",
      "Iteration 7, loss = 1.25387929\n",
      "Iteration 8, loss = 1.25325425\n",
      "Iteration 9, loss = 1.24780838\n",
      "Iteration 10, loss = 1.24534829\n",
      "Iteration 11, loss = 1.27320006\n",
      "Iteration 12, loss = 1.26217744\n",
      "Iteration 13, loss = 1.24019221\n",
      "Iteration 14, loss = 1.25976821\n",
      "Iteration 15, loss = 1.25253385\n",
      "Iteration 16, loss = 1.24474681\n",
      "Iteration 17, loss = 1.25105210\n",
      "Iteration 18, loss = 1.25060912\n",
      "Iteration 5, loss = 1.25251179\n",
      "Iteration 6, loss = 1.24246538\n",
      "Iteration 7, loss = 1.25387929\n",
      "Iteration 8, loss = 1.25325425\n",
      "Iteration 9, loss = 1.24780838\n",
      "Iteration 10, loss = 1.24534829\n",
      "Iteration 11, loss = 1.27320006\n",
      "Iteration 12, loss = 1.26217744\n",
      "Iteration 13, loss = 1.24019221\n",
      "Iteration 14, loss = 1.25976821\n",
      "Iteration 15, loss = 1.25253385\n",
      "Iteration 16, loss = 1.24474681\n",
      "Iteration 17, loss = 1.25105210\n",
      "Iteration 18, loss = 1.25060912\n",
      "Iteration 19, loss = 1.25200552\n",
      "Iteration 20, loss = 1.25428521\n",
      "Iteration 21, loss = 1.25275096\n",
      "Iteration 22, loss = 1.24824860\n",
      "Iteration 23, loss = 1.25531258\n",
      "Iteration 24, loss = 1.24473988\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31505089\n",
      "Iteration 2, loss = 1.26412009\n",
      "Iteration 3, loss = 1.24780433\n",
      "Iteration 4, loss = 1.24643235\n",
      "Iteration 5, loss = 1.28472672\n",
      "Iteration 6, loss = 1.23710644\n",
      "Iteration 7, loss = 1.25644793\n",
      "Iteration 19, loss = 1.25200552\n",
      "Iteration 20, loss = 1.25428521\n",
      "Iteration 21, loss = 1.25275096\n",
      "Iteration 22, loss = 1.24824860\n",
      "Iteration 23, loss = 1.25531258\n",
      "Iteration 24, loss = 1.24473988\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31505089\n",
      "Iteration 2, loss = 1.26412009\n",
      "Iteration 3, loss = 1.24780433\n",
      "Iteration 4, loss = 1.24643235\n",
      "Iteration 5, loss = 1.28472672\n",
      "Iteration 6, loss = 1.23710644\n",
      "Iteration 7, loss = 1.25644793\n",
      "Iteration 8, loss = 1.25152229\n",
      "Iteration 9, loss = 1.24271559\n",
      "Iteration 10, loss = 1.25265171\n",
      "Iteration 11, loss = 1.26208512\n",
      "Iteration 12, loss = 1.27396321\n",
      "Iteration 13, loss = 1.25479780\n",
      "Iteration 14, loss = 1.27944630\n",
      "Iteration 15, loss = 1.24592088\n",
      "Iteration 16, loss = 1.26049706\n",
      "Iteration 17, loss = 1.24032578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33585329\n",
      "Iteration 2, loss = 1.13597717\n",
      "Iteration 8, loss = 1.25152229\n",
      "Iteration 9, loss = 1.24271559\n",
      "Iteration 10, loss = 1.25265171\n",
      "Iteration 11, loss = 1.26208512\n",
      "Iteration 12, loss = 1.27396321\n",
      "Iteration 13, loss = 1.25479780\n",
      "Iteration 14, loss = 1.27944630\n",
      "Iteration 15, loss = 1.24592088\n",
      "Iteration 16, loss = 1.26049706\n",
      "Iteration 17, loss = 1.24032578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33585329\n",
      "Iteration 2, loss = 1.13597717\n",
      "Iteration 3, loss = 1.17912563\n",
      "Iteration 4, loss = 1.07942885\n",
      "Iteration 5, loss = 1.09575330\n",
      "Iteration 6, loss = 1.13056703\n",
      "Iteration 7, loss = 1.10085904\n",
      "Iteration 8, loss = 1.20189318\n",
      "Iteration 9, loss = 1.26984896\n",
      "Iteration 10, loss = 1.26707518\n",
      "Iteration 11, loss = 1.26610989\n",
      "Iteration 12, loss = 1.25463220\n",
      "Iteration 13, loss = 1.25780088\n",
      "Iteration 14, loss = 1.28924234\n",
      "Iteration 15, loss = 1.24509727\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 1.17912563\n",
      "Iteration 4, loss = 1.07942885\n",
      "Iteration 5, loss = 1.09575330\n",
      "Iteration 6, loss = 1.13056703\n",
      "Iteration 7, loss = 1.10085904\n",
      "Iteration 8, loss = 1.20189318\n",
      "Iteration 9, loss = 1.26984896\n",
      "Iteration 10, loss = 1.26707518\n",
      "Iteration 11, loss = 1.26610989\n",
      "Iteration 12, loss = 1.25463220\n",
      "Iteration 13, loss = 1.25780088\n",
      "Iteration 14, loss = 1.28924234\n",
      "Iteration 15, loss = 1.24509727\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33604217\n",
      "Iteration 2, loss = 1.15407285\n",
      "Iteration 3, loss = 1.11499594\n",
      "Iteration 4, loss = 1.10028161\n",
      "Iteration 5, loss = 1.08233168\n",
      "Iteration 6, loss = 1.06906269\n",
      "Iteration 7, loss = 1.13124687\n",
      "Iteration 8, loss = 1.10999087\n",
      "Iteration 9, loss = 1.05654066\n",
      "Iteration 10, loss = 1.04787234\n",
      "Iteration 11, loss = 1.04796155\n",
      "Iteration 12, loss = 1.24970529\n",
      "Iteration 13, loss = 1.09651220\n",
      "Iteration 14, loss = 1.06531439\n",
      "Iteration 1, loss = 1.33604217\n",
      "Iteration 2, loss = 1.15407285\n",
      "Iteration 3, loss = 1.11499594\n",
      "Iteration 4, loss = 1.10028161\n",
      "Iteration 5, loss = 1.08233168\n",
      "Iteration 6, loss = 1.06906269\n",
      "Iteration 7, loss = 1.13124687\n",
      "Iteration 8, loss = 1.10999087\n",
      "Iteration 9, loss = 1.05654066\n",
      "Iteration 10, loss = 1.04787234\n",
      "Iteration 11, loss = 1.04796155\n",
      "Iteration 12, loss = 1.24970529\n",
      "Iteration 13, loss = 1.09651220\n",
      "Iteration 14, loss = 1.06531439\n",
      "Iteration 15, loss = 1.05743734\n",
      "Iteration 16, loss = 1.31216284\n",
      "Iteration 17, loss = 1.28953637\n",
      "Iteration 18, loss = 1.29098403\n",
      "Iteration 19, loss = 1.31620929\n",
      "Iteration 20, loss = 1.27137796\n",
      "Iteration 21, loss = 1.30535968\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27717928\n",
      "Iteration 2, loss = 1.17336909\n",
      "Iteration 3, loss = 1.23107351\n",
      "Iteration 4, loss = 1.16986380\n",
      "Iteration 5, loss = 1.27888720\n",
      "Iteration 6, loss = 1.28645203\n",
      "Iteration 15, loss = 1.05743734\n",
      "Iteration 16, loss = 1.31216284\n",
      "Iteration 17, loss = 1.28953637\n",
      "Iteration 18, loss = 1.29098403\n",
      "Iteration 19, loss = 1.31620929\n",
      "Iteration 20, loss = 1.27137796\n",
      "Iteration 21, loss = 1.30535968\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27717928\n",
      "Iteration 2, loss = 1.17336909\n",
      "Iteration 3, loss = 1.23107351\n",
      "Iteration 4, loss = 1.16986380\n",
      "Iteration 5, loss = 1.27888720\n",
      "Iteration 6, loss = 1.28645203\n",
      "Iteration 7, loss = 1.24541344\n",
      "Iteration 8, loss = 1.28471810\n",
      "Iteration 9, loss = 1.27504959\n",
      "Iteration 10, loss = 1.27799859\n",
      "Iteration 11, loss = 1.26406884\n",
      "Iteration 12, loss = 1.26686889\n",
      "Iteration 13, loss = 1.27052290\n",
      "Iteration 14, loss = 1.29526773\n",
      "Iteration 15, loss = 1.27606730\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30807783\n",
      "Iteration 2, loss = 1.26348594\n",
      "Iteration 3, loss = 1.25342547\n",
      "Iteration 7, loss = 1.24541344\n",
      "Iteration 8, loss = 1.28471810\n",
      "Iteration 9, loss = 1.27504959\n",
      "Iteration 10, loss = 1.27799859\n",
      "Iteration 11, loss = 1.26406884\n",
      "Iteration 12, loss = 1.26686889\n",
      "Iteration 13, loss = 1.27052290\n",
      "Iteration 14, loss = 1.29526773\n",
      "Iteration 15, loss = 1.27606730\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30807783\n",
      "Iteration 2, loss = 1.26348594\n",
      "Iteration 3, loss = 1.25342547\n",
      "Iteration 4, loss = 1.24636334\n",
      "Iteration 5, loss = 1.25251179\n",
      "Iteration 6, loss = 1.24246538\n",
      "Iteration 7, loss = 1.25387929\n",
      "Iteration 8, loss = 1.25325425\n",
      "Iteration 9, loss = 1.24780838\n",
      "Iteration 10, loss = 1.24534829\n",
      "Iteration 11, loss = 1.27320006\n",
      "Iteration 12, loss = 1.26217744\n",
      "Iteration 13, loss = 1.24019221\n",
      "Iteration 14, loss = 1.25976821\n",
      "Iteration 15, loss = 1.25253385\n",
      "Iteration 16, loss = 1.24474681\n",
      "Iteration 17, loss = 1.25105210\n",
      "Iteration 18, loss = 1.25060912\n",
      "Iteration 4, loss = 1.24636334\n",
      "Iteration 5, loss = 1.25251179\n",
      "Iteration 6, loss = 1.24246538\n",
      "Iteration 7, loss = 1.25387929\n",
      "Iteration 8, loss = 1.25325425\n",
      "Iteration 9, loss = 1.24780838\n",
      "Iteration 10, loss = 1.24534829\n",
      "Iteration 11, loss = 1.27320006\n",
      "Iteration 12, loss = 1.26217744\n",
      "Iteration 13, loss = 1.24019221\n",
      "Iteration 14, loss = 1.25976821\n",
      "Iteration 15, loss = 1.25253385\n",
      "Iteration 16, loss = 1.24474681\n",
      "Iteration 17, loss = 1.25105210\n",
      "Iteration 18, loss = 1.25060912\n",
      "Iteration 19, loss = 1.25200552\n",
      "Iteration 20, loss = 1.25428521\n",
      "Iteration 21, loss = 1.25275096\n",
      "Iteration 22, loss = 1.24824860\n",
      "Iteration 23, loss = 1.25531258\n",
      "Iteration 24, loss = 1.24473988\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31505089\n",
      "Iteration 2, loss = 1.26412009\n",
      "Iteration 3, loss = 1.24780433\n",
      "Iteration 4, loss = 1.24643235\n",
      "Iteration 5, loss = 1.28472672\n",
      "Iteration 6, loss = 1.23710644\n",
      "Iteration 7, loss = 1.25644793\n",
      "Iteration 19, loss = 1.25200552\n",
      "Iteration 20, loss = 1.25428521\n",
      "Iteration 21, loss = 1.25275096\n",
      "Iteration 22, loss = 1.24824860\n",
      "Iteration 23, loss = 1.25531258\n",
      "Iteration 24, loss = 1.24473988\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.31505089\n",
      "Iteration 2, loss = 1.26412009\n",
      "Iteration 3, loss = 1.24780433\n",
      "Iteration 4, loss = 1.24643235\n",
      "Iteration 5, loss = 1.28472672\n",
      "Iteration 6, loss = 1.23710644\n",
      "Iteration 7, loss = 1.25644793\n",
      "Iteration 8, loss = 1.25152229\n",
      "Iteration 9, loss = 1.24271559\n",
      "Iteration 10, loss = 1.25265171\n",
      "Iteration 11, loss = 1.26208512\n",
      "Iteration 12, loss = 1.27396321\n",
      "Iteration 13, loss = 1.25479780\n",
      "Iteration 14, loss = 1.27944630\n",
      "Iteration 15, loss = 1.24592088\n",
      "Iteration 16, loss = 1.26049706\n",
      "Iteration 17, loss = 1.24032578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33585329\n",
      "Iteration 2, loss = 1.13597717\n",
      "Iteration 8, loss = 1.25152229\n",
      "Iteration 9, loss = 1.24271559\n",
      "Iteration 10, loss = 1.25265171\n",
      "Iteration 11, loss = 1.26208512\n",
      "Iteration 12, loss = 1.27396321\n",
      "Iteration 13, loss = 1.25479780\n",
      "Iteration 14, loss = 1.27944630\n",
      "Iteration 15, loss = 1.24592088\n",
      "Iteration 16, loss = 1.26049706\n",
      "Iteration 17, loss = 1.24032578\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33585329\n",
      "Iteration 2, loss = 1.13597717\n",
      "Iteration 3, loss = 1.17912563\n",
      "Iteration 4, loss = 1.07942885\n",
      "Iteration 5, loss = 1.09575330\n",
      "Iteration 6, loss = 1.13056703\n",
      "Iteration 7, loss = 1.10085904\n",
      "Iteration 8, loss = 1.20189318\n",
      "Iteration 9, loss = 1.26984896\n",
      "Iteration 10, loss = 1.26707518\n",
      "Iteration 11, loss = 1.26610989\n",
      "Iteration 12, loss = 1.25463220\n",
      "Iteration 13, loss = 1.25780088\n",
      "Iteration 14, loss = 1.28924234\n",
      "Iteration 15, loss = 1.24509727\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33604217\n",
      "Iteration 3, loss = 1.17912563\n",
      "Iteration 4, loss = 1.07942885\n",
      "Iteration 5, loss = 1.09575330\n",
      "Iteration 6, loss = 1.13056703\n",
      "Iteration 7, loss = 1.10085904\n",
      "Iteration 8, loss = 1.20189318\n",
      "Iteration 9, loss = 1.26984896\n",
      "Iteration 10, loss = 1.26707518\n",
      "Iteration 11, loss = 1.26610989\n",
      "Iteration 12, loss = 1.25463220\n",
      "Iteration 13, loss = 1.25780088\n",
      "Iteration 14, loss = 1.28924234\n",
      "Iteration 15, loss = 1.24509727\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33604217\n",
      "Iteration 2, loss = 1.15407285\n",
      "Iteration 3, loss = 1.11499594\n",
      "Iteration 4, loss = 1.10028161\n",
      "Iteration 5, loss = 1.08233168\n",
      "Iteration 6, loss = 1.06906269\n",
      "Iteration 7, loss = 1.13124687\n",
      "Iteration 8, loss = 1.10999087\n",
      "Iteration 9, loss = 1.05654066\n",
      "Iteration 10, loss = 1.04787234\n",
      "Iteration 11, loss = 1.04796155\n",
      "Iteration 12, loss = 1.24970529\n",
      "Iteration 13, loss = 1.09651220\n",
      "Iteration 14, loss = 1.06531439\n",
      "Iteration 15, loss = 1.05743734\n",
      "Iteration 2, loss = 1.15407285\n",
      "Iteration 3, loss = 1.11499594\n",
      "Iteration 4, loss = 1.10028161\n",
      "Iteration 5, loss = 1.08233168\n",
      "Iteration 6, loss = 1.06906269\n",
      "Iteration 7, loss = 1.13124687\n",
      "Iteration 8, loss = 1.10999087\n",
      "Iteration 9, loss = 1.05654066\n",
      "Iteration 10, loss = 1.04787234\n",
      "Iteration 11, loss = 1.04796155\n",
      "Iteration 12, loss = 1.24970529\n",
      "Iteration 13, loss = 1.09651220\n",
      "Iteration 14, loss = 1.06531439\n",
      "Iteration 15, loss = 1.05743734\n",
      "Iteration 16, loss = 1.31216284\n",
      "Iteration 17, loss = 1.28953637\n",
      "Iteration 18, loss = 1.29098403\n",
      "Iteration 19, loss = 1.31620929\n",
      "Iteration 20, loss = 1.27137796\n",
      "Iteration 21, loss = 1.30535968\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27717928\n",
      "Iteration 2, loss = 1.17336909\n",
      "Iteration 3, loss = 1.23107351\n",
      "Iteration 4, loss = 1.16986380\n",
      "Iteration 5, loss = 1.27888720\n",
      "Iteration 6, loss = 1.28645203\n",
      "Iteration 7, loss = 1.24541344\n",
      "Iteration 8, loss = 1.28471810\n",
      "Iteration 9, loss = 1.27504959\n",
      "Iteration 16, loss = 1.31216284\n",
      "Iteration 17, loss = 1.28953637\n",
      "Iteration 18, loss = 1.29098403\n",
      "Iteration 19, loss = 1.31620929\n",
      "Iteration 20, loss = 1.27137796\n",
      "Iteration 21, loss = 1.30535968\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27717928\n",
      "Iteration 2, loss = 1.17336909\n",
      "Iteration 3, loss = 1.23107351\n",
      "Iteration 4, loss = 1.16986380\n",
      "Iteration 5, loss = 1.27888720\n",
      "Iteration 6, loss = 1.28645203\n",
      "Iteration 7, loss = 1.24541344\n",
      "Iteration 8, loss = 1.28471810\n",
      "Iteration 9, loss = 1.27504959\n",
      "Iteration 10, loss = 1.27799859\n",
      "Iteration 11, loss = 1.26406884\n",
      "Iteration 12, loss = 1.26686889\n",
      "Iteration 13, loss = 1.27052290\n",
      "Iteration 14, loss = 1.29526773\n",
      "Iteration 15, loss = 1.27606730\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19521142\n",
      "Iteration 2, loss = 1.07920065\n",
      "Iteration 3, loss = 1.07166637\n",
      "Iteration 4, loss = 1.00994545\n",
      "Iteration 5, loss = 0.99965735\n",
      "Iteration 6, loss = 1.05376214\n",
      "Iteration 10, loss = 1.27799859\n",
      "Iteration 11, loss = 1.26406884\n",
      "Iteration 12, loss = 1.26686889\n",
      "Iteration 13, loss = 1.27052290\n",
      "Iteration 14, loss = 1.29526773\n",
      "Iteration 15, loss = 1.27606730\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19521142\n",
      "Iteration 2, loss = 1.07920065\n",
      "Iteration 3, loss = 1.07166637\n",
      "Iteration 4, loss = 1.00994545\n",
      "Iteration 5, loss = 0.99965735\n",
      "Iteration 6, loss = 1.05376214\n",
      "Iteration 7, loss = 0.92874364\n",
      "Iteration 8, loss = 0.95462282\n",
      "Iteration 9, loss = 0.92898886\n",
      "Iteration 10, loss = 0.97620129\n",
      "Iteration 1, loss = 1.15981444\n",
      "Iteration 2, loss = 1.03269819\n",
      "Iteration 3, loss = 1.00027667\n",
      "Iteration 4, loss = 0.96531857\n",
      "Iteration 5, loss = 0.92785876\n",
      "Iteration 6, loss = 0.96096190\n",
      "Iteration 7, loss = 0.90707382\n",
      "Iteration 8, loss = 0.89368253\n",
      "Iteration 7, loss = 0.92874364\n",
      "Iteration 8, loss = 0.95462282\n",
      "Iteration 9, loss = 0.92898886\n",
      "Iteration 10, loss = 0.97620129\n",
      "Iteration 1, loss = 1.15981444\n",
      "Iteration 2, loss = 1.03269819\n",
      "Iteration 3, loss = 1.00027667\n",
      "Iteration 4, loss = 0.96531857\n",
      "Iteration 5, loss = 0.92785876\n",
      "Iteration 6, loss = 0.96096190\n",
      "Iteration 7, loss = 0.90707382\n",
      "Iteration 8, loss = 0.89368253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.90326915\n",
      "Iteration 10, loss = 0.89675765\n",
      "Iteration 1, loss = 1.19674363\n",
      "Iteration 2, loss = 1.06777041\n",
      "Iteration 3, loss = 1.03861274\n",
      "Iteration 4, loss = 0.97706584\n",
      "Iteration 5, loss = 0.97449620\n",
      "Iteration 6, loss = 1.01497945\n",
      "Iteration 7, loss = 0.97673231\n",
      "Iteration 8, loss = 0.97692204\n",
      "Iteration 9, loss = 0.93194997\n",
      "Iteration 10, loss = 0.92898394\n",
      "Iteration 1, loss = 1.20895264\n",
      "Iteration 9, loss = 0.90326915\n",
      "Iteration 10, loss = 0.89675765\n",
      "Iteration 1, loss = 1.19674363\n",
      "Iteration 2, loss = 1.06777041\n",
      "Iteration 3, loss = 1.03861274\n",
      "Iteration 4, loss = 0.97706584\n",
      "Iteration 5, loss = 0.97449620\n",
      "Iteration 6, loss = 1.01497945\n",
      "Iteration 7, loss = 0.97673231\n",
      "Iteration 8, loss = 0.97692204\n",
      "Iteration 9, loss = 0.93194997\n",
      "Iteration 10, loss = 0.92898394\n",
      "Iteration 1, loss = 1.20895264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.06621597\n",
      "Iteration 3, loss = 1.05619700\n",
      "Iteration 4, loss = 1.01154092\n",
      "Iteration 5, loss = 1.00116152\n",
      "Iteration 6, loss = 1.00691377\n",
      "Iteration 7, loss = 1.00722439\n",
      "Iteration 8, loss = 1.02051174\n",
      "Iteration 9, loss = 0.94917411\n",
      "Iteration 10, loss = 0.96036247\n",
      "Iteration 1, loss = 1.20853471\n",
      "Iteration 2, loss = 1.06485025\n",
      "Iteration 3, loss = 1.02441930\n",
      "Iteration 2, loss = 1.06621597\n",
      "Iteration 3, loss = 1.05619700\n",
      "Iteration 4, loss = 1.01154092\n",
      "Iteration 5, loss = 1.00116152\n",
      "Iteration 6, loss = 1.00691377\n",
      "Iteration 7, loss = 1.00722439\n",
      "Iteration 8, loss = 1.02051174\n",
      "Iteration 9, loss = 0.94917411\n",
      "Iteration 10, loss = 0.96036247\n",
      "Iteration 1, loss = 1.20853471\n",
      "Iteration 2, loss = 1.06485025\n",
      "Iteration 3, loss = 1.02441930\n",
      "Iteration 4, loss = 1.00072191\n",
      "Iteration 5, loss = 0.99397384\n",
      "Iteration 6, loss = 1.00812112\n",
      "Iteration 7, loss = 0.94666601\n",
      "Iteration 8, loss = 0.99527227\n",
      "Iteration 9, loss = 0.93026815\n",
      "Iteration 10, loss = 0.91135503\n",
      "Iteration 1, loss = 1.19521142\n",
      "Iteration 2, loss = 1.07920065\n",
      "Iteration 3, loss = 1.07166637\n",
      "Iteration 4, loss = 1.00994545\n",
      "Iteration 5, loss = 0.99965735\n",
      "Iteration 6, loss = 1.05376214\n",
      "Iteration 4, loss = 1.00072191\n",
      "Iteration 5, loss = 0.99397384\n",
      "Iteration 6, loss = 1.00812112\n",
      "Iteration 7, loss = 0.94666601\n",
      "Iteration 8, loss = 0.99527227\n",
      "Iteration 9, loss = 0.93026815\n",
      "Iteration 10, loss = 0.91135503\n",
      "Iteration 1, loss = 1.19521142\n",
      "Iteration 2, loss = 1.07920065\n",
      "Iteration 3, loss = 1.07166637\n",
      "Iteration 4, loss = 1.00994545\n",
      "Iteration 5, loss = 0.99965735\n",
      "Iteration 6, loss = 1.05376214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.92874364\n",
      "Iteration 8, loss = 0.95462282\n",
      "Iteration 9, loss = 0.92898886\n",
      "Iteration 10, loss = 0.97620129\n",
      "Iteration 11, loss = 0.98670261\n",
      "Iteration 12, loss = 0.96935080\n",
      "Iteration 13, loss = 0.94736941\n",
      "Iteration 14, loss = 0.93080221\n",
      "Iteration 15, loss = 0.90363288\n",
      "Iteration 16, loss = 0.88576650\n",
      "Iteration 17, loss = 0.89933486\n",
      "Iteration 18, loss = 0.91289125\n",
      "Iteration 19, loss = 0.89400940\n",
      "Iteration 20, loss = 0.91532258\n",
      "Iteration 7, loss = 0.92874364\n",
      "Iteration 8, loss = 0.95462282\n",
      "Iteration 9, loss = 0.92898886\n",
      "Iteration 10, loss = 0.97620129\n",
      "Iteration 11, loss = 0.98670261\n",
      "Iteration 12, loss = 0.96935080\n",
      "Iteration 13, loss = 0.94736941\n",
      "Iteration 14, loss = 0.93080221\n",
      "Iteration 15, loss = 0.90363288\n",
      "Iteration 16, loss = 0.88576650\n",
      "Iteration 17, loss = 0.89933486\n",
      "Iteration 18, loss = 0.91289125\n",
      "Iteration 19, loss = 0.89400940\n",
      "Iteration 20, loss = 0.91532258\n",
      "Iteration 21, loss = 0.91896685\n",
      "Iteration 22, loss = 0.87265671\n",
      "Iteration 23, loss = 0.84991923\n",
      "Iteration 24, loss = 0.88756169\n",
      "Iteration 25, loss = 0.88708116\n",
      "Iteration 26, loss = 0.87674062\n",
      "Iteration 27, loss = 0.89420041\n",
      "Iteration 28, loss = 0.87096004\n",
      "Iteration 29, loss = 0.90216572\n",
      "Iteration 30, loss = 0.87566494\n",
      "Iteration 31, loss = 0.88022250\n",
      "Iteration 32, loss = 0.85227556\n",
      "Iteration 33, loss = 0.82862743\n",
      "Iteration 34, loss = 0.83724026\n",
      "Iteration 35, loss = 0.84896800\n",
      "Iteration 21, loss = 0.91896685\n",
      "Iteration 22, loss = 0.87265671\n",
      "Iteration 23, loss = 0.84991923\n",
      "Iteration 24, loss = 0.88756169\n",
      "Iteration 25, loss = 0.88708116\n",
      "Iteration 26, loss = 0.87674062\n",
      "Iteration 27, loss = 0.89420041\n",
      "Iteration 28, loss = 0.87096004\n",
      "Iteration 29, loss = 0.90216572\n",
      "Iteration 30, loss = 0.87566494\n",
      "Iteration 31, loss = 0.88022250\n",
      "Iteration 32, loss = 0.85227556\n",
      "Iteration 33, loss = 0.82862743\n",
      "Iteration 34, loss = 0.83724026\n",
      "Iteration 35, loss = 0.84896800\n",
      "Iteration 36, loss = 0.82648854\n",
      "Iteration 37, loss = 0.83729311\n",
      "Iteration 38, loss = 0.79439943\n",
      "Iteration 39, loss = 0.82767296\n",
      "Iteration 40, loss = 0.85383861\n",
      "Iteration 41, loss = 0.78305056\n",
      "Iteration 42, loss = 0.84904946\n",
      "Iteration 43, loss = 0.79905238\n",
      "Iteration 44, loss = 0.78517723\n",
      "Iteration 45, loss = 0.77144858\n",
      "Iteration 46, loss = 0.80733728\n",
      "Iteration 47, loss = 0.81364006\n",
      "Iteration 48, loss = 0.78022443\n",
      "Iteration 49, loss = 0.76033656\n",
      "Iteration 36, loss = 0.82648854\n",
      "Iteration 37, loss = 0.83729311\n",
      "Iteration 38, loss = 0.79439943\n",
      "Iteration 39, loss = 0.82767296\n",
      "Iteration 40, loss = 0.85383861\n",
      "Iteration 41, loss = 0.78305056\n",
      "Iteration 42, loss = 0.84904946\n",
      "Iteration 43, loss = 0.79905238\n",
      "Iteration 44, loss = 0.78517723\n",
      "Iteration 45, loss = 0.77144858\n",
      "Iteration 46, loss = 0.80733728\n",
      "Iteration 47, loss = 0.81364006\n",
      "Iteration 48, loss = 0.78022443\n",
      "Iteration 49, loss = 0.76033656\n",
      "Iteration 50, loss = 0.82066904\n",
      "Iteration 1, loss = 1.15981444\n",
      "Iteration 2, loss = 1.03269819\n",
      "Iteration 3, loss = 1.00027667\n",
      "Iteration 4, loss = 0.96531857\n",
      "Iteration 5, loss = 0.92785876\n",
      "Iteration 6, loss = 0.96096190\n",
      "Iteration 7, loss = 0.90707382\n",
      "Iteration 8, loss = 0.89368253\n",
      "Iteration 9, loss = 0.90326915\n",
      "Iteration 10, loss = 0.89675765\n",
      "Iteration 11, loss = 0.91327907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 0.82066904\n",
      "Iteration 1, loss = 1.15981444\n",
      "Iteration 2, loss = 1.03269819\n",
      "Iteration 3, loss = 1.00027667\n",
      "Iteration 4, loss = 0.96531857\n",
      "Iteration 5, loss = 0.92785876\n",
      "Iteration 6, loss = 0.96096190\n",
      "Iteration 7, loss = 0.90707382\n",
      "Iteration 8, loss = 0.89368253\n",
      "Iteration 9, loss = 0.90326915\n",
      "Iteration 10, loss = 0.89675765\n",
      "Iteration 11, loss = 0.91327907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.91368832\n",
      "Iteration 13, loss = 0.86775987\n",
      "Iteration 14, loss = 0.88305605\n",
      "Iteration 15, loss = 0.86058205\n",
      "Iteration 16, loss = 0.84220298\n",
      "Iteration 17, loss = 0.88111355\n",
      "Iteration 18, loss = 0.85274924\n",
      "Iteration 19, loss = 0.82861064\n",
      "Iteration 20, loss = 0.85055798\n",
      "Iteration 21, loss = 0.83410203\n",
      "Iteration 22, loss = 0.82451377\n",
      "Iteration 23, loss = 0.88407072\n",
      "Iteration 24, loss = 0.85082601\n",
      "Iteration 25, loss = 0.87453818\n",
      "Iteration 12, loss = 0.91368832\n",
      "Iteration 13, loss = 0.86775987\n",
      "Iteration 14, loss = 0.88305605\n",
      "Iteration 15, loss = 0.86058205\n",
      "Iteration 16, loss = 0.84220298\n",
      "Iteration 17, loss = 0.88111355\n",
      "Iteration 18, loss = 0.85274924\n",
      "Iteration 19, loss = 0.82861064\n",
      "Iteration 20, loss = 0.85055798\n",
      "Iteration 21, loss = 0.83410203\n",
      "Iteration 22, loss = 0.82451377\n",
      "Iteration 23, loss = 0.88407072\n",
      "Iteration 24, loss = 0.85082601\n",
      "Iteration 25, loss = 0.87453818\n",
      "Iteration 26, loss = 0.81527378\n",
      "Iteration 27, loss = 0.83078217\n",
      "Iteration 28, loss = 0.82798108\n",
      "Iteration 29, loss = 0.85955798\n",
      "Iteration 30, loss = 0.81566652\n",
      "Iteration 31, loss = 0.78954118\n",
      "Iteration 32, loss = 0.80338039\n",
      "Iteration 33, loss = 0.82615727\n",
      "Iteration 34, loss = 0.77383073\n",
      "Iteration 35, loss = 0.80110773\n",
      "Iteration 36, loss = 0.76757064\n",
      "Iteration 37, loss = 0.80769228\n",
      "Iteration 38, loss = 0.77066814\n",
      "Iteration 39, loss = 0.80979332\n",
      "Iteration 40, loss = 0.77917393\n",
      "Iteration 26, loss = 0.81527378\n",
      "Iteration 27, loss = 0.83078217\n",
      "Iteration 28, loss = 0.82798108\n",
      "Iteration 29, loss = 0.85955798\n",
      "Iteration 30, loss = 0.81566652\n",
      "Iteration 31, loss = 0.78954118\n",
      "Iteration 32, loss = 0.80338039\n",
      "Iteration 33, loss = 0.82615727\n",
      "Iteration 34, loss = 0.77383073\n",
      "Iteration 35, loss = 0.80110773\n",
      "Iteration 36, loss = 0.76757064\n",
      "Iteration 37, loss = 0.80769228\n",
      "Iteration 38, loss = 0.77066814\n",
      "Iteration 39, loss = 0.80979332\n",
      "Iteration 40, loss = 0.77917393\n",
      "Iteration 41, loss = 0.78403814\n",
      "Iteration 42, loss = 0.75208364\n",
      "Iteration 43, loss = 0.79307071\n",
      "Iteration 44, loss = 0.80614071\n",
      "Iteration 45, loss = 0.74238935\n",
      "Iteration 46, loss = 0.74797596\n",
      "Iteration 47, loss = 0.73297936\n",
      "Iteration 48, loss = 0.73138142\n",
      "Iteration 49, loss = 0.73027175\n",
      "Iteration 50, loss = 0.73299902\n",
      "Iteration 1, loss = 1.19674363\n",
      "Iteration 2, loss = 1.06777041\n",
      "Iteration 3, loss = 1.03861274\n",
      "Iteration 4, loss = 0.97706584\n",
      "Iteration 41, loss = 0.78403814\n",
      "Iteration 42, loss = 0.75208364\n",
      "Iteration 43, loss = 0.79307071\n",
      "Iteration 44, loss = 0.80614071\n",
      "Iteration 45, loss = 0.74238935\n",
      "Iteration 46, loss = 0.74797596\n",
      "Iteration 47, loss = 0.73297936\n",
      "Iteration 48, loss = 0.73138142\n",
      "Iteration 49, loss = 0.73027175\n",
      "Iteration 50, loss = 0.73299902\n",
      "Iteration 1, loss = 1.19674363\n",
      "Iteration 2, loss = 1.06777041\n",
      "Iteration 3, loss = 1.03861274\n",
      "Iteration 4, loss = 0.97706584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.97449620\n",
      "Iteration 6, loss = 1.01497945\n",
      "Iteration 7, loss = 0.97673231\n",
      "Iteration 8, loss = 0.97692204\n",
      "Iteration 9, loss = 0.93194997\n",
      "Iteration 10, loss = 0.92898394\n",
      "Iteration 11, loss = 0.90640959\n",
      "Iteration 12, loss = 0.93544417\n",
      "Iteration 13, loss = 0.91460923\n",
      "Iteration 14, loss = 0.90012640\n",
      "Iteration 15, loss = 0.90544892\n",
      "Iteration 16, loss = 0.87690685\n",
      "Iteration 17, loss = 0.92228688\n",
      "Iteration 5, loss = 0.97449620\n",
      "Iteration 6, loss = 1.01497945\n",
      "Iteration 7, loss = 0.97673231\n",
      "Iteration 8, loss = 0.97692204\n",
      "Iteration 9, loss = 0.93194997\n",
      "Iteration 10, loss = 0.92898394\n",
      "Iteration 11, loss = 0.90640959\n",
      "Iteration 12, loss = 0.93544417\n",
      "Iteration 13, loss = 0.91460923\n",
      "Iteration 14, loss = 0.90012640\n",
      "Iteration 15, loss = 0.90544892\n",
      "Iteration 16, loss = 0.87690685\n",
      "Iteration 17, loss = 0.92228688\n",
      "Iteration 18, loss = 0.90732797\n",
      "Iteration 19, loss = 0.89040855\n",
      "Iteration 20, loss = 0.88952846\n",
      "Iteration 21, loss = 0.91154324\n",
      "Iteration 22, loss = 0.86260034\n",
      "Iteration 23, loss = 0.88265931\n",
      "Iteration 24, loss = 0.88510105\n",
      "Iteration 25, loss = 0.86579817\n",
      "Iteration 26, loss = 0.85996036\n",
      "Iteration 27, loss = 0.82157747\n",
      "Iteration 28, loss = 0.84681234\n",
      "Iteration 29, loss = 0.86778526\n",
      "Iteration 30, loss = 0.88423127\n",
      "Iteration 31, loss = 0.81905783\n",
      "Iteration 18, loss = 0.90732797\n",
      "Iteration 19, loss = 0.89040855\n",
      "Iteration 20, loss = 0.88952846\n",
      "Iteration 21, loss = 0.91154324\n",
      "Iteration 22, loss = 0.86260034\n",
      "Iteration 23, loss = 0.88265931\n",
      "Iteration 24, loss = 0.88510105\n",
      "Iteration 25, loss = 0.86579817\n",
      "Iteration 26, loss = 0.85996036\n",
      "Iteration 27, loss = 0.82157747\n",
      "Iteration 28, loss = 0.84681234\n",
      "Iteration 29, loss = 0.86778526\n",
      "Iteration 30, loss = 0.88423127\n",
      "Iteration 31, loss = 0.81905783\n",
      "Iteration 32, loss = 0.86547282\n",
      "Iteration 33, loss = 0.82523984\n",
      "Iteration 34, loss = 0.80709356\n",
      "Iteration 35, loss = 0.82764535\n",
      "Iteration 36, loss = 0.81554719\n",
      "Iteration 37, loss = 0.81376696\n",
      "Iteration 38, loss = 0.82758444\n",
      "Iteration 39, loss = 0.78153666\n",
      "Iteration 40, loss = 0.78431810\n",
      "Iteration 41, loss = 0.84118235\n",
      "Iteration 42, loss = 0.81003189\n",
      "Iteration 43, loss = 0.80017729\n",
      "Iteration 44, loss = 0.86217949\n",
      "Iteration 45, loss = 0.76478212\n",
      "Iteration 46, loss = 0.80256346\n",
      "Iteration 32, loss = 0.86547282\n",
      "Iteration 33, loss = 0.82523984\n",
      "Iteration 34, loss = 0.80709356\n",
      "Iteration 35, loss = 0.82764535\n",
      "Iteration 36, loss = 0.81554719\n",
      "Iteration 37, loss = 0.81376696\n",
      "Iteration 38, loss = 0.82758444\n",
      "Iteration 39, loss = 0.78153666\n",
      "Iteration 40, loss = 0.78431810\n",
      "Iteration 41, loss = 0.84118235\n",
      "Iteration 42, loss = 0.81003189\n",
      "Iteration 43, loss = 0.80017729\n",
      "Iteration 44, loss = 0.86217949\n",
      "Iteration 45, loss = 0.76478212\n",
      "Iteration 46, loss = 0.80256346\n",
      "Iteration 47, loss = 0.76209478\n",
      "Iteration 48, loss = 0.77862158\n",
      "Iteration 49, loss = 0.78193600\n",
      "Iteration 50, loss = 0.75013501\n",
      "Iteration 1, loss = 1.20895264\n",
      "Iteration 2, loss = 1.06621597\n",
      "Iteration 3, loss = 1.05619700\n",
      "Iteration 4, loss = 1.01154092\n",
      "Iteration 5, loss = 1.00116152\n",
      "Iteration 6, loss = 1.00691377\n",
      "Iteration 7, loss = 1.00722439\n",
      "Iteration 8, loss = 1.02051174\n",
      "Iteration 9, loss = 0.94917411\n",
      "Iteration 47, loss = 0.76209478\n",
      "Iteration 48, loss = 0.77862158\n",
      "Iteration 49, loss = 0.78193600\n",
      "Iteration 50, loss = 0.75013501\n",
      "Iteration 1, loss = 1.20895264\n",
      "Iteration 2, loss = 1.06621597\n",
      "Iteration 3, loss = 1.05619700\n",
      "Iteration 4, loss = 1.01154092\n",
      "Iteration 5, loss = 1.00116152\n",
      "Iteration 6, loss = 1.00691377\n",
      "Iteration 7, loss = 1.00722439\n",
      "Iteration 8, loss = 1.02051174\n",
      "Iteration 9, loss = 0.94917411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.96036247\n",
      "Iteration 11, loss = 0.94228064\n",
      "Iteration 12, loss = 0.96240830\n",
      "Iteration 13, loss = 0.93932915\n",
      "Iteration 14, loss = 0.93438818\n",
      "Iteration 15, loss = 0.91372955\n",
      "Iteration 16, loss = 0.92583806\n",
      "Iteration 17, loss = 0.91934109\n",
      "Iteration 18, loss = 0.91650529\n",
      "Iteration 19, loss = 0.90497954\n",
      "Iteration 20, loss = 0.90724676\n",
      "Iteration 21, loss = 0.89412716\n",
      "Iteration 22, loss = 0.85425338\n",
      "Iteration 23, loss = 0.92032656\n",
      "Iteration 24, loss = 0.90775652\n",
      "Iteration 10, loss = 0.96036247\n",
      "Iteration 11, loss = 0.94228064\n",
      "Iteration 12, loss = 0.96240830\n",
      "Iteration 13, loss = 0.93932915\n",
      "Iteration 14, loss = 0.93438818\n",
      "Iteration 15, loss = 0.91372955\n",
      "Iteration 16, loss = 0.92583806\n",
      "Iteration 17, loss = 0.91934109\n",
      "Iteration 18, loss = 0.91650529\n",
      "Iteration 19, loss = 0.90497954\n",
      "Iteration 20, loss = 0.90724676\n",
      "Iteration 21, loss = 0.89412716\n",
      "Iteration 22, loss = 0.85425338\n",
      "Iteration 23, loss = 0.92032656\n",
      "Iteration 24, loss = 0.90775652\n",
      "Iteration 25, loss = 0.86681477\n",
      "Iteration 26, loss = 0.88179688\n",
      "Iteration 27, loss = 0.86786881\n",
      "Iteration 28, loss = 0.89045830\n",
      "Iteration 29, loss = 0.89226236\n",
      "Iteration 30, loss = 0.87399245\n",
      "Iteration 31, loss = 0.84597518\n",
      "Iteration 32, loss = 0.85583363\n",
      "Iteration 33, loss = 0.87676714\n",
      "Iteration 34, loss = 0.85256865\n",
      "Iteration 35, loss = 0.83948807\n",
      "Iteration 36, loss = 0.83469299\n",
      "Iteration 37, loss = 0.89576956\n",
      "Iteration 38, loss = 0.86052505\n",
      "Iteration 25, loss = 0.86681477\n",
      "Iteration 26, loss = 0.88179688\n",
      "Iteration 27, loss = 0.86786881\n",
      "Iteration 28, loss = 0.89045830\n",
      "Iteration 29, loss = 0.89226236\n",
      "Iteration 30, loss = 0.87399245\n",
      "Iteration 31, loss = 0.84597518\n",
      "Iteration 32, loss = 0.85583363\n",
      "Iteration 33, loss = 0.87676714\n",
      "Iteration 34, loss = 0.85256865\n",
      "Iteration 35, loss = 0.83948807\n",
      "Iteration 36, loss = 0.83469299\n",
      "Iteration 37, loss = 0.89576956\n",
      "Iteration 38, loss = 0.86052505\n",
      "Iteration 39, loss = 0.80386525\n",
      "Iteration 40, loss = 0.83766380\n",
      "Iteration 41, loss = 0.83277912\n",
      "Iteration 42, loss = 0.81412717\n",
      "Iteration 43, loss = 0.80574461\n",
      "Iteration 44, loss = 0.79851434\n",
      "Iteration 45, loss = 0.82060777\n",
      "Iteration 46, loss = 0.80002278\n",
      "Iteration 47, loss = 0.75885588\n",
      "Iteration 48, loss = 0.77036781\n",
      "Iteration 49, loss = 0.81226347\n",
      "Iteration 50, loss = 0.74088269\n",
      "Iteration 1, loss = 1.20853471\n",
      "Iteration 39, loss = 0.80386525\n",
      "Iteration 40, loss = 0.83766380\n",
      "Iteration 41, loss = 0.83277912\n",
      "Iteration 42, loss = 0.81412717\n",
      "Iteration 43, loss = 0.80574461\n",
      "Iteration 44, loss = 0.79851434\n",
      "Iteration 45, loss = 0.82060777\n",
      "Iteration 46, loss = 0.80002278\n",
      "Iteration 47, loss = 0.75885588\n",
      "Iteration 48, loss = 0.77036781\n",
      "Iteration 49, loss = 0.81226347\n",
      "Iteration 50, loss = 0.74088269\n",
      "Iteration 1, loss = 1.20853471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.06485025\n",
      "Iteration 3, loss = 1.02441930\n",
      "Iteration 4, loss = 1.00072191\n",
      "Iteration 5, loss = 0.99397384\n",
      "Iteration 6, loss = 1.00812112\n",
      "Iteration 7, loss = 0.94666601\n",
      "Iteration 8, loss = 0.99527227\n",
      "Iteration 9, loss = 0.93026815\n",
      "Iteration 10, loss = 0.91135503\n",
      "Iteration 11, loss = 0.92457894\n",
      "Iteration 12, loss = 0.90922636\n",
      "Iteration 13, loss = 0.95838744\n",
      "Iteration 14, loss = 0.92782684\n",
      "Iteration 15, loss = 0.91697909\n",
      "Iteration 2, loss = 1.06485025\n",
      "Iteration 3, loss = 1.02441930\n",
      "Iteration 4, loss = 1.00072191\n",
      "Iteration 5, loss = 0.99397384\n",
      "Iteration 6, loss = 1.00812112\n",
      "Iteration 7, loss = 0.94666601\n",
      "Iteration 8, loss = 0.99527227\n",
      "Iteration 9, loss = 0.93026815\n",
      "Iteration 10, loss = 0.91135503\n",
      "Iteration 11, loss = 0.92457894\n",
      "Iteration 12, loss = 0.90922636\n",
      "Iteration 13, loss = 0.95838744\n",
      "Iteration 14, loss = 0.92782684\n",
      "Iteration 15, loss = 0.91697909\n",
      "Iteration 16, loss = 0.92506421\n",
      "Iteration 17, loss = 0.93044031\n",
      "Iteration 18, loss = 0.92371096\n",
      "Iteration 19, loss = 0.90314622\n",
      "Iteration 20, loss = 0.93297527\n",
      "Iteration 21, loss = 0.89914952\n",
      "Iteration 22, loss = 0.89063160\n",
      "Iteration 23, loss = 0.89372748\n",
      "Iteration 24, loss = 0.90117597\n",
      "Iteration 25, loss = 0.88172550\n",
      "Iteration 26, loss = 0.88730613\n",
      "Iteration 27, loss = 0.86029697\n",
      "Iteration 28, loss = 0.86706262\n",
      "Iteration 29, loss = 0.84547014\n",
      "Iteration 30, loss = 0.89604530\n",
      "Iteration 16, loss = 0.92506421\n",
      "Iteration 17, loss = 0.93044031\n",
      "Iteration 18, loss = 0.92371096\n",
      "Iteration 19, loss = 0.90314622\n",
      "Iteration 20, loss = 0.93297527\n",
      "Iteration 21, loss = 0.89914952\n",
      "Iteration 22, loss = 0.89063160\n",
      "Iteration 23, loss = 0.89372748\n",
      "Iteration 24, loss = 0.90117597\n",
      "Iteration 25, loss = 0.88172550\n",
      "Iteration 26, loss = 0.88730613\n",
      "Iteration 27, loss = 0.86029697\n",
      "Iteration 28, loss = 0.86706262\n",
      "Iteration 29, loss = 0.84547014\n",
      "Iteration 30, loss = 0.89604530\n",
      "Iteration 31, loss = 0.87362945\n",
      "Iteration 32, loss = 0.83578626\n",
      "Iteration 33, loss = 0.93806236\n",
      "Iteration 34, loss = 0.84631356\n",
      "Iteration 35, loss = 0.83864116\n",
      "Iteration 36, loss = 0.84193965\n",
      "Iteration 37, loss = 0.85992549\n",
      "Iteration 38, loss = 0.85011734\n",
      "Iteration 39, loss = 0.82438006\n",
      "Iteration 40, loss = 0.84010029\n",
      "Iteration 41, loss = 0.81509192\n",
      "Iteration 42, loss = 0.83608204\n",
      "Iteration 43, loss = 0.81649122\n",
      "Iteration 44, loss = 0.81688761\n",
      "Iteration 31, loss = 0.87362945\n",
      "Iteration 32, loss = 0.83578626\n",
      "Iteration 33, loss = 0.93806236\n",
      "Iteration 34, loss = 0.84631356\n",
      "Iteration 35, loss = 0.83864116\n",
      "Iteration 36, loss = 0.84193965\n",
      "Iteration 37, loss = 0.85992549\n",
      "Iteration 38, loss = 0.85011734\n",
      "Iteration 39, loss = 0.82438006\n",
      "Iteration 40, loss = 0.84010029\n",
      "Iteration 41, loss = 0.81509192\n",
      "Iteration 42, loss = 0.83608204\n",
      "Iteration 43, loss = 0.81649122\n",
      "Iteration 44, loss = 0.81688761\n",
      "Iteration 45, loss = 0.80999478\n",
      "Iteration 46, loss = 0.83481418\n",
      "Iteration 47, loss = 0.78188064\n",
      "Iteration 48, loss = 0.80530640\n",
      "Iteration 49, loss = 0.80572384\n",
      "Iteration 50, loss = 0.76713634\n",
      "Iteration 1, loss = 1.19521142\n",
      "Iteration 2, loss = 1.07920065\n",
      "Iteration 3, loss = 1.07166637\n",
      "Iteration 4, loss = 1.00994545\n",
      "Iteration 5, loss = 0.99965735\n",
      "Iteration 6, loss = 1.05376214\n",
      "Iteration 7, loss = 0.92874364\n",
      "Iteration 45, loss = 0.80999478\n",
      "Iteration 46, loss = 0.83481418\n",
      "Iteration 47, loss = 0.78188064\n",
      "Iteration 48, loss = 0.80530640\n",
      "Iteration 49, loss = 0.80572384\n",
      "Iteration 50, loss = 0.76713634\n",
      "Iteration 1, loss = 1.19521142\n",
      "Iteration 2, loss = 1.07920065\n",
      "Iteration 3, loss = 1.07166637\n",
      "Iteration 4, loss = 1.00994545\n",
      "Iteration 5, loss = 0.99965735\n",
      "Iteration 6, loss = 1.05376214\n",
      "Iteration 7, loss = 0.92874364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.95462282\n",
      "Iteration 9, loss = 0.92898886\n",
      "Iteration 10, loss = 0.97620129\n",
      "Iteration 11, loss = 0.98670261\n",
      "Iteration 12, loss = 0.96935080\n",
      "Iteration 13, loss = 0.94736941\n",
      "Iteration 14, loss = 0.93080221\n",
      "Iteration 15, loss = 0.90363288\n",
      "Iteration 16, loss = 0.88576650\n",
      "Iteration 17, loss = 0.89933486\n",
      "Iteration 18, loss = 0.91289125\n",
      "Iteration 19, loss = 0.89400940\n",
      "Iteration 20, loss = 0.91532258\n",
      "Iteration 21, loss = 0.91896685\n",
      "Iteration 8, loss = 0.95462282\n",
      "Iteration 9, loss = 0.92898886\n",
      "Iteration 10, loss = 0.97620129\n",
      "Iteration 11, loss = 0.98670261\n",
      "Iteration 12, loss = 0.96935080\n",
      "Iteration 13, loss = 0.94736941\n",
      "Iteration 14, loss = 0.93080221\n",
      "Iteration 15, loss = 0.90363288\n",
      "Iteration 16, loss = 0.88576650\n",
      "Iteration 17, loss = 0.89933486\n",
      "Iteration 18, loss = 0.91289125\n",
      "Iteration 19, loss = 0.89400940\n",
      "Iteration 20, loss = 0.91532258\n",
      "Iteration 21, loss = 0.91896685\n",
      "Iteration 22, loss = 0.87265671\n",
      "Iteration 23, loss = 0.84991923\n",
      "Iteration 24, loss = 0.88756169\n",
      "Iteration 25, loss = 0.88708116\n",
      "Iteration 26, loss = 0.87674062\n",
      "Iteration 27, loss = 0.89420041\n",
      "Iteration 28, loss = 0.87096004\n",
      "Iteration 29, loss = 0.90216572\n",
      "Iteration 30, loss = 0.87566494\n",
      "Iteration 31, loss = 0.88022250\n",
      "Iteration 32, loss = 0.85227556\n",
      "Iteration 33, loss = 0.82862743\n",
      "Iteration 34, loss = 0.83724026\n",
      "Iteration 35, loss = 0.84896800\n",
      "Iteration 22, loss = 0.87265671\n",
      "Iteration 23, loss = 0.84991923\n",
      "Iteration 24, loss = 0.88756169\n",
      "Iteration 25, loss = 0.88708116\n",
      "Iteration 26, loss = 0.87674062\n",
      "Iteration 27, loss = 0.89420041\n",
      "Iteration 28, loss = 0.87096004\n",
      "Iteration 29, loss = 0.90216572\n",
      "Iteration 30, loss = 0.87566494\n",
      "Iteration 31, loss = 0.88022250\n",
      "Iteration 32, loss = 0.85227556\n",
      "Iteration 33, loss = 0.82862743\n",
      "Iteration 34, loss = 0.83724026\n",
      "Iteration 35, loss = 0.84896800\n",
      "Iteration 36, loss = 0.82648854\n",
      "Iteration 37, loss = 0.83729311\n",
      "Iteration 38, loss = 0.79439943\n",
      "Iteration 39, loss = 0.82767296\n",
      "Iteration 40, loss = 0.85383861\n",
      "Iteration 41, loss = 0.78305056\n",
      "Iteration 42, loss = 0.84904946\n",
      "Iteration 43, loss = 0.79905238\n",
      "Iteration 44, loss = 0.78517723\n",
      "Iteration 45, loss = 0.77144858\n",
      "Iteration 46, loss = 0.80733728\n",
      "Iteration 47, loss = 0.81364006\n",
      "Iteration 48, loss = 0.78022443\n",
      "Iteration 49, loss = 0.76033656\n",
      "Iteration 50, loss = 0.82066904\n",
      "Iteration 51, loss = 0.79372942\n",
      "Iteration 36, loss = 0.82648854\n",
      "Iteration 37, loss = 0.83729311\n",
      "Iteration 38, loss = 0.79439943\n",
      "Iteration 39, loss = 0.82767296\n",
      "Iteration 40, loss = 0.85383861\n",
      "Iteration 41, loss = 0.78305056\n",
      "Iteration 42, loss = 0.84904946\n",
      "Iteration 43, loss = 0.79905238\n",
      "Iteration 44, loss = 0.78517723\n",
      "Iteration 45, loss = 0.77144858\n",
      "Iteration 46, loss = 0.80733728\n",
      "Iteration 47, loss = 0.81364006\n",
      "Iteration 48, loss = 0.78022443\n",
      "Iteration 49, loss = 0.76033656\n",
      "Iteration 50, loss = 0.82066904\n",
      "Iteration 51, loss = 0.79372942\n",
      "Iteration 52, loss = 0.76290727\n",
      "Iteration 53, loss = 0.77347662\n",
      "Iteration 54, loss = 0.77966255\n",
      "Iteration 55, loss = 0.83913758\n",
      "Iteration 56, loss = 0.73729110\n",
      "Iteration 57, loss = 0.78072768\n",
      "Iteration 58, loss = 0.75110953\n",
      "Iteration 59, loss = 0.71453985\n",
      "Iteration 60, loss = 0.72870415\n",
      "Iteration 61, loss = 0.71122970\n",
      "Iteration 62, loss = 0.70330156\n",
      "Iteration 63, loss = 0.72413939\n",
      "Iteration 64, loss = 0.78800614\n",
      "Iteration 65, loss = 0.80402635\n",
      "Iteration 52, loss = 0.76290727\n",
      "Iteration 53, loss = 0.77347662\n",
      "Iteration 54, loss = 0.77966255\n",
      "Iteration 55, loss = 0.83913758\n",
      "Iteration 56, loss = 0.73729110\n",
      "Iteration 57, loss = 0.78072768\n",
      "Iteration 58, loss = 0.75110953\n",
      "Iteration 59, loss = 0.71453985\n",
      "Iteration 60, loss = 0.72870415\n",
      "Iteration 61, loss = 0.71122970\n",
      "Iteration 62, loss = 0.70330156\n",
      "Iteration 63, loss = 0.72413939\n",
      "Iteration 64, loss = 0.78800614\n",
      "Iteration 65, loss = 0.80402635\n",
      "Iteration 66, loss = 0.74464214\n",
      "Iteration 67, loss = 0.71019554\n",
      "Iteration 68, loss = 0.73329580\n",
      "Iteration 69, loss = 0.71946193\n",
      "Iteration 70, loss = 0.72243150\n",
      "Iteration 71, loss = 0.75811313\n",
      "Iteration 72, loss = 0.77413699\n",
      "Iteration 73, loss = 0.76304696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15981444\n",
      "Iteration 2, loss = 1.03269819\n",
      "Iteration 3, loss = 1.00027667\n",
      "Iteration 4, loss = 0.96531857\n",
      "Iteration 5, loss = 0.92785876\n",
      "Iteration 6, loss = 0.96096190\n",
      "Iteration 66, loss = 0.74464214\n",
      "Iteration 67, loss = 0.71019554\n",
      "Iteration 68, loss = 0.73329580\n",
      "Iteration 69, loss = 0.71946193\n",
      "Iteration 70, loss = 0.72243150\n",
      "Iteration 71, loss = 0.75811313\n",
      "Iteration 72, loss = 0.77413699\n",
      "Iteration 73, loss = 0.76304696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15981444\n",
      "Iteration 2, loss = 1.03269819\n",
      "Iteration 3, loss = 1.00027667\n",
      "Iteration 4, loss = 0.96531857\n",
      "Iteration 5, loss = 0.92785876\n",
      "Iteration 6, loss = 0.96096190\n",
      "Iteration 7, loss = 0.90707382\n",
      "Iteration 8, loss = 0.89368253\n",
      "Iteration 9, loss = 0.90326915\n",
      "Iteration 10, loss = 0.89675765\n",
      "Iteration 11, loss = 0.91327907\n",
      "Iteration 12, loss = 0.91368832\n",
      "Iteration 13, loss = 0.86775987\n",
      "Iteration 14, loss = 0.88305605\n",
      "Iteration 15, loss = 0.86058205\n",
      "Iteration 16, loss = 0.84220298\n",
      "Iteration 17, loss = 0.88111355\n",
      "Iteration 18, loss = 0.85274924\n",
      "Iteration 19, loss = 0.82861064\n",
      "Iteration 7, loss = 0.90707382\n",
      "Iteration 8, loss = 0.89368253\n",
      "Iteration 9, loss = 0.90326915\n",
      "Iteration 10, loss = 0.89675765\n",
      "Iteration 11, loss = 0.91327907\n",
      "Iteration 12, loss = 0.91368832\n",
      "Iteration 13, loss = 0.86775987\n",
      "Iteration 14, loss = 0.88305605\n",
      "Iteration 15, loss = 0.86058205\n",
      "Iteration 16, loss = 0.84220298\n",
      "Iteration 17, loss = 0.88111355\n",
      "Iteration 18, loss = 0.85274924\n",
      "Iteration 19, loss = 0.82861064\n",
      "Iteration 20, loss = 0.85055798\n",
      "Iteration 21, loss = 0.83410203\n",
      "Iteration 22, loss = 0.82451377\n",
      "Iteration 23, loss = 0.88407072\n",
      "Iteration 24, loss = 0.85082601\n",
      "Iteration 25, loss = 0.87453818\n",
      "Iteration 26, loss = 0.81527378\n",
      "Iteration 27, loss = 0.83078217\n",
      "Iteration 28, loss = 0.82798108\n",
      "Iteration 29, loss = 0.85955798\n",
      "Iteration 30, loss = 0.81566652\n",
      "Iteration 31, loss = 0.78954118\n",
      "Iteration 32, loss = 0.80338039\n",
      "Iteration 33, loss = 0.82615727\n",
      "Iteration 20, loss = 0.85055798\n",
      "Iteration 21, loss = 0.83410203\n",
      "Iteration 22, loss = 0.82451377\n",
      "Iteration 23, loss = 0.88407072\n",
      "Iteration 24, loss = 0.85082601\n",
      "Iteration 25, loss = 0.87453818\n",
      "Iteration 26, loss = 0.81527378\n",
      "Iteration 27, loss = 0.83078217\n",
      "Iteration 28, loss = 0.82798108\n",
      "Iteration 29, loss = 0.85955798\n",
      "Iteration 30, loss = 0.81566652\n",
      "Iteration 31, loss = 0.78954118\n",
      "Iteration 32, loss = 0.80338039\n",
      "Iteration 33, loss = 0.82615727\n",
      "Iteration 34, loss = 0.77383073\n",
      "Iteration 35, loss = 0.80110773\n",
      "Iteration 36, loss = 0.76757064\n",
      "Iteration 37, loss = 0.80769228\n",
      "Iteration 38, loss = 0.77066814\n",
      "Iteration 39, loss = 0.80979332\n",
      "Iteration 40, loss = 0.77917393\n",
      "Iteration 41, loss = 0.78403814\n",
      "Iteration 42, loss = 0.75208364\n",
      "Iteration 43, loss = 0.79307071\n",
      "Iteration 44, loss = 0.80614071\n",
      "Iteration 45, loss = 0.74238935\n",
      "Iteration 46, loss = 0.74797596\n",
      "Iteration 47, loss = 0.73297936\n",
      "Iteration 48, loss = 0.73138142\n",
      "Iteration 34, loss = 0.77383073\n",
      "Iteration 35, loss = 0.80110773\n",
      "Iteration 36, loss = 0.76757064\n",
      "Iteration 37, loss = 0.80769228\n",
      "Iteration 38, loss = 0.77066814\n",
      "Iteration 39, loss = 0.80979332\n",
      "Iteration 40, loss = 0.77917393\n",
      "Iteration 41, loss = 0.78403814\n",
      "Iteration 42, loss = 0.75208364\n",
      "Iteration 43, loss = 0.79307071\n",
      "Iteration 44, loss = 0.80614071\n",
      "Iteration 45, loss = 0.74238935\n",
      "Iteration 46, loss = 0.74797596\n",
      "Iteration 47, loss = 0.73297936\n",
      "Iteration 48, loss = 0.73138142\n",
      "Iteration 49, loss = 0.73027175\n",
      "Iteration 50, loss = 0.73299902\n",
      "Iteration 51, loss = 0.73773293\n",
      "Iteration 52, loss = 0.72138821\n",
      "Iteration 53, loss = 0.70505915\n",
      "Iteration 54, loss = 0.70681891\n",
      "Iteration 55, loss = 0.72174807\n",
      "Iteration 56, loss = 0.71130461\n",
      "Iteration 57, loss = 0.68908121\n",
      "Iteration 58, loss = 0.72136918\n",
      "Iteration 59, loss = 0.71360622\n",
      "Iteration 60, loss = 0.69575634\n",
      "Iteration 61, loss = 0.69235142\n",
      "Iteration 62, loss = 0.68393238\n",
      "Iteration 63, loss = 0.65664106\n",
      "Iteration 49, loss = 0.73027175\n",
      "Iteration 50, loss = 0.73299902\n",
      "Iteration 51, loss = 0.73773293\n",
      "Iteration 52, loss = 0.72138821\n",
      "Iteration 53, loss = 0.70505915\n",
      "Iteration 54, loss = 0.70681891\n",
      "Iteration 55, loss = 0.72174807\n",
      "Iteration 56, loss = 0.71130461\n",
      "Iteration 57, loss = 0.68908121\n",
      "Iteration 58, loss = 0.72136918\n",
      "Iteration 59, loss = 0.71360622\n",
      "Iteration 60, loss = 0.69575634\n",
      "Iteration 61, loss = 0.69235142\n",
      "Iteration 62, loss = 0.68393238\n",
      "Iteration 63, loss = 0.65664106\n",
      "Iteration 64, loss = 0.72877986\n",
      "Iteration 65, loss = 0.70437096\n",
      "Iteration 66, loss = 0.68438946\n",
      "Iteration 67, loss = 0.70555745\n",
      "Iteration 68, loss = 0.69825090\n",
      "Iteration 69, loss = 0.68141633\n",
      "Iteration 70, loss = 0.68479891\n",
      "Iteration 71, loss = 0.65211394\n",
      "Iteration 72, loss = 0.66251932\n",
      "Iteration 73, loss = 0.67349998\n",
      "Iteration 74, loss = 0.65851085\n",
      "Iteration 75, loss = 0.66842444\n",
      "Iteration 76, loss = 0.62299974\n",
      "Iteration 77, loss = 0.62525675\n",
      "Iteration 78, loss = 0.70169256\n",
      "Iteration 64, loss = 0.72877986\n",
      "Iteration 65, loss = 0.70437096\n",
      "Iteration 66, loss = 0.68438946\n",
      "Iteration 67, loss = 0.70555745\n",
      "Iteration 68, loss = 0.69825090\n",
      "Iteration 69, loss = 0.68141633\n",
      "Iteration 70, loss = 0.68479891\n",
      "Iteration 71, loss = 0.65211394\n",
      "Iteration 72, loss = 0.66251932\n",
      "Iteration 73, loss = 0.67349998\n",
      "Iteration 74, loss = 0.65851085\n",
      "Iteration 75, loss = 0.66842444\n",
      "Iteration 76, loss = 0.62299974\n",
      "Iteration 77, loss = 0.62525675\n",
      "Iteration 78, loss = 0.70169256\n",
      "Iteration 79, loss = 0.67999956\n",
      "Iteration 80, loss = 0.67094767\n",
      "Iteration 81, loss = 0.65876039\n",
      "Iteration 82, loss = 0.69088064\n",
      "Iteration 83, loss = 0.67461845\n",
      "Iteration 84, loss = 0.66651043\n",
      "Iteration 85, loss = 0.67070300\n",
      "Iteration 86, loss = 0.63645418\n",
      "Iteration 87, loss = 0.63579747\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19674363\n",
      "Iteration 2, loss = 1.06777041\n",
      "Iteration 3, loss = 1.03861274\n",
      "Iteration 4, loss = 0.97706584\n",
      "Iteration 79, loss = 0.67999956\n",
      "Iteration 80, loss = 0.67094767\n",
      "Iteration 81, loss = 0.65876039\n",
      "Iteration 82, loss = 0.69088064\n",
      "Iteration 83, loss = 0.67461845\n",
      "Iteration 84, loss = 0.66651043\n",
      "Iteration 85, loss = 0.67070300\n",
      "Iteration 86, loss = 0.63645418\n",
      "Iteration 87, loss = 0.63579747\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19674363\n",
      "Iteration 2, loss = 1.06777041\n",
      "Iteration 3, loss = 1.03861274\n",
      "Iteration 4, loss = 0.97706584\n",
      "Iteration 5, loss = 0.97449620\n",
      "Iteration 6, loss = 1.01497945\n",
      "Iteration 7, loss = 0.97673231\n",
      "Iteration 8, loss = 0.97692204\n",
      "Iteration 9, loss = 0.93194997\n",
      "Iteration 10, loss = 0.92898394\n",
      "Iteration 11, loss = 0.90640959\n",
      "Iteration 12, loss = 0.93544417\n",
      "Iteration 13, loss = 0.91460923\n",
      "Iteration 14, loss = 0.90012640\n",
      "Iteration 15, loss = 0.90544892\n",
      "Iteration 16, loss = 0.87690685\n",
      "Iteration 5, loss = 0.97449620\n",
      "Iteration 6, loss = 1.01497945\n",
      "Iteration 7, loss = 0.97673231\n",
      "Iteration 8, loss = 0.97692204\n",
      "Iteration 9, loss = 0.93194997\n",
      "Iteration 10, loss = 0.92898394\n",
      "Iteration 11, loss = 0.90640959\n",
      "Iteration 12, loss = 0.93544417\n",
      "Iteration 13, loss = 0.91460923\n",
      "Iteration 14, loss = 0.90012640\n",
      "Iteration 15, loss = 0.90544892\n",
      "Iteration 16, loss = 0.87690685\n",
      "Iteration 17, loss = 0.92228688\n",
      "Iteration 18, loss = 0.90732797\n",
      "Iteration 19, loss = 0.89040855\n",
      "Iteration 20, loss = 0.88952846\n",
      "Iteration 21, loss = 0.91154324\n",
      "Iteration 22, loss = 0.86260034\n",
      "Iteration 23, loss = 0.88265931\n",
      "Iteration 24, loss = 0.88510105\n",
      "Iteration 25, loss = 0.86579817\n",
      "Iteration 26, loss = 0.85996036\n",
      "Iteration 27, loss = 0.82157747\n",
      "Iteration 28, loss = 0.84681234\n",
      "Iteration 29, loss = 0.86778526\n",
      "Iteration 30, loss = 0.88423127\n",
      "Iteration 31, loss = 0.81905783\n",
      "Iteration 32, loss = 0.86547282\n",
      "Iteration 17, loss = 0.92228688\n",
      "Iteration 18, loss = 0.90732797\n",
      "Iteration 19, loss = 0.89040855\n",
      "Iteration 20, loss = 0.88952846\n",
      "Iteration 21, loss = 0.91154324\n",
      "Iteration 22, loss = 0.86260034\n",
      "Iteration 23, loss = 0.88265931\n",
      "Iteration 24, loss = 0.88510105\n",
      "Iteration 25, loss = 0.86579817\n",
      "Iteration 26, loss = 0.85996036\n",
      "Iteration 27, loss = 0.82157747\n",
      "Iteration 28, loss = 0.84681234\n",
      "Iteration 29, loss = 0.86778526\n",
      "Iteration 30, loss = 0.88423127\n",
      "Iteration 31, loss = 0.81905783\n",
      "Iteration 32, loss = 0.86547282\n",
      "Iteration 33, loss = 0.82523984\n",
      "Iteration 34, loss = 0.80709356\n",
      "Iteration 35, loss = 0.82764535\n",
      "Iteration 36, loss = 0.81554719\n",
      "Iteration 37, loss = 0.81376696\n",
      "Iteration 38, loss = 0.82758444\n",
      "Iteration 39, loss = 0.78153666\n",
      "Iteration 40, loss = 0.78431810\n",
      "Iteration 41, loss = 0.84118235\n",
      "Iteration 42, loss = 0.81003189\n",
      "Iteration 43, loss = 0.80017729\n",
      "Iteration 44, loss = 0.86217949\n",
      "Iteration 45, loss = 0.76478212\n",
      "Iteration 46, loss = 0.80256346\n",
      "Iteration 47, loss = 0.76209478\n",
      "Iteration 33, loss = 0.82523984\n",
      "Iteration 34, loss = 0.80709356\n",
      "Iteration 35, loss = 0.82764535\n",
      "Iteration 36, loss = 0.81554719\n",
      "Iteration 37, loss = 0.81376696\n",
      "Iteration 38, loss = 0.82758444\n",
      "Iteration 39, loss = 0.78153666\n",
      "Iteration 40, loss = 0.78431810\n",
      "Iteration 41, loss = 0.84118235\n",
      "Iteration 42, loss = 0.81003189\n",
      "Iteration 43, loss = 0.80017729\n",
      "Iteration 44, loss = 0.86217949\n",
      "Iteration 45, loss = 0.76478212\n",
      "Iteration 46, loss = 0.80256346\n",
      "Iteration 47, loss = 0.76209478\n",
      "Iteration 48, loss = 0.77862158\n",
      "Iteration 49, loss = 0.78193600\n",
      "Iteration 50, loss = 0.75013501\n",
      "Iteration 51, loss = 0.75709878\n",
      "Iteration 52, loss = 0.76496087\n",
      "Iteration 53, loss = 0.76996707\n",
      "Iteration 54, loss = 0.75679623\n",
      "Iteration 55, loss = 0.81300834\n",
      "Iteration 56, loss = 0.72035792\n",
      "Iteration 57, loss = 0.72531856\n",
      "Iteration 58, loss = 0.81969953\n",
      "Iteration 59, loss = 0.79857081\n",
      "Iteration 60, loss = 0.78379492\n",
      "Iteration 61, loss = 0.72412555\n",
      "Iteration 62, loss = 0.72507516\n",
      "Iteration 63, loss = 0.81844658\n",
      "Iteration 48, loss = 0.77862158\n",
      "Iteration 49, loss = 0.78193600\n",
      "Iteration 50, loss = 0.75013501\n",
      "Iteration 51, loss = 0.75709878\n",
      "Iteration 52, loss = 0.76496087\n",
      "Iteration 53, loss = 0.76996707\n",
      "Iteration 54, loss = 0.75679623\n",
      "Iteration 55, loss = 0.81300834\n",
      "Iteration 56, loss = 0.72035792\n",
      "Iteration 57, loss = 0.72531856\n",
      "Iteration 58, loss = 0.81969953\n",
      "Iteration 59, loss = 0.79857081\n",
      "Iteration 60, loss = 0.78379492\n",
      "Iteration 61, loss = 0.72412555\n",
      "Iteration 62, loss = 0.72507516\n",
      "Iteration 63, loss = 0.81844658\n",
      "Iteration 64, loss = 0.71013766\n",
      "Iteration 65, loss = 0.72880964\n",
      "Iteration 66, loss = 0.74345274\n",
      "Iteration 67, loss = 0.74941828\n",
      "Iteration 68, loss = 0.77989147\n",
      "Iteration 69, loss = 0.72265605\n",
      "Iteration 70, loss = 0.72497552\n",
      "Iteration 71, loss = 0.74106148\n",
      "Iteration 72, loss = 0.71414290\n",
      "Iteration 73, loss = 0.74098498\n",
      "Iteration 74, loss = 0.74507710\n",
      "Iteration 75, loss = 0.71539370\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20895264\n",
      "Iteration 64, loss = 0.71013766\n",
      "Iteration 65, loss = 0.72880964\n",
      "Iteration 66, loss = 0.74345274\n",
      "Iteration 67, loss = 0.74941828\n",
      "Iteration 68, loss = 0.77989147\n",
      "Iteration 69, loss = 0.72265605\n",
      "Iteration 70, loss = 0.72497552\n",
      "Iteration 71, loss = 0.74106148\n",
      "Iteration 72, loss = 0.71414290\n",
      "Iteration 73, loss = 0.74098498\n",
      "Iteration 74, loss = 0.74507710\n",
      "Iteration 75, loss = 0.71539370\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20895264\n",
      "Iteration 2, loss = 1.06621597\n",
      "Iteration 3, loss = 1.05619700\n",
      "Iteration 4, loss = 1.01154092\n",
      "Iteration 5, loss = 1.00116152\n",
      "Iteration 6, loss = 1.00691377\n",
      "Iteration 7, loss = 1.00722439\n",
      "Iteration 8, loss = 1.02051174\n",
      "Iteration 9, loss = 0.94917411\n",
      "Iteration 10, loss = 0.96036247\n",
      "Iteration 11, loss = 0.94228064\n",
      "Iteration 12, loss = 0.96240830\n",
      "Iteration 13, loss = 0.93932915\n",
      "Iteration 14, loss = 0.93438818\n",
      "Iteration 15, loss = 0.91372955\n",
      "Iteration 2, loss = 1.06621597\n",
      "Iteration 3, loss = 1.05619700\n",
      "Iteration 4, loss = 1.01154092\n",
      "Iteration 5, loss = 1.00116152\n",
      "Iteration 6, loss = 1.00691377\n",
      "Iteration 7, loss = 1.00722439\n",
      "Iteration 8, loss = 1.02051174\n",
      "Iteration 9, loss = 0.94917411\n",
      "Iteration 10, loss = 0.96036247\n",
      "Iteration 11, loss = 0.94228064\n",
      "Iteration 12, loss = 0.96240830\n",
      "Iteration 13, loss = 0.93932915\n",
      "Iteration 14, loss = 0.93438818\n",
      "Iteration 15, loss = 0.91372955\n",
      "Iteration 16, loss = 0.92583806\n",
      "Iteration 17, loss = 0.91934109\n",
      "Iteration 18, loss = 0.91650529\n",
      "Iteration 19, loss = 0.90497954\n",
      "Iteration 20, loss = 0.90724676\n",
      "Iteration 21, loss = 0.89412716\n",
      "Iteration 22, loss = 0.85425338\n",
      "Iteration 23, loss = 0.92032656\n",
      "Iteration 24, loss = 0.90775652\n",
      "Iteration 25, loss = 0.86681477\n",
      "Iteration 26, loss = 0.88179688\n",
      "Iteration 27, loss = 0.86786881\n",
      "Iteration 28, loss = 0.89045830\n",
      "Iteration 29, loss = 0.89226236\n",
      "Iteration 30, loss = 0.87399245\n",
      "Iteration 16, loss = 0.92583806\n",
      "Iteration 17, loss = 0.91934109\n",
      "Iteration 18, loss = 0.91650529\n",
      "Iteration 19, loss = 0.90497954\n",
      "Iteration 20, loss = 0.90724676\n",
      "Iteration 21, loss = 0.89412716\n",
      "Iteration 22, loss = 0.85425338\n",
      "Iteration 23, loss = 0.92032656\n",
      "Iteration 24, loss = 0.90775652\n",
      "Iteration 25, loss = 0.86681477\n",
      "Iteration 26, loss = 0.88179688\n",
      "Iteration 27, loss = 0.86786881\n",
      "Iteration 28, loss = 0.89045830\n",
      "Iteration 29, loss = 0.89226236\n",
      "Iteration 30, loss = 0.87399245\n",
      "Iteration 31, loss = 0.84597518\n",
      "Iteration 32, loss = 0.85583363\n",
      "Iteration 33, loss = 0.87676714\n",
      "Iteration 34, loss = 0.85256865\n",
      "Iteration 35, loss = 0.83948807\n",
      "Iteration 36, loss = 0.83469299\n",
      "Iteration 37, loss = 0.89576956\n",
      "Iteration 38, loss = 0.86052505\n",
      "Iteration 39, loss = 0.80386525\n",
      "Iteration 40, loss = 0.83766380\n",
      "Iteration 41, loss = 0.83277912\n",
      "Iteration 42, loss = 0.81412717\n",
      "Iteration 43, loss = 0.80574461\n",
      "Iteration 44, loss = 0.79851434\n",
      "Iteration 31, loss = 0.84597518\n",
      "Iteration 32, loss = 0.85583363\n",
      "Iteration 33, loss = 0.87676714\n",
      "Iteration 34, loss = 0.85256865\n",
      "Iteration 35, loss = 0.83948807\n",
      "Iteration 36, loss = 0.83469299\n",
      "Iteration 37, loss = 0.89576956\n",
      "Iteration 38, loss = 0.86052505\n",
      "Iteration 39, loss = 0.80386525\n",
      "Iteration 40, loss = 0.83766380\n",
      "Iteration 41, loss = 0.83277912\n",
      "Iteration 42, loss = 0.81412717\n",
      "Iteration 43, loss = 0.80574461\n",
      "Iteration 44, loss = 0.79851434\n",
      "Iteration 45, loss = 0.82060777\n",
      "Iteration 46, loss = 0.80002278\n",
      "Iteration 47, loss = 0.75885588\n",
      "Iteration 48, loss = 0.77036781\n",
      "Iteration 49, loss = 0.81226347\n",
      "Iteration 50, loss = 0.74088269\n",
      "Iteration 51, loss = 0.76385818\n",
      "Iteration 52, loss = 0.77828247\n",
      "Iteration 53, loss = 0.75970680\n",
      "Iteration 54, loss = 0.81133753\n",
      "Iteration 55, loss = 0.75040248\n",
      "Iteration 56, loss = 0.77197240\n",
      "Iteration 57, loss = 0.72760934\n",
      "Iteration 58, loss = 0.73815265\n",
      "Iteration 59, loss = 0.77111287\n",
      "Iteration 45, loss = 0.82060777\n",
      "Iteration 46, loss = 0.80002278\n",
      "Iteration 47, loss = 0.75885588\n",
      "Iteration 48, loss = 0.77036781\n",
      "Iteration 49, loss = 0.81226347\n",
      "Iteration 50, loss = 0.74088269\n",
      "Iteration 51, loss = 0.76385818\n",
      "Iteration 52, loss = 0.77828247\n",
      "Iteration 53, loss = 0.75970680\n",
      "Iteration 54, loss = 0.81133753\n",
      "Iteration 55, loss = 0.75040248\n",
      "Iteration 56, loss = 0.77197240\n",
      "Iteration 57, loss = 0.72760934\n",
      "Iteration 58, loss = 0.73815265\n",
      "Iteration 59, loss = 0.77111287\n",
      "Iteration 60, loss = 0.73007070\n",
      "Iteration 61, loss = 0.75205312\n",
      "Iteration 62, loss = 0.73200139\n",
      "Iteration 63, loss = 0.83980670\n",
      "Iteration 64, loss = 0.73079747\n",
      "Iteration 65, loss = 0.70339992\n",
      "Iteration 66, loss = 0.73517014\n",
      "Iteration 67, loss = 0.69256290\n",
      "Iteration 68, loss = 0.71231414\n",
      "Iteration 69, loss = 0.71911826\n",
      "Iteration 70, loss = 0.68770333\n",
      "Iteration 71, loss = 0.63851582\n",
      "Iteration 72, loss = 0.69414105\n",
      "Iteration 73, loss = 0.69760977\n",
      "Iteration 74, loss = 0.73920215\n",
      "Iteration 60, loss = 0.73007070\n",
      "Iteration 61, loss = 0.75205312\n",
      "Iteration 62, loss = 0.73200139\n",
      "Iteration 63, loss = 0.83980670\n",
      "Iteration 64, loss = 0.73079747\n",
      "Iteration 65, loss = 0.70339992\n",
      "Iteration 66, loss = 0.73517014\n",
      "Iteration 67, loss = 0.69256290\n",
      "Iteration 68, loss = 0.71231414\n",
      "Iteration 69, loss = 0.71911826\n",
      "Iteration 70, loss = 0.68770333\n",
      "Iteration 71, loss = 0.63851582\n",
      "Iteration 72, loss = 0.69414105\n",
      "Iteration 73, loss = 0.69760977\n",
      "Iteration 74, loss = 0.73920215\n",
      "Iteration 75, loss = 0.69661941\n",
      "Iteration 76, loss = 0.69291582\n",
      "Iteration 77, loss = 0.75835212\n",
      "Iteration 78, loss = 0.73703105\n",
      "Iteration 79, loss = 0.69843516\n",
      "Iteration 80, loss = 0.66160732\n",
      "Iteration 81, loss = 0.66670862\n",
      "Iteration 82, loss = 0.65591141\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20853471\n",
      "Iteration 2, loss = 1.06485025\n",
      "Iteration 3, loss = 1.02441930\n",
      "Iteration 4, loss = 1.00072191\n",
      "Iteration 5, loss = 0.99397384\n",
      "Iteration 75, loss = 0.69661941\n",
      "Iteration 76, loss = 0.69291582\n",
      "Iteration 77, loss = 0.75835212\n",
      "Iteration 78, loss = 0.73703105\n",
      "Iteration 79, loss = 0.69843516\n",
      "Iteration 80, loss = 0.66160732\n",
      "Iteration 81, loss = 0.66670862\n",
      "Iteration 82, loss = 0.65591141\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.20853471\n",
      "Iteration 2, loss = 1.06485025\n",
      "Iteration 3, loss = 1.02441930\n",
      "Iteration 4, loss = 1.00072191\n",
      "Iteration 5, loss = 0.99397384\n",
      "Iteration 6, loss = 1.00812112\n",
      "Iteration 7, loss = 0.94666601\n",
      "Iteration 8, loss = 0.99527227\n",
      "Iteration 9, loss = 0.93026815\n",
      "Iteration 10, loss = 0.91135503\n",
      "Iteration 11, loss = 0.92457894\n",
      "Iteration 12, loss = 0.90922636\n",
      "Iteration 13, loss = 0.95838744\n",
      "Iteration 14, loss = 0.92782684\n",
      "Iteration 15, loss = 0.91697909\n",
      "Iteration 16, loss = 0.92506421\n",
      "Iteration 17, loss = 0.93044031\n",
      "Iteration 18, loss = 0.92371096\n",
      "Iteration 19, loss = 0.90314622\n",
      "Iteration 6, loss = 1.00812112\n",
      "Iteration 7, loss = 0.94666601\n",
      "Iteration 8, loss = 0.99527227\n",
      "Iteration 9, loss = 0.93026815\n",
      "Iteration 10, loss = 0.91135503\n",
      "Iteration 11, loss = 0.92457894\n",
      "Iteration 12, loss = 0.90922636\n",
      "Iteration 13, loss = 0.95838744\n",
      "Iteration 14, loss = 0.92782684\n",
      "Iteration 15, loss = 0.91697909\n",
      "Iteration 16, loss = 0.92506421\n",
      "Iteration 17, loss = 0.93044031\n",
      "Iteration 18, loss = 0.92371096\n",
      "Iteration 19, loss = 0.90314622\n",
      "Iteration 20, loss = 0.93297527\n",
      "Iteration 21, loss = 0.89914952\n",
      "Iteration 22, loss = 0.89063160\n",
      "Iteration 23, loss = 0.89372748\n",
      "Iteration 24, loss = 0.90117597\n",
      "Iteration 25, loss = 0.88172550\n",
      "Iteration 26, loss = 0.88730613\n",
      "Iteration 27, loss = 0.86029697\n",
      "Iteration 28, loss = 0.86706262\n",
      "Iteration 29, loss = 0.84547014\n",
      "Iteration 30, loss = 0.89604530\n",
      "Iteration 31, loss = 0.87362945\n",
      "Iteration 32, loss = 0.83578626\n",
      "Iteration 33, loss = 0.93806236\n",
      "Iteration 20, loss = 0.93297527\n",
      "Iteration 21, loss = 0.89914952\n",
      "Iteration 22, loss = 0.89063160\n",
      "Iteration 23, loss = 0.89372748\n",
      "Iteration 24, loss = 0.90117597\n",
      "Iteration 25, loss = 0.88172550\n",
      "Iteration 26, loss = 0.88730613\n",
      "Iteration 27, loss = 0.86029697\n",
      "Iteration 28, loss = 0.86706262\n",
      "Iteration 29, loss = 0.84547014\n",
      "Iteration 30, loss = 0.89604530\n",
      "Iteration 31, loss = 0.87362945\n",
      "Iteration 32, loss = 0.83578626\n",
      "Iteration 33, loss = 0.93806236\n",
      "Iteration 34, loss = 0.84631356\n",
      "Iteration 35, loss = 0.83864116\n",
      "Iteration 36, loss = 0.84193965\n",
      "Iteration 37, loss = 0.85992549\n",
      "Iteration 38, loss = 0.85011734\n",
      "Iteration 39, loss = 0.82438006\n",
      "Iteration 40, loss = 0.84010029\n",
      "Iteration 41, loss = 0.81509192\n",
      "Iteration 42, loss = 0.83608204\n",
      "Iteration 43, loss = 0.81649122\n",
      "Iteration 44, loss = 0.81688761\n",
      "Iteration 45, loss = 0.80999478\n",
      "Iteration 46, loss = 0.83481418\n",
      "Iteration 47, loss = 0.78188064\n",
      "Iteration 48, loss = 0.80530640\n",
      "Iteration 34, loss = 0.84631356\n",
      "Iteration 35, loss = 0.83864116\n",
      "Iteration 36, loss = 0.84193965\n",
      "Iteration 37, loss = 0.85992549\n",
      "Iteration 38, loss = 0.85011734\n",
      "Iteration 39, loss = 0.82438006\n",
      "Iteration 40, loss = 0.84010029\n",
      "Iteration 41, loss = 0.81509192\n",
      "Iteration 42, loss = 0.83608204\n",
      "Iteration 43, loss = 0.81649122\n",
      "Iteration 44, loss = 0.81688761\n",
      "Iteration 45, loss = 0.80999478\n",
      "Iteration 46, loss = 0.83481418\n",
      "Iteration 47, loss = 0.78188064\n",
      "Iteration 48, loss = 0.80530640\n",
      "Iteration 49, loss = 0.80572384\n",
      "Iteration 50, loss = 0.76713634\n",
      "Iteration 51, loss = 0.78547625\n",
      "Iteration 52, loss = 0.82331183\n",
      "Iteration 53, loss = 0.79144188\n",
      "Iteration 54, loss = 0.75919906\n",
      "Iteration 55, loss = 0.78550188\n",
      "Iteration 56, loss = 0.77438143\n",
      "Iteration 57, loss = 0.77244446\n",
      "Iteration 58, loss = 0.75954861\n",
      "Iteration 59, loss = 0.79383641\n",
      "Iteration 60, loss = 0.75101547\n",
      "Iteration 61, loss = 0.77634286\n",
      "Iteration 62, loss = 0.74205043\n",
      "Iteration 63, loss = 0.77834763\n",
      "Iteration 49, loss = 0.80572384\n",
      "Iteration 50, loss = 0.76713634\n",
      "Iteration 51, loss = 0.78547625\n",
      "Iteration 52, loss = 0.82331183\n",
      "Iteration 53, loss = 0.79144188\n",
      "Iteration 54, loss = 0.75919906\n",
      "Iteration 55, loss = 0.78550188\n",
      "Iteration 56, loss = 0.77438143\n",
      "Iteration 57, loss = 0.77244446\n",
      "Iteration 58, loss = 0.75954861\n",
      "Iteration 59, loss = 0.79383641\n",
      "Iteration 60, loss = 0.75101547\n",
      "Iteration 61, loss = 0.77634286\n",
      "Iteration 62, loss = 0.74205043\n",
      "Iteration 63, loss = 0.77834763\n",
      "Iteration 64, loss = 0.76291016\n",
      "Iteration 65, loss = 0.76601805\n",
      "Iteration 66, loss = 0.75939502\n",
      "Iteration 67, loss = 0.74104577\n",
      "Iteration 68, loss = 0.74310841\n",
      "Iteration 69, loss = 0.77562375\n",
      "Iteration 70, loss = 0.77663306\n",
      "Iteration 71, loss = 0.71101852\n",
      "Iteration 72, loss = 0.75334700\n",
      "Iteration 73, loss = 0.71971999\n",
      "Iteration 74, loss = 0.74668165\n",
      "Iteration 75, loss = 0.73158977\n",
      "Iteration 76, loss = 0.71334412\n",
      "Iteration 77, loss = 0.73660513\n",
      "Iteration 78, loss = 0.73198560\n",
      "Iteration 64, loss = 0.76291016\n",
      "Iteration 65, loss = 0.76601805\n",
      "Iteration 66, loss = 0.75939502\n",
      "Iteration 67, loss = 0.74104577\n",
      "Iteration 68, loss = 0.74310841\n",
      "Iteration 69, loss = 0.77562375\n",
      "Iteration 70, loss = 0.77663306\n",
      "Iteration 71, loss = 0.71101852\n",
      "Iteration 72, loss = 0.75334700\n",
      "Iteration 73, loss = 0.71971999\n",
      "Iteration 74, loss = 0.74668165\n",
      "Iteration 75, loss = 0.73158977\n",
      "Iteration 76, loss = 0.71334412\n",
      "Iteration 77, loss = 0.73660513\n",
      "Iteration 78, loss = 0.73198560\n",
      "Iteration 79, loss = 0.73082575\n",
      "Iteration 80, loss = 0.70934706\n",
      "Iteration 81, loss = 0.72426764\n",
      "Iteration 82, loss = 0.71352351\n",
      "Iteration 83, loss = 0.69306625\n",
      "Iteration 84, loss = 0.71213159\n",
      "Iteration 85, loss = 0.72771376\n",
      "Iteration 86, loss = 0.71859854\n",
      "Iteration 87, loss = 0.72577389\n",
      "Iteration 88, loss = 0.70799780\n",
      "Iteration 89, loss = 0.72097293\n",
      "Iteration 90, loss = 0.74535741\n",
      "Iteration 91, loss = 0.72718089\n",
      "Iteration 92, loss = 0.72608541\n",
      "Iteration 93, loss = 0.68605968\n",
      "Iteration 79, loss = 0.73082575\n",
      "Iteration 80, loss = 0.70934706\n",
      "Iteration 81, loss = 0.72426764\n",
      "Iteration 82, loss = 0.71352351\n",
      "Iteration 83, loss = 0.69306625\n",
      "Iteration 84, loss = 0.71213159\n",
      "Iteration 85, loss = 0.72771376\n",
      "Iteration 86, loss = 0.71859854\n",
      "Iteration 87, loss = 0.72577389\n",
      "Iteration 88, loss = 0.70799780\n",
      "Iteration 89, loss = 0.72097293\n",
      "Iteration 90, loss = 0.74535741\n",
      "Iteration 91, loss = 0.72718089\n",
      "Iteration 92, loss = 0.72608541\n",
      "Iteration 93, loss = 0.68605968\n",
      "Iteration 94, loss = 0.68861816\n",
      "Iteration 95, loss = 0.70296811\n",
      "Iteration 96, loss = 0.72027419\n",
      "Iteration 97, loss = 0.81859890\n",
      "Iteration 98, loss = 0.70199375\n",
      "Iteration 99, loss = 0.71166678\n",
      "Iteration 100, loss = 0.70202215\n",
      "Iteration 1, loss = 1.22386711\n",
      "Iteration 2, loss = 1.11443864\n",
      "Iteration 3, loss = 1.07971722\n",
      "Iteration 4, loss = 1.02997365\n",
      "Iteration 5, loss = 1.02342203\n",
      "Iteration 6, loss = 1.08466987\n",
      "Iteration 94, loss = 0.68861816\n",
      "Iteration 95, loss = 0.70296811\n",
      "Iteration 96, loss = 0.72027419\n",
      "Iteration 97, loss = 0.81859890\n",
      "Iteration 98, loss = 0.70199375\n",
      "Iteration 99, loss = 0.71166678\n",
      "Iteration 100, loss = 0.70202215\n",
      "Iteration 1, loss = 1.22386711\n",
      "Iteration 2, loss = 1.11443864\n",
      "Iteration 3, loss = 1.07971722\n",
      "Iteration 4, loss = 1.02997365\n",
      "Iteration 5, loss = 1.02342203\n",
      "Iteration 6, loss = 1.08466987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 1.00253811\n",
      "Iteration 8, loss = 1.04192941\n",
      "Iteration 9, loss = 0.99387443\n",
      "Iteration 10, loss = 1.03784293\n",
      "Iteration 1, loss = 1.18341526\n",
      "Iteration 2, loss = 1.08398065\n",
      "Iteration 3, loss = 0.99821164\n",
      "Iteration 4, loss = 0.99214498\n",
      "Iteration 5, loss = 0.94951359\n",
      "Iteration 6, loss = 0.98117197\n",
      "Iteration 7, loss = 0.94291697\n",
      "Iteration 8, loss = 1.02045474\n",
      "Iteration 9, loss = 0.95674357\n",
      "Iteration 7, loss = 1.00253811\n",
      "Iteration 8, loss = 1.04192941\n",
      "Iteration 9, loss = 0.99387443\n",
      "Iteration 10, loss = 1.03784293\n",
      "Iteration 1, loss = 1.18341526\n",
      "Iteration 2, loss = 1.08398065\n",
      "Iteration 3, loss = 0.99821164\n",
      "Iteration 4, loss = 0.99214498\n",
      "Iteration 5, loss = 0.94951359\n",
      "Iteration 6, loss = 0.98117197\n",
      "Iteration 7, loss = 0.94291697\n",
      "Iteration 8, loss = 1.02045474\n",
      "Iteration 9, loss = 0.95674357\n",
      "Iteration 10, loss = 0.94847243\n",
      "Iteration 1, loss = 1.21033869\n",
      "Iteration 2, loss = 1.09759050\n",
      "Iteration 3, loss = 1.03647859\n",
      "Iteration 4, loss = 0.97797224\n",
      "Iteration 5, loss = 1.01092476\n",
      "Iteration 6, loss = 1.02746038\n",
      "Iteration 7, loss = 0.97381688\n",
      "Iteration 8, loss = 1.01484865\n",
      "Iteration 9, loss = 1.00929304\n",
      "Iteration 10, loss = 0.98910433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.94847243\n",
      "Iteration 1, loss = 1.21033869\n",
      "Iteration 2, loss = 1.09759050\n",
      "Iteration 3, loss = 1.03647859\n",
      "Iteration 4, loss = 0.97797224\n",
      "Iteration 5, loss = 1.01092476\n",
      "Iteration 6, loss = 1.02746038\n",
      "Iteration 7, loss = 0.97381688\n",
      "Iteration 8, loss = 1.01484865\n",
      "Iteration 9, loss = 1.00929304\n",
      "Iteration 10, loss = 0.98910433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22658096\n",
      "Iteration 2, loss = 1.09729849\n",
      "Iteration 3, loss = 1.02991666\n",
      "Iteration 4, loss = 1.03955746\n",
      "Iteration 5, loss = 1.03546268\n",
      "Iteration 6, loss = 1.03001671\n",
      "Iteration 7, loss = 0.98799643\n",
      "Iteration 8, loss = 1.04888943\n",
      "Iteration 9, loss = 1.00090912\n",
      "Iteration 10, loss = 1.03826690\n",
      "Iteration 1, loss = 1.22049864\n",
      "Iteration 2, loss = 1.08908521\n",
      "Iteration 1, loss = 1.22658096\n",
      "Iteration 2, loss = 1.09729849\n",
      "Iteration 3, loss = 1.02991666\n",
      "Iteration 4, loss = 1.03955746\n",
      "Iteration 5, loss = 1.03546268\n",
      "Iteration 6, loss = 1.03001671\n",
      "Iteration 7, loss = 0.98799643\n",
      "Iteration 8, loss = 1.04888943\n",
      "Iteration 9, loss = 1.00090912\n",
      "Iteration 10, loss = 1.03826690\n",
      "Iteration 1, loss = 1.22049864\n",
      "Iteration 2, loss = 1.08908521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.99837032\n",
      "Iteration 4, loss = 0.99140915\n",
      "Iteration 5, loss = 1.01740782\n",
      "Iteration 6, loss = 1.03311418\n",
      "Iteration 7, loss = 0.96210783\n",
      "Iteration 8, loss = 1.00920375\n",
      "Iteration 9, loss = 0.96792466\n",
      "Iteration 10, loss = 0.95008309\n",
      "Iteration 1, loss = 1.22386711\n",
      "Iteration 2, loss = 1.11443864\n",
      "Iteration 3, loss = 1.07971722\n",
      "Iteration 4, loss = 1.02997365\n",
      "Iteration 3, loss = 0.99837032\n",
      "Iteration 4, loss = 0.99140915\n",
      "Iteration 5, loss = 1.01740782\n",
      "Iteration 6, loss = 1.03311418\n",
      "Iteration 7, loss = 0.96210783\n",
      "Iteration 8, loss = 1.00920375\n",
      "Iteration 9, loss = 0.96792466\n",
      "Iteration 10, loss = 0.95008309\n",
      "Iteration 1, loss = 1.22386711\n",
      "Iteration 2, loss = 1.11443864\n",
      "Iteration 3, loss = 1.07971722\n",
      "Iteration 4, loss = 1.02997365\n",
      "Iteration 5, loss = 1.02342203\n",
      "Iteration 6, loss = 1.08466987\n",
      "Iteration 7, loss = 1.00253811\n",
      "Iteration 8, loss = 1.04192941\n",
      "Iteration 9, loss = 0.99387443\n",
      "Iteration 10, loss = 1.03784293\n",
      "Iteration 11, loss = 1.03553850\n",
      "Iteration 12, loss = 1.08270622\n",
      "Iteration 13, loss = 0.97413437\n",
      "Iteration 14, loss = 0.99854028\n",
      "Iteration 15, loss = 0.98463122\n",
      "Iteration 16, loss = 0.97487459\n",
      "Iteration 17, loss = 1.03928398\n",
      "Iteration 5, loss = 1.02342203\n",
      "Iteration 6, loss = 1.08466987\n",
      "Iteration 7, loss = 1.00253811\n",
      "Iteration 8, loss = 1.04192941\n",
      "Iteration 9, loss = 0.99387443\n",
      "Iteration 10, loss = 1.03784293\n",
      "Iteration 11, loss = 1.03553850\n",
      "Iteration 12, loss = 1.08270622\n",
      "Iteration 13, loss = 0.97413437\n",
      "Iteration 14, loss = 0.99854028\n",
      "Iteration 15, loss = 0.98463122\n",
      "Iteration 16, loss = 0.97487459\n",
      "Iteration 17, loss = 1.03928398\n",
      "Iteration 18, loss = 1.01309062\n",
      "Iteration 19, loss = 0.98900883\n",
      "Iteration 20, loss = 0.98358310\n",
      "Iteration 21, loss = 0.99773511\n",
      "Iteration 22, loss = 0.96903969\n",
      "Iteration 23, loss = 0.94412149\n",
      "Iteration 24, loss = 0.97949112\n",
      "Iteration 25, loss = 1.00018134\n",
      "Iteration 26, loss = 1.01575226\n",
      "Iteration 27, loss = 0.99006675\n",
      "Iteration 28, loss = 0.96452272\n",
      "Iteration 29, loss = 0.99420691\n",
      "Iteration 30, loss = 0.96713334\n",
      "Iteration 31, loss = 0.95231951\n",
      "Iteration 32, loss = 1.05326316\n",
      "Iteration 33, loss = 0.98937298\n",
      "Iteration 18, loss = 1.01309062\n",
      "Iteration 19, loss = 0.98900883\n",
      "Iteration 20, loss = 0.98358310\n",
      "Iteration 21, loss = 0.99773511\n",
      "Iteration 22, loss = 0.96903969\n",
      "Iteration 23, loss = 0.94412149\n",
      "Iteration 24, loss = 0.97949112\n",
      "Iteration 25, loss = 1.00018134\n",
      "Iteration 26, loss = 1.01575226\n",
      "Iteration 27, loss = 0.99006675\n",
      "Iteration 28, loss = 0.96452272\n",
      "Iteration 29, loss = 0.99420691\n",
      "Iteration 30, loss = 0.96713334\n",
      "Iteration 31, loss = 0.95231951\n",
      "Iteration 32, loss = 1.05326316\n",
      "Iteration 33, loss = 0.98937298\n",
      "Iteration 34, loss = 0.93618218\n",
      "Iteration 35, loss = 0.95584431\n",
      "Iteration 36, loss = 1.01494191\n",
      "Iteration 37, loss = 1.00343431\n",
      "Iteration 38, loss = 0.98417157\n",
      "Iteration 39, loss = 1.00184155\n",
      "Iteration 40, loss = 1.02910539\n",
      "Iteration 41, loss = 0.99545656\n",
      "Iteration 42, loss = 1.00101052\n",
      "Iteration 43, loss = 0.97479361\n",
      "Iteration 44, loss = 0.98599851\n",
      "Iteration 45, loss = 1.02361722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18341526\n",
      "Iteration 34, loss = 0.93618218\n",
      "Iteration 35, loss = 0.95584431\n",
      "Iteration 36, loss = 1.01494191\n",
      "Iteration 37, loss = 1.00343431\n",
      "Iteration 38, loss = 0.98417157\n",
      "Iteration 39, loss = 1.00184155\n",
      "Iteration 40, loss = 1.02910539\n",
      "Iteration 41, loss = 0.99545656\n",
      "Iteration 42, loss = 1.00101052\n",
      "Iteration 43, loss = 0.97479361\n",
      "Iteration 44, loss = 0.98599851\n",
      "Iteration 45, loss = 1.02361722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18341526\n",
      "Iteration 2, loss = 1.08398065\n",
      "Iteration 3, loss = 0.99821164\n",
      "Iteration 4, loss = 0.99214498\n",
      "Iteration 5, loss = 0.94951359\n",
      "Iteration 6, loss = 0.98117197\n",
      "Iteration 7, loss = 0.94291697\n",
      "Iteration 8, loss = 1.02045474\n",
      "Iteration 9, loss = 0.95674357\n",
      "Iteration 10, loss = 0.94847243\n",
      "Iteration 11, loss = 0.99989774\n",
      "Iteration 12, loss = 1.03522070\n",
      "Iteration 13, loss = 0.93561287\n",
      "Iteration 2, loss = 1.08398065\n",
      "Iteration 3, loss = 0.99821164\n",
      "Iteration 4, loss = 0.99214498\n",
      "Iteration 5, loss = 0.94951359\n",
      "Iteration 6, loss = 0.98117197\n",
      "Iteration 7, loss = 0.94291697\n",
      "Iteration 8, loss = 1.02045474\n",
      "Iteration 9, loss = 0.95674357\n",
      "Iteration 10, loss = 0.94847243\n",
      "Iteration 11, loss = 0.99989774\n",
      "Iteration 12, loss = 1.03522070\n",
      "Iteration 13, loss = 0.93561287\n",
      "Iteration 14, loss = 0.93182992\n",
      "Iteration 15, loss = 0.94767770\n",
      "Iteration 16, loss = 0.94884492\n",
      "Iteration 17, loss = 0.97607326\n",
      "Iteration 18, loss = 0.94699294\n",
      "Iteration 19, loss = 0.93355932\n",
      "Iteration 20, loss = 0.93561346\n",
      "Iteration 21, loss = 0.92733872\n",
      "Iteration 22, loss = 0.96460860\n",
      "Iteration 23, loss = 0.95345580\n",
      "Iteration 24, loss = 0.97116505\n",
      "Iteration 25, loss = 0.95609070\n",
      "Iteration 26, loss = 0.93406948\n",
      "Iteration 27, loss = 0.88351895\n",
      "Iteration 14, loss = 0.93182992\n",
      "Iteration 15, loss = 0.94767770\n",
      "Iteration 16, loss = 0.94884492\n",
      "Iteration 17, loss = 0.97607326\n",
      "Iteration 18, loss = 0.94699294\n",
      "Iteration 19, loss = 0.93355932\n",
      "Iteration 20, loss = 0.93561346\n",
      "Iteration 21, loss = 0.92733872\n",
      "Iteration 22, loss = 0.96460860\n",
      "Iteration 23, loss = 0.95345580\n",
      "Iteration 24, loss = 0.97116505\n",
      "Iteration 25, loss = 0.95609070\n",
      "Iteration 26, loss = 0.93406948\n",
      "Iteration 27, loss = 0.88351895\n",
      "Iteration 28, loss = 0.95237564\n",
      "Iteration 29, loss = 0.98256282\n",
      "Iteration 30, loss = 0.97048895\n",
      "Iteration 31, loss = 0.92768938\n",
      "Iteration 32, loss = 0.95428766\n",
      "Iteration 33, loss = 0.91660393\n",
      "Iteration 34, loss = 0.91038054\n",
      "Iteration 35, loss = 0.93352373\n",
      "Iteration 36, loss = 0.90446457\n",
      "Iteration 37, loss = 0.91329255\n",
      "Iteration 38, loss = 0.89536874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21033869\n",
      "Iteration 2, loss = 1.09759050\n",
      "Iteration 28, loss = 0.95237564\n",
      "Iteration 29, loss = 0.98256282\n",
      "Iteration 30, loss = 0.97048895\n",
      "Iteration 31, loss = 0.92768938\n",
      "Iteration 32, loss = 0.95428766\n",
      "Iteration 33, loss = 0.91660393\n",
      "Iteration 34, loss = 0.91038054\n",
      "Iteration 35, loss = 0.93352373\n",
      "Iteration 36, loss = 0.90446457\n",
      "Iteration 37, loss = 0.91329255\n",
      "Iteration 38, loss = 0.89536874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21033869\n",
      "Iteration 2, loss = 1.09759050\n",
      "Iteration 3, loss = 1.03647859\n",
      "Iteration 4, loss = 0.97797224\n",
      "Iteration 5, loss = 1.01092476\n",
      "Iteration 6, loss = 1.02746038\n",
      "Iteration 7, loss = 0.97381688\n",
      "Iteration 8, loss = 1.01484865\n",
      "Iteration 9, loss = 1.00929304\n",
      "Iteration 10, loss = 0.98910433\n",
      "Iteration 11, loss = 0.96915911\n",
      "Iteration 12, loss = 0.97008312\n",
      "Iteration 13, loss = 0.95491541\n",
      "Iteration 14, loss = 0.95090778\n",
      "Iteration 3, loss = 1.03647859\n",
      "Iteration 4, loss = 0.97797224\n",
      "Iteration 5, loss = 1.01092476\n",
      "Iteration 6, loss = 1.02746038\n",
      "Iteration 7, loss = 0.97381688\n",
      "Iteration 8, loss = 1.01484865\n",
      "Iteration 9, loss = 1.00929304\n",
      "Iteration 10, loss = 0.98910433\n",
      "Iteration 11, loss = 0.96915911\n",
      "Iteration 12, loss = 0.97008312\n",
      "Iteration 13, loss = 0.95491541\n",
      "Iteration 14, loss = 0.95090778\n",
      "Iteration 15, loss = 0.94340981\n",
      "Iteration 16, loss = 0.93969152\n",
      "Iteration 17, loss = 0.96238267\n",
      "Iteration 18, loss = 0.93379248\n",
      "Iteration 19, loss = 0.93645034\n",
      "Iteration 20, loss = 0.92679037\n",
      "Iteration 21, loss = 0.99959501\n",
      "Iteration 22, loss = 0.95830701\n",
      "Iteration 23, loss = 0.95718313\n",
      "Iteration 24, loss = 0.97533033\n",
      "Iteration 25, loss = 0.95241275\n",
      "Iteration 26, loss = 1.00726182\n",
      "Iteration 27, loss = 0.95426762\n",
      "Iteration 28, loss = 0.96246753\n",
      "Iteration 15, loss = 0.94340981\n",
      "Iteration 16, loss = 0.93969152\n",
      "Iteration 17, loss = 0.96238267\n",
      "Iteration 18, loss = 0.93379248\n",
      "Iteration 19, loss = 0.93645034\n",
      "Iteration 20, loss = 0.92679037\n",
      "Iteration 21, loss = 0.99959501\n",
      "Iteration 22, loss = 0.95830701\n",
      "Iteration 23, loss = 0.95718313\n",
      "Iteration 24, loss = 0.97533033\n",
      "Iteration 25, loss = 0.95241275\n",
      "Iteration 26, loss = 1.00726182\n",
      "Iteration 27, loss = 0.95426762\n",
      "Iteration 28, loss = 0.96246753\n",
      "Iteration 29, loss = 1.05794481\n",
      "Iteration 30, loss = 0.95995784\n",
      "Iteration 31, loss = 0.93250203\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22658096\n",
      "Iteration 2, loss = 1.09729849\n",
      "Iteration 3, loss = 1.02991666\n",
      "Iteration 4, loss = 1.03955746\n",
      "Iteration 5, loss = 1.03546268\n",
      "Iteration 6, loss = 1.03001671\n",
      "Iteration 7, loss = 0.98799643\n",
      "Iteration 8, loss = 1.04888943\n",
      "Iteration 9, loss = 1.00090912\n",
      "Iteration 29, loss = 1.05794481\n",
      "Iteration 30, loss = 0.95995784\n",
      "Iteration 31, loss = 0.93250203\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22658096\n",
      "Iteration 2, loss = 1.09729849\n",
      "Iteration 3, loss = 1.02991666\n",
      "Iteration 4, loss = 1.03955746\n",
      "Iteration 5, loss = 1.03546268\n",
      "Iteration 6, loss = 1.03001671\n",
      "Iteration 7, loss = 0.98799643\n",
      "Iteration 8, loss = 1.04888943\n",
      "Iteration 9, loss = 1.00090912\n",
      "Iteration 10, loss = 1.03826690\n",
      "Iteration 11, loss = 1.05496362\n",
      "Iteration 12, loss = 1.00825084\n",
      "Iteration 13, loss = 0.97460132\n",
      "Iteration 14, loss = 0.97534891\n",
      "Iteration 15, loss = 0.94789141\n",
      "Iteration 16, loss = 0.97580083\n",
      "Iteration 17, loss = 0.98488138\n",
      "Iteration 18, loss = 1.00472476\n",
      "Iteration 19, loss = 0.98743213\n",
      "Iteration 20, loss = 0.98133745\n",
      "Iteration 21, loss = 0.95704384\n",
      "Iteration 22, loss = 0.92101030\n",
      "Iteration 23, loss = 0.99838131\n",
      "Iteration 10, loss = 1.03826690\n",
      "Iteration 11, loss = 1.05496362\n",
      "Iteration 12, loss = 1.00825084\n",
      "Iteration 13, loss = 0.97460132\n",
      "Iteration 14, loss = 0.97534891\n",
      "Iteration 15, loss = 0.94789141\n",
      "Iteration 16, loss = 0.97580083\n",
      "Iteration 17, loss = 0.98488138\n",
      "Iteration 18, loss = 1.00472476\n",
      "Iteration 19, loss = 0.98743213\n",
      "Iteration 20, loss = 0.98133745\n",
      "Iteration 21, loss = 0.95704384\n",
      "Iteration 22, loss = 0.92101030\n",
      "Iteration 23, loss = 0.99838131\n",
      "Iteration 24, loss = 0.95025616\n",
      "Iteration 25, loss = 0.93885292\n",
      "Iteration 26, loss = 0.93135937\n",
      "Iteration 27, loss = 0.93891651\n",
      "Iteration 28, loss = 0.91547631\n",
      "Iteration 29, loss = 0.96369334\n",
      "Iteration 30, loss = 0.94558006\n",
      "Iteration 31, loss = 0.94673128\n",
      "Iteration 32, loss = 0.89804659\n",
      "Iteration 33, loss = 0.93166547\n",
      "Iteration 34, loss = 0.92650229\n",
      "Iteration 35, loss = 0.91397799\n",
      "Iteration 36, loss = 0.93811525\n",
      "Iteration 37, loss = 0.94887996\n",
      "Iteration 24, loss = 0.95025616\n",
      "Iteration 25, loss = 0.93885292\n",
      "Iteration 26, loss = 0.93135937\n",
      "Iteration 27, loss = 0.93891651\n",
      "Iteration 28, loss = 0.91547631\n",
      "Iteration 29, loss = 0.96369334\n",
      "Iteration 30, loss = 0.94558006\n",
      "Iteration 31, loss = 0.94673128\n",
      "Iteration 32, loss = 0.89804659\n",
      "Iteration 33, loss = 0.93166547\n",
      "Iteration 34, loss = 0.92650229\n",
      "Iteration 35, loss = 0.91397799\n",
      "Iteration 36, loss = 0.93811525\n",
      "Iteration 37, loss = 0.94887996\n",
      "Iteration 38, loss = 0.93889417\n",
      "Iteration 39, loss = 0.92088241\n",
      "Iteration 40, loss = 0.90373236\n",
      "Iteration 41, loss = 0.88633528\n",
      "Iteration 42, loss = 0.91746862\n",
      "Iteration 43, loss = 0.90228158\n",
      "Iteration 44, loss = 0.88640409\n",
      "Iteration 45, loss = 1.05096263\n",
      "Iteration 46, loss = 0.95339489\n",
      "Iteration 47, loss = 0.90209669\n",
      "Iteration 48, loss = 0.92151070\n",
      "Iteration 49, loss = 0.92624960\n",
      "Iteration 50, loss = 0.86305927\n",
      "Iteration 1, loss = 1.22049864\n",
      "Iteration 38, loss = 0.93889417\n",
      "Iteration 39, loss = 0.92088241\n",
      "Iteration 40, loss = 0.90373236\n",
      "Iteration 41, loss = 0.88633528\n",
      "Iteration 42, loss = 0.91746862\n",
      "Iteration 43, loss = 0.90228158\n",
      "Iteration 44, loss = 0.88640409\n",
      "Iteration 45, loss = 1.05096263\n",
      "Iteration 46, loss = 0.95339489\n",
      "Iteration 47, loss = 0.90209669\n",
      "Iteration 48, loss = 0.92151070\n",
      "Iteration 49, loss = 0.92624960\n",
      "Iteration 50, loss = 0.86305927\n",
      "Iteration 1, loss = 1.22049864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.08908521\n",
      "Iteration 3, loss = 0.99837032\n",
      "Iteration 4, loss = 0.99140915\n",
      "Iteration 5, loss = 1.01740782\n",
      "Iteration 6, loss = 1.03311418\n",
      "Iteration 7, loss = 0.96210783\n",
      "Iteration 8, loss = 1.00920375\n",
      "Iteration 9, loss = 0.96792466\n",
      "Iteration 10, loss = 0.95008309\n",
      "Iteration 11, loss = 0.98586509\n",
      "Iteration 12, loss = 0.93497209\n",
      "Iteration 13, loss = 0.98586892\n",
      "Iteration 2, loss = 1.08908521\n",
      "Iteration 3, loss = 0.99837032\n",
      "Iteration 4, loss = 0.99140915\n",
      "Iteration 5, loss = 1.01740782\n",
      "Iteration 6, loss = 1.03311418\n",
      "Iteration 7, loss = 0.96210783\n",
      "Iteration 8, loss = 1.00920375\n",
      "Iteration 9, loss = 0.96792466\n",
      "Iteration 10, loss = 0.95008309\n",
      "Iteration 11, loss = 0.98586509\n",
      "Iteration 12, loss = 0.93497209\n",
      "Iteration 13, loss = 0.98586892\n",
      "Iteration 14, loss = 0.94077158\n",
      "Iteration 15, loss = 0.93202934\n",
      "Iteration 16, loss = 0.94928177\n",
      "Iteration 17, loss = 0.98703498\n",
      "Iteration 18, loss = 0.96361888\n",
      "Iteration 19, loss = 0.98151529\n",
      "Iteration 20, loss = 0.98534382\n",
      "Iteration 21, loss = 0.96756903\n",
      "Iteration 22, loss = 0.95292888\n",
      "Iteration 23, loss = 0.96855867\n",
      "Iteration 24, loss = 0.94896323\n",
      "Iteration 25, loss = 0.94533920\n",
      "Iteration 26, loss = 0.95554254\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22386711\n",
      "Iteration 2, loss = 1.11443864\n",
      "Iteration 14, loss = 0.94077158\n",
      "Iteration 15, loss = 0.93202934\n",
      "Iteration 16, loss = 0.94928177\n",
      "Iteration 17, loss = 0.98703498\n",
      "Iteration 18, loss = 0.96361888\n",
      "Iteration 19, loss = 0.98151529\n",
      "Iteration 20, loss = 0.98534382\n",
      "Iteration 21, loss = 0.96756903\n",
      "Iteration 22, loss = 0.95292888\n",
      "Iteration 23, loss = 0.96855867\n",
      "Iteration 24, loss = 0.94896323\n",
      "Iteration 25, loss = 0.94533920\n",
      "Iteration 26, loss = 0.95554254\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22386711\n",
      "Iteration 2, loss = 1.11443864\n",
      "Iteration 3, loss = 1.07971722\n",
      "Iteration 4, loss = 1.02997365\n",
      "Iteration 5, loss = 1.02342203\n",
      "Iteration 6, loss = 1.08466987\n",
      "Iteration 7, loss = 1.00253811\n",
      "Iteration 8, loss = 1.04192941\n",
      "Iteration 9, loss = 0.99387443\n",
      "Iteration 10, loss = 1.03784293\n",
      "Iteration 11, loss = 1.03553850\n",
      "Iteration 12, loss = 1.08270622\n",
      "Iteration 13, loss = 0.97413437\n",
      "Iteration 14, loss = 0.99854028\n",
      "Iteration 15, loss = 0.98463122\n",
      "Iteration 3, loss = 1.07971722\n",
      "Iteration 4, loss = 1.02997365\n",
      "Iteration 5, loss = 1.02342203\n",
      "Iteration 6, loss = 1.08466987\n",
      "Iteration 7, loss = 1.00253811\n",
      "Iteration 8, loss = 1.04192941\n",
      "Iteration 9, loss = 0.99387443\n",
      "Iteration 10, loss = 1.03784293\n",
      "Iteration 11, loss = 1.03553850\n",
      "Iteration 12, loss = 1.08270622\n",
      "Iteration 13, loss = 0.97413437\n",
      "Iteration 14, loss = 0.99854028\n",
      "Iteration 15, loss = 0.98463122\n",
      "Iteration 16, loss = 0.97487459\n",
      "Iteration 17, loss = 1.03928398\n",
      "Iteration 18, loss = 1.01309062\n",
      "Iteration 19, loss = 0.98900883\n",
      "Iteration 20, loss = 0.98358310\n",
      "Iteration 21, loss = 0.99773511\n",
      "Iteration 22, loss = 0.96903969\n",
      "Iteration 23, loss = 0.94412149\n",
      "Iteration 24, loss = 0.97949112\n",
      "Iteration 25, loss = 1.00018134\n",
      "Iteration 26, loss = 1.01575226\n",
      "Iteration 27, loss = 0.99006675\n",
      "Iteration 28, loss = 0.96452272\n",
      "Iteration 29, loss = 0.99420691\n",
      "Iteration 30, loss = 0.96713334\n",
      "Iteration 16, loss = 0.97487459\n",
      "Iteration 17, loss = 1.03928398\n",
      "Iteration 18, loss = 1.01309062\n",
      "Iteration 19, loss = 0.98900883\n",
      "Iteration 20, loss = 0.98358310\n",
      "Iteration 21, loss = 0.99773511\n",
      "Iteration 22, loss = 0.96903969\n",
      "Iteration 23, loss = 0.94412149\n",
      "Iteration 24, loss = 0.97949112\n",
      "Iteration 25, loss = 1.00018134\n",
      "Iteration 26, loss = 1.01575226\n",
      "Iteration 27, loss = 0.99006675\n",
      "Iteration 28, loss = 0.96452272\n",
      "Iteration 29, loss = 0.99420691\n",
      "Iteration 30, loss = 0.96713334\n",
      "Iteration 31, loss = 0.95231951\n",
      "Iteration 32, loss = 1.05326316\n",
      "Iteration 33, loss = 0.98937298\n",
      "Iteration 34, loss = 0.93618218\n",
      "Iteration 35, loss = 0.95584431\n",
      "Iteration 36, loss = 1.01494191\n",
      "Iteration 37, loss = 1.00343431\n",
      "Iteration 38, loss = 0.98417157\n",
      "Iteration 39, loss = 1.00184155\n",
      "Iteration 40, loss = 1.02910539\n",
      "Iteration 41, loss = 0.99545656\n",
      "Iteration 42, loss = 1.00101052\n",
      "Iteration 43, loss = 0.97479361\n",
      "Iteration 44, loss = 0.98599851\n",
      "Iteration 31, loss = 0.95231951\n",
      "Iteration 32, loss = 1.05326316\n",
      "Iteration 33, loss = 0.98937298\n",
      "Iteration 34, loss = 0.93618218\n",
      "Iteration 35, loss = 0.95584431\n",
      "Iteration 36, loss = 1.01494191\n",
      "Iteration 37, loss = 1.00343431\n",
      "Iteration 38, loss = 0.98417157\n",
      "Iteration 39, loss = 1.00184155\n",
      "Iteration 40, loss = 1.02910539\n",
      "Iteration 41, loss = 0.99545656\n",
      "Iteration 42, loss = 1.00101052\n",
      "Iteration 43, loss = 0.97479361\n",
      "Iteration 44, loss = 0.98599851\n",
      "Iteration 45, loss = 1.02361722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18341526\n",
      "Iteration 2, loss = 1.08398065\n",
      "Iteration 3, loss = 0.99821164\n",
      "Iteration 4, loss = 0.99214498\n",
      "Iteration 5, loss = 0.94951359\n",
      "Iteration 6, loss = 0.98117197\n",
      "Iteration 7, loss = 0.94291697\n",
      "Iteration 8, loss = 1.02045474\n",
      "Iteration 9, loss = 0.95674357\n",
      "Iteration 10, loss = 0.94847243\n",
      "Iteration 45, loss = 1.02361722\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.18341526\n",
      "Iteration 2, loss = 1.08398065\n",
      "Iteration 3, loss = 0.99821164\n",
      "Iteration 4, loss = 0.99214498\n",
      "Iteration 5, loss = 0.94951359\n",
      "Iteration 6, loss = 0.98117197\n",
      "Iteration 7, loss = 0.94291697\n",
      "Iteration 8, loss = 1.02045474\n",
      "Iteration 9, loss = 0.95674357\n",
      "Iteration 10, loss = 0.94847243\n",
      "Iteration 11, loss = 0.99989774\n",
      "Iteration 12, loss = 1.03522070\n",
      "Iteration 13, loss = 0.93561287\n",
      "Iteration 14, loss = 0.93182992\n",
      "Iteration 15, loss = 0.94767770\n",
      "Iteration 16, loss = 0.94884492\n",
      "Iteration 17, loss = 0.97607326\n",
      "Iteration 18, loss = 0.94699294\n",
      "Iteration 19, loss = 0.93355932\n",
      "Iteration 20, loss = 0.93561346\n",
      "Iteration 21, loss = 0.92733872\n",
      "Iteration 22, loss = 0.96460860\n",
      "Iteration 23, loss = 0.95345580\n",
      "Iteration 24, loss = 0.97116505\n",
      "Iteration 25, loss = 0.95609070\n",
      "Iteration 11, loss = 0.99989774\n",
      "Iteration 12, loss = 1.03522070\n",
      "Iteration 13, loss = 0.93561287\n",
      "Iteration 14, loss = 0.93182992\n",
      "Iteration 15, loss = 0.94767770\n",
      "Iteration 16, loss = 0.94884492\n",
      "Iteration 17, loss = 0.97607326\n",
      "Iteration 18, loss = 0.94699294\n",
      "Iteration 19, loss = 0.93355932\n",
      "Iteration 20, loss = 0.93561346\n",
      "Iteration 21, loss = 0.92733872\n",
      "Iteration 22, loss = 0.96460860\n",
      "Iteration 23, loss = 0.95345580\n",
      "Iteration 24, loss = 0.97116505\n",
      "Iteration 25, loss = 0.95609070\n",
      "Iteration 26, loss = 0.93406948\n",
      "Iteration 27, loss = 0.88351895\n",
      "Iteration 28, loss = 0.95237564\n",
      "Iteration 29, loss = 0.98256282\n",
      "Iteration 30, loss = 0.97048895\n",
      "Iteration 31, loss = 0.92768938\n",
      "Iteration 32, loss = 0.95428766\n",
      "Iteration 33, loss = 0.91660393\n",
      "Iteration 34, loss = 0.91038054\n",
      "Iteration 35, loss = 0.93352373\n",
      "Iteration 36, loss = 0.90446457\n",
      "Iteration 37, loss = 0.91329255\n",
      "Iteration 38, loss = 0.89536874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21033869\n",
      "Iteration 26, loss = 0.93406948\n",
      "Iteration 27, loss = 0.88351895\n",
      "Iteration 28, loss = 0.95237564\n",
      "Iteration 29, loss = 0.98256282\n",
      "Iteration 30, loss = 0.97048895\n",
      "Iteration 31, loss = 0.92768938\n",
      "Iteration 32, loss = 0.95428766\n",
      "Iteration 33, loss = 0.91660393\n",
      "Iteration 34, loss = 0.91038054\n",
      "Iteration 35, loss = 0.93352373\n",
      "Iteration 36, loss = 0.90446457\n",
      "Iteration 37, loss = 0.91329255\n",
      "Iteration 38, loss = 0.89536874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21033869\n",
      "Iteration 2, loss = 1.09759050\n",
      "Iteration 3, loss = 1.03647859\n",
      "Iteration 4, loss = 0.97797224\n",
      "Iteration 5, loss = 1.01092476\n",
      "Iteration 6, loss = 1.02746038\n",
      "Iteration 7, loss = 0.97381688\n",
      "Iteration 8, loss = 1.01484865\n",
      "Iteration 9, loss = 1.00929304\n",
      "Iteration 10, loss = 0.98910433\n",
      "Iteration 11, loss = 0.96915911\n",
      "Iteration 12, loss = 0.97008312\n",
      "Iteration 13, loss = 0.95491541\n",
      "Iteration 2, loss = 1.09759050\n",
      "Iteration 3, loss = 1.03647859\n",
      "Iteration 4, loss = 0.97797224\n",
      "Iteration 5, loss = 1.01092476\n",
      "Iteration 6, loss = 1.02746038\n",
      "Iteration 7, loss = 0.97381688\n",
      "Iteration 8, loss = 1.01484865\n",
      "Iteration 9, loss = 1.00929304\n",
      "Iteration 10, loss = 0.98910433\n",
      "Iteration 11, loss = 0.96915911\n",
      "Iteration 12, loss = 0.97008312\n",
      "Iteration 13, loss = 0.95491541\n",
      "Iteration 14, loss = 0.95090778\n",
      "Iteration 15, loss = 0.94340981\n",
      "Iteration 16, loss = 0.93969152\n",
      "Iteration 17, loss = 0.96238267\n",
      "Iteration 18, loss = 0.93379248\n",
      "Iteration 19, loss = 0.93645034\n",
      "Iteration 20, loss = 0.92679037\n",
      "Iteration 21, loss = 0.99959501\n",
      "Iteration 22, loss = 0.95830701\n",
      "Iteration 23, loss = 0.95718313\n",
      "Iteration 24, loss = 0.97533033\n",
      "Iteration 25, loss = 0.95241275\n",
      "Iteration 26, loss = 1.00726182\n",
      "Iteration 27, loss = 0.95426762\n",
      "Iteration 28, loss = 0.96246753\n",
      "Iteration 14, loss = 0.95090778\n",
      "Iteration 15, loss = 0.94340981\n",
      "Iteration 16, loss = 0.93969152\n",
      "Iteration 17, loss = 0.96238267\n",
      "Iteration 18, loss = 0.93379248\n",
      "Iteration 19, loss = 0.93645034\n",
      "Iteration 20, loss = 0.92679037\n",
      "Iteration 21, loss = 0.99959501\n",
      "Iteration 22, loss = 0.95830701\n",
      "Iteration 23, loss = 0.95718313\n",
      "Iteration 24, loss = 0.97533033\n",
      "Iteration 25, loss = 0.95241275\n",
      "Iteration 26, loss = 1.00726182\n",
      "Iteration 27, loss = 0.95426762\n",
      "Iteration 28, loss = 0.96246753\n",
      "Iteration 29, loss = 1.05794481\n",
      "Iteration 30, loss = 0.95995784\n",
      "Iteration 31, loss = 0.93250203\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22658096\n",
      "Iteration 2, loss = 1.09729849\n",
      "Iteration 3, loss = 1.02991666\n",
      "Iteration 4, loss = 1.03955746\n",
      "Iteration 5, loss = 1.03546268\n",
      "Iteration 6, loss = 1.03001671\n",
      "Iteration 7, loss = 0.98799643\n",
      "Iteration 8, loss = 1.04888943\n",
      "Iteration 9, loss = 1.00090912\n",
      "Iteration 29, loss = 1.05794481\n",
      "Iteration 30, loss = 0.95995784\n",
      "Iteration 31, loss = 0.93250203\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22658096\n",
      "Iteration 2, loss = 1.09729849\n",
      "Iteration 3, loss = 1.02991666\n",
      "Iteration 4, loss = 1.03955746\n",
      "Iteration 5, loss = 1.03546268\n",
      "Iteration 6, loss = 1.03001671\n",
      "Iteration 7, loss = 0.98799643\n",
      "Iteration 8, loss = 1.04888943\n",
      "Iteration 9, loss = 1.00090912\n",
      "Iteration 10, loss = 1.03826690\n",
      "Iteration 11, loss = 1.05496362\n",
      "Iteration 12, loss = 1.00825084\n",
      "Iteration 13, loss = 0.97460132\n",
      "Iteration 14, loss = 0.97534891\n",
      "Iteration 15, loss = 0.94789141\n",
      "Iteration 16, loss = 0.97580083\n",
      "Iteration 17, loss = 0.98488138\n",
      "Iteration 18, loss = 1.00472476\n",
      "Iteration 19, loss = 0.98743213\n",
      "Iteration 20, loss = 0.98133745\n",
      "Iteration 21, loss = 0.95704384\n",
      "Iteration 22, loss = 0.92101030\n",
      "Iteration 23, loss = 0.99838131\n",
      "Iteration 24, loss = 0.95025616\n",
      "Iteration 10, loss = 1.03826690\n",
      "Iteration 11, loss = 1.05496362\n",
      "Iteration 12, loss = 1.00825084\n",
      "Iteration 13, loss = 0.97460132\n",
      "Iteration 14, loss = 0.97534891\n",
      "Iteration 15, loss = 0.94789141\n",
      "Iteration 16, loss = 0.97580083\n",
      "Iteration 17, loss = 0.98488138\n",
      "Iteration 18, loss = 1.00472476\n",
      "Iteration 19, loss = 0.98743213\n",
      "Iteration 20, loss = 0.98133745\n",
      "Iteration 21, loss = 0.95704384\n",
      "Iteration 22, loss = 0.92101030\n",
      "Iteration 23, loss = 0.99838131\n",
      "Iteration 24, loss = 0.95025616\n",
      "Iteration 25, loss = 0.93885292\n",
      "Iteration 26, loss = 0.93135937\n",
      "Iteration 27, loss = 0.93891651\n",
      "Iteration 28, loss = 0.91547631\n",
      "Iteration 29, loss = 0.96369334\n",
      "Iteration 30, loss = 0.94558006\n",
      "Iteration 31, loss = 0.94673128\n",
      "Iteration 32, loss = 0.89804659\n",
      "Iteration 33, loss = 0.93166547\n",
      "Iteration 34, loss = 0.92650229\n",
      "Iteration 35, loss = 0.91397799\n",
      "Iteration 36, loss = 0.93811525\n",
      "Iteration 37, loss = 0.94887996\n",
      "Iteration 38, loss = 0.93889417\n",
      "Iteration 39, loss = 0.92088241\n",
      "Iteration 25, loss = 0.93885292\n",
      "Iteration 26, loss = 0.93135937\n",
      "Iteration 27, loss = 0.93891651\n",
      "Iteration 28, loss = 0.91547631\n",
      "Iteration 29, loss = 0.96369334\n",
      "Iteration 30, loss = 0.94558006\n",
      "Iteration 31, loss = 0.94673128\n",
      "Iteration 32, loss = 0.89804659\n",
      "Iteration 33, loss = 0.93166547\n",
      "Iteration 34, loss = 0.92650229\n",
      "Iteration 35, loss = 0.91397799\n",
      "Iteration 36, loss = 0.93811525\n",
      "Iteration 37, loss = 0.94887996\n",
      "Iteration 38, loss = 0.93889417\n",
      "Iteration 39, loss = 0.92088241\n",
      "Iteration 40, loss = 0.90373236\n",
      "Iteration 41, loss = 0.88633528\n",
      "Iteration 42, loss = 0.91746862\n",
      "Iteration 43, loss = 0.90228158\n",
      "Iteration 44, loss = 0.88640409\n",
      "Iteration 45, loss = 1.05096263\n",
      "Iteration 46, loss = 0.95339489\n",
      "Iteration 47, loss = 0.90209669\n",
      "Iteration 48, loss = 0.92151070\n",
      "Iteration 49, loss = 0.92624960\n",
      "Iteration 50, loss = 0.86305927\n",
      "Iteration 51, loss = 0.91988594\n",
      "Iteration 52, loss = 0.94129937\n",
      "Iteration 53, loss = 0.85686925\n",
      "Iteration 40, loss = 0.90373236\n",
      "Iteration 41, loss = 0.88633528\n",
      "Iteration 42, loss = 0.91746862\n",
      "Iteration 43, loss = 0.90228158\n",
      "Iteration 44, loss = 0.88640409\n",
      "Iteration 45, loss = 1.05096263\n",
      "Iteration 46, loss = 0.95339489\n",
      "Iteration 47, loss = 0.90209669\n",
      "Iteration 48, loss = 0.92151070\n",
      "Iteration 49, loss = 0.92624960\n",
      "Iteration 50, loss = 0.86305927\n",
      "Iteration 51, loss = 0.91988594\n",
      "Iteration 52, loss = 0.94129937\n",
      "Iteration 53, loss = 0.85686925\n",
      "Iteration 54, loss = 0.91223102\n",
      "Iteration 55, loss = 0.87814196\n",
      "Iteration 56, loss = 0.89612853\n",
      "Iteration 57, loss = 0.90703962\n",
      "Iteration 58, loss = 0.90292698\n",
      "Iteration 59, loss = 0.95579562\n",
      "Iteration 60, loss = 0.90327374\n",
      "Iteration 61, loss = 0.93885873\n",
      "Iteration 62, loss = 0.92885178\n",
      "Iteration 63, loss = 0.90942864\n",
      "Iteration 64, loss = 0.92352600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22049864\n",
      "Iteration 2, loss = 1.08908521\n",
      "Iteration 3, loss = 0.99837032\n",
      "Iteration 54, loss = 0.91223102\n",
      "Iteration 55, loss = 0.87814196\n",
      "Iteration 56, loss = 0.89612853\n",
      "Iteration 57, loss = 0.90703962\n",
      "Iteration 58, loss = 0.90292698\n",
      "Iteration 59, loss = 0.95579562\n",
      "Iteration 60, loss = 0.90327374\n",
      "Iteration 61, loss = 0.93885873\n",
      "Iteration 62, loss = 0.92885178\n",
      "Iteration 63, loss = 0.90942864\n",
      "Iteration 64, loss = 0.92352600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22049864\n",
      "Iteration 2, loss = 1.08908521\n",
      "Iteration 3, loss = 0.99837032\n",
      "Iteration 4, loss = 0.99140915\n",
      "Iteration 5, loss = 1.01740782\n",
      "Iteration 6, loss = 1.03311418\n",
      "Iteration 7, loss = 0.96210783\n",
      "Iteration 8, loss = 1.00920375\n",
      "Iteration 9, loss = 0.96792466\n",
      "Iteration 10, loss = 0.95008309\n",
      "Iteration 11, loss = 0.98586509\n",
      "Iteration 12, loss = 0.93497209\n",
      "Iteration 13, loss = 0.98586892\n",
      "Iteration 14, loss = 0.94077158\n",
      "Iteration 15, loss = 0.93202934\n",
      "Iteration 4, loss = 0.99140915\n",
      "Iteration 5, loss = 1.01740782\n",
      "Iteration 6, loss = 1.03311418\n",
      "Iteration 7, loss = 0.96210783\n",
      "Iteration 8, loss = 1.00920375\n",
      "Iteration 9, loss = 0.96792466\n",
      "Iteration 10, loss = 0.95008309\n",
      "Iteration 11, loss = 0.98586509\n",
      "Iteration 12, loss = 0.93497209\n",
      "Iteration 13, loss = 0.98586892\n",
      "Iteration 14, loss = 0.94077158\n",
      "Iteration 15, loss = 0.93202934\n",
      "Iteration 16, loss = 0.94928177\n",
      "Iteration 17, loss = 0.98703498\n",
      "Iteration 18, loss = 0.96361888\n",
      "Iteration 19, loss = 0.98151529\n",
      "Iteration 20, loss = 0.98534382\n",
      "Iteration 21, loss = 0.96756903\n",
      "Iteration 22, loss = 0.95292888\n",
      "Iteration 23, loss = 0.96855867\n",
      "Iteration 24, loss = 0.94896323\n",
      "Iteration 25, loss = 0.94533920\n",
      "Iteration 26, loss = 0.95554254\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24995255\n",
      "Iteration 2, loss = 1.17685238\n",
      "Iteration 3, loss = 1.08057248\n",
      "Iteration 16, loss = 0.94928177\n",
      "Iteration 17, loss = 0.98703498\n",
      "Iteration 18, loss = 0.96361888\n",
      "Iteration 19, loss = 0.98151529\n",
      "Iteration 20, loss = 0.98534382\n",
      "Iteration 21, loss = 0.96756903\n",
      "Iteration 22, loss = 0.95292888\n",
      "Iteration 23, loss = 0.96855867\n",
      "Iteration 24, loss = 0.94896323\n",
      "Iteration 25, loss = 0.94533920\n",
      "Iteration 26, loss = 0.95554254\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24995255\n",
      "Iteration 2, loss = 1.17685238\n",
      "Iteration 3, loss = 1.08057248\n",
      "Iteration 4, loss = 1.02601922\n",
      "Iteration 5, loss = 1.06229373\n",
      "Iteration 6, loss = 1.07201451\n",
      "Iteration 7, loss = 1.02276879\n",
      "Iteration 8, loss = 1.02305176\n",
      "Iteration 9, loss = 1.03325959\n",
      "Iteration 10, loss = 1.02486634\n",
      "Iteration 1, loss = 1.21548479\n",
      "Iteration 2, loss = 1.17443674\n",
      "Iteration 3, loss = 1.09844550\n",
      "Iteration 4, loss = 1.15529311\n",
      "Iteration 5, loss = 1.00768750\n",
      "Iteration 6, loss = 1.06278554\n",
      "Iteration 4, loss = 1.02601922\n",
      "Iteration 5, loss = 1.06229373\n",
      "Iteration 6, loss = 1.07201451\n",
      "Iteration 7, loss = 1.02276879\n",
      "Iteration 8, loss = 1.02305176\n",
      "Iteration 9, loss = 1.03325959\n",
      "Iteration 10, loss = 1.02486634\n",
      "Iteration 1, loss = 1.21548479\n",
      "Iteration 2, loss = 1.17443674\n",
      "Iteration 3, loss = 1.09844550\n",
      "Iteration 4, loss = 1.15529311\n",
      "Iteration 5, loss = 1.00768750\n",
      "Iteration 6, loss = 1.06278554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.95904158\n",
      "Iteration 8, loss = 0.97494434\n",
      "Iteration 9, loss = 0.94655635\n",
      "Iteration 10, loss = 0.95799246\n",
      "Iteration 1, loss = 1.24209246\n",
      "Iteration 2, loss = 1.28197181\n",
      "Iteration 3, loss = 1.25780358\n",
      "Iteration 4, loss = 1.26766806\n",
      "Iteration 5, loss = 1.26189464\n",
      "Iteration 6, loss = 1.25612662\n",
      "Iteration 7, loss = 1.26537119\n",
      "Iteration 8, loss = 1.28227981\n",
      "Iteration 9, loss = 1.25971126\n",
      "Iteration 7, loss = 0.95904158\n",
      "Iteration 8, loss = 0.97494434\n",
      "Iteration 9, loss = 0.94655635\n",
      "Iteration 10, loss = 0.95799246\n",
      "Iteration 1, loss = 1.24209246\n",
      "Iteration 2, loss = 1.28197181\n",
      "Iteration 3, loss = 1.25780358\n",
      "Iteration 4, loss = 1.26766806\n",
      "Iteration 5, loss = 1.26189464\n",
      "Iteration 6, loss = 1.25612662\n",
      "Iteration 7, loss = 1.26537119\n",
      "Iteration 8, loss = 1.28227981\n",
      "Iteration 9, loss = 1.25971126\n",
      "Iteration 10, loss = 1.26706964\n",
      "Iteration 1, loss = 1.27473856\n",
      "Iteration 2, loss = 1.09818144\n",
      "Iteration 3, loss = 1.06059900\n",
      "Iteration 4, loss = 1.06806855\n",
      "Iteration 5, loss = 1.08587208\n",
      "Iteration 6, loss = 1.05788813\n",
      "Iteration 7, loss = 1.07511306\n",
      "Iteration 8, loss = 1.09812276\n",
      "Iteration 9, loss = 1.04662712\n",
      "Iteration 10, loss = 1.03933398\n",
      "Iteration 1, loss = 1.26327412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 1.26706964\n",
      "Iteration 1, loss = 1.27473856\n",
      "Iteration 2, loss = 1.09818144\n",
      "Iteration 3, loss = 1.06059900\n",
      "Iteration 4, loss = 1.06806855\n",
      "Iteration 5, loss = 1.08587208\n",
      "Iteration 6, loss = 1.05788813\n",
      "Iteration 7, loss = 1.07511306\n",
      "Iteration 8, loss = 1.09812276\n",
      "Iteration 9, loss = 1.04662712\n",
      "Iteration 10, loss = 1.03933398\n",
      "Iteration 1, loss = 1.26327412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.20902991\n",
      "Iteration 3, loss = 1.02504644\n",
      "Iteration 4, loss = 1.01296779\n",
      "Iteration 5, loss = 1.08248285\n",
      "Iteration 6, loss = 1.04734737\n",
      "Iteration 7, loss = 1.00484026\n",
      "Iteration 8, loss = 1.06871270\n",
      "Iteration 9, loss = 1.04790245\n",
      "Iteration 10, loss = 1.00782614\n",
      "Iteration 1, loss = 1.24995255\n",
      "Iteration 2, loss = 1.17685238\n",
      "Iteration 3, loss = 1.08057248\n",
      "Iteration 2, loss = 1.20902991\n",
      "Iteration 3, loss = 1.02504644\n",
      "Iteration 4, loss = 1.01296779\n",
      "Iteration 5, loss = 1.08248285\n",
      "Iteration 6, loss = 1.04734737\n",
      "Iteration 7, loss = 1.00484026\n",
      "Iteration 8, loss = 1.06871270\n",
      "Iteration 9, loss = 1.04790245\n",
      "Iteration 10, loss = 1.00782614\n",
      "Iteration 1, loss = 1.24995255\n",
      "Iteration 2, loss = 1.17685238\n",
      "Iteration 3, loss = 1.08057248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.02601922\n",
      "Iteration 5, loss = 1.06229373\n",
      "Iteration 6, loss = 1.07201451\n",
      "Iteration 7, loss = 1.02276879\n",
      "Iteration 8, loss = 1.02305176\n",
      "Iteration 9, loss = 1.03325959\n",
      "Iteration 10, loss = 1.02486634\n",
      "Iteration 11, loss = 1.05387954\n",
      "Iteration 12, loss = 1.05161216\n",
      "Iteration 13, loss = 0.98205017\n",
      "Iteration 14, loss = 1.01382833\n",
      "Iteration 15, loss = 1.04845137\n",
      "Iteration 16, loss = 0.98083183\n",
      "Iteration 17, loss = 0.98308309\n",
      "Iteration 4, loss = 1.02601922\n",
      "Iteration 5, loss = 1.06229373\n",
      "Iteration 6, loss = 1.07201451\n",
      "Iteration 7, loss = 1.02276879\n",
      "Iteration 8, loss = 1.02305176\n",
      "Iteration 9, loss = 1.03325959\n",
      "Iteration 10, loss = 1.02486634\n",
      "Iteration 11, loss = 1.05387954\n",
      "Iteration 12, loss = 1.05161216\n",
      "Iteration 13, loss = 0.98205017\n",
      "Iteration 14, loss = 1.01382833\n",
      "Iteration 15, loss = 1.04845137\n",
      "Iteration 16, loss = 0.98083183\n",
      "Iteration 17, loss = 0.98308309\n",
      "Iteration 18, loss = 0.96517719\n",
      "Iteration 19, loss = 0.99147890\n",
      "Iteration 20, loss = 0.97414379\n",
      "Iteration 21, loss = 0.98742771\n",
      "Iteration 22, loss = 0.97267542\n",
      "Iteration 23, loss = 0.97097140\n",
      "Iteration 24, loss = 0.97870210\n",
      "Iteration 25, loss = 0.98044332\n",
      "Iteration 26, loss = 0.97475224\n",
      "Iteration 27, loss = 0.97015885\n",
      "Iteration 28, loss = 0.97909017\n",
      "Iteration 29, loss = 0.97003270\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21548479\n",
      "Iteration 2, loss = 1.17443674\n",
      "Iteration 18, loss = 0.96517719\n",
      "Iteration 19, loss = 0.99147890\n",
      "Iteration 20, loss = 0.97414379\n",
      "Iteration 21, loss = 0.98742771\n",
      "Iteration 22, loss = 0.97267542\n",
      "Iteration 23, loss = 0.97097140\n",
      "Iteration 24, loss = 0.97870210\n",
      "Iteration 25, loss = 0.98044332\n",
      "Iteration 26, loss = 0.97475224\n",
      "Iteration 27, loss = 0.97015885\n",
      "Iteration 28, loss = 0.97909017\n",
      "Iteration 29, loss = 0.97003270\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21548479\n",
      "Iteration 2, loss = 1.17443674\n",
      "Iteration 3, loss = 1.09844550\n",
      "Iteration 4, loss = 1.15529311\n",
      "Iteration 5, loss = 1.00768750\n",
      "Iteration 6, loss = 1.06278554\n",
      "Iteration 7, loss = 0.95904158\n",
      "Iteration 8, loss = 0.97494434\n",
      "Iteration 9, loss = 0.94655635\n",
      "Iteration 10, loss = 0.95799246\n",
      "Iteration 11, loss = 1.26883746\n",
      "Iteration 12, loss = 1.26781887\n",
      "Iteration 13, loss = 1.23691341\n",
      "Iteration 14, loss = 1.13556900\n",
      "Iteration 15, loss = 1.25458052\n",
      "Iteration 3, loss = 1.09844550\n",
      "Iteration 4, loss = 1.15529311\n",
      "Iteration 5, loss = 1.00768750\n",
      "Iteration 6, loss = 1.06278554\n",
      "Iteration 7, loss = 0.95904158\n",
      "Iteration 8, loss = 0.97494434\n",
      "Iteration 9, loss = 0.94655635\n",
      "Iteration 10, loss = 0.95799246\n",
      "Iteration 11, loss = 1.26883746\n",
      "Iteration 12, loss = 1.26781887\n",
      "Iteration 13, loss = 1.23691341\n",
      "Iteration 14, loss = 1.13556900\n",
      "Iteration 15, loss = 1.25458052\n",
      "Iteration 16, loss = 1.26984036\n",
      "Iteration 17, loss = 1.27537337\n",
      "Iteration 18, loss = 1.26400335\n",
      "Iteration 19, loss = 1.26447748\n",
      "Iteration 20, loss = 1.26696320\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24209246\n",
      "Iteration 2, loss = 1.28197181\n",
      "Iteration 3, loss = 1.25780358\n",
      "Iteration 4, loss = 1.26766806\n",
      "Iteration 5, loss = 1.26189464\n",
      "Iteration 6, loss = 1.25612662\n",
      "Iteration 7, loss = 1.26537119\n",
      "Iteration 16, loss = 1.26984036\n",
      "Iteration 17, loss = 1.27537337\n",
      "Iteration 18, loss = 1.26400335\n",
      "Iteration 19, loss = 1.26447748\n",
      "Iteration 20, loss = 1.26696320\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24209246\n",
      "Iteration 2, loss = 1.28197181\n",
      "Iteration 3, loss = 1.25780358\n",
      "Iteration 4, loss = 1.26766806\n",
      "Iteration 5, loss = 1.26189464\n",
      "Iteration 6, loss = 1.25612662\n",
      "Iteration 7, loss = 1.26537119\n",
      "Iteration 8, loss = 1.28227981\n",
      "Iteration 9, loss = 1.25971126\n",
      "Iteration 10, loss = 1.26706964\n",
      "Iteration 11, loss = 1.25969996\n",
      "Iteration 12, loss = 1.25467323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27473856\n",
      "Iteration 2, loss = 1.09818144\n",
      "Iteration 3, loss = 1.06059900\n",
      "Iteration 4, loss = 1.06806855\n",
      "Iteration 5, loss = 1.08587208\n",
      "Iteration 6, loss = 1.05788813\n",
      "Iteration 7, loss = 1.07511306\n",
      "Iteration 8, loss = 1.28227981\n",
      "Iteration 9, loss = 1.25971126\n",
      "Iteration 10, loss = 1.26706964\n",
      "Iteration 11, loss = 1.25969996\n",
      "Iteration 12, loss = 1.25467323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27473856\n",
      "Iteration 2, loss = 1.09818144\n",
      "Iteration 3, loss = 1.06059900\n",
      "Iteration 4, loss = 1.06806855\n",
      "Iteration 5, loss = 1.08587208\n",
      "Iteration 6, loss = 1.05788813\n",
      "Iteration 7, loss = 1.07511306\n",
      "Iteration 8, loss = 1.09812276\n",
      "Iteration 9, loss = 1.04662712\n",
      "Iteration 10, loss = 1.03933398\n",
      "Iteration 11, loss = 1.06115160\n",
      "Iteration 12, loss = 1.11762814\n",
      "Iteration 13, loss = 1.12229504\n",
      "Iteration 14, loss = 1.09854369\n",
      "Iteration 15, loss = 1.05275818\n",
      "Iteration 16, loss = 1.04085972\n",
      "Iteration 17, loss = 1.04373627\n",
      "Iteration 18, loss = 1.05213327\n",
      "Iteration 19, loss = 1.15293776\n",
      "Iteration 20, loss = 1.14139036\n",
      "Iteration 21, loss = 1.22985883\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 8, loss = 1.09812276\n",
      "Iteration 9, loss = 1.04662712\n",
      "Iteration 10, loss = 1.03933398\n",
      "Iteration 11, loss = 1.06115160\n",
      "Iteration 12, loss = 1.11762814\n",
      "Iteration 13, loss = 1.12229504\n",
      "Iteration 14, loss = 1.09854369\n",
      "Iteration 15, loss = 1.05275818\n",
      "Iteration 16, loss = 1.04085972\n",
      "Iteration 17, loss = 1.04373627\n",
      "Iteration 18, loss = 1.05213327\n",
      "Iteration 19, loss = 1.15293776\n",
      "Iteration 20, loss = 1.14139036\n",
      "Iteration 21, loss = 1.22985883\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26327412\n",
      "Iteration 2, loss = 1.20902991\n",
      "Iteration 3, loss = 1.02504644\n",
      "Iteration 4, loss = 1.01296779\n",
      "Iteration 5, loss = 1.08248285\n",
      "Iteration 6, loss = 1.04734737\n",
      "Iteration 7, loss = 1.00484026\n",
      "Iteration 8, loss = 1.06871270\n",
      "Iteration 9, loss = 1.04790245\n",
      "Iteration 10, loss = 1.00782614\n",
      "Iteration 11, loss = 1.03867001\n",
      "Iteration 12, loss = 0.99828022\n",
      "Iteration 13, loss = 1.04413449\n",
      "Iteration 1, loss = 1.26327412\n",
      "Iteration 2, loss = 1.20902991\n",
      "Iteration 3, loss = 1.02504644\n",
      "Iteration 4, loss = 1.01296779\n",
      "Iteration 5, loss = 1.08248285\n",
      "Iteration 6, loss = 1.04734737\n",
      "Iteration 7, loss = 1.00484026\n",
      "Iteration 8, loss = 1.06871270\n",
      "Iteration 9, loss = 1.04790245\n",
      "Iteration 10, loss = 1.00782614\n",
      "Iteration 11, loss = 1.03867001\n",
      "Iteration 12, loss = 0.99828022\n",
      "Iteration 13, loss = 1.04413449\n",
      "Iteration 14, loss = 1.00319997\n",
      "Iteration 15, loss = 0.99078623\n",
      "Iteration 16, loss = 1.00789335\n",
      "Iteration 17, loss = 1.01717578\n",
      "Iteration 18, loss = 1.02776547\n",
      "Iteration 19, loss = 1.02632736\n",
      "Iteration 20, loss = 1.06387011\n",
      "Iteration 21, loss = 1.05918729\n",
      "Iteration 22, loss = 1.20962987\n",
      "Iteration 23, loss = 1.10338924\n",
      "Iteration 24, loss = 1.05478378\n",
      "Iteration 25, loss = 1.01391585\n",
      "Iteration 26, loss = 1.02759073\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24995255\n",
      "Iteration 14, loss = 1.00319997\n",
      "Iteration 15, loss = 0.99078623\n",
      "Iteration 16, loss = 1.00789335\n",
      "Iteration 17, loss = 1.01717578\n",
      "Iteration 18, loss = 1.02776547\n",
      "Iteration 19, loss = 1.02632736\n",
      "Iteration 20, loss = 1.06387011\n",
      "Iteration 21, loss = 1.05918729\n",
      "Iteration 22, loss = 1.20962987\n",
      "Iteration 23, loss = 1.10338924\n",
      "Iteration 24, loss = 1.05478378\n",
      "Iteration 25, loss = 1.01391585\n",
      "Iteration 26, loss = 1.02759073\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24995255\n",
      "Iteration 2, loss = 1.17685238\n",
      "Iteration 3, loss = 1.08057248\n",
      "Iteration 4, loss = 1.02601922\n",
      "Iteration 5, loss = 1.06229373\n",
      "Iteration 6, loss = 1.07201451\n",
      "Iteration 7, loss = 1.02276879\n",
      "Iteration 8, loss = 1.02305176\n",
      "Iteration 9, loss = 1.03325959\n",
      "Iteration 10, loss = 1.02486634\n",
      "Iteration 11, loss = 1.05387954\n",
      "Iteration 12, loss = 1.05161216\n",
      "Iteration 13, loss = 0.98205017\n",
      "Iteration 14, loss = 1.01382833\n",
      "Iteration 15, loss = 1.04845137\n",
      "Iteration 2, loss = 1.17685238\n",
      "Iteration 3, loss = 1.08057248\n",
      "Iteration 4, loss = 1.02601922\n",
      "Iteration 5, loss = 1.06229373\n",
      "Iteration 6, loss = 1.07201451\n",
      "Iteration 7, loss = 1.02276879\n",
      "Iteration 8, loss = 1.02305176\n",
      "Iteration 9, loss = 1.03325959\n",
      "Iteration 10, loss = 1.02486634\n",
      "Iteration 11, loss = 1.05387954\n",
      "Iteration 12, loss = 1.05161216\n",
      "Iteration 13, loss = 0.98205017\n",
      "Iteration 14, loss = 1.01382833\n",
      "Iteration 15, loss = 1.04845137\n",
      "Iteration 16, loss = 0.98083183\n",
      "Iteration 17, loss = 0.98308309\n",
      "Iteration 18, loss = 0.96517719\n",
      "Iteration 19, loss = 0.99147890\n",
      "Iteration 20, loss = 0.97414379\n",
      "Iteration 21, loss = 0.98742771\n",
      "Iteration 22, loss = 0.97267542\n",
      "Iteration 23, loss = 0.97097140\n",
      "Iteration 24, loss = 0.97870210\n",
      "Iteration 25, loss = 0.98044332\n",
      "Iteration 26, loss = 0.97475224\n",
      "Iteration 27, loss = 0.97015885\n",
      "Iteration 28, loss = 0.97909017\n",
      "Iteration 29, loss = 0.97003270\n",
      "Iteration 16, loss = 0.98083183\n",
      "Iteration 17, loss = 0.98308309\n",
      "Iteration 18, loss = 0.96517719\n",
      "Iteration 19, loss = 0.99147890\n",
      "Iteration 20, loss = 0.97414379\n",
      "Iteration 21, loss = 0.98742771\n",
      "Iteration 22, loss = 0.97267542\n",
      "Iteration 23, loss = 0.97097140\n",
      "Iteration 24, loss = 0.97870210\n",
      "Iteration 25, loss = 0.98044332\n",
      "Iteration 26, loss = 0.97475224\n",
      "Iteration 27, loss = 0.97015885\n",
      "Iteration 28, loss = 0.97909017\n",
      "Iteration 29, loss = 0.97003270\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21548479\n",
      "Iteration 2, loss = 1.17443674\n",
      "Iteration 3, loss = 1.09844550\n",
      "Iteration 4, loss = 1.15529311\n",
      "Iteration 5, loss = 1.00768750\n",
      "Iteration 6, loss = 1.06278554\n",
      "Iteration 7, loss = 0.95904158\n",
      "Iteration 8, loss = 0.97494434\n",
      "Iteration 9, loss = 0.94655635\n",
      "Iteration 10, loss = 0.95799246\n",
      "Iteration 11, loss = 1.26883746\n",
      "Iteration 12, loss = 1.26781887\n",
      "Iteration 13, loss = 1.23691341\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.21548479\n",
      "Iteration 2, loss = 1.17443674\n",
      "Iteration 3, loss = 1.09844550\n",
      "Iteration 4, loss = 1.15529311\n",
      "Iteration 5, loss = 1.00768750\n",
      "Iteration 6, loss = 1.06278554\n",
      "Iteration 7, loss = 0.95904158\n",
      "Iteration 8, loss = 0.97494434\n",
      "Iteration 9, loss = 0.94655635\n",
      "Iteration 10, loss = 0.95799246\n",
      "Iteration 11, loss = 1.26883746\n",
      "Iteration 12, loss = 1.26781887\n",
      "Iteration 13, loss = 1.23691341\n",
      "Iteration 14, loss = 1.13556900\n",
      "Iteration 15, loss = 1.25458052\n",
      "Iteration 16, loss = 1.26984036\n",
      "Iteration 17, loss = 1.27537337\n",
      "Iteration 18, loss = 1.26400335\n",
      "Iteration 19, loss = 1.26447748\n",
      "Iteration 20, loss = 1.26696320\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24209246\n",
      "Iteration 2, loss = 1.28197181\n",
      "Iteration 3, loss = 1.25780358\n",
      "Iteration 4, loss = 1.26766806\n",
      "Iteration 5, loss = 1.26189464\n",
      "Iteration 6, loss = 1.25612662\n",
      "Iteration 7, loss = 1.26537119\n",
      "Iteration 14, loss = 1.13556900\n",
      "Iteration 15, loss = 1.25458052\n",
      "Iteration 16, loss = 1.26984036\n",
      "Iteration 17, loss = 1.27537337\n",
      "Iteration 18, loss = 1.26400335\n",
      "Iteration 19, loss = 1.26447748\n",
      "Iteration 20, loss = 1.26696320\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24209246\n",
      "Iteration 2, loss = 1.28197181\n",
      "Iteration 3, loss = 1.25780358\n",
      "Iteration 4, loss = 1.26766806\n",
      "Iteration 5, loss = 1.26189464\n",
      "Iteration 6, loss = 1.25612662\n",
      "Iteration 7, loss = 1.26537119\n",
      "Iteration 8, loss = 1.28227981\n",
      "Iteration 9, loss = 1.25971126\n",
      "Iteration 10, loss = 1.26706964\n",
      "Iteration 11, loss = 1.25969996\n",
      "Iteration 12, loss = 1.25467323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27473856\n",
      "Iteration 2, loss = 1.09818144\n",
      "Iteration 3, loss = 1.06059900\n",
      "Iteration 4, loss = 1.06806855\n",
      "Iteration 5, loss = 1.08587208\n",
      "Iteration 6, loss = 1.05788813\n",
      "Iteration 8, loss = 1.28227981\n",
      "Iteration 9, loss = 1.25971126\n",
      "Iteration 10, loss = 1.26706964\n",
      "Iteration 11, loss = 1.25969996\n",
      "Iteration 12, loss = 1.25467323\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27473856\n",
      "Iteration 2, loss = 1.09818144\n",
      "Iteration 3, loss = 1.06059900\n",
      "Iteration 4, loss = 1.06806855\n",
      "Iteration 5, loss = 1.08587208\n",
      "Iteration 6, loss = 1.05788813\n",
      "Iteration 7, loss = 1.07511306\n",
      "Iteration 8, loss = 1.09812276\n",
      "Iteration 9, loss = 1.04662712\n",
      "Iteration 10, loss = 1.03933398\n",
      "Iteration 11, loss = 1.06115160\n",
      "Iteration 12, loss = 1.11762814\n",
      "Iteration 13, loss = 1.12229504\n",
      "Iteration 14, loss = 1.09854369\n",
      "Iteration 15, loss = 1.05275818\n",
      "Iteration 16, loss = 1.04085972\n",
      "Iteration 17, loss = 1.04373627\n",
      "Iteration 18, loss = 1.05213327\n",
      "Iteration 19, loss = 1.15293776\n",
      "Iteration 20, loss = 1.14139036\n",
      "Iteration 7, loss = 1.07511306\n",
      "Iteration 8, loss = 1.09812276\n",
      "Iteration 9, loss = 1.04662712\n",
      "Iteration 10, loss = 1.03933398\n",
      "Iteration 11, loss = 1.06115160\n",
      "Iteration 12, loss = 1.11762814\n",
      "Iteration 13, loss = 1.12229504\n",
      "Iteration 14, loss = 1.09854369\n",
      "Iteration 15, loss = 1.05275818\n",
      "Iteration 16, loss = 1.04085972\n",
      "Iteration 17, loss = 1.04373627\n",
      "Iteration 18, loss = 1.05213327\n",
      "Iteration 19, loss = 1.15293776\n",
      "Iteration 20, loss = 1.14139036\n",
      "Iteration 21, loss = 1.22985883\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26327412\n",
      "Iteration 2, loss = 1.20902991\n",
      "Iteration 3, loss = 1.02504644\n",
      "Iteration 4, loss = 1.01296779\n",
      "Iteration 5, loss = 1.08248285\n",
      "Iteration 6, loss = 1.04734737\n",
      "Iteration 7, loss = 1.00484026\n",
      "Iteration 8, loss = 1.06871270\n",
      "Iteration 9, loss = 1.04790245\n",
      "Iteration 10, loss = 1.00782614\n",
      "Iteration 11, loss = 1.03867001\n",
      "Iteration 21, loss = 1.22985883\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.26327412\n",
      "Iteration 2, loss = 1.20902991\n",
      "Iteration 3, loss = 1.02504644\n",
      "Iteration 4, loss = 1.01296779\n",
      "Iteration 5, loss = 1.08248285\n",
      "Iteration 6, loss = 1.04734737\n",
      "Iteration 7, loss = 1.00484026\n",
      "Iteration 8, loss = 1.06871270\n",
      "Iteration 9, loss = 1.04790245\n",
      "Iteration 10, loss = 1.00782614\n",
      "Iteration 11, loss = 1.03867001\n",
      "Iteration 12, loss = 0.99828022\n",
      "Iteration 13, loss = 1.04413449\n",
      "Iteration 14, loss = 1.00319997\n",
      "Iteration 15, loss = 0.99078623\n",
      "Iteration 16, loss = 1.00789335\n",
      "Iteration 17, loss = 1.01717578\n",
      "Iteration 18, loss = 1.02776547\n",
      "Iteration 19, loss = 1.02632736\n",
      "Iteration 20, loss = 1.06387011\n",
      "Iteration 21, loss = 1.05918729\n",
      "Iteration 22, loss = 1.20962987\n",
      "Iteration 23, loss = 1.10338924\n",
      "Iteration 24, loss = 1.05478378\n",
      "Iteration 25, loss = 1.01391585\n",
      "Iteration 12, loss = 0.99828022\n",
      "Iteration 13, loss = 1.04413449\n",
      "Iteration 14, loss = 1.00319997\n",
      "Iteration 15, loss = 0.99078623\n",
      "Iteration 16, loss = 1.00789335\n",
      "Iteration 17, loss = 1.01717578\n",
      "Iteration 18, loss = 1.02776547\n",
      "Iteration 19, loss = 1.02632736\n",
      "Iteration 20, loss = 1.06387011\n",
      "Iteration 21, loss = 1.05918729\n",
      "Iteration 22, loss = 1.20962987\n",
      "Iteration 23, loss = 1.10338924\n",
      "Iteration 24, loss = 1.05478378\n",
      "Iteration 25, loss = 1.01391585\n",
      "Iteration 26, loss = 1.02759073\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25852007\n",
      "Iteration 2, loss = 1.21183849\n",
      "Iteration 3, loss = 1.28871798\n",
      "Iteration 4, loss = 1.26000856\n",
      "Iteration 5, loss = 1.26227123\n",
      "Iteration 6, loss = 1.26229963\n",
      "Iteration 7, loss = 1.25036002\n",
      "Iteration 8, loss = 1.24345159\n",
      "Iteration 9, loss = 1.24835616\n",
      "Iteration 10, loss = 1.26036659\n",
      "Iteration 1, loss = 1.24233170\n",
      "Iteration 26, loss = 1.02759073\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25852007\n",
      "Iteration 2, loss = 1.21183849\n",
      "Iteration 3, loss = 1.28871798\n",
      "Iteration 4, loss = 1.26000856\n",
      "Iteration 5, loss = 1.26227123\n",
      "Iteration 6, loss = 1.26229963\n",
      "Iteration 7, loss = 1.25036002\n",
      "Iteration 8, loss = 1.24345159\n",
      "Iteration 9, loss = 1.24835616\n",
      "Iteration 10, loss = 1.26036659\n",
      "Iteration 1, loss = 1.24233170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.26625682\n",
      "Iteration 3, loss = 1.19527243\n",
      "Iteration 4, loss = 1.42725152\n",
      "Iteration 5, loss = 1.26575912\n",
      "Iteration 6, loss = 1.26659664\n",
      "Iteration 7, loss = 1.25982078\n",
      "Iteration 8, loss = 1.26696507\n",
      "Iteration 9, loss = 1.26068681\n",
      "Iteration 10, loss = 1.25981623\n",
      "Iteration 1, loss = 1.27298426\n",
      "Iteration 2, loss = 1.27497429\n",
      "Iteration 3, loss = 1.26386566\n",
      "Iteration 2, loss = 1.26625682\n",
      "Iteration 3, loss = 1.19527243\n",
      "Iteration 4, loss = 1.42725152\n",
      "Iteration 5, loss = 1.26575912\n",
      "Iteration 6, loss = 1.26659664\n",
      "Iteration 7, loss = 1.25982078\n",
      "Iteration 8, loss = 1.26696507\n",
      "Iteration 9, loss = 1.26068681\n",
      "Iteration 10, loss = 1.25981623\n",
      "Iteration 1, loss = 1.27298426\n",
      "Iteration 2, loss = 1.27497429\n",
      "Iteration 3, loss = 1.26386566\n",
      "Iteration 4, loss = 1.27006983\n",
      "Iteration 5, loss = 1.26735070\n",
      "Iteration 6, loss = 1.26351081\n",
      "Iteration 7, loss = 1.27071444\n",
      "Iteration 8, loss = 1.27941767\n",
      "Iteration 9, loss = 1.26119239\n",
      "Iteration 10, loss = 1.27186702\n",
      "Iteration 1, loss = 1.28696135\n",
      "Iteration 2, loss = 1.25698205\n",
      "Iteration 3, loss = 1.26076752\n",
      "Iteration 4, loss = 1.26043800\n",
      "Iteration 4, loss = 1.27006983\n",
      "Iteration 5, loss = 1.26735070\n",
      "Iteration 6, loss = 1.26351081\n",
      "Iteration 7, loss = 1.27071444\n",
      "Iteration 8, loss = 1.27941767\n",
      "Iteration 9, loss = 1.26119239\n",
      "Iteration 10, loss = 1.27186702\n",
      "Iteration 1, loss = 1.28696135\n",
      "Iteration 2, loss = 1.25698205\n",
      "Iteration 3, loss = 1.26076752\n",
      "Iteration 4, loss = 1.26043800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 1.25291685\n",
      "Iteration 6, loss = 1.25448986\n",
      "Iteration 7, loss = 1.27164882\n",
      "Iteration 8, loss = 1.26195546\n",
      "Iteration 9, loss = 1.25848680\n",
      "Iteration 10, loss = 1.25912264\n",
      "Iteration 1, loss = 1.30651496\n",
      "Iteration 2, loss = 1.26524719\n",
      "Iteration 3, loss = 1.27652442\n",
      "Iteration 4, loss = 1.26876817\n",
      "Iteration 5, loss = 1.26476418\n",
      "Iteration 6, loss = 1.26633593\n",
      "Iteration 7, loss = 1.26877632\n",
      "Iteration 5, loss = 1.25291685\n",
      "Iteration 6, loss = 1.25448986\n",
      "Iteration 7, loss = 1.27164882\n",
      "Iteration 8, loss = 1.26195546\n",
      "Iteration 9, loss = 1.25848680\n",
      "Iteration 10, loss = 1.25912264\n",
      "Iteration 1, loss = 1.30651496\n",
      "Iteration 2, loss = 1.26524719\n",
      "Iteration 3, loss = 1.27652442\n",
      "Iteration 4, loss = 1.26876817\n",
      "Iteration 5, loss = 1.26476418\n",
      "Iteration 6, loss = 1.26633593\n",
      "Iteration 7, loss = 1.26877632\n",
      "Iteration 8, loss = 1.27329771\n",
      "Iteration 9, loss = 1.26109187\n",
      "Iteration 10, loss = 1.26272028\n",
      "Iteration 1, loss = 1.25852007\n",
      "Iteration 2, loss = 1.21183849\n",
      "Iteration 3, loss = 1.28871798\n",
      "Iteration 4, loss = 1.26000856\n",
      "Iteration 5, loss = 1.26227123\n",
      "Iteration 6, loss = 1.26229963\n",
      "Iteration 7, loss = 1.25036002\n",
      "Iteration 8, loss = 1.24345159\n",
      "Iteration 9, loss = 1.24835616\n",
      "Iteration 10, loss = 1.26036659\n",
      "Iteration 8, loss = 1.27329771\n",
      "Iteration 9, loss = 1.26109187\n",
      "Iteration 10, loss = 1.26272028\n",
      "Iteration 1, loss = 1.25852007\n",
      "Iteration 2, loss = 1.21183849\n",
      "Iteration 3, loss = 1.28871798\n",
      "Iteration 4, loss = 1.26000856\n",
      "Iteration 5, loss = 1.26227123\n",
      "Iteration 6, loss = 1.26229963\n",
      "Iteration 7, loss = 1.25036002\n",
      "Iteration 8, loss = 1.24345159\n",
      "Iteration 9, loss = 1.24835616\n",
      "Iteration 10, loss = 1.26036659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 1.27149469\n",
      "Iteration 12, loss = 1.26891732\n",
      "Iteration 13, loss = 1.24356819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24233170\n",
      "Iteration 2, loss = 1.26625682\n",
      "Iteration 3, loss = 1.19527243\n",
      "Iteration 4, loss = 1.42725152\n",
      "Iteration 5, loss = 1.26575912\n",
      "Iteration 6, loss = 1.26659664\n",
      "Iteration 7, loss = 1.25982078\n",
      "Iteration 8, loss = 1.26696507\n",
      "Iteration 9, loss = 1.26068681\n",
      "Iteration 11, loss = 1.27149469\n",
      "Iteration 12, loss = 1.26891732\n",
      "Iteration 13, loss = 1.24356819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24233170\n",
      "Iteration 2, loss = 1.26625682\n",
      "Iteration 3, loss = 1.19527243\n",
      "Iteration 4, loss = 1.42725152\n",
      "Iteration 5, loss = 1.26575912\n",
      "Iteration 6, loss = 1.26659664\n",
      "Iteration 7, loss = 1.25982078\n",
      "Iteration 8, loss = 1.26696507\n",
      "Iteration 9, loss = 1.26068681\n",
      "Iteration 10, loss = 1.25981623\n",
      "Iteration 11, loss = 1.27974507\n",
      "Iteration 12, loss = 1.26459663\n",
      "Iteration 13, loss = 1.25083404\n",
      "Iteration 14, loss = 1.24923687\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27298426\n",
      "Iteration 2, loss = 1.27497429\n",
      "Iteration 3, loss = 1.26386566\n",
      "Iteration 4, loss = 1.27006983\n",
      "Iteration 5, loss = 1.26735070\n",
      "Iteration 6, loss = 1.26351081\n",
      "Iteration 10, loss = 1.25981623\n",
      "Iteration 11, loss = 1.27974507\n",
      "Iteration 12, loss = 1.26459663\n",
      "Iteration 13, loss = 1.25083404\n",
      "Iteration 14, loss = 1.24923687\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27298426\n",
      "Iteration 2, loss = 1.27497429\n",
      "Iteration 3, loss = 1.26386566\n",
      "Iteration 4, loss = 1.27006983\n",
      "Iteration 5, loss = 1.26735070\n",
      "Iteration 6, loss = 1.26351081\n",
      "Iteration 7, loss = 1.27071444\n",
      "Iteration 8, loss = 1.27941767\n",
      "Iteration 9, loss = 1.26119239\n",
      "Iteration 10, loss = 1.27186702\n",
      "Iteration 11, loss = 1.26733739\n",
      "Iteration 12, loss = 1.26000917\n",
      "Iteration 13, loss = 1.24888328\n",
      "Iteration 14, loss = 1.25975413\n",
      "Iteration 15, loss = 1.25635610\n",
      "Iteration 16, loss = 1.26592631\n",
      "Iteration 17, loss = 1.27419522\n",
      "Iteration 18, loss = 1.25662692\n",
      "Iteration 19, loss = 1.26277172\n",
      "Iteration 7, loss = 1.27071444\n",
      "Iteration 8, loss = 1.27941767\n",
      "Iteration 9, loss = 1.26119239\n",
      "Iteration 10, loss = 1.27186702\n",
      "Iteration 11, loss = 1.26733739\n",
      "Iteration 12, loss = 1.26000917\n",
      "Iteration 13, loss = 1.24888328\n",
      "Iteration 14, loss = 1.25975413\n",
      "Iteration 15, loss = 1.25635610\n",
      "Iteration 16, loss = 1.26592631\n",
      "Iteration 17, loss = 1.27419522\n",
      "Iteration 18, loss = 1.25662692\n",
      "Iteration 19, loss = 1.26277172\n",
      "Iteration 20, loss = 1.26614571\n",
      "Iteration 21, loss = 1.25732442\n",
      "Iteration 22, loss = 1.25103095\n",
      "Iteration 23, loss = 1.26900374\n",
      "Iteration 24, loss = 1.27262045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28696135\n",
      "Iteration 2, loss = 1.25698205\n",
      "Iteration 3, loss = 1.26076752\n",
      "Iteration 4, loss = 1.26043800\n",
      "Iteration 5, loss = 1.25291685\n",
      "Iteration 6, loss = 1.25448986\n",
      "Iteration 7, loss = 1.27164882\n",
      "Iteration 8, loss = 1.26195546\n",
      "Iteration 20, loss = 1.26614571\n",
      "Iteration 21, loss = 1.25732442\n",
      "Iteration 22, loss = 1.25103095\n",
      "Iteration 23, loss = 1.26900374\n",
      "Iteration 24, loss = 1.27262045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28696135\n",
      "Iteration 2, loss = 1.25698205\n",
      "Iteration 3, loss = 1.26076752\n",
      "Iteration 4, loss = 1.26043800\n",
      "Iteration 5, loss = 1.25291685\n",
      "Iteration 6, loss = 1.25448986\n",
      "Iteration 7, loss = 1.27164882\n",
      "Iteration 8, loss = 1.26195546\n",
      "Iteration 9, loss = 1.25848680\n",
      "Iteration 10, loss = 1.25912264\n",
      "Iteration 11, loss = 1.26243196\n",
      "Iteration 12, loss = 1.25937946\n",
      "Iteration 13, loss = 1.24908831\n",
      "Iteration 14, loss = 1.25065370\n",
      "Iteration 15, loss = 1.25299291\n",
      "Iteration 16, loss = 1.24827219\n",
      "Iteration 17, loss = 1.25601456\n",
      "Iteration 18, loss = 1.26692145\n",
      "Iteration 19, loss = 1.25411750\n",
      "Iteration 20, loss = 1.26949096\n",
      "Iteration 21, loss = 1.24793261\n",
      "Iteration 22, loss = 1.24843977\n",
      "Iteration 9, loss = 1.25848680\n",
      "Iteration 10, loss = 1.25912264\n",
      "Iteration 11, loss = 1.26243196\n",
      "Iteration 12, loss = 1.25937946\n",
      "Iteration 13, loss = 1.24908831\n",
      "Iteration 14, loss = 1.25065370\n",
      "Iteration 15, loss = 1.25299291\n",
      "Iteration 16, loss = 1.24827219\n",
      "Iteration 17, loss = 1.25601456\n",
      "Iteration 18, loss = 1.26692145\n",
      "Iteration 19, loss = 1.25411750\n",
      "Iteration 20, loss = 1.26949096\n",
      "Iteration 21, loss = 1.24793261\n",
      "Iteration 22, loss = 1.24843977\n",
      "Iteration 23, loss = 1.25822701\n",
      "Iteration 24, loss = 1.25791089\n",
      "Iteration 25, loss = 1.24937047\n",
      "Iteration 26, loss = 1.25569331\n",
      "Iteration 27, loss = 1.24195605\n",
      "Iteration 28, loss = 1.24366102\n",
      "Iteration 29, loss = 1.25078901\n",
      "Iteration 30, loss = 1.24542474\n",
      "Iteration 31, loss = 1.25449770\n",
      "Iteration 32, loss = 1.25455543\n",
      "Iteration 33, loss = 1.26059963\n",
      "Iteration 34, loss = 1.25778789\n",
      "Iteration 35, loss = 1.24768417\n",
      "Iteration 36, loss = 1.24532567\n",
      "Iteration 23, loss = 1.25822701\n",
      "Iteration 24, loss = 1.25791089\n",
      "Iteration 25, loss = 1.24937047\n",
      "Iteration 26, loss = 1.25569331\n",
      "Iteration 27, loss = 1.24195605\n",
      "Iteration 28, loss = 1.24366102\n",
      "Iteration 29, loss = 1.25078901\n",
      "Iteration 30, loss = 1.24542474\n",
      "Iteration 31, loss = 1.25449770\n",
      "Iteration 32, loss = 1.25455543\n",
      "Iteration 33, loss = 1.26059963\n",
      "Iteration 34, loss = 1.25778789\n",
      "Iteration 35, loss = 1.24768417\n",
      "Iteration 36, loss = 1.24532567\n",
      "Iteration 37, loss = 1.26568028\n",
      "Iteration 38, loss = 1.25338113\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30651496\n",
      "Iteration 2, loss = 1.26524719\n",
      "Iteration 3, loss = 1.27652442\n",
      "Iteration 4, loss = 1.26876817\n",
      "Iteration 5, loss = 1.26476418\n",
      "Iteration 6, loss = 1.26633593\n",
      "Iteration 7, loss = 1.26877632\n",
      "Iteration 8, loss = 1.27329771\n",
      "Iteration 9, loss = 1.26109187\n",
      "Iteration 10, loss = 1.26272028\n",
      "Iteration 37, loss = 1.26568028\n",
      "Iteration 38, loss = 1.25338113\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30651496\n",
      "Iteration 2, loss = 1.26524719\n",
      "Iteration 3, loss = 1.27652442\n",
      "Iteration 4, loss = 1.26876817\n",
      "Iteration 5, loss = 1.26476418\n",
      "Iteration 6, loss = 1.26633593\n",
      "Iteration 7, loss = 1.26877632\n",
      "Iteration 8, loss = 1.27329771\n",
      "Iteration 9, loss = 1.26109187\n",
      "Iteration 10, loss = 1.26272028\n",
      "Iteration 11, loss = 1.26579042\n",
      "Iteration 12, loss = 1.26521450\n",
      "Iteration 13, loss = 1.27365824\n",
      "Iteration 14, loss = 1.26216035\n",
      "Iteration 15, loss = 1.26530503\n",
      "Iteration 16, loss = 1.27189365\n",
      "Iteration 17, loss = 1.27027704\n",
      "Iteration 18, loss = 1.27656569\n",
      "Iteration 19, loss = 1.26222245\n",
      "Iteration 20, loss = 1.28255802\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25852007\n",
      "Iteration 2, loss = 1.21183849\n",
      "Iteration 3, loss = 1.28871798\n",
      "Iteration 4, loss = 1.26000856\n",
      "Iteration 11, loss = 1.26579042\n",
      "Iteration 12, loss = 1.26521450\n",
      "Iteration 13, loss = 1.27365824\n",
      "Iteration 14, loss = 1.26216035\n",
      "Iteration 15, loss = 1.26530503\n",
      "Iteration 16, loss = 1.27189365\n",
      "Iteration 17, loss = 1.27027704\n",
      "Iteration 18, loss = 1.27656569\n",
      "Iteration 19, loss = 1.26222245\n",
      "Iteration 20, loss = 1.28255802\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25852007\n",
      "Iteration 2, loss = 1.21183849\n",
      "Iteration 3, loss = 1.28871798\n",
      "Iteration 4, loss = 1.26000856\n",
      "Iteration 5, loss = 1.26227123\n",
      "Iteration 6, loss = 1.26229963\n",
      "Iteration 7, loss = 1.25036002\n",
      "Iteration 8, loss = 1.24345159\n",
      "Iteration 9, loss = 1.24835616\n",
      "Iteration 10, loss = 1.26036659\n",
      "Iteration 11, loss = 1.27149469\n",
      "Iteration 12, loss = 1.26891732\n",
      "Iteration 13, loss = 1.24356819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24233170\n",
      "Iteration 2, loss = 1.26625682\n",
      "Iteration 3, loss = 1.19527243\n",
      "Iteration 4, loss = 1.42725152\n",
      "Iteration 5, loss = 1.26227123\n",
      "Iteration 6, loss = 1.26229963\n",
      "Iteration 7, loss = 1.25036002\n",
      "Iteration 8, loss = 1.24345159\n",
      "Iteration 9, loss = 1.24835616\n",
      "Iteration 10, loss = 1.26036659\n",
      "Iteration 11, loss = 1.27149469\n",
      "Iteration 12, loss = 1.26891732\n",
      "Iteration 13, loss = 1.24356819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.24233170\n",
      "Iteration 2, loss = 1.26625682\n",
      "Iteration 3, loss = 1.19527243\n",
      "Iteration 4, loss = 1.42725152\n",
      "Iteration 5, loss = 1.26575912\n",
      "Iteration 6, loss = 1.26659664\n",
      "Iteration 7, loss = 1.25982078\n",
      "Iteration 8, loss = 1.26696507\n",
      "Iteration 9, loss = 1.26068681\n",
      "Iteration 10, loss = 1.25981623\n",
      "Iteration 11, loss = 1.27974507\n",
      "Iteration 12, loss = 1.26459663\n",
      "Iteration 13, loss = 1.25083404\n",
      "Iteration 14, loss = 1.24923687\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27298426\n",
      "Iteration 2, loss = 1.27497429\n",
      "Iteration 3, loss = 1.26386566\n",
      "Iteration 5, loss = 1.26575912\n",
      "Iteration 6, loss = 1.26659664\n",
      "Iteration 7, loss = 1.25982078\n",
      "Iteration 8, loss = 1.26696507\n",
      "Iteration 9, loss = 1.26068681\n",
      "Iteration 10, loss = 1.25981623\n",
      "Iteration 11, loss = 1.27974507\n",
      "Iteration 12, loss = 1.26459663\n",
      "Iteration 13, loss = 1.25083404\n",
      "Iteration 14, loss = 1.24923687\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.27298426\n",
      "Iteration 2, loss = 1.27497429\n",
      "Iteration 3, loss = 1.26386566\n",
      "Iteration 4, loss = 1.27006983\n",
      "Iteration 5, loss = 1.26735070\n",
      "Iteration 6, loss = 1.26351081\n",
      "Iteration 7, loss = 1.27071444\n",
      "Iteration 8, loss = 1.27941767\n",
      "Iteration 9, loss = 1.26119239\n",
      "Iteration 10, loss = 1.27186702\n",
      "Iteration 11, loss = 1.26733739\n",
      "Iteration 12, loss = 1.26000917\n",
      "Iteration 13, loss = 1.24888328\n",
      "Iteration 14, loss = 1.25975413\n",
      "Iteration 15, loss = 1.25635610\n",
      "Iteration 16, loss = 1.26592631\n",
      "Iteration 17, loss = 1.27419522\n",
      "Iteration 4, loss = 1.27006983\n",
      "Iteration 5, loss = 1.26735070\n",
      "Iteration 6, loss = 1.26351081\n",
      "Iteration 7, loss = 1.27071444\n",
      "Iteration 8, loss = 1.27941767\n",
      "Iteration 9, loss = 1.26119239\n",
      "Iteration 10, loss = 1.27186702\n",
      "Iteration 11, loss = 1.26733739\n",
      "Iteration 12, loss = 1.26000917\n",
      "Iteration 13, loss = 1.24888328\n",
      "Iteration 14, loss = 1.25975413\n",
      "Iteration 15, loss = 1.25635610\n",
      "Iteration 16, loss = 1.26592631\n",
      "Iteration 17, loss = 1.27419522\n",
      "Iteration 18, loss = 1.25662692\n",
      "Iteration 19, loss = 1.26277172\n",
      "Iteration 20, loss = 1.26614571\n",
      "Iteration 21, loss = 1.25732442\n",
      "Iteration 22, loss = 1.25103095\n",
      "Iteration 23, loss = 1.26900374\n",
      "Iteration 24, loss = 1.27262045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28696135\n",
      "Iteration 2, loss = 1.25698205\n",
      "Iteration 3, loss = 1.26076752\n",
      "Iteration 4, loss = 1.26043800\n",
      "Iteration 5, loss = 1.25291685\n",
      "Iteration 6, loss = 1.25448986\n",
      "Iteration 7, loss = 1.27164882\n",
      "Iteration 8, loss = 1.26195546\n",
      "Iteration 18, loss = 1.25662692\n",
      "Iteration 19, loss = 1.26277172\n",
      "Iteration 20, loss = 1.26614571\n",
      "Iteration 21, loss = 1.25732442\n",
      "Iteration 22, loss = 1.25103095\n",
      "Iteration 23, loss = 1.26900374\n",
      "Iteration 24, loss = 1.27262045\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.28696135\n",
      "Iteration 2, loss = 1.25698205\n",
      "Iteration 3, loss = 1.26076752\n",
      "Iteration 4, loss = 1.26043800\n",
      "Iteration 5, loss = 1.25291685\n",
      "Iteration 6, loss = 1.25448986\n",
      "Iteration 7, loss = 1.27164882\n",
      "Iteration 8, loss = 1.26195546\n",
      "Iteration 9, loss = 1.25848680\n",
      "Iteration 10, loss = 1.25912264\n",
      "Iteration 11, loss = 1.26243196\n",
      "Iteration 12, loss = 1.25937946\n",
      "Iteration 13, loss = 1.24908831\n",
      "Iteration 14, loss = 1.25065370\n",
      "Iteration 15, loss = 1.25299291\n",
      "Iteration 16, loss = 1.24827219\n",
      "Iteration 17, loss = 1.25601456\n",
      "Iteration 18, loss = 1.26692145\n",
      "Iteration 19, loss = 1.25411750\n",
      "Iteration 20, loss = 1.26949096\n",
      "Iteration 21, loss = 1.24793261\n",
      "Iteration 22, loss = 1.24843977\n",
      "Iteration 9, loss = 1.25848680\n",
      "Iteration 10, loss = 1.25912264\n",
      "Iteration 11, loss = 1.26243196\n",
      "Iteration 12, loss = 1.25937946\n",
      "Iteration 13, loss = 1.24908831\n",
      "Iteration 14, loss = 1.25065370\n",
      "Iteration 15, loss = 1.25299291\n",
      "Iteration 16, loss = 1.24827219\n",
      "Iteration 17, loss = 1.25601456\n",
      "Iteration 18, loss = 1.26692145\n",
      "Iteration 19, loss = 1.25411750\n",
      "Iteration 20, loss = 1.26949096\n",
      "Iteration 21, loss = 1.24793261\n",
      "Iteration 22, loss = 1.24843977\n",
      "Iteration 23, loss = 1.25822701\n",
      "Iteration 24, loss = 1.25791089\n",
      "Iteration 25, loss = 1.24937047\n",
      "Iteration 26, loss = 1.25569331\n",
      "Iteration 27, loss = 1.24195605\n",
      "Iteration 28, loss = 1.24366102\n",
      "Iteration 29, loss = 1.25078901\n",
      "Iteration 30, loss = 1.24542474\n",
      "Iteration 31, loss = 1.25449770\n",
      "Iteration 32, loss = 1.25455543\n",
      "Iteration 33, loss = 1.26059963\n",
      "Iteration 34, loss = 1.25778789\n",
      "Iteration 35, loss = 1.24768417\n",
      "Iteration 23, loss = 1.25822701\n",
      "Iteration 24, loss = 1.25791089\n",
      "Iteration 25, loss = 1.24937047\n",
      "Iteration 26, loss = 1.25569331\n",
      "Iteration 27, loss = 1.24195605\n",
      "Iteration 28, loss = 1.24366102\n",
      "Iteration 29, loss = 1.25078901\n",
      "Iteration 30, loss = 1.24542474\n",
      "Iteration 31, loss = 1.25449770\n",
      "Iteration 32, loss = 1.25455543\n",
      "Iteration 33, loss = 1.26059963\n",
      "Iteration 34, loss = 1.25778789\n",
      "Iteration 35, loss = 1.24768417\n",
      "Iteration 36, loss = 1.24532567\n",
      "Iteration 37, loss = 1.26568028\n",
      "Iteration 38, loss = 1.25338113\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30651496\n",
      "Iteration 2, loss = 1.26524719\n",
      "Iteration 3, loss = 1.27652442\n",
      "Iteration 4, loss = 1.26876817\n",
      "Iteration 5, loss = 1.26476418\n",
      "Iteration 6, loss = 1.26633593\n",
      "Iteration 7, loss = 1.26877632\n",
      "Iteration 8, loss = 1.27329771\n",
      "Iteration 9, loss = 1.26109187\n",
      "Iteration 10, loss = 1.26272028\n",
      "Iteration 11, loss = 1.26579042\n",
      "Iteration 36, loss = 1.24532567\n",
      "Iteration 37, loss = 1.26568028\n",
      "Iteration 38, loss = 1.25338113\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30651496\n",
      "Iteration 2, loss = 1.26524719\n",
      "Iteration 3, loss = 1.27652442\n",
      "Iteration 4, loss = 1.26876817\n",
      "Iteration 5, loss = 1.26476418\n",
      "Iteration 6, loss = 1.26633593\n",
      "Iteration 7, loss = 1.26877632\n",
      "Iteration 8, loss = 1.27329771\n",
      "Iteration 9, loss = 1.26109187\n",
      "Iteration 10, loss = 1.26272028\n",
      "Iteration 11, loss = 1.26579042\n",
      "Iteration 12, loss = 1.26521450\n",
      "Iteration 13, loss = 1.27365824\n",
      "Iteration 14, loss = 1.26216035\n",
      "Iteration 15, loss = 1.26530503\n",
      "Iteration 16, loss = 1.27189365\n",
      "Iteration 17, loss = 1.27027704\n",
      "Iteration 18, loss = 1.27656569\n",
      "Iteration 19, loss = 1.26222245\n",
      "Iteration 20, loss = 1.28255802\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 12, loss = 1.26521450\n",
      "Iteration 13, loss = 1.27365824\n",
      "Iteration 14, loss = 1.26216035\n",
      "Iteration 15, loss = 1.26530503\n",
      "Iteration 16, loss = 1.27189365\n",
      "Iteration 17, loss = 1.27027704\n",
      "Iteration 18, loss = 1.27656569\n",
      "Iteration 19, loss = 1.26222245\n",
      "Iteration 20, loss = 1.28255802\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22201759\n",
      "Iteration 2, loss = 1.01551550\n",
      "Iteration 3, loss = 0.97951400\n",
      "Iteration 4, loss = 0.95913423\n",
      "Iteration 5, loss = 1.00286318\n",
      "Iteration 6, loss = 0.97285807\n",
      "Iteration 7, loss = 0.94771123\n",
      "Iteration 8, loss = 0.97168184\n",
      "Iteration 9, loss = 0.94961696\n",
      "Iteration 10, loss = 0.96316598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22201759\n",
      "Iteration 2, loss = 1.01551550\n",
      "Iteration 3, loss = 0.97951400\n",
      "Iteration 4, loss = 0.95913423\n",
      "Iteration 5, loss = 1.00286318\n",
      "Iteration 6, loss = 0.97285807\n",
      "Iteration 7, loss = 0.94771123\n",
      "Iteration 8, loss = 0.97168184\n",
      "Iteration 9, loss = 0.94961696\n",
      "Iteration 10, loss = 0.96316598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(alpha=0.001, batch_size=10,\n",
       "                                     hidden_layer_sizes=(50, 10),\n",
       "                                     learning_rate_init=0.1, random_state=1,\n",
       "                                     solver='sgd', verbose=5),\n",
       "             param_grid={'hidden_layer_sizes': [(20, 5), (20, 10), (20, 15),\n",
       "                                                (20, 20), (40, 5), (40, 10),\n",
       "                                                (40, 15), (40, 20), (60, 5),\n",
       "                                                (60, 10), (60, 15), (60, 20),\n",
       "                                                (80, 5), (80, 10), (80, 15),\n",
       "                                                (80, 20)],\n",
       "                         'learning_rate_init': array([0.05, 0.1 , 0.15, 0.2 ]),\n",
       "                         'max_iter': [10, 50, 100]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(alpha=0.001, batch_size=10,\n",
       "                                     hidden_layer_sizes=(50, 10),\n",
       "                                     learning_rate_init=0.1, random_state=1,\n",
       "                                     solver='sgd', verbose=5),\n",
       "             param_grid={'hidden_layer_sizes': [(20, 5), (20, 10), (20, 15),\n",
       "                                                (20, 20), (40, 5), (40, 10),\n",
       "                                                (40, 15), (40, 20), (60, 5),\n",
       "                                                (60, 10), (60, 15), (60, 20),\n",
       "                                                (80, 5), (80, 10), (80, 15),\n",
       "                                                (80, 20)],\n",
       "                         'learning_rate_init': array([0.05, 0.1 , 0.15, 0.2 ]),\n",
       "                         'max_iter': [10, 50, 100]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search to optimize algorithm\n",
    "\n",
    "max_iter_test = [10, 50, 100]\n",
    "hidden_layer_sizes_test = [(a, b) for a in 20 * np.arange(1,5) for b in 5 * np.arange(1, 5)]\n",
    "\n",
    "learning_rates = 0.05 * np.arange(1,5)\n",
    "\n",
    "param_grid_test = dict(learning_rate_init=learning_rates, hidden_layer_sizes=hidden_layer_sizes_test,\n",
    "                 max_iter=max_iter_test)\n",
    "\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=param_grid_test)\n",
    "\n",
    "grid.fit(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "764282f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyper-parameters :  {'hidden_layer_sizes': (60, 10), 'learning_rate_init': 0.05, 'max_iter': 10}\n",
      "Optimal Accuracy :  0.8083333333333332\n",
      "Optimal Hyper-parameters :  {'hidden_layer_sizes': (60, 10), 'learning_rate_init': 0.05, 'max_iter': 10}\n",
      "Optimal Accuracy :  0.8083333333333332\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Hyper-parameters : \", grid.best_params_)\n",
    "print(\"Optimal Accuracy : \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763a15c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Xiao Bao Bao\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Tanh: \n",
      "==============================\n",
      "Training set score: 0.773438\n",
      "Test set score: 0.739583\n",
      "Accuracy :  0.7395833333333334\n",
      "Mean Square Error :  0.234375\n",
      "Confusion Matrix for each label : \n",
      "[[[57  4]\n",
      "  [20 15]]\n",
      "\n",
      " [[14 21]\n",
      "  [ 0 61]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.43      0.56        35\n",
      "           1       0.74      1.00      0.85        61\n",
      "\n",
      "   micro avg       0.75      0.79      0.77        96\n",
      "   macro avg       0.77      0.71      0.70        96\n",
      "weighted avg       0.76      0.79      0.74        96\n",
      " samples avg       0.77      0.79      0.77        96\n",
      "\n",
      "Neural Network ReLU: \n",
      "==============================\n",
      "Training set score: 0.817708\n",
      "Test set score: 0.781250\n",
      "Accuracy :  0.78125\n",
      "Mean Square Error :  0.21875\n",
      "Confusion Matrix for each label : \n",
      "[[[61  0]\n",
      "  [21 14]]\n",
      "\n",
      " [[14 21]\n",
      "  [ 0 61]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        35\n",
      "           1       0.74      1.00      0.85        61\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        96\n",
      "   macro avg       0.87      0.70      0.71        96\n",
      "weighted avg       0.84      0.78      0.75        96\n",
      " samples avg       0.78      0.78      0.78        96\n",
      "\n",
      "Neural Network Tanh: \n",
      "==============================\n",
      "Training set score: 0.773438\n",
      "Test set score: 0.739583\n",
      "Accuracy :  0.7395833333333334\n",
      "Mean Square Error :  0.234375\n",
      "Confusion Matrix for each label : \n",
      "[[[57  4]\n",
      "  [20 15]]\n",
      "\n",
      " [[14 21]\n",
      "  [ 0 61]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.43      0.56        35\n",
      "           1       0.74      1.00      0.85        61\n",
      "\n",
      "   micro avg       0.75      0.79      0.77        96\n",
      "   macro avg       0.77      0.71      0.70        96\n",
      "weighted avg       0.76      0.79      0.74        96\n",
      " samples avg       0.77      0.79      0.77        96\n",
      "\n",
      "Neural Network ReLU: \n",
      "==============================\n",
      "Training set score: 0.817708\n",
      "Test set score: 0.781250\n",
      "Accuracy :  0.78125\n",
      "Mean Square Error :  0.21875\n",
      "Confusion Matrix for each label : \n",
      "[[[61  0]\n",
      "  [21 14]]\n",
      "\n",
      " [[14 21]\n",
      "  [ 0 61]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        35\n",
      "           1       0.74      1.00      0.85        61\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        96\n",
      "   macro avg       0.87      0.70      0.71        96\n",
      "weighted avg       0.84      0.78      0.75        96\n",
      " samples avg       0.78      0.78      0.78        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test different Activation Functions\n",
    "\n",
    "mlp_sigmoid = MLPClassifier(solver='sgd', random_state=1, activation='tanh', alpha=1e-3,verbose=False,\n",
    "                   learning_rate_init=0.05, batch_size = 10, hidden_layer_sizes=(60, 10), max_iter=10)\n",
    "\n",
    "mlp_relu = MLPClassifier(solver='sgd', random_state=1, activation='relu', alpha=1e-3,verbose=False,\n",
    "                   learning_rate_init=0.05, batch_size = 10, hidden_layer_sizes=(60, 10), max_iter=10)\n",
    "\n",
    "mlp_sigmoid.fit(X_train, y_train)\n",
    "predictions_sig = mlp_sigmoid.predict(X_test)\n",
    "\n",
    "mlp_relu.fit(X_train, y_train)\n",
    "predictions_relu = mlp_relu.predict(X_test)\n",
    "\n",
    "print(\"Neural Network Tanh: \")\n",
    "print(\"=\" * 30)\n",
    "print(\"Training set score: %f\" % mlp_sigmoid.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp_sigmoid.score(X_test, y_test))\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test, predictions_sig))\n",
    "print(\"Mean Square Error : \", mean_squared_error(y_test, predictions_sig))\n",
    "\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_test, predictions_sig))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test, predictions_sig))\n",
    "\n",
    "print(\"Neural Network ReLU: \")\n",
    "print(\"=\" * 30)\n",
    "print(\"Training set score: %f\" % mlp_relu.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp_relu.score(X_test, y_test))\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test, predictions_relu))\n",
    "print(\"Mean Square Error : \", mean_squared_error(y_test, predictions_relu))\n",
    "\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_test, predictions_relu))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test, predictions_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9e163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
