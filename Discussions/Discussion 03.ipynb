{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c167fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion 03 - Classification, Feed-Forward Neural Networks, Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc87b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goals\n",
    "\n",
    "<!-- - What is Classification? -->\n",
    "- Maximum Likelihood Estimation for Logistic Regression\n",
    "- Newton's Method\n",
    "- Single Perceptron Model\n",
    "- Multi-layer Perceptron Model\n",
    "- Data Pre-processing\n",
    "    - Normalization\n",
    "    - One-hot Encoding\n",
    "- Activation Function\n",
    "    - Sigmoid\n",
    "    - ReLU\n",
    "    - Leaky ReLU\n",
    "    \n",
    "Instructor : Bharath Kinnal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbb567",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- ## What is Classification\n",
    "Classification is to a predictive modeling problem where a given example of input data is predicted to be in a particular category. To model a classifier, a training dataset is required with many examples of inputs and outputs from which to learn. There are four main types of classification models :\n",
    "\n",
    "- __Binary Classifier :__\n",
    "    Classifies the input data into one of 2 classes\n",
    "- __Multi-Class Classifier :__\n",
    "    Classifies the input data into one of multiple classes\n",
    "- __Multi-Label Classifier :__\n",
    "    Classifies the input data into one or more classes\n",
    "- __Imbalanced Classifier :__\n",
    "    Similar to binary classifiers, but the majority of training data belong to one class while a minority of the training data belong to the other class.\n",
    "\n",
    "It can be seen that Logistic Regression is an example of a binary classifier. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5e68a",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation for Logistic Regression\n",
    "\n",
    "Binary classification using logistic regression mainly involves using the sigmoid function to find the probabilities of the output data to be either 0 and 1. For the model to accurately predict output variable as 0 or 1, we need to find the best fit sigmoid curve, that is, we need to create an efficient boundary between the 0 and 1 values. A cost function which maximizes the likelihood of getting desired output values, is called as Maximum Likelihood Estimation (MLE) function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d5c06",
   "metadata": {},
   "source": [
    "Given the input data $x_i$, the probability of getting the output $y_i$ will be $p(y_i|x_i,w_i) = (g(x_i, w_i))^{y_i} \\cdot (1 - g(x_i, w_i))^{1 - y_i}$, where $g()$ is the sigmoid function. So, for all input data $X = [x_1, x_2, \\dots, x_n]$, the likelihood/probability of getting the output vector $Y = [y_1, y_2, \\dots, y_n]$ is given below :\n",
    "\n",
    "$$\\text{Likelihood, }P(Y|X,W) = \\prod^{n}_{i=1} (g(x_i, w_i))^{y_i} \\cdot (1 - g(x_i, w_i))^{1 - y_i}$$\n",
    "\n",
    "$$\\text{Log-Likelihood, }l(W) = log(P(Y|X,W)) = \\sum^{n}_{i=1} y_i log(g(x_i, w_i)) + (1 - y_i) log(1 - g(x_i, w_i))$$\n",
    "\n",
    "Optimizing the regression model involves maximizing the value of $l(W)$. This can be done by updating the weights through gradient descent (or ascent) as follows :\n",
    "\n",
    "$$w^{n+1}_{i} = w^{n}_i + \\alpha(y_i - g(x_i,w^{n}_i))x_i$$\n",
    "\n",
    "where $\\alpha$ is the learning rate. The weight $w_i$ is updated until convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8599deff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 2)\n",
      "292.1237916181633\n"
     ]
    }
   ],
   "source": [
    "#Program to find numbers > 5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Sigmoid Function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def combination_function(X,W) :\n",
    "    if X.ndim == 1 :\n",
    "        Z = W * X\n",
    "    else :\n",
    "        Z = np.dot(X, W)\n",
    "    return Z\n",
    "\n",
    "#Log-Likelihood Function\n",
    "def log_likelihood(X, Y, W):\n",
    "    Z = combination_function(X,W)\n",
    "    #Z = np.dot(X, W)\n",
    "    ll = np.sum( Y*np.log(sigmoid(Z)) + (1-Y)*(1 - np.log(sigmoid(Z))))\n",
    "    return ll\n",
    "\n",
    "#Logistic Regression Function\n",
    "def logistic_regression(X, Y, num_steps = 500, learning_rate = 0.1, add_intercept = True):\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.column_stack((intercept, X))\n",
    "    \n",
    "    print(X.shape)\n",
    "    \n",
    "    if X.ndim == 1 :\n",
    "        weights = np.zeros(1)\n",
    "    else :\n",
    "        weights = np.zeros(X.shape[1])\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        scores = combination_function(X,weights)\n",
    "        predictions = sigmoid(scores)\n",
    "        \n",
    "        #print(predictions)\n",
    "        # Update weights with gradient\n",
    "        output_error_signal = Y - predictions\n",
    "        gradient = np.dot(output_error_signal.T, X)\n",
    "        weights += learning_rate * gradient\n",
    "        \n",
    "        \n",
    "    return X, weights\n",
    "\n",
    "X = np.linspace(-10, 10, 21)\n",
    "y = np.ones(21)\n",
    "y[:16] = 0\n",
    "\n",
    "w = np.zeros(21)\n",
    "y_pred = sigmoid(combination_function(X,w))\n",
    "\n",
    "X, w = logistic_regression(X,y)\n",
    "print(log_likelihood(X, y, w))\n",
    "#print(w)\n",
    "\n",
    "\n",
    "y_pred = sigmoid(combination_function(X,w))\n",
    "\n",
    "X = X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473b3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"x\") \n",
    "plt.ylabel(\"y\") \n",
    "plt.plot(X, y, label = 'expected') \n",
    "plt.plot(X, y_pred, label = 'calculated') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9df90",
   "metadata": {},
   "source": [
    "### Newton's Method\n",
    "In order to find a value of $w$ such that the log-likelihood $l(w)$ is maximum, the first-order derivative $l'(w) = 0$. Newton's Method (or Newton-Raphson Method) is a root-finding algorithm that uses the first few terms of the Taylor series of the function $l(w)$ about a point $w$. Starting with an arbitrary weight $w^0_i$, the weight can be optimized to give better value of $l(w_i)$ using the following update rule :\n",
    "\n",
    "$$w_i^{n+1} = w_i^{n} + \\eta \\frac{\\frac{\\delta l(w_i)}{\\delta w_i}}{\\frac{\\delta^2 l(w_i)}{(\\delta w_i)^2}}$$\n",
    "\n",
    "An intuitive explanation can be shown in the following representation below. Here, considering the function $f(x) = l'(x)$, we can see that the value of $l'(x)$ converges to 0 at $x = x_5$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7943a7",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee7a14",
   "metadata": {},
   "source": [
    "## Single Perceptron Model\n",
    "\n",
    "The perceptron model calculates the weighted sum of the input, and then returns 1 if the weighted sum is more\n",
    "than a threshold, or less returns 0.\n",
    "\n",
    "Given an input $X = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix}$ to a single perceptron, the output $y$ can be calcluated as follows :\n",
    "\n",
    "$$z = W^T X = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
    "\n",
    "$$y = \\begin{cases}\n",
    "      1 & \\text{if $z \\ge threshold$}\\\\\n",
    "      0 & \\text{if $z < threshold$}\n",
    "    \\end{cases}$$\n",
    "\n",
    "Here, $W = \\begin{pmatrix} w_0 \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{pmatrix}$ are the weights asssociated with the perceptron, and they are the parameters that need to be optimized during training. \n",
    "\n",
    "The weights are updated in each iteration (epoch) as follows :\n",
    "\n",
    "$$w^{n+1}_{i} = w^{n}_i + \\alpha(y_i - g(x_i,w^{n}_i))x_i$$\n",
    "\n",
    "The weight $w_0$ is the __bias__ associated with the perceptron, which allows the perceptron to give a non-zero output even when the input is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b50bd",
   "metadata": {},
   "source": [
    "The Perceptron and Logistic Regression models are motivated from two very different directions. Perceptron is essentially defined by its update rule. If the data are linearly separable, perceptron is guaranteed to converge, as the perceptron makes non-zero (and non-vanishing) progress towards a separating solution on every update. \n",
    "\n",
    "By contrast, logistic regression is instead motivated from a probabilistic perspective, and the update comes from taking the gradient. Gradient-based optimization techniques are guaranteed to converge, but the likelihood can never truly be maximized with a finite set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "53f48166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Gate\n",
      "Loss =  [0 0 0 0]\n",
      "Weights =  [0.4 0.4 0.4]\n",
      "Final Accuracy =  1.0\n",
      "OR Gate\n",
      "Loss =  [0 0 0 0]\n",
      "Weights =  [0.8 0.5 0.5]\n",
      "Final Accuracy =  1.0\n",
      "XOR Gate\n",
      "Loss =  [-1  0  0 -1]\n",
      "Weights =  [9.00000000e-01 2.77555756e-17 2.77555756e-17]\n",
      "Final Accuracy =  0.5\n"
     ]
    }
   ],
   "source": [
    "#Single Perceptron Model for AND gate\n",
    "\n",
    "X = np.asarray([[0,0], [0,1], [1,0], [1,1]])\n",
    "AND_gate = [0, 0, 0, 1]\n",
    "OR_gate = [0, 1, 1, 1]\n",
    "XOR_gate = [0, 1, 1, 0]\n",
    "w = [0,0,0]\n",
    "\n",
    "def feed_forward(x, w) :\n",
    "    thresh = 1\n",
    "    \n",
    "    z = np.dot(x,w)\n",
    "    #sum([x[i] * w[i] for i in range(len(x))])\n",
    "    #z += w[-1]\n",
    "    \n",
    "    y = 1 * (z>thresh)\n",
    "    #print(y)\n",
    "    return y\n",
    "\n",
    "def train(X, w, expected, alpha = 0.1, epoch = 50) :\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    #print(X)\n",
    "    accuracy = 0\n",
    "    for n in range(epoch) :\n",
    "#         for i in range(len(X)) :\n",
    "#             x = X[i]\n",
    "#             # Add bias\n",
    "#             np.insert(x,0,1)\n",
    "#             print(x)\n",
    "\n",
    "        y = feed_forward(X,w)\n",
    "\n",
    "        w = w + alpha * np.dot((expected - y), X)\n",
    "        #w = [w[j] + alpha * (expected[i] - y) * x[j] for j in range(len(x))]\n",
    "        #print('Loss = ', expected - y)\n",
    "        #print('Weights = ', w)\n",
    "        \n",
    "        accuracy = (4 - abs(sum(expected - y)))/4\n",
    "    \n",
    "    print('Loss = ', expected - y)\n",
    "    print('Weights = ', w)\n",
    "    print('Final Accuracy = ', accuracy)\n",
    "    #display_linear_separation(X,w,)\n",
    "\n",
    "print('AND Gate')\n",
    "train(X,w, AND_gate)\n",
    "print('OR Gate')\n",
    "train(X,w, OR_gate)\n",
    "print('XOR Gate')\n",
    "train(X,w, XOR_gate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe85c46",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron Model\n",
    "A neural network, also called a Multi-Layer-Perceptron (MLP), consists of a layered, feedforward, completely-connected network of neurons. There are mainly 3 types of layers in a neural network :\n",
    "- __Input layer :__ The number of nodes depends on the number and types of dataset attributes\n",
    "- __Output layer :__ The number of nodes may be more than 1 depending on the classification task.\n",
    "- __Hidden layer :__ The number of nodes depends on the complexity of the pattern, and is determined mainly through trial and error. A neural network without a hidden layer is a perceptron model. \n",
    "\n",
    "<!-- A Feed-Forward NN (FFNN) is composed of two or more layers, but mostly 3 layers, with activation functions usually step or logistic function.  -->\n",
    "The activation function in NN makes them non-linear regressors. A NN without an activation function is a linear regressor. The final layer can be another logistic regression/perceptron or a linear regression model depending whether it is a classification or regression problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f253e",
   "metadata": {},
   "source": [
    "Given an input $X = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix}$ to a neuron, the output $y$ can be calcluated as follows :\n",
    "\n",
    "$$z = W^T X = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
    "\n",
    "$$y = Act(z)\n",
    "%     \\begin{cases}\n",
    "%       1 & \\text{if $Act(z) \\ge threshold$}\\\\\n",
    "%       0 & \\text{if $ < threshold$}\n",
    "%     \\end{cases}$$\n",
    "\n",
    "Here, $Act()$ is the activation function used by the neuron, and $W = \\begin{pmatrix} w_0 \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{pmatrix}$ are the weights associated with the neuron. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ede919",
   "metadata": {},
   "source": [
    "Here's an example of a multi-layer perceptron classifier using sklearn. Here, we will use the Iris dataset and MLPClassifier function from the Sci-Kit Learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba30361",
   "metadata": {},
   "source": [
    "<!-- Load the input data `X` and output class data `y` from the Iris dataset, and split it into training and testing data (usually a 70:30 or 80:20 split).  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c14459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = iris_data.target\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d3342a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size=0.2)\n",
    "sc_X = MinMaxScaler()\n",
    "X_trainscaled=sc_X.fit_transform(X_train)\n",
    "X_testscaled=sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "94ff26fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32),activation=\"relu\",solver = 'sgd', max_iter = 2000, random_state=1)\n",
    "clf.fit(X_trainscaled, y_train)\n",
    "y_pred = clf.predict(X_testscaled) \n",
    "print(clf.score(X_testscaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b510f",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "In this section, we will be discussing about how and why the input data is processed before it is passed through the classifier. It is used to make the data readable to the classifier, and to make each feature equally important for classification. In general, all attributes (continuous and categorical variables) must be encoded in a standardized manner, taking values between 0 and 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ca860",
   "metadata": {},
   "source": [
    "### Min-Max Normalization\n",
    "Min-max normalization is a data normalization technique that scales numeric data between the range 0 to 1. For any continuous variable $x$ lying within the range $[x_{min}, x_{max}]$, the scaled variable $x_{scaled}$ can be calculated as follows :\n",
    "$$x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37090189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 90, 85, 70, 50]\n",
      "[1.0, 0.8, 0.7, 0.4, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Example for min-max normalization :\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "def min_max_normalization(x) :\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    x = [(a - x_min)/(x_max - x_min) for a in x]\n",
    "    return x\n",
    "\n",
    "grades = [100, 90, 85, 70, 50]\n",
    "print(grades)\n",
    "print(min_max_normalization(grades))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffed652",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "One hot encoding is a data processing method to convert each categorical value as a vector of binary values, where only the index of the observed category is set to 1. One of the main reasons why categorical data needs to be one-hot encoded is that categorical data is unreadable to most machine learning model.\n",
    "\n",
    "There are 2 steps involved while converting categorical data into one-hot binary arrays\n",
    "- Assign each unique category value to an integer value.\n",
    "- Assign a new binary vector for each unique integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d6d050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog' 'cat' 'sheep' 'lizard' 'lizard' 'cat' 'lizard' 'dog' 'dog' 'cow']\n",
      "[2 0 4 3 3 0 3 2 2 1]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharath/intel/intelpython3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array \n",
    "from numpy import argmax \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "myData = [ 'dog' , 'cat' , 'sheep' , 'lizard' , 'lizard' , 'cat' , 'lizard' , 'dog' , 'dog' , 'cow' ]\n",
    " \n",
    "# convert to an array\n",
    "myData = array(myData)\n",
    "print(myData)\n",
    "\n",
    "# encode as integers\n",
    "myData_encoder = LabelEncoder()\n",
    "myData_encoded =  myData_encoder.fit_transform(myData) \n",
    "print (myData_encoded)\n",
    " \n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False) # disable sparse return type\n",
    "# reshape the array\n",
    "myData_encoded = myData_encoded.reshape(len(myData_encoded), 1) \n",
    "onehot_encoded = onehot_encoder.fit_transform(myData_encoded) \n",
    " \n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3841f1",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "An activation function is a mathematical function that controls the output of a neural network. Activation functions help in determining whether a neuron is to be fired or not. Some popular activation functions are :\n",
    "- Sigmoid Function\n",
    "- ReLU\n",
    "- Leaky ReLU\n",
    "\n",
    "Activation is responsible for adding non-linearity to the output of a neural network model. Without an activation function, a neural network is simply a linear regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388faa5",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "It's an activation function that returns a value between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d834a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2bb2b",
   "metadata": {},
   "source": [
    "One of the disadvantages of the sigmoid function is that towards the end regions the Y values respond very less to the change in X values. This results in a problem known as the vanishing gradient problem, which slows down the learning process and hence is undesirable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cf1e2",
   "metadata": {},
   "source": [
    "#### Rectified Linear Unit (ReLU)\n",
    "The ReLU activation function returns 0 if the input is negative otherwise return the input as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15155940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return 0.2 * x * (x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84792023",
   "metadata": {},
   "source": [
    "The problem with ReLU is that the gradient for negative inputs comes out to be zero. This again leads to the problem of vanishing gradient (zero-gradient) for negative inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de5298",
   "metadata": {},
   "source": [
    "#### Leaky ReLU\n",
    "The ReLU activation function returns 0 if the input is negative otherwise return the input as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f3c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return (0.2 * x * (x >= 0)) + ((0.1 * x) * (x < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b4df8f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.ion()\n",
    "\n",
    "x = np.linspace(-10, 10, 100)   \n",
    "s = sig(x)\n",
    "\n",
    "plt.plot(x, s, label = 'sigmoid') \n",
    "#plt.show()\n",
    "#plt.pause(0.0001)\n",
    "#plt.clf()\n",
    "\n",
    "r = relu(x)\n",
    "lr = leaky_relu(x)\n",
    "plt.xlabel(\"x\") \n",
    "plt.ylabel(\"Act(x)\")  \n",
    "plt.plot(x, r, label = 'relu') \n",
    "plt.plot(x, lr, label = 'leaky_relu') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be50666",
   "metadata": {},
   "source": [
    "<!-- ## Training and Tetsing a Neural Network -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4d7daffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_classification(n_samples=100, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=1)\n",
    "# clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "# clf.predict_proba(X_test[:1])\n",
    "# #array([[0.038..., 0.961...]])\n",
    "# clf.predict(X_test[:5, :])\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "22d31850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# #rom sklearn.metrics import plot_confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# labels = [\"Setosa\",\"Versicolor\",\"Virginica\"]\n",
    "# fig=confusion_matrix(y_pred, y_test)\n",
    "# #fig.figure_.suptitle(\"Confusion Matrix for Iris Dataset\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
