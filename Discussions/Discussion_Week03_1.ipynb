{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 05 - Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will be using [the Wine Dataset from UCI](https://archive.ics.uci.edu/ml/datasets/wine) and [the Car Evaluation Dataset from UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). <br >\n",
    "**Wine Dataset** <br >\n",
    "The data is the results of a chemical analysis of wines grown in the same region in Italy. <br >\n",
    "There are 13 different measurements taken from 3 types of wines(cultivators/grapevines). <br >\n",
    "**Car Evaluation Dataset** <br >\n",
    "The data examines the acceptability of a car from 6 aspectes, collected from a decision model. <br >\n",
    "It classifies the car value into 4 levels. <br >\n",
    "\n",
    "\n",
    "### Goals\n",
    "- Naïve Bayes Classifier\n",
    "- Different variations and when to use\n",
    "- Imbalanced Strategies\n",
    "\n",
    "Instruction: Yun-Hsin Kuo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "data, classes = load_wine(return_X_y=True, as_frame=True) \n",
    "df = data.copy()\n",
    "df['class'] = classes\n",
    "df['class'].value_counts() \n",
    "# df['class'].value_counts().index can return the set of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61\n",
       "0    44\n",
       "2    37\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=21)\n",
    "\n",
    "X_train, y_train = train.copy().drop(columns=['class']), train['class']\n",
    "X_test, y_test = test.copy().drop(columns=['class']), test['class']\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes Classifier\n",
    "\n",
    "### Overview\n",
    "\n",
    "It starts with **Bayes' theorem**:\n",
    "\n",
    "$P(class|instance) = \\dfrac{P(instance| class) \\times P(class)}{P(instance)} $, or the same as <br >\n",
    "\n",
    "$P(y|X) = \\dfrac{P(X|y)\\times P(y)}{P(X)}$\n",
    "\n",
    "Some explanations of these terms:\n",
    " - $P(y)$: The probability of observing class $y$ in reality. ( prior probability for $y$ )\n",
    " - $P(X)$: The probability of observing instance $X$ in reality. ( prior probability for $X$ )\n",
    " - $P(y|X)$: Given we observe instance $X$, what is the probability that it belongs to class $y$? ( posterior probability )\n",
    " - $P(X|y)$: Given we observe class $y$, what is the probability that we observe instance $X$ in this class? ( **likelihood** )\n",
    "\n",
    "In our dataset, instance $X$ is actually a set of $m$ attributes/features that $X = \\{x_1, x_2, x_3, \\ldots , x_m \\}$, so we are actually dealing with\n",
    "\n",
    "$P(y|x_1, x_2, \\ldots, x_m) = \\dfrac{P(x_1, x_2, \\ldots, x_m|y) \\times P(y)}{P(x_1, x_2, \\ldots, x_m)}$\n",
    "\n",
    "Then we have a **\"naïve\" assumption** that every pair of attributes/features are **independent**, such that\n",
    "\n",
    "$P(y|x_1, x_2, \\ldots, x_m) = \\dfrac{P(x_1, x_2, \\ldots, x_m|y) \\times P(y)}{P(x_1, x_2, \\ldots, x_m)} = \\dfrac{\\displaystyle \\prod_{j=1}^{m}P(x_j|y) \\times P(y)}{P(x_1, x_2, \\ldots, x_m)}$\n",
    "\n",
    "Since the denominator would be constant across all classes, what we are pursuing is \n",
    "\n",
    "$P(class|instance) = P(y|X) = P(y|x_1, x_2, \\ldots, x_m) \\propto \\displaystyle \\prod_{j=1}^{m}P(x_j|y) \\times P(y)$\n",
    "\n",
    "Sometimes you might have seen another variation besides the product:\n",
    "\n",
    "$\\log(P(y|X)) \\propto \\displaystyle \\sum_{j=1}^{m}\\log(P(x_j|y)) + \\log P(y)$\n",
    "\n",
    "This deals with the situation of having very small probabilities by looking at the logarithmic space.\n",
    "\n",
    "\n",
    "### Goal\n",
    "\n",
    "$\\hat y = \\underset{y}{\\operatorname{argmax}} \\displaystyle \\prod_{j=1}^{m}P(x_j|y) \\times P(y)$\n",
    "\n",
    "$P(y)$ will always be calculated as the relative frequency of class $y$ in our training set. <br >\n",
    "As a result, the main problem now becomes finding the conditional probabilities, $P(x_j|y)$. <br >\n",
    "We can have different assumptions about the distribution $P(x_j|y)$. This is also why we have variations of Naïve Bayes classifiers.\n",
    "\n",
    "### Variations of Naïve Bayes Classifiers\n",
    "\n",
    "Choosing which one to use is important, especially when we are working with different types of features.\n",
    "\n",
    " - Gaussian Naïve Bayes\n",
    " - Multinomial Naïve Bayes\n",
    "     - Categorical Naïve Bayes\n",
    " - Bernoulli Naïve Bayes\n",
    " \n",
    "Here is [a general overview](https://towardsdatascience.com/why-how-to-use-the-naive-bayes-algorithms-in-a-regulated-industry-with-sklearn-python-code-dbd8304ab2cf) on these classifiers.\n",
    "\n",
    "#### Gaussian Naïve Bayes\n",
    "This is often used when we are working with **numerical features**. \n",
    "But specifically, you can use it when you have a continuous distribution in your features.\n",
    "\n",
    "The assumption about $P(x_j|y)$ is that each feature follows a normal(Gaussian) distribution, where Gaussian distribution is in fact,\n",
    "\n",
    "$P(x_j|y) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2_y}}  \\exp{\\left(-\\dfrac{(x_j - \\mu_y)^2}{2\\sigma^2_y}\\right)}$\n",
    "\n",
    "We actually just need to know $\\sigma^2_y$ and $\\mu_y$ during training, which are that feature's variance and average within class $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are doing classifications on pandas dataframes, this would be slower than on numpy arrays.\n",
    "class GaussianClf:\n",
    "    def __init__(self, logarithmic=False):\n",
    "        self.log = logarithmic\n",
    "        self.classes = None # Unique classes\n",
    "        self.N = None # Number of training data points\n",
    "        self.M = None # Number of features\n",
    "        # The following are gonna be pandas dataframes, used to compute P(X_j|y). \n",
    "        # Each row refers to one class, each column refers to one feature.\n",
    "        self.mean = None \n",
    "        self.var = None\n",
    "        # This is technically a pandas series, i.e., only one column, but each row refers to one class.\n",
    "        self.prior = None # P(y)\n",
    "    \n",
    "    def fit(self, X, y): \n",
    "        self.classes = y.unique()\n",
    "        (self.N, self.M) = X.shape\n",
    "        \n",
    "        # X.groupby(y) will let us be able to do class-wise calculation at one time\n",
    "        # .apply(func) enables us do calculation for each class\n",
    "        # You can just print them out\n",
    "        self.mean = X.groupby(y).apply(np.mean)\n",
    "        self.var = X.groupby(y).apply(np.var)\n",
    "        self.prior = X.groupby(y).apply(lambda x: len(x)/self.N) # Relative Frequency\n",
    "\n",
    "    def computeGaussian(self, x, c):\n",
    "        # Fetch the variance and the average of all features within one specific class\n",
    "        mean = self.mean.loc[c, :]\n",
    "        var = self.var.loc[c, :]\n",
    "        \n",
    "        numerator = np.exp((-1/2)*((x-mean)**2/(var)))\n",
    "        denominator = np.sqrt(2*np.pi*var)\n",
    "        \n",
    "        # It returns P(X_j|y) for all the features\n",
    "        return numerator / denominator\n",
    "        \n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        # This returns the column name, i.e., the class, that has the maximum value along the rows.\n",
    "        return probs.idxmax(axis=1)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        probs = pd.DataFrame(None, columns=self.classes)\n",
    "        for c in probs.columns:\n",
    "            if self.log:\n",
    "                probs[c] = X.apply(lambda x: np.sum(np.log(self.computeGaussian(x, c))) + np.log(self.prior[c]), axis=1) \n",
    "            else:\n",
    "                probs[c] = X.apply(lambda x: self.computeGaussian(x, c).prod() * self.prior[c], axis=1)\n",
    "        # You can just print this out as well.\n",
    "        # Note that the numbers would be unintuitive because we drop the denominator.\n",
    "        return probs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        44\n",
      "           1       0.97      0.98      0.98        61\n",
      "           2       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.98       142\n",
      "   macro avg       0.98      0.98      0.98       142\n",
      "weighted avg       0.98      0.98      0.98       142\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "clf = GaussianClf(logarithmic=False)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "Z_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "Z_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "print(classification_report(y_train, clf.predict(Z_train)))\n",
    "print(classification_report(y_test, clf.predict(Z_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check on Gaussian Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        44\n",
      "           1       0.97      0.98      0.98        61\n",
      "           2       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.98       142\n",
      "   macro avg       0.98      0.98      0.98       142\n",
      "weighted avg       0.98      0.98      0.98       142\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "NB = GaussianNB()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "NB.fit(scaler.transform(X_train), np.asarray(y_train))\n",
    "\n",
    "print(classification_report(y_train, NB.predict(scaler.transform(X_train))))\n",
    "print(classification_report(y_test, NB.predict(scaler.transform(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Car Evaluation Dataset\n",
    "\n",
    "#### Attribute Information\n",
    "1. **buying**: buying price\n",
    "2. **maint**: maintenance price\n",
    "3. **doors**: number of doors\n",
    "4. **persons**: capacity in terms of persons to carry\n",
    "5. **lug_boot**: the size of luggage boot\n",
    "6. **safety**: estimated safety of the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: class, dtype: int64\n",
      "buying ['vhigh' 'high' 'med' 'low']\n",
      "maint ['vhigh' 'high' 'med' 'low']\n",
      "doors ['2' '3' '4' '5more']\n",
      "persons ['2' '4' 'more']\n",
      "lug_boot ['small' 'med' 'big']\n",
      "safety ['low' 'med' 'high']\n",
      "class ['unacc' 'acc' 'vgood' 'good']\n"
     ]
    }
   ],
   "source": [
    "cols = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=cols)\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    976\n",
       "acc      298\n",
       "vgood     54\n",
       "good      54\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=21)\n",
    "\n",
    "X_train, y_train = train.copy().drop(columns=['class']), train['class']\n",
    "X_test, y_test = test.copy().drop(columns=['class']), test['class']\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Naïve Bayes and Multinomial Naïve Bayes\n",
    "\n",
    "These two share the same formulas, but they make different assumptions. <br >\n",
    "CategoricalNB assumes each feature follows a categorical distribution, whereas MultinomialNB assumes each feature follows a multinomial distribution. Categorical distribution essentially is a special case of multinomial distribution. <br >\n",
    "\n",
    "Specifically, CategoricalNB should be used when we are working with **categorical features**, where the numbers contain **no order information** in our encoded features. <br >\n",
    "On the other hand, Multinomial Naïve Bayes should be used when the numbers **count** in the encodings. \n",
    "\n",
    "In the following example, MultinomialNB would prioritize \"tokyo\" over the other two because its label is 2, larger than either 0 or 1. <br >\n",
    "But CategoricalNB would treat them equally. <br >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_enc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paris</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokyo</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amsterdam</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  city_enc  y\n",
       "0      paris         1  0\n",
       "1      paris         1  1\n",
       "2      tokyo         2  0\n",
       "3  amsterdam         0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "d = {'city': [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"], 'city_enc': [1, 1, 2, 0],\n",
    "     'y': [0, 1, 0, 1]}\n",
    "display(pd.DataFrame(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(x_j|y) = \\dfrac{N_{yj} + \\alpha}{N_y + \\alpha m}$\n",
    "\n",
    "$N_{yj}$: Total counts of feature $x_j$ appeared in class $y$. <br >\n",
    "$N_y$: Total counts of all features in class $y$. $N_y = \\sum_{j=1}^{m} N_{yj}$ <br >\n",
    "$\\alpha$: A smoothing parameter that prevents zero probabilities. <br >\n",
    "\n",
    "Here is a [very detailed explanation](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html) that tells the difference between MultinomialNB and CategoricalNB, if you'd like to know more about theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        86\n",
      "           1       0.50      0.27      0.35        15\n",
      "           2       0.87      0.97      0.92       234\n",
      "           3       0.75      0.27      0.40        11\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.70      0.52      0.57       346\n",
      "weighted avg       0.80      0.82      0.80       346\n",
      "\n",
      "[array(['high', 'low', 'med', 'vhigh'], dtype=object), array(['high', 'low', 'med', 'vhigh'], dtype=object), array(['2', '3', '4', '5more'], dtype=object), array(['2', '4', 'more'], dtype=object), array(['big', 'med', 'small'], dtype=object), array(['high', 'low', 'med'], dtype=object)]\n",
      "['acc' 'good' 'unacc' 'vgood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.OrdinalEncoder() # Encodes each category as integers. From 0 to n_classes - 1\n",
    "y_encoder = preprocessing.LabelEncoder() # Same functionality\n",
    "NB = CategoricalNB() # You can try using MultinomialNB\n",
    "\n",
    "encoder.fit(X_train)\n",
    "y_encoder.fit(y_train)\n",
    "\n",
    "NB.fit(encoder.transform(X_train), y_encoder.transform(y_train))\n",
    "print(classification_report(y_encoder.transform(y_test), NB.predict(encoder.transform(X_test))))\n",
    "print(encoder.categories_)\n",
    "print(y_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "1399       0      3      3        2         1       1\n",
       "1090       1      1      0        1         0       1\n",
       "406        3      0      3        0         0       1\n",
       "541        2      2      0        0         0       1\n",
       "72         3      3      2        2         0       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Manual Mapping if you got your preference.\n",
    "remap = {\n",
    "    \"buying\": {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
    "    \"maint\": {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
    "    \"doors\": {\"2\": 0, \"3\": 1, \"4\": 2, \"5more\": 3},\n",
    "    \"persons\": {\"2\": 0, \"4\": 1, \"more\": 2},\n",
    "    \"lug_boot\": {\"small\": 0, \"med\": 1, \"big\": 2},\n",
    "    \"safety\": {\"low\": 0, \"med\": 1, \"high\": 2},\n",
    "}\n",
    "display(X_train.replace(remap).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Encodings for Categorical Attributes\n",
    "\n",
    "When we use **one-hot encoding** for categorical attributes, all of the variations can actually be adopted in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        86\n",
      "           1       0.50      0.27      0.35        15\n",
      "           2       0.87      0.97      0.92       234\n",
      "           3       0.75      0.27      0.40        11\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.70      0.52      0.57       346\n",
      "weighted avg       0.80      0.82      0.80       346\n",
      "\n",
      "['acc' 'good' 'unacc' 'vgood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import CategoricalNB, BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "NB = MultinomialNB() # You can try using GaussianNB or CategoricalNB.\n",
    "\n",
    "encoder.fit(X_train)\n",
    "y_encoder.fit(y_train)\n",
    "\n",
    "#.toarray() is to deal with GaussianNB due to sparsity\n",
    "NB.fit(encoder.transform(X_train).toarray(), y_encoder.transform(y_train)) \n",
    "print(classification_report(y_encoder.transform(y_test), NB.predict(encoder.transform(X_test).toarray())))\n",
    "print(y_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Naïve Bayes\n",
    "\n",
    "Generally used when you are working with **binary features**. <br >\n",
    "It assumes that each feature follows a Bernoulli distribution.\n",
    "\n",
    "$P(x_j|y) = P(j|y)\\cdot x_j + (1 - P(j|y))\\cdot(1 - x_j)$\n",
    "\n",
    "Example: tossing a coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78        86\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.96      0.94      0.95       234\n",
      "           3       0.69      0.82      0.75        11\n",
      "\n",
      "    accuracy                           0.88       346\n",
      "   macro avg       0.72      0.74      0.73       346\n",
      "weighted avg       0.88      0.88      0.88       346\n",
      "\n",
      "['acc' 'good' 'unacc' 'vgood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "NB = BernoulliNB() \n",
    "\n",
    "encoder.fit(X_train)\n",
    "y_encoder.fit(y_train)\n",
    "\n",
    "NB.fit(encoder.transform(X_train).toarray(), y_encoder.transform(y_train))\n",
    "print(classification_report(y_encoder.transform(y_test), NB.predict(encoder.transform(X_test).toarray())))\n",
    "print(y_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway for Naïve Bayes\n",
    " - Fast for training and prediction\n",
    " - Not many samples needed if what you have can faithfully reconstruct the distribution\n",
    " - Often used as a baseline due to the naïve assumption\n",
    " - MultinomialNB is often adopted and effective when it comes to text classification task\n",
    " - Using right variation is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Strategies\n",
    "\n",
    "Notice that in our original car dataset, very less points belong to either class \"good\" or class \"vgood\". <br >\n",
    "These are often known as the minority class. <br >\n",
    "One reason why this is an issue is that often the minority is the class we're interested in the most. <br >\n",
    "Another reason is that it can affect our classification performance.\n",
    "\n",
    "In general, there are two ways to deal with this challenge, and both have their pros and cons.\n",
    "\n",
    "- Oversampling: Generateing samples for the minority class.\n",
    "- Undersampling: Dropping samples from the majority class.\n",
    "\n",
    "In practice, oversampling is generally preferable. You might only consider undersampling when the minority class has sufficient size so that the only problem is just imbalance.\n",
    "\n",
    "There is a Python package [\"imbalanced-learn\"](https://imbalanced-learn.org/stable/index.html) that includes most re-sampling techiques and is compatible with scikit-learn.\n",
    "\n",
    "\n",
    "### Oversampling\n",
    "\n",
    "The intuitive way to do oversampling is to randomly sample our data and duplicate them. ( RandomOverSampler ) <br >\n",
    "Another more advanced technique is called SMOTE: Synthetic Minority Over-sampling Technique. <br >\n",
    "It considers the neighbors of a sampled point and generates an artificial data point. <br >\n",
    "\n",
    "However, the more imbalanced the dataset is, the more likely we would have overfitting issue in the minority class, such that our generalization error increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unacc    976\n",
      "acc      976\n",
      "vgood    976\n",
      "good     976\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=21)\n",
    "X_os, y_os = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_os.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Training ####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       976\n",
      "           1       0.86      0.91      0.88       976\n",
      "           2       1.00      0.80      0.89       976\n",
      "           3       0.88      1.00      0.93       976\n",
      "\n",
      "    accuracy                           0.88      3904\n",
      "   macro avg       0.88      0.88      0.88      3904\n",
      "weighted avg       0.88      0.88      0.88      3904\n",
      "\n",
      "#### Testing ####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70        86\n",
      "           1       0.46      0.73      0.56        15\n",
      "           2       1.00      0.82      0.90       234\n",
      "           3       0.58      1.00      0.73        11\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.66      0.84      0.72       346\n",
      "weighted avg       0.87      0.82      0.83       346\n",
      "\n",
      "['acc' 'good' 'unacc' 'vgood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.OrdinalEncoder()\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "NB = CategoricalNB()\n",
    "\n",
    "encoder.fit(X_os)\n",
    "y_encoder.fit(y_os)\n",
    "\n",
    "NB.fit(encoder.transform(X_os), y_encoder.transform(y_os))\n",
    "print('#### Training ####')\n",
    "print(classification_report(y_encoder.transform(y_os), NB.predict(encoder.transform(X_os))))\n",
    "print('#### Testing ####')\n",
    "print(classification_report(y_encoder.transform(y_test), NB.predict(encoder.transform(X_test))))\n",
    "print(y_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "Simply randomly remove data points from the majority class.\n",
    "\n",
    "However, we suffer the risk of losing important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good     54\n",
      "vgood    54\n",
      "unacc    54\n",
      "acc      54\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=21)\n",
    "X_us, y_us = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_us.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Training ####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80        54\n",
      "           1       0.86      0.91      0.88        54\n",
      "           2       0.96      0.81      0.88        54\n",
      "           3       0.84      1.00      0.92        54\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "#### Testing ####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        86\n",
      "           1       0.33      0.73      0.46        15\n",
      "           2       0.97      0.82      0.89       234\n",
      "           3       0.39      1.00      0.56        11\n",
      "\n",
      "    accuracy                           0.79       346\n",
      "   macro avg       0.60      0.81      0.65       346\n",
      "weighted avg       0.85      0.79      0.81       346\n",
      "\n",
      "['acc' 'good' 'unacc' 'vgood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.OrdinalEncoder()\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "NB = CategoricalNB()\n",
    "\n",
    "encoder.fit(X_us)\n",
    "y_encoder.fit(y_us)\n",
    "\n",
    "NB.fit(encoder.transform(X_us), y_encoder.transform(y_us))\n",
    "print('#### Training ####')\n",
    "print(classification_report(y_encoder.transform(y_us), NB.predict(encoder.transform(X_us))))\n",
    "print('#### Testing ####')\n",
    "print(classification_report(y_encoder.transform(y_test), NB.predict(encoder.transform(X_test))))\n",
    "print(y_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting for Installing imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn delayed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
